import{_ as d,o as a,c as i,a as e,t as s,C as p,F as l,p as g,e as y,f as w,q as b}from"./chunks/framework.DulMeQy4.js";const v={name:"PoemCard",props:{poem:{type:Object,required:!0}}},k={class:"card"},T={class:"question"},S={class:"answer"};function A(h,t,n,c,u,o){return a(),i("div",k,[e("div",T,s(n.poem.input),1),t[0]||(t[0]=e("div",{class:"separator"},null,-1)),e("div",S,s(n.poem.output)+"🚨"+s(n.poem.context),1)])}const C=d(v,[["render",A],["__scopeId","data-v-755e13df"]]),x=JSON.parse(`[{"output":". The resulting true field of view is 0.64","context":"allowing an object such as the Orion nebula","input":"which appears elliptical with an angular diameter of 65 G 60 arcminutes","field4":"to be viewable through the telescope in its entirety","field5":"where the whole of the nebula is within the observable world. Using methods such as this can greatly increase one's viewing potential ensuring the observable world can contain the entire object","field6":"or whether to increase or decrease magnification viewing the object in a different aspect."},{"output":"The surface brightness at such a magnification significantly reduces","context":"resulting in a far dimmer appearance. A dimmer appearance results in less visual detail of the object. Details such as matter","input":"rings","field4":"spiral arms","field5":"and gases may be completely hidden from the observer","field6":"giving a far less complete view of the object or range. Physics dictates that at the theoretical minimum magnification of the telescope","field7":"the surface brightness is at 100%. Practically","field8":"however","field9":"various factors prevent 100% brightness; these include telescope limitations (focal length","field10":"eyepiece focal length","field11":"etc.) and the age of the observer."},{"output":"Age plays a role in brightness","context":"as a contributing factor is the observer's pupil. With age the pupil naturally shrinks in diameter; generally accepted a young adult may have a 7?mm diameter pupil","input":"an older adult as little as 5?mm","field4":"and a younger person larger at 9?mm. The minimum magnification"},{"output":"{\\\\displaystyle m={\\\\frac {D}{d}}={\\\\frac {130}{7}}\\\\approx 18.6}"},{"output":". A problematic instance may be apparent","context":"achieving a theoretical surface brightness of 100%","input":"as the required effective focal length of the optical system may require an eyepiece with too large a diameter."},{"output":"Some telescopes cannot achieve the theoretical surface brightness of 100%","context":"while some telescopes can achieve it using a very small-diameter eyepiece. To find what eyepiece is required to get minimum magnification one can rearrange the magnification formula","input":"where it is now the division of the telescope's focal length over the minimum magnification:"},{"output":"{\\\\displaystyle {\\\\frac {F}{m}}={\\\\frac {650}{18.6}}\\\\approx 35}"},{"output":". An eyepiece of 35?mm is a non-standard size and would not be purchasable; in this scenario to achieve 100% one would require a standard manufactured eyepiece size of 40?mm. As the eyepiece has a larger focal length than the minimum magnification","context":"an abundance of wasted light is not received through the eyes."},{"output":"The increase in surface brightness as one reduces magnification is limited; that limitation is what is described as the exit pupil: a cylinder of light that projects out the eyepiece to the observer. An exit pupil must match or be smaller in diameter than one's pupil to receive the full amount of projected light; a larger exit pupil results in the wasted light. The exit pupil"},{"output":"{\\\\displaystyle e={\\\\frac {D}{m}}={\\\\frac {130}{18.6}}\\\\approx 7}"},{"output":". The pupil and exit pupil are almost identical in diameter","context":"giving no wasted observable light with the optical system. A 7?mm pupil falls slightly short of 100% brightness","input":"where the surface brightness"},{"output":"{\\\\displaystyle B=2*p^{2}=2*7^{2}=98}"},{"output":". The limitation here is the pupil diameter; it's an unfortunate result and degrades with age. Some observable light loss is expected and decreasing the magnification cannot increase surface brightness once the system has reached its minimum usable magnification","context":"hence why the term is referred to as usable."},{"output":"When using a CCD to record observations","context":"the CCD is placed in the focal plane. Image scale (sometimes called plate scale) describes how the angular size of the object being observed is related to the physical size of the projected image in the focal plane"},{"output":"{\\\\displaystyle i={\\\\frac {\\\\alpha }{\\\\alpha f}}={\\\\frac {1}{f}}.}"},{"output":"No telescope can form a perfect image. Even if a reflecting telescope could have a perfect mirror","context":"or a refracting telescope could have a perfect lens","input":"the effects of aperture diffraction are unavoidable. In reality","field4":"perfect mirrors and perfect lenses do not exist","field5":"so image aberrations in addition to aperture diffraction must be taken into account. Image aberrations can be broken down into two main classes","field6":"monochromatic","field7":"and polychromatic. In 1857","field8":"Philipp Ludwig von Seidel (1821ÿ1896) decomposed the first order monochromatic aberrations into five constituent aberrations. They are now commonly referred to as the five Seidel Aberrations."},{"output":"Optical defects are always listed in the above order","context":"since this expresses their interdependence as first order aberrations via moves of the exit/entrance pupils. The first Seidel aberration","input":"Spherical Aberration","field4":"is independent of the position of the exit pupil (as it is the same for axial and extra-axial pencils). The second","field5":"coma","field6":"changes as a function of pupil distance and spherical aberration","field7":"hence the well-known result that it is impossible to correct the coma in a lens free of spherical aberration by simply moving the pupil. Similar dependencies affect the remaining aberrations in the list."},{"output":"Optical telescopes have been used in astronomical research since the time of their invention in the early 17th century. Many types have been constructed over the years depending on the optical technology","context":"such as refracting and reflecting","input":"the nature of the light or object being imaged","field4":"and even where they are placed","field5":"such as space telescopes. Some are classified by the task they perform such as Solar telescopes."},{"output":"Nearly all large research-grade astronomical telescopes are reflectors. Some reasons are:"},{"output":"Most large research reflectors operate at different focal planes","context":"depending on the type and size of the instrument being used. These including the prime focus of the main mirror","input":"the cassegrain focus (light bounced back down behind the primary mirror)","field4":"and even external to the telescope all together (such as the Nasmyth and coud focus).[23]"},{"output":"A new era of telescope making was inaugurated by the Multiple Mirror Telescope (MMT)","context":"with a mirror composed of six segments synthesizing a mirror of 4.5 meters diameter. This has now been replaced by a single 6.5 m mirror. Its example was followed by the Keck telescopes with 10 m segmented mirrors."},{"output":"The largest current ground-based telescopes have a primary mirror of between 6 and 11 meters in diameter. In this generation of telescopes","context":"the mirror is usually very thin","input":"and is kept in an optimal shape by an array of actuators (see active optics). This technology has driven new designs for future telescopes with diameters of 30","field4":"50 and even 100 meters."},{"output":"Relatively cheap","context":"mass-produced ~2 meter telescopes have recently been developed and have made a significant impact on astronomy research. These allow many astronomical targets to be monitored continuously","input":"and for large areas of sky to be surveyed. Many are robotic telescopes","field4":"computer controlled over the internet (see e.g. the Liverpool Telescope and the Faulkes Telescope North and South)","field5":"allowing automated follow-up of astronomical events."},{"output":"Initially the detector used in telescopes was the human eye. Later","context":"the sensitized photographic plate took its place","input":"and the spectrograph was introduced","field4":"allowing the gathering of spectral information. After the photographic plate","field5":"successive generations of electronic detectors","field6":"such as the charge-coupled device (CCDs)","field7":"have been perfected","field8":"each with more sensitivity and resolution","field9":"and often with a wider wavelength coverage."},{"output":"Current research telescopes have several instruments to choose from such as:"},{"output":"The phenomenon of optical diffraction sets a limit to the resolution and image quality that a telescope can achieve","context":"which is the effective area of the Airy disc","input":"which limits how close two such discs can be placed. This absolute limit is called the diffraction limit (and may be approximated by the Rayleigh criterion","field4":"Dawes limit or Sparrow's resolution limit). This limit depends on the wavelength of the studied light (so that the limit for red light comes much earlier than the limit for blue light) and on the diameter of the telescope mirror. This means that a telescope with a certain mirror diameter can theoretically resolve up to a certain limit at a certain wavelength. For conventional telescopes on Earth","field5":"the diffraction limit is not relevant for telescopes bigger than about 10?cm. Instead","field6":"the seeing","field7":"or blur caused by the atmosphere","field8":"sets the resolution limit. But in space","field9":"or if adaptive optics are used","field10":"then reaching the diffraction limit is sometimes possible. At this point","field11":"if greater resolution is needed at that wavelength","field12":"a wider mirror has to be built or aperture synthesis performed using an array of nearby telescopes."},{"output":"In recent years","context":"a number of technologies to overcome the distortions caused by atmosphere on ground-based telescopes have been developed","input":"with good results. See adaptive optics","field4":"speckle imaging and optical interferometry."},{"output":"Media related to Optical telescopes at Wikimedia Commons\\"","context":"What kind of light does an optical telescope collect?"},{"output":"ecclesiastical title used in the Latter Day Saint movement","context":"Prophet, seer, and revelator is an ecclesiastical title used in the Latter Day Saint movement. The Church of Jesus Christ of Latter-day Saints (LDS Church) is the largest denomination of the movement, and it currently applies the terms to the members of the First Presidency and the Quorum of the Twelve Apostles. In the past, it has also been applied to the Presiding Patriarch of the church and the Assistant President of the Church. Other sects and denominations of the movement also use these terms.\\r\\n\\r\\n\\r\\nThe phrase \\"prophet, seer, and revelator\\" is derived from a number of revelations received by the founder of the Latter Day Saint movement, Joseph Smith. The first revelation received by Smith after the organization of the Church of Christ on April 6, 1830, declared that \\"there shall be a record kept among you; and in it [Smith] shalt be called a seer, a translator, a prophet, an apostle of Jesus Christ, an elder of the church through the will of God the Father, and the grace of your Lord Jesus Christ\\".[1] In 1835, Smith further clarified the role of the President of the Church, \\"to preside over the whole church, and ... to be a seer, a revelator, a translator, and a prophet\\".[2] In 1841, Smith recorded a revelation that again restated these roles: \\"I give unto you my servant Joseph to be a presiding elder over all my church, to be a translator, a revelator, a seer, and prophet.\\"[3] In 1836, at the dedication of the Kirtland Temple, approximately one year after Smith organized the church's Quorum of the Twelve Apostles, he instructed that the members of the First Presidency and the apostles should also be accepted by the church as prophets, seers, and revelators:\\r\\nI made a short address, and called upon the several quorums, and all the congregation of Saints, to acknowledge the Presidency as Prophets and Seers and uphold them by their prayers. ... I then called upon the quorums and congregation of Saints, to acknowledge the Twelve, who were present, as Prophets, Seers, Revelators, and special witnesses to all the nations of the earth holding the keys of the kingdom, to unlock it, or cause it to be done among them, and uphold them by their prayers.[4]\\r\\nLater, Smith further confirmed that people other than the President of the Church may hold these titles. For example, in 1841, a revelation described the role of Smith's brother Hyrum Smith as Assistant President of the Church: \\"And from this time forth I appoint unto him that he may be a prophet, and a seer, and a revelator unto my church, as well as my servant Joseph\\".[5]\\r\\nThe words prophet, seer, and revelator have separate and distinct meanings within the Latter Day Saint movement. LDS Church apostle John A. Widtsoe described the meanings of the terms and the differences between them:[6]\\r\\nA prophet is a teacher. That is the essential meaning of the word. He teaches the body of truth, the gospel, revealed by the Lord to man; and under inspiration explains it to the understanding of the people. He is an expounder of truth. Moreover, he shows that the way to human happiness is through obedience to God's law. He calls to repentance those who wander away from the truth. He becomes a warrior for the consummation of the Lords purposes with respect to the human family. The purpose of his life is to uphold the Lord's plan of salvation. All this he does by close communion with the Lord, until he is \\"full of power by the spirit of the Lord.\\" (Micah 3:8; see also D&C 20:26; 34:10; 43:16)\\r\\nThe teacher must learn before he can teach. Therefore in ancient and modern times there have been schools of the prophets, in which the mysteries of the kingdom have been taught to men who would go out to teach the gospel and to fight the battles of the Lord. These \\"prophets\\" need not be called to an office; they go out as teachers of truth, always and everywhere.\\r\\nA prophet also receives revelations from the Lord. These may be explanations of truths already received, or new truths not formerly possessed by man. Such revelations are always confined to the official position held. The lower will not receive revelations for the higher office.\\r\\nIn the course of time the word \\"prophet\\" has come to mean, perhaps chiefly, a man who receives revelations, and directions from the Lord. The principal business of a prophet has mistakenly been thought to foretell coming events, to utter prophecies, which is only one of the several prophetic functions.\\r\\nIn the sense that a prophet is a man who receives revelations from the Lord, the titles \\"seer and revelator\\" merely amplify the larger and inclusive meaning of the title \\"prophet.\\" Clearly, however, there is much wisdom in the specific statement of the functions of the prophet as seer and revelator, as is done in the conferences of the Church.\\r\\nA seer is one who sees with spiritual eyes. He perceives the meaning of that which seems obscure to others; therefore he is an interpreter and clarifier of eternal truth. He foresees the future from the past and the present. This he does by the power of the Lord operating through him directly, or indirectly with the aid of divine instruments such as the Urim and Thummim. In short, he is one who sees, who walks in the Lord's light with open eyes. (Book of Mormon, Mosiah 8:15-17)\\r\\nA revelator makes known, with the Lord's help, something before unknown. It may be new or forgotten truth, or a new or forgotten application of known truth to mans need. Always, the revelator deals with truth, certain truth (D&C 100:11) and always it comes with the divine stamp of approval. Revelation may be received in various ways, but it always presupposes that the revelator has so lived and conducted himself as to be in tune or harmony with the divine spirit of revelation, the spirit of truth, and therefore capable of receiving divine messages.\\r\\nAt the biannual general conference of the LDS Church, the name of the President of the Church is presented to the members as \\"prophet, seer, and revelator and President of The Church of Jesus Christ of Latter-day Saints\\".[7] Members are invited to vote to sustain the president in these roles, and the signalling for any opposing votes is also allowed. Additionally, the counselors in the First Presidency and the members of the Quorum of the Twelve Apostles are sustained by the membership as \\"prophets, seers, and revelators\\".[7] Until October 1979, the Presiding Patriarch of the church was also sustained as a \\"prophet, seer, and revelator\\".[8] Apostles who are not members of the Quorum of the Twelve or the First Presidency and other general authorities, (e.g., members of the Quorums of the Seventy and Presiding Bishopric) are not sustained as prophets, seers, and revelators.\\r\\nThe procedure of sustaining is repeated in local congregations of the LDS Church several times per year at stake, district, ward, or branch conferences. These procedures are mandated by the theology of the LDS Church, which dictates governance by the \\"common consent\\" of the membership.[9][clarification needed]","input":"What is a prophet seer and revelator lds?"},{"output":"Christianity","context":"\\r\\n\\r\\nReligion in England (2011)[1]\\r\\n\\r\\nReligion in the United Kingdom, and in the countries that preceded it, has been dominated for over 1,400 years by various forms of Christianity. Religious affiliations of United Kingdom citizens are recorded by regular surveys, the four major ones being the national decennial census, the Labour Force Survey, the British Social Attitudes survey and the European Social Survey. \\r\\n\\r\\nAccording to the 2011 Census, Christianity is the majority religion, followed by Islam, Hinduism, Sikhism, Judaism and Buddhism in terms of number of adherents. Among Christians, Anglicans are the most common denomination, followed by the Catholics, Presbyterians, Methodists and Baptists. This, and the relatively large number of individuals with nominal or no religious affiliations, has led commentators to variously describe the United Kingdom as a multi-faith and secularised society.\\r\\n\\r\\nThe United Kingdom was formed by the union of previously independent countries in 1707, and consequently most of the largest religious groups do not have UK-wide organisational structures. While some groups have separate structures for the individual countries of the United Kingdom, others have a single structure covering England and Wales or Great Britain. Similarly, due to the relatively recent creation of Northern Ireland in 1921, most major religious groups in Northern Ireland are organised on an all-Ireland basis.\\r\\n\\r\\nWhile the United Kingdom as a whole lacks an official religion, the Church of England remains the state church of its largest constituent country, England. The Monarch of the United Kingdom is the Supreme Governor of the Church, and accordingly, only a Protestant may inherit the British throne.\\r\\n\\r\\nPre-Roman forms of religion in Britain included various forms of ancestor worship and paganism.[3] Little is known about the details of such religions (see British paganism). Forms of Christianity have dominated religious life in what is now the United Kingdom for over 1,400 years. It was introduced by the Romans to what is now England, Wales, and Southern Scotland. The doctrine of Pelagianism, declared heretical in the Council of Carthage (418), originated with a British-born ascetic, Pelagius.\\r\\n\\r\\nThe Anglo-Saxon invasions briefly re-introduced paganism in the 5th and 6th centuries; Christianity was again brought to Great Britain by  Catholic Church and Irish-Scottish missionaries in the course of the 7th century (see Anglo-Saxon Christianity).[4]\\r\\nInsular Christianity as it stood between the 6th and 8th centuries retained some idiosyncrasies in terms of liturgy and calendar, but it had been nominally united with Roman Christianity since at least the Synod of Whitby of 664. Still in the Anglo-Saxon period, the archbishops of Canterbury established a tradition of receiving their pallium from Rome to symbolize the authority of the Pope.\\r\\n\\r\\nThe Catholic Church remained the dominant form of Western Christianity in Britain throughout the Middle Ages, but the (Anglican) Church of England became the independent established church in England and Wales in 1534 as a result of the English Reformation.[5] It retains a representation in the UK Parliament and the British monarch is its Supreme Governor.[6]\\r\\n\\r\\nIn Scotland, the Presbyterian Church of Scotland, established in a separate Scottish Reformation in the sixteenth century, is recognized as the national church. It is not subject to state control and the British monarch is an ordinary member, required to swear an oath to \\"maintain and preserve the Protestant Religion and Presbyterian Church Government\\" upon his or her accession.[7][8]\\r\\n\\r\\nThe adherence to the Catholic Church continued at various levels in different parts of Britain, especially among recusants and in the north of England,[9] but most strongly in Ireland. This would expand in Great Britain, partly due to Irish immigration in the nineteenth century,[10] the Catholic emancipation and the Restoration of the English hierarchy.\\r\\n\\r\\nParticularly from the mid-seventeenth century, forms of Protestant nonconformity, including Congregationalists, Baptists, Quakers and, later, Methodists, grew outside of the established church.[11] The (Anglican) Church in Wales was disestablished in 1920 and, as the (Anglican) Church of Ireland was disestablished in 1870 before the partition of Ireland, there is no established church in Northern Ireland.[12]\\r\\n\\r\\nThe Jews in England were expelled in 1290 and only emancipated in the 19th century. British Jews had numbered fewer than 10,000 in 1800 but around 120,000 after 1881 when Russian Jews settled permanently in Britain.[13]\\r\\n\\r\\nThe substantial immigration to the United Kingdom since the 1920s has contributed to the growth of foreign faiths, especially of Islam, Hinduism and Sikhism,[14]\\r\\nBuddhism in the United Kingdom experienced growth partly due to immigration and partly due to conversion (especially when including Secular Buddhism).[15]\\r\\n\\r\\nAs elsewhere in the western world, religious demographics have become part of the discourse on multiculturalism, with Britain variously described as a post-Christian society,[16] as \\"multi-faith\\",[17] or as secularised.[18] Scholars have suggested multiple possible reasons for the decline, but have not agreed on their relative importance. Martin Wellings lays out the \\"classical model\\" of secularisation, while noting that it has been challenged by some scholars.\\r\\n\\r\\nThe familiar starting-point, a classical model of secularisation, argues that religious faith becomes less plausible and religious practice more difficult in advanced industrial and urbanized societies. The breakdown or disruption of traditional communities and norms of behavior; the spread of a scientific world-view diminishing the scope of the supernatural and the role of God; increasing material affluence promoting self-reliance and this-worldly optimism; and greater awareness and toleration of different creeds and ideas, encouraging religious pluralism and eviscerating commitment to a particular faith, all form components of the case for secularisation. Applied to the British churches in general by Steve Bruce and to Methodism in particular by Robert Currie, this model traces decline back to the Victorian era and charts in the twentieth century a steady ebbing of the sea of faith.[19][20][21]\\r\\n\\r\\nIn the 2011 census, Christianity was the largest religion, stated as their affiliation by 59.5% of the total population.[22][23][24] This figure was found to be 53% in the 2007 Tearfund survey,[25] 42.9 percent in the 2009 British Social Attitudes Survey[26] and 42.98 percent in the EU-funded European Social Survey published in April 2009[27] for those identifying as Christian.\\r\\n\\r\\nAlthough there was no UK-wide data in the 2001 or the 2011 census on adherence to individual Christian denominations, since they are asked only in the Scottish and in the Northern Irish Censuses,[28] using the same principle as applied in the 2001 census, a survey carried out in the end of 2008 by Ipsos MORI and based on a scientifically robust sample, found the population of England and Wales to be 47.0% Anglican, 9.6% Catholic and 8.7% other Christians; 4.8% were Muslim, 3.4% were members of other religions. 5.3% were Agnostics, 6.8% were Atheists and 15.0% were not sure about their religious affiliation or refused to answer to the question.[29]\\r\\n\\r\\nCeri Peach estimated in 2005 that 62% of Christians were Anglican, 13.5% Catholic, 6% Presbyterian and 3.4% Methodist, with small numbers in other Protestant denominations and the Orthodox church.[30]\\r\\n\\r\\nThe 2009 British Social Attitudes Survey, which covers Great Britain but not Northern Ireland, indicated that over 50 percent would self-classify as not religious at all, 19.9 percent were part of the Church of England, 9.3% non-denominational Christian, 8.6% Catholic, 2.2% Presbyterian/Church of Scotland, 1.3% Methodist, 0.53% Baptist, 1.17% other Protestant, 0.23% United Reformed Church/Congregational, 0.06% Free Presbyterian, 0.03% Brethren Christian and 0.41% other Christian.[26]\\r\\n\\r\\nIn a 2016 survey conducted by BSA (British Social Attitudes) on religious affiliation; 53% of respondents indicated 'no religion' and 41% indicated they were Christians, while 6% affiliated with non-Christian religions (Islam, Hinduism, Judaism etc.)[31]\\r\\n\\r\\nThe wording of the question affects the outcome of polls as is apparent when comparing the results of the Scottish census with that of the English and Welsh census.[32][33][34][35] An ICM poll for The Guardian in 2006 asked the question \\"Which religion do you yourself belong to?\\" with a response of 64% stating \\"Christian\\" and 26% stating \\"none\\". In the same survey, 63% claimed they are not religious with just 33% claiming they are.[36] This suggests that the religious UK population identify themselves as having Christian beliefs, but maybe not as active \\"church-goers\\".[37]\\r\\n\\r\\nReligions other than Christianity, such as Islam, Hinduism, Sikhism and Judaism, have established a presence in the United Kingdom, both through immigration and by attracting converts. Others that have done so include the Bah' Faith, the Rastafari movement and Neopaganism.\\r\\n\\r\\nThe statistics for current religion (not religion of upbringing where also asked) from the 2011 census and the corresponding statistics from the 2001 census are set out in the tables below.\\r\\n\\r\\nReligious affiliations of UK citizens are recorded by regular surveys, the four major ones being the UK Census,[43] the Labour Force Survey,[44] the British Social Attitudes survey[45] and the European Social Survey.[46] The different questions asked by these surveys produced different results:\\r\\n\\r\\nOther surveys:\\r\\n\\r\\nThe British Social Attitudes surveys and the European Social Surveys are fielded to adult individuals.[31][27] In contrast, the United Kingdom Census and the Labour Force Surveys are household surveys; the respondent completes the questionnaire on behalf of each member of the household,[34][35][57] including children,[49] as well as for themselves. The 2010 Labour Force Survey claimed that 54% of children aged from birth to four years were Christian, rising to 59% for children aged between 5 and 9 and 65% for children aged between 10 and 14.[49] The inclusion of children with adult-imposed religions influences the results of the polls.[37][58]\\r\\n\\r\\nOther major polls agree with the British Social Attitudes surveys and the European Social Surveys, with a YouGov survey fielded in February 2012 indicating that 43% of respondents claimed to belong to a religion and 76% claimed they were not very religious or not religious at all.[59] An Ipsos MORI survey fielded in August 2003 indicated that 18% of respondents claimed to be \\"a practising member of an organised religion\\" and 25% claimed \\"I am a non-practising member of an organised religion\\".[60] A 2015 study estimated some 25,000 believers in Christ from a Muslim background, most of whom belong to an evangelical or Pentecostal community.[61]\\r\\n\\r\\nSociety in the United Kingdom is markedly more secular than it was in the past and the number of churchgoers fell over the second half of the 20th century.[62] The Ipsos MORI poll in 2003 reported that 18% were \\"a practising member of an organised religion\\".[60] The Tearfund Survey in 2007 found that only 7% of the population considered themselves as practising Christians. Some 10% attended church weekly and two-thirds had not gone to church in the past year.[25][63] The Tearfund Survey also found that two-thirds of UK adults (66%) or 32.2 million people had no connection with the Church at present (nor with another religion). These people were evenly divided between those who have been in the past but have since left (16 million) and those who have never been in their lives (16.2 million).\\r\\n\\r\\nA survey in 2002 found Christmas attendance at Anglican churches in England varied between 10.19% of the population in the diocese of Hereford, down to just 2.16% in Manchester.[64] Church attendance at Christmas in some dioceses was up to three times the average for the rest of the year. Overall church attendance at Christmas has been steadily increasing in recent years; a 2005 poll found that 43 per cent expected to attend a church service over the Christmas period, in comparison with 39% and 33% for corresponding polls taken in 2003 and 2001 respectively.[65]\\r\\n\\r\\nA December 2007 report by Christian Research showed that the services of the Catholic Church had become the best-attended services of Christian denominations in England, with average attendance at Sunday Mass of 861,000, compared to 852,000 attending Anglican services. Attendance at Anglican services had declined by 20% between 2000 and 2006, while attendance at Catholic services, boosted by large-scale immigration from Poland and Lithuania, had declined by only 13%. In Scotland, attendance at Church of Scotland services declined by 19% and attendance at Catholic services fell by 25%.[66] British Social Attitudes Surveys have shown the proportion of those in Great Britain who consider they \\"belong to\\" Christianity to have fallen from 66% in 1983 to 43% in 2009.[26]\\r\\n\\r\\nIn 2012 about 6% of the population of the United Kingdom regularly attended church, with the average age of attendees being 51; in contrast, in 1980,  11% had regularly attended, with an average age of 37. It is predicted that by 2020 attendance will be around 4%, with an average age of 56.[62] This decline in church attendance has forced many churches to close down across the United Kingdom, with the Church of England alone closing 1,500 churches between 1969 and 2002. Their fates include dereliction, demolition, and residential, artistic and commercial conversion.[67] In October 2014 weekly attendance at Church of England services dropped below 1 million for the first time. At Christmas 2014, 2.4 million attended. For that year baptisms were 130,000, down 12% since 2004; marriages were 50,000, down 19%; and funerals 146,000, down 29%. The Church estimated that about 1% of churchgoers were lost to death each year; the Church's age profile suggested that attendances would continue to decline.[68]\\r\\n\\r\\nOne study showed that in 2004 at least 930,000 Muslims attended a mosque at least once a week, just outnumbering the 916,000 regular churchgoers in the Church of England.[69] Muslim sources claim the number of practising Muslims is underestimated as nearly all of them pray at home.[70]\\r\\n\\r\\n\\"Do you consider yourself as belonging to any particular religion or denomination?\\"\\r\\n\\r\\nSource: European social survey 2002ÿ2010[71]\\r\\n\\r\\nThere is a disparity between the figures for those identifying themselves with a particular religion and for those proclaiming a belief in a God:\\r\\n\\r\\nIn the 2001 census, 390,127 individuals (0.7 percent of total respondents) in England and Wales self-identified as followers of the Jedi faith. This Jedi census phenomenon followed an internet campaign that claimed, incorrectly, that the Jedi belief system would receive official government recognition as a religion if it received enough support in the census.[75] An email in support of the campaign, quoted by BBC News, invited people to \\"do it because you love Star Wars?... or just to annoy people\\".[76] The Office for National Statistics revealed the total figure in a press release entitled \\"390,000 Jedi there are\\".[77]\\r\\n\\r\\nChurches Together in England\\r\\n\\r\\nOriental Orthodox\\r\\n\\r\\nThe United Kingdom was formed by the union of previously independent states in 1707,[78][79][80] and consequently most of the largest religious groups do not have UK-wide organisational structures. While some groups have separate structures for the individual countries of the United Kingdom, others have a single structure covering England and Wales or Great Britain. Similarly, due to the relatively recent creation of Northern Ireland in 1921, most major religious groups in Northern Ireland are organised on an all-Ireland basis.\\r\\n\\r\\nThe Church of England is the established church in England.[5] Its most senior bishops sit in the national parliament and the Queen is its supreme governor. It is also the \\"mother church\\" of the worldwide Anglican Communion. The Church of England separated from the Catholic Church in 1534 and became the established church by an Act of Parliament in the Act of Supremacy, beginning a series of events known as the English Reformation.[81]  Historically it has been the predominant Christian denomination in England and Wales, in terms of both influence and number of adherents.\\r\\n\\r\\nThe Scottish Episcopal Church, which is part of the Anglican Communion (but not a \\"daughter church\\" of the Church of England),[82] dates from the final establishment of Presbyterianism in Scotland in 1690, when it split from the Church of Scotland. In the 1920s, the Church in Wales became disestablished and independent from the Church of England, but remains in the Anglican Communion.[83]\\r\\n\\r\\nDuring the years 2012 to 2014 the number of members of the Church of England dropped by around 1.7 million.[84][85][86]\\r\\n\\r\\nIn Scotland, the Church of Scotland (informally known by its Scots language name, \\"the Kirk\\"), is recognised as the national church.[87] It is not subject to state control and the British monarch is an ordinary member, required to swear an oath to \\"maintain and preserve the Protestant Religion and Presbyterian Church Government\\" upon his or her accession.[88] Splits in the Church of Scotland, especially in the 19th century, led to the creation of various other Presbyterian churches in Scotland, including the Free Church of Scotland, which claims to be the constitutional continuator of the Church in Scotland and was founded in 1843. The Free Presbyterian Church of Scotland was formed in 1893 by some who left the Free Church over alleged weakening of her position and likewise claims to be the spiritual descendant of the Scottish Reformation. The Evangelical Presbyterian Church in England and Wales was founded in the late 1980s and organized themselves as a presbytery in 1996. As of  2016[update] they had 15 churches in the UK.[89]\\r\\n  The Presbyterian Church in Ireland is the largest Protestant denomination and second largest church in Northern Ireland. The Free Presbyterian Church of Ulster was founded on 17 March 1951 by the cleric and politician Ian Paisley. It has about 60 churches in Northern Ireland. The Presbyterian Church of Wales seceded from the Church of England in 1811 and formally formed itself into a separate body in 1823. The Non-subscribing Presbyterian Church of Ireland has 31 congregations in Northern Ireland,[90] with the first Presbytery being formed in Antrim in 1725.[91]\\r\\n\\r\\nThe United Reformed Church (URC), a union of Presbyterian and Congregational churches, consists of about 1,500 congregations[92] in England, Scotland and Wales. There are about 600 Congregational churches in the United Kingdom. In England there are three main groups, the Congregational Federation, the Evangelical Fellowship of Congregational Churches, and about 100 Congregational churches that are loosely federated with other congregations in the Fellowship of Independent Evangelical Churches, or are unaffiliated. In Scotland the churches are mostly member of the Congregational Federation and in Wales which traditionally has a larger number of Congregationalists, most are members of the Union of Welsh Independents.\\r\\n\\r\\nThe Methodist movement traces its origin to the evangelical awakening in the 18th century. The British Methodist Church, which has congregations throughout Great Britain, the Channel Islands, the Isle of Man, Malta and Gibraltar, has around 290,000 members,[93] and 5,900 churches,[93] though only around 3,000 members in 50 congregations are in Scotland. In the 1960s, it made ecumenical overtures to the Church of England, aimed at church unity. Formally, these failed when they were rejected by the Church of England's General Synod in 1972. However, conversations and co-operation continued, leading on 1 November 2003 to the signing of a covenant between the two churches.[94]\\r\\n\\r\\nThe Methodist Church in Ireland covers the whole of the island of Ireland, including Northern Ireland where it is the fourth-largest denomination.\\r\\n\\r\\nOther Methodist denominations in Britain include the Salvation Army, founded in 1865;[95] the Free Methodist Church, a holiness church; and the Church of the Nazarene.\\r\\n\\r\\nThe Baptist Union of Great Britain, despite its name, covers just England and Wales.[96] There is a separate Baptist Union of Scotland and the Association of Baptist Churches in Ireland is an all-Ireland organisation.[97] Other Baptist associations also exist in England, such as the Grace Baptist association and the Gospel Standard Baptists.\\r\\n\\r\\nAssemblies of God in Great Britain are part of the World Assemblies of God Fellowship with over 600 churches in Great Britain.[98] Assemblies of God Ireland cover the whole of the island of Ireland, including Northern Ireland. The Apostolic Church commenced in the early part of the 20th century in South Wales and now has over 110 churches across the United Kingdom. Elim Pentecostal Church as of  2013[update] had over 500 churches across the United Kingdom.[98]\\r\\n\\r\\nThere is also a growing number of independent, charismatic churches that encourage Pentecostal practices as part of their worship. These are broadly grouped together as the British New Church Movement and could number up to 400,000 members. The phenomenon of immigrant churches and congregations that began with the arrival of the HMT Empire Windrush from the West Indies in 1948 stands as a unique trend. West Indian congregations that started from this time include the Church of God, New Testament Assembly and New Testament Church of God.\\r\\n\\r\\nAfricans began to arrive in the early 1980s and established their own congregations. Foremost among these are Matthew Ashimolowo from Nigeria and his Kingsway International Christian Centre in London that may be the largest church in Western Europe.[99]\\r\\n\\r\\nThe Britain Yearly Meeting is the umbrella body for the Religious Society of Friends (Quakers) in Great Britain, the Channel Isles and the Isle of Man. It has 14,260 adult members.[100]   Northern Ireland comes under the umbrella of the Ireland Yearly Meeting.\\r\\n\\r\\nThe Catholic Church has separate national organisations for England, Wales, and Scotland, which means there is no single hierarchy for the Catholic Church in the United Kingdom. Catholicism is the second largest denomination in England and Wales, with around five million members, mainly in England.[101] There is, however, a single apostolic nuncio to Great Britain, presently Archbishop Edward Joseph Adams. Catholicism is Scotland's largest Christian denomination, representing a fifth of the population.[102] The apostolic nuncio to the whole of Ireland (both Northern Ireland and the Republic of Ireland) is Jude Thaddeus Okolo. Eastern Rite Catholics in the United Kingdom are served by their own clergy and do not belong to the Latin Church dioceses but are still in full communion with the Bishop of Rome.\\r\\n\\r\\nOrthodox Christianity is a relatively minor faith in the United Kingdom when compared to Protestantism and Catholicism; most Orthodox churches cater to immigrants from Eastern Europe and the Balkans\\r\\nand is a relatively minor faith among Britons themselves\\r\\n\\r\\nAdherents of Eastern Orthodox Christianity in the United Kingdom are traditionally organized in accordance with patrimonial ecclesiastical jurisdictions. The Russian Orthodox Church has a Diocese of Sourozh, which covers Great Britain and Ireland,[103] and the Russian Orthodox Church Outside Russia also has a diocese in the same territory.[104] The Ecumenical Patriarchate has established the Archdiocese of Thyateira and Great Britain, that covers England, Wales, Scotland and Ireland as well as Malta. The Patriarchate of Antioch has several parishes and missions within the Diocese of the British Isles and Ireland.[105] Other Eastern Orthodox Churches represented in the United Kingdom include the Georgian Orthodox Church, the Romanian Orthodox Church and the Bulgarian Orthodox Church.\\r\\n\\r\\nAdherents of Oriental Orthodox Christianity in the United Kingdom are also traditionally organized in accordance with their patrimonial ecclesiastical jurisdictions, each community having its own parishes and priests. The Coptic Orthodox Church of Alexandria has two regional Dioceses in the United Kingdom: the Diocese of Ireland, Scotland, North East England, and the Diocese of the Midlands. Other Oriental Orthodox Churches represented in the United Kingdom include the Syriac Orthodox Church, the Armenian Apostolic Church, the Eritrean Orthodox Tewahedo Church, the Ethiopian Orthodox Tewahedo Church and the only Oriental Orthodox Church who isn't recognised its jurisdiction with main body is the British Orthodox Church also known formerly as Orthodox Church of the British Isles.\\r\\n\\r\\nOther denominations and groups include the Seventh-day Adventist Church, the Seventh Day Baptists, the Plymouth Brethren,[106] and Newfrontiers.[107]\\r\\n\\r\\nThe first missionaries from the Church of Jesus Christ of Latter Day Saints to proselytise in the British Isles arrived in 1837. By 1900 as many as 100,000 converts had joined the faith, but most of these early members soon emigrated to the United States to join the main body of the church. From the 1950s emigration to the United States began to be discouraged and local congregations grew more rapidly. Today the church claims just over 186,000 members across the United Kingdom, in over 330 local congregations, known as 'wards' or 'branches'. The church also maintains two temples in England, the first opening in the London area in 1958, and the second completed in 1998 in Preston and known as the Preston England Temple. Preston is also the site of the first preaching by LDS missionaries in 1837, and is home to the oldest continually existing Latter Day Saint congregation anywhere in the world.[108][109] Restored 1994ÿ2000, the Gadfield Elm Chapel in Worcestershire is the oldest extant chapel of the LDS Church.[110]\\r\\n\\r\\nJehovah's Witnesses had 137,631 \\"publishers\\" (a term referring to members actively involved in preaching) in the United Kingdom in 2015.[111] The Church of Christ, Scientist is also represented in the UK. The General Assembly of Unitarian and Free Christian Churches is the umbrella organisation for  Unitarian, Free Christian and other liberal religious congregations in the United Kingdom. The Unitarian Christian Association was formed in 1991. There are an estimated 18,000 Christadelphians in the UK.\\r\\n\\r\\nEstimates in 2009 suggested a total of about 2.4 million Muslims over all the United Kingdom.[112][113] According to Pew Forum on Religion and Public Life, the number of Muslims in Britain could be up to 3 million.[114] The vast majority of Muslims in the United Kingdom live in England and Wales: of 1,591,126 Muslims recorded at the 2001 Census, 1,546,626 were living in England and Wales, where they form 3 per cent of the population; 42,557 were living in Scotland, forming 0.8 per cent of the population;[115] and 1,943 were living in Northern Ireland.[116] Between 2001 and 2009 the Muslim population increased roughly 10 times faster than the rest of society.[117]\\r\\n\\r\\nMost Muslim immigrants to the United Kingdom came from former colonies. The biggest groups of Muslims are of Pakistani, Bangladeshi, Indian and Arab origins,[118] with the remainder coming from Muslim-dominated areas such as Southwest Asia, Somalia, Malaysia, and Indonesia.[119] During the 18th century, lascars (sailors) who worked for the British East India Company settled in port towns with local wives.[120] These numbered only 24,037 in 1891 but 51,616 on the eve of World War I.[121] Naval cooks, including Sake Dean Mahomet, also came from what is now the Sylhet Division of Bangladesh.[122] From the 1950s onwards, the growing Muslim population has led to a number of notable Mosques being established, including East London Mosque, London Central Mosque, Manchester Central Mosque,  London Markaz,  and the Baitul Futuh of the Ahmadiyya Muslim Community. According to Kevin Brice, a researcher at the University of Wales, Trinity Saint David, thousands convert to Islam annually and there are approximately 100,000 converts to Islam in Britain, where they run two mosques.[123]\\r\\n\\r\\nAccording to a Labour Force Survey estimate, the total number of Muslims in Great Britain in 2008 was 2,422,000, around 4 per cent of the total population.[124] Between 2004 and 2008, the Muslim population grew by more than 500,000.[124] In 2010, The Pew Forum on Religion and Public Life estimated 2,869,000 Muslims in Great Britain.[125]\\r\\nThe largest age-bracket within the British Muslim population were those under the age of 4, at 301,000 in September 2008.[124] The Muslim Council of Britain and the Islamic Forum of Europe are the umbrellas organisations for many local, regional and specialist Islamic organisations in the United Kingdom, although it is disputed how representative this organisation is of British Muslims as a whole.\\r\\n\\r\\nMuslims are by far the poorest religious or non religious community in the UK. For comparison, the median net wealth for Jews stands at S422 000, Sikhs at S229 000, Christians at S223 000 and Hindus at S 206 000 while for Muslims the figure stands at S42 000.[126]\\r\\n\\r\\nMuslims also happen to be the most disproportionately represented religious group facing arrest, trial and imprisonment, with 13.1% of prisoners being Muslims while the community represents 4% of those aged 15 years or older within the general population.[127]\\r\\n\\r\\nThe Jewish Naturalisation Act, enacted in 1753, permitted the naturalisation of foreign Jews, but was repealed the next year. The first graduate from the University of Glasgow who was openly known to be Jewish was in 1787. Unlike their English contemporaries, Scottish students were not required to take a religious oath. In 1841 Isaac Lyon Goldsmid was made baronet, the first Jew to receive a hereditary title. The first Jewish Lord Mayor of the City of London, Sir David Salomons, was elected in 1855, followed by the 1858 emancipation of the Jews. On 26 July 1858, Lionel de Rothschild was finally allowed to sit in the House of Commons of the United Kingdom when the law restricting the oath of office to Christians was changed. (Benjamin Disraeli, a baptised, teenage convert to Christianity of Jewish parentage, was already an MP at this time and rose to become Prime Minister in 1874.) In 1884 Nathan Mayer Rothschild, 1st Baron Rothschild became the first Jewish member of the British House of Lords; again Disraeli was already a member.\\r\\n\\r\\nBritish Jews number around 300,000 with the United Kingdom having the fifth largest Jewish community worldwide.[128] However, this figure did not include Jews who identified 'by ethnicity only' in England and Wales or Scottish Jews who identified as Jewish by upbringing but held no current religion. A report in August 2007 by University of Manchester historian Dr Yaakov Wise stated that 75 per cent of all births in the Jewish community were to ultra-orthodox, Haredi parents, and that the increase of ultra-orthodox Jewry has led to a significant rise in the proportion of British Jews who are ultra-orthodox.[129]\\r\\n\\r\\nHowever various studies suggest that within some Jewish communities and particularly in some strictly Orthodox areas, many residents ignored the voluntary question on religion following the advice of their religious leaders resulting in a serious undercount, therefore it is impossible to give an accurate number on the total UK Jewish population. It may be even more than double the official estimates, heavily powered by the very high birth rate of orthodox families and British people who are Jewish by origin but not religion; as it currently stands, the Jewish as ethnicity section is not documented on the census.[citation needed]\\r\\n\\r\\nThe Bah' Faith in the United Kingdom has a historical connection with the earliest phases of the Bah' Faith starting in 1845 and has had a major effect on the development of communities of the religion in far flung nations around the world. It is estimated that between 1951 and 1993, Bah's from the United Kingdom settled in 138 countries.[130]\\r\\n\\r\\nThe earliest Buddhist influence on Britain came through its imperial connections with Southeast Asia, and as a result the early connections were with the Theravada traditions of Burma, Thailand, and Sri Lanka. The tradition of study resulted in the foundation of the Pali Text Society, which undertook the task of translating the Pali Canon of Buddhist texts into English. Buddhism as a path of practise was pioneered by the Theosophists, Madame Blavatsky and Colonel Olcott, and in 1880 they became the first Westerners to receive the refuges and precepts, the ceremony by which one traditionally becomes a Buddhist.\\r\\n\\r\\nIn 1924 London's Buddhist Society was founded, and in 1926 the Theravadin London Buddhist Vihara. The rate of growth was slow but steady through the century, and the 1950s saw the development of interest in Zen Buddhism. In 1967 Kagyu Samy Ling Monastery and Tibetan Centre, now the largest Tibetan Buddhist centre in Western Europe, was founded in Scotland. The first home-grown Buddhist movement was also founded in 1967, the Friends of the Western Buddhist Order (now the Triratna Buddhist Community). There are some Soka Gakkai groups in the United Kingdom.\\r\\n\\r\\nHinduism was the religion of 558,810 people in Great Britain according to the 2001 census[131] but an estimate in a British newspaper in 2007 has put the figure as high as 1.5 million.[132] One Non-governmental organisation estimated as of 2007 that there are 800,000 Hindus in the United Kingdom.[133] Although most British Hindus live in England, with half living in London alone,[134] small but growing Hindu communities also exist in Northern Ireland, Scotland and Wales.\\r\\n\\r\\nAs of 2006, there are around 25,000 Jains in the United Kingdom.[135]\\r\\n\\r\\nOne of the first Jain settlers, Champat Rai Jain, was in England during 1892ÿ1897 to study law. He established the Rishabh Jain Lending Library in 1930. Later, he translated several Jain texts into English.[136]\\r\\n\\r\\nLeicester houses one of the world's few Jain temples outside of India.[137] There is an Institute of Jainology at Greenford, London.[138]\\r\\n\\r\\nSikhism was recorded as the religion of 336,149 people in the United Kingdom at the time of the 2001 Census.[139] While England is home to the majority of Sikhs in the United Kingdom, small communities also exist in Northern Ireland, Scotland and Wales.\\r\\n\\r\\nThe first recorded Sikh settler in the United Kingdom was Maharaja Duleep Singh, dethroned and exiled in 1849 at the age of 14, after the Anglo-Sikh wars. During the reign of King Edward VII the first Sikh society in the UK was founded in 1908, it was called The Khalsa Jatha. http://www.open.ac.uk/researchprojects/makingbritain/content/sikh-dharamsala-london. \\r\\nThe first Sikh Gurdwara (temple) was established in 1911, in Shepherds Bush, Putney, London. The first wave of Sikh migration came in the 1940s, mostly of men from the Punjab seeking work in industries such as foundries and textiles. These new arrivals mostly settled in London, Birmingham, Wolverhampton, the Midlands and West Yorkshire. Thousands of Sikhs from East Africa followed later.\\r\\n\\r\\nIn the 2001 Census, a total of 42,262 people from England, Scotland, and Wales declared themselves to be pagans or adherents of Wicca. However, other surveys have led to estimates of around 250,000 or even higher.[140][141]\\r\\n\\r\\nIn the United Kingdom, census figures do not allow an accurate breakdown of traditions within the Pagan heading, as a campaign by the Pagan Federation before the 2001 Census encouraged Wiccans, Heathens, Druids and others all to use the same write-in term 'Pagan' in order to maximise the numbers reported. For the first time, respondents were able to write in an affiliation not covered by the checklist of common religions, and a total of 42,262 people from England, Scotland and Wales declared themselves to be Pagans by this method. These figures were not immediately analysed by the Office for National Statistics, but were released after an application by the Pagan Federation of Scotland.[142]\\r\\n\\r\\nDuring the Iron Age, Celtic polytheism was the predominant religion in the area now known as England. Neo-Druidism grew out of the Celtic revival in 18th century Romanticism. A 2012 Druid analysis estimates that there are roughly 11,000 Druids in Britain.[143]\\r\\n\\r\\nThough the main political parties are secular, the formation of the Labour Party was influenced by Christian socialism and by leaders from a nonconformist background, such as Keir Hardie. On the other hand, the Church of England was once nicknamed \\"the Conservative Party at prayer\\", though this has changed since the 1980s as the Church has moved to the left of the Conservative Party on social and economic issues.[144]\\r\\n\\r\\nSome minor parties are explicitly 'religious' in ideology: two  'Christian' parties ÿ the Christian Party and the Christian Peoples Alliance, fielded joint candidates at the 2009 European Parliament elections and increased their share of the vote to come eighth, with 249,493 votes (1.6% of total votes cast), and in London, where the CPA had three councillors,[145] the Christian parties picked up 51,336 votes (2.9% of the vote), up slightly from the 45,038 gained in 2004.[146]\\r\\n\\r\\nThe Church of England is represented in the UK Parliament by 26 bishops (the Lords Spiritual) and the British monarch is a member of the church (required under Article 2 of the Treaty of Union) as well as its Supreme Governor.[147] The Lords Spiritual have seats in the House of Lords and debate government policies affecting the whole of the United Kingdom. The Church of England also has the right to draft legislative measures (related to religious administration) through the General Synod that can then be passed into law by Parliament.[148] The Prime Minister, regardless of personal beliefs, plays a key role in the appointment of Church of England bishops, although in July 2007 Gordon Brown proposed reforms of the Prime Minister's ability to affect Church of England appointments.[149]\\r\\n\\r\\nReligious education and Collective Worship are compulsory in many state schools in England and Wales by virtue of clauses 69 and 70 of the School Standards and Framework Act 1998. Clause 71 of the act gives parents the right to withdraw their children from Religious Education and Collective Worship[150] and parents should be informed of their right in accordance with guidelines published by the Department for Education; \\"a school should ensure parents or carers are informed of this right\\".[151] The content of the religious education is decided locally by the Standing Advisory Council on Religious Education.\\r\\n\\r\\nIn England and Wales, a significant number of state funded schools are faith schools with the vast majority Christian (mainly either of Church of England or Catholic) though there are also Jewish, Muslim and Sikh faith schools. Faith schools follow the same national curriculum as state schools, though with the added ethos of the host religion. Until 1944 there was no requirement for state schools to provide religious education or worship, although most did so. The Education Act 1944 introduced a requirement for a daily act of collective worship and for religious education but did not define what was allowable under these terms. The act contained provisions to allow parents to withdraw their children from these activities and for teachers to refuse to participate. The Education Reform Act 1988 introduced a further requirement that the majority of collective worship be \\"wholly or mainly of a broadly Christian character\\".[152] According to a 2003 report from the  Office for Standards in Education, a \\"third of governing bodies do not fulfil their statutory duties adequately, sometimes because of a failure to pursue thoroughly enough such matters as arranging a daily act of collective worship\\".[153]\\r\\n\\r\\nIn Scotland, the majority of schools are non-denominational, but separate Catholic schools, with an element of control by the Catholic Church, are provided within the state system. The Education (Scotland) Act 1980 imposes a statutory duty on all local authorities to provide religious education and religious observance in Scottish schools. These are currently defined by the Scottish Government's Curriculum for Excellence (2005).[154]\\r\\n\\r\\nNorthern Ireland has a highly segregated education system. 95 per cent of pupils attend either maintained (Catholic) schools or controlled schools, which are open to children of all faiths and none, though in practise most pupils are from the Protestant community.[citation needed]\\r\\n\\r\\nPrisoners are given religious freedom and privileges while in prison. This includes access to a chaplain or religious advisor, authorised religious reading materials,[155] ability to change faith, as well as other privileges.[156]  Several faith-based outreach programmes provide faith promoting guidance and counselling.[157][158][159]\\r\\n\\r\\nEvery three months, the Ministry of Justice collects data, including religious affiliation, of all UK prisoners and is published as the Offender Management Caseload Statistics.[160] This data is then compiled into reports and published in the House of Commons library.\\r\\n\\r\\nOn 31 March 2015 the prison population of England and Wales was recorded as 49% Christian, 14% Muslim, 2% Buddhist, 2% other religions and 31% no religion.[161]\\r\\n\\r\\nThe Communications Act 2003 requires certain broadcasters in the United Kingdom to carry a \\"suitable quantity and range of programmes\\" dealing with religion and other beliefs, as part of their public service broadcasting.[162] Prominent examples of religious programming include the BBC television programme Songs of Praise, aired on a Sunday evening with an average weekly audience of 2.5 million,[163] and the Thought for the Day slot on BBC Radio 4. Channels also offer documentaries on, or from the perspective of a criticism of organised religion. A significant example is Richard Dawkins' two-part Channel 4 documentary, The Root of all Evil?. Open disbelief of, or even mockery of organised religion, is not regarded as a taboo in the British media, though it has occasionally provoked controversy ÿ for example, the movie Monty Python's Life of Brian,[164] the poem \\"The Love That Dares to Speak Its Name\\",[165] and the musical Jerry Springer: The Opera,[166] all of which involved characters based on Jesus, were subject to public outcry and blasphemy allegations, while The Satanic Verses, a novel by British Indian author Salman Rushdie which includes a fantasy sequence about Muhammed, caused global protests including several by British Muslims.[167] British comedy has a history of parody on the subject of religion.[citation needed]\\r\\n\\r\\nThe Interfaith Network for the United Kingdom encompasses the main faith organisations of the United Kingdom, either directly with denominational important representatives or through joint bodies for these denominations, promotes local interfaith cooperation, promotes understanding between faiths and convenes meetings and conferences where social and religious questions of concern to the different faith communities can be examined together, including meetings of the Network's Faith Communities Consultative Forum.[169]\\r\\n\\r\\nEcumenical friendship and cooperation has gradually developed between Christian denominations and where inter-sect prejudice exists this has via education and employment policy been made a pressing public matter in dealing with its two prominent examples ÿ sectarianism in Glasgow and Northern Ireland ÿ where segregation is declining.\\r\\n\\r\\nIn the early 21st century, the Racial and Religious Hatred Act 2006 made it an offence in England and Wales to incite hatred against a person on the grounds of their religion. The common law offences of blasphemy and blasphemous libel were abolished with the coming into effect of the Criminal Justice and Immigration Act 2008 on 8 July 2008.\\r\\n\\r\\n2005ÿ2010 polls have shown that public opinion in the United Kingdom generally tends towards a suspicion or outright disapproval of radical or evangelical religiosity, though moderate groups and individuals are rarely subject to less favourable treatment from society or employers.[170]\\r\\n\\r\\nThe Equality Act 2010 prohibits discrimination against people on the basis of religion, in the supply of goods and services and selection for employment, subject to very limited exceptions (such as the right of schools and religious institutions to appoint paid ministers).\\r\\n\\r\\nThere is no strict separation of church and state in the United Kingdom.  Accordingly, most public officials may display the most common identifiers of a major religion in the course of their duties ÿ for example, rosary beads. Chaplains are provided in the armed forces (see Royal Army Chaplains' Department, RAF Chaplains Branch) and in prisons.\\r\\n\\r\\nAlthough school uniform codes are generally drawn up flexibly enough to accommodate compulsory items of religious dress, some schools have banned wearing the crucifix in a necklace, arguing that to do so is not a requirement of Christianity where they prohibit all other necklaces.  Post-adolescence, the wearing of a necklace is permitted in some F.E. colleges who permit religious insignia necklaces on a wider basis, which are without exception permitted at universities.[171]\\r\\n\\r\\nSome churches have warned that the Equality Act 2010 could force them to go against their faith when hiring staff.[172]\\r\\n\\r\\nIn 2011 two judges of the Court of Appeal of England and Wales upheld previous statements in the country's jurisprudence that the (non-canon) laws of the United Kingdom 'do not include Christianity'. Therefore, a local authority was acting lawfully in denying a Christian married couple the right to foster care because of stated negative views on homosexuality.  In terms of the rights recognised \\"in the case of fostering arrangements at least, the right of homosexuals to equality should take precedence over the right of Christians to manifest their beliefs and moral values\\".[173]\\r\\n\\r\\nLevels of affiliation vary between different part of the UK, particularly between Great Britain and Northern Ireland. The percentages declaring themselves Christians in the 2011 Census are 59.4 in England, 57.6 in Wales and 53.8 in Scotland, which decreased by 12.3, 14.3, and 11.3 percentage points respectively from the census of 2001.[174][175][176][177] This is argued to make them the fastest secularising nations in history.[178] Northern Ireland remains one of the most religious nations in western Europe[citation needed] with 82.3% of the population claiming Christian affiliation, with a decline of only 3.5% by the 2011 census, while \\"other religions\\" have increased in membership.[174] Religion has been seen as both a product and a cause of political divisions in Northern Ireland.[179]\\r\\n\\r\\nChristian\\r\\n\\r\\nJewish\\r\\n\\r\\nIslamic\\r\\n\\r\\nOther","input":"What is the primary religion in the united kingdom?"},{"output":"bales","context":"Hay is grass, legumes, or other herbaceous plants that have been cut, dried, and stored for use as animal fodder, particularly for grazing animals such as cattle, horses, goats, and sheep. Hay is also fed to smaller animals such as rabbits and guinea pigs. Pigs may be fed hay, but they do not digest it as efficiently as more fully herbivorous animals.\\r\\nHay can be used as animal fodder when or where there is not enough pasture or rangeland on which to graze an animal, when grazing is unavailable due to weather (such as during the winter) or when lush pasture by itself is too rich for the health of the animal. It is also fed during times when an animal is unable to access pasture, such as when animals are kept in a stable or barn.\\r\\n\\r\\n\\r\\nCommonly used plants for hay include mixtures of grasses such as ryegrass (Lolium species), timothy, brome, fescue, Bermuda grass, orchard grass, and other species, depending on region. Hay may also include legumes, such as alfalfa (lucerne) and clovers (red, white and subterranean). Legumes in hay are ideally cut pre-bloom. Other pasture forbs are also sometimes a part of the mix, though these plants are not necessarily desired as certain forbs are toxic to some animals.\\r\\nOat, barley, and wheat plant materials are occasionally cut green and made into hay for animal fodder; however they are more usually used in the form of straw, a harvest byproduct where the stems and dead leaves are baled after the grain has been harvested and threshed. Straw is used mainly for animal bedding. Although straw is also used as fodder, particularly as a source of dietary fiber, it has lower nutritional value than hay.\\r\\nIt is the leaf and seed material in the hay that determines its quality. Farmers try to harvest hay at the point when the seed heads are not quite ripe and the leaf is at its maximum when the grass is mowed in the field. The cut material is allowed to dry so that the bulk of the moisture is removed but the leafy material is still robust enough to be picked up from the ground by machinery and processed into storage in bales, stacks or pits.\\r\\n Hay is very sensitive to weather conditions, especially when it is harvested. In drought conditions, both seed and leaf production are stunted, making hay that has a high ratio of dry coarse stems that have very low nutritional values. If the weather is too wet, the cut hay may spoil in the field before it can be baled. Thus the biggest challenge and risk for farmers in producing hay crops is the weather, especially the weather of the particular few weeks when the plants are at the best age/maturity for hay. A lucky break in the weather often moves the haymaking tasks (such as mowing, tedding, and baling) to the top priority on the farm's to-do list. This is reflected in the idiom to make hay while the sun shines. Hay that was too wet at cutting may develop rot and mold after being baled, creating the potential for toxins to form in the feed, which could make the animals sick.\\r\\nAfter harvest, hay also has to be stored in a manner to prevent it from getting wet. Mold and spoilage reduce nutritional value and may cause illness in animals. A symbiotic fungus in fescue may cause illness in horses and cattle.[1]\\r\\nThe successful harvest of maximum yields of high-quality hay is entirely dependent on the coincident occurrence of optimum crop, field, and weather conditions. When this occurs, there may be a period of intense activity on the hay farm while harvest proceeds until weather conditions become unfavourable.\\r\\nHay or grass is the foundation of the diet for all grazing animals and can provide as much as 100% of the fodder required for an animal. Hay is usually fed to an animal in place of allowing the animal to graze on grasses in a pasture, particularly in the winter or during times when drought or other conditions make pasture unavailable. Animals that can eat hay vary in the types of grasses suitable for consumption, the ways they consume hay, and how they digest it. Therefore, different types of animals require hay that consists of similar plants to what they would eat while grazing, and likewise, plants that are toxic to an animal in pasture are also toxic if they are dried into hay.\\r\\nMost animals are fed hay in two daily feedings, morning and evening. However, this schedule is more for the convenience of humans, as most grazing animals on pasture naturally consume fodder in multiple feedings throughout the day. Some animals, especially those being raised for meat, may be given enough hay that they simply are able to eat all day. Other animals, especially those that are ridden or driven as working animals, are only free to eat when not working, and may be given a more limited amount of hay to prevent them from getting too fat. The proper amount of hay and the type of hay required varies somewhat between different species. Some animals are also fed concentrated feeds such as grain or vitamin supplements in addition to hay. In most cases, hay or pasture forage must make up 50% or more of the diet by weight.\\r\\nOne of the most significant differences in hay digestion is between ruminant animals, such as cattle and sheep; and nonruminant, hindgut fermentors, such as horses. Both types of animals can digest cellulose in grass and hay, but do so by different mechanisms. Because of the four-chambered stomach of cattle, they are often able to break down older forage and have more tolerance of mold and changes in diet. The single-chambered stomach and cecum or \\"hindgut\\" of the horse uses bacterial processes to break down cellulose that are more sensitive to changes in feeds and the presence of mold or other toxins, requiring horses to be fed hay of a more consistent type and quality.[2]\\r\\nDifferent animals also use hay in different ways: cattle evolved to eat forages in relatively large quantities at a single feeding, and then, due to the process of rumination, take a considerable amount of time for their stomachs to digest food, often accomplished while the animal is lying down, at rest. Thus quantity of hay is important for cattle, who can effectively digest hay of low quality if fed in sufficient amounts. Sheep will eat between two and four percent of their body weight per day in dry feed, such as hay,[3] and are very efficient at obtaining the most nutrition possible from three to five pounds per day of hay or other forage.[4] They require three to four hours per day to eat enough hay to meet their nutritional requirements.[5]\\r\\nUnlike ruminants, horses digest food in small portions throughout the day, and can only use approximately 2.5% of their body weight in feed in any 24-hour period. They evolved to be continuously on the move while grazing, (covering up to 50 miles (80?km) per day in the wild) and their stomach digests food quite rapidly. Thus, they extract more nutrition out of smaller quantities of feed.[6] However, when horses are fed low-quality hay, they may develop an unhealthy, obese, \\"hay belly\\" due to over-consumption of \\"empty\\" calories. If their type of feed is changed dramatically, or if they are fed moldy hay or hay containing toxic plants, they can become ill; colic is the leading cause of death in horses. Contaminated hay can also lead to respiratory problems in horses. Hay can be soaked in water, sprinkled with water or subjected to steaming to reduce dust.\\r\\nHay production and harvest, colloquially known as \\"making hay\\",[7] \\"haymaking\\", or \\"doing hay\\", involves a multiple step process: cutting, drying or \\"curing\\", raking, processing, and storing. Hayfields do not have to be reseeded each year in the way that grain crops are, but regular fertilizing is usually desirable, and overseeding a field every few years helps increase yield.\\r\\nMethods and the terminology to describe the steps of making hay have varied greatly throughout history, and many regional variations still exist today. However, whether done by hand or by modern mechanized equipment, tall grass and legumes at the proper stage of maturity must be cut, then allowed to dry (preferably by the sun), then raked into long, narrow piles known as windrows. Next, the cured hay is gathered up in some form (usually by some type of baling process) and placed for storage into a haystack or into a barn or shed to protect it from moisture and rot.\\r\\nDuring the growing season, which is spring and early summer in temperate climates, grass grows at a fast pace. It is at its greatest nutritive value when all leaves are fully developed and seed or flower heads are just a bit short of full maturity. When growth is at a maximum in the pasture or field, if judged correctly, it is cut. Grass hay cut too early will not cure as easily due to high moisture content, plus it will produce a lower yield per acre than longer, more mature grass. But hay cut too late is coarser, lower in resale value and has lost some of its nutrients. There is usually about a two-week \\"window\\" of time in which grass is at its ideal stage for harvesting hay. The time for cutting alfalfa hay is ideally done when plants reach maximum height and are producing flower buds or just beginning to bloom, cutting during or after full bloom results in lower nutritional value of the hay.\\r\\nHay can be raked into rows as it is cut, then turned periodically to dry, particularly if a modern swather is used. Or, especially with older equipment or methods, the hay is cut and allowed to lie spread out in the field until it is dry, then raked into rows for processing into bales afterwards. During the drying period, which can take several days, the process is usually sped up by turning the cut hay over with a hay rake or spreading it out with a tedder. If it rains while the hay is drying, turning the windrow can also allow it to dry faster. However, turning the hay too often or too roughly can also cause drying leaf matter to fall off, reducing the nutrients available to animals. Drying can also be sped up by mechanized processes, such as use of a hay conditioner, or by use of chemicals sprayed onto the hay to speed evaporation of moisture, though these are more expensive techniques, not in general use except in areas where there is a combination of modern technology, high prices for hay, and too much rain for hay to dry properly.[8]\\r\\nOnce hay is cut, dried and raked into windrows, it is usually gathered into bales or bundles, then hauled to a central location for storage. In some places, depending on geography, region, climate, and culture, hay is gathered loose and stacked without being baled first.\\r\\nHay must be fully dried when baled and kept dry in storage. If hay is baled while too moist or becomes wet while in storage, there is a significant risk of spontaneous combustion.[9] Hay stored outside must be stacked in such a way that moisture contact is minimal. Some stacks are arranged in such a manner that the hay itself \\"sheds\\" water when it falls. Other methods of stacking use the first layers or bales of hay as a cover to protect the rest. To completely keep out moisture, outside haystacks can also be covered by tarps, and many round bales are partially wrapped in plastic as part of the baling process. Hay is also stored under a roof when resources permit. It is frequently placed inside sheds, or stacked inside of a barn. On the other hand, care must also be taken that hay is never exposed to any possible source of heat or flame, as dry hay and the dust it produces are highly flammable.\\r\\nEarly farmers noticed that growing fields produced more fodder in the spring than the animals could consume, and that cutting the grass in the summer, allowing it to dry and storing it for the winter provided their domesticated animals with better quality nutrition than simply allowing them to dig through snow in the winter to find dried grass. Therefore, some fields were \\"shut up\\" for hay.[citation needed]\\r\\nUp to the end of the 19th century, grass and legumes were not often grown together because crops were rotated.[citation needed] However, by the 20th century, good forage management techniques demonstrated that highly productive pastures were a mix of grasses and legumes, so compromises were made when it was time to mow. Later still, some farmers grew crops, like straight alfalfa (lucerne), for special-purpose hay such as that fed to dairy cattle.\\r\\nMuch hay was originally cut by scythe by teams of workers, dried in the field and gathered loose on wagons. Later, haying would be done by horse-drawn implements such as mowers. With the invention of agricultural machinery such as the tractor and the baler, most hay production became mechanized by the 1930s.\\r\\nAfter hay was cut and had dried, the hay was raked or rowed up by raking it into a linear heap by hand or with a horse-drawn implement. Turning hay, when needed, originally was done by hand with a fork or rake. Once the dried hay was rowed up, pitch forks were used to pile it loose, originally onto a horse-drawn cart or wagon, later onto a truck or tractor-drawn trailer, for which a sweep could be used instead of pitch forks.\\r\\nLoose hay was taken to an area designated for storageusually a slightly raised area for drainageand built into a hay stack. The stack was made waterproof as it was built (a skilled task) and the hay would compress under its own weight and cure by the release of heat from the residual moisture in the hay and from the compression forces. The stack was fenced from the rest of the paddock in a rick yard, and often thatched or sheeted to keep it dry. When needed, slices of hay would be cut using a hay knife and fed out to animals each day.\\r\\nOn some farms the loose hay was stored in a barrack, shed, or barn, normally in such a way that it would compress down and cure. Hay could be stored in a specially designed barn with little internal structure to allow more room for the hay loft. Alternatively, an upper storey of a cow-shed or stable was used, with hatches in the floor to allow hay to be thrown down into hay-racks below.\\r\\nDepending on region, the term \\"hay rick\\" could refer to the machine for cutting hay, the hay stack or the wagon used to collect the hay.\\r\\nModern mechanized hay production today is usually performed by a number of machines. While small operations use a tractor to pull various implements for mowing and raking, larger operations use specialized machines such as a mower or a swather, which are designed to cut the hay and arrange it into a windrow in one step. Balers are usually pulled by a tractor, with larger balers requiring more powerful tractors.\\r\\nMobile balers, machines which gather and bale hay in one process, were first developed around 1940. The first balers produced rectangular bales small enough for a person to lift, usually between 70 and 100 pounds (32 and 45?kg) each. The size and shape made it possible for people to pick bales up, stack them on a vehicle for transport to a storage area, then build a haystack by hand. However, to save labor and increase safety, loaders and stackers were also developed to mechanise the transport of small bales from the field to the haystack. Later in the 20th century, balers were developed capable of producing large bales that weigh up to 3,000 pounds (1,400?kg).[10]\\r\\nConditioning of hay has become popular. The basic idea is that it decreases drying time, particularly in humid climates or if rain interferes with haying. Usually, a salt solution is sprayed over the top of the hay (generally alfalfa) that helps to dry the hay. Conditioning can also refer to the rollers inside a swather that crimps the alfalfa to help squeeze out the moisture.[citation needed]\\r\\nModern hay production often relies on artificial fertilizer and herbicides. Traditionally, manure has been used on hayfields, but modern chemical fertilizers are used today as well. Hay that is to be certified as weed-free for use in wilderness areas must often be sprayed with chemical herbicides to keep unwanted weeds from the field, and sometimes even non-certified hayfields are sprayed to limit the production of noxious weeds. However, organic forms of fertilization and weed control are required for hay grown for consumption by animals whose meat will ultimately be certified organic. To that end, compost and field rotation can enhance soil fertility, and regular mowing of fields in the growth phase of the hay will often reduce the prevalence of undesired weeds. In recent times, some producers have experimented with human sewage sludge to grow hay. This is not a certified organic method and no warning labels are mandated by EPA.[11] One concern with hay grown on human sewage sludge is that the hay can take up heavy metals, which are then consumed by animals.[12] Molybdenum poisoning is a particular concern in ruminants such as cows and goats, and there have been animal deaths.[13][14][15] Another concern is with a herbicide known as aminopyralid, which can pass through the digestive tract in animals, making their resulting manure toxic to many plants and thus unsuitable as fertilizer for food crops.[16] Aminopyralid and related herbicides can persist in the environment for several years.\\r\\nSmall bales are still produced today. While balers for small bales are still manufactured, as well as loaders and stackers, there are some farms that still use equipment manufactured over 50 years ago, kept in good repair. The small bale remains part of overall ranch lore and tradition with \\"hay bucking\\" competitions still held for fun at many rodeos and county fairs.\\r\\nSmall square bales are stacked in a criss-crossed fashion sometimes called a \\"rick\\" or \\"hayrick\\". Rain tends to wash nutrition out of hay and can cause spoilage or mold. Hay in small square bales is particularly susceptible to this, and is therefore often stored in a hayshed or protected by tarpaulins. If this is not done, the top two layers of the stack are often lost to rot and mold, and if the stack is not arranged in a proper hayrick, moisture can seep even deeper into the stack. The rounded shape and tighter compaction of small (and large) round bales makes them less susceptible to spoilage, as the water is less likely to penetrate into the bale. The addition of net wrap, which is not used on square bales, offers even greater weather resistance.\\r\\nPeople who keep small numbers of animals may prefer small bales that can be handled by one person without machinery. There is also a risk that hay bales may be moldy, or contain decaying carcasses of small creatures that were accidentally killed by baling equipment and swept up into the bale, which can produce toxins such as botulism. Both can be deadly to non-ruminant herbivores, such as horses, and when this occurs, the entire contaminated bale generally is thrown out, another reason some people continue to support the market for small bales.\\r\\nFarmers who need to make large amounts of hay are likely to choose balers which produce much larger bales, maximizing the amount of hay which is protected from the elements. Large bales come in two types, round and square. Large square bales, which can weigh up to 1,000 kilograms (2,200?lb), can be stacked and are easier to transport on trucks. Large round bales, which typically weigh 300?to 400 kilograms (660ÿ880?lb), are more moisture-resistant, and pack the hay more densely (especially at the center). Round bales are quickly fed with the use of mechanized equipment.\\r\\nThe ratio of volume to surface area makes it possible for many dry-area farmers to leave large bales outside until they are consumed. Wet-area farmers and those in climates with heavy snowfall can stack round bales under a shed or tarp, but can also use a light but durable plastic wrap that partially encloses bales left outside. The wrap repels moisture, but leaves the ends of the bale exposed so that the hay itself can \\"breathe\\" and does not begin to ferment. However, when it is possible to store round bales under a shed, they last longer and less hay is lost to rot and moisture.[17]\\r\\nFor animals that eat silage, a bale wrapper may be used to seal a round bale completely and trigger the fermentation process. It is a technique used as a money-saving process by producers who do not have access to a silo, and for producing silage that is transported to other locations. However, a silo is still a preferred method for making silage.[18] In very damp climates, it is a legitimate alternative to drying hay completely and when processed properly, the natural fermentation process prevents mold and rot. Round bale silage is also sometimes called \\"haylage\\", and is seen more commonly in Europe than in either the United States or Australia. However, hay stored in this fashion must remain completely sealed in plastic, as any holes or tears can stop the preservation properties of fermentation and lead to spoilage.[19]\\r\\nHaystacks are stacks of harvested hay, stacked in many different ways, depending upon region of the world, climate, if baled or loose, and so on. Hay requires protection from weather, and is optimally stored inside buildings or other structures, but haystacks are also built in an open field. A fence may be built to enclose a haystack and prevent roaming animals from eating it,[20][21] or animals may feed directly from a field-constructed stack as part of their winter feeding.[22]\\r\\nHaystacks are also called haycocks in some dialects of English. The words are usually styled as solid compounds, but not always. They are also sometimes called stooks, shocks, or ricks.\\r\\nLoose stacks are built to prevent accumulation of moisture and promote drying, or curing. In some places, this is accomplished by constructing stacks with a conical or ridged top.[20][23] The exterior may look gray on the surface after weathering, but the inner hay retains traces of its fresh-cut aroma and maintains a faded green tint.[20] They can be covered with thatch,[23][24] or kept within a protective structure. One such structure is a moveable roof supported by four posts, historically called a Dutch roof, hay barrack, or hay cap.[24][25] Haystacks may also be built on top of a foundation laid on the ground to reduce spoilage, in some places made of wood or brush.[20] In other areas, hay is stacked loose, built around a central pole, a tree, or within an area of three or four poles to add stability to the stack.[26][27][28]\\r\\nOne loose hay stacking technique seen in the British isles is to initially stack freshly cut hay into smaller mounds called foot cocks, hay coles, kyles, hayshocks or haycocks, to facilitate initial curing.[20][29] These are sometimes built atop platforms or tripods formed of three poles, used to keep hay off the ground and let air into the center for better drying.[30] The shape causes dew and rain water roll down the sides, allowing the hay within to cure.[20] People who handle the hay may use hayforks or pitchforks to move or pitch the hay in building haycocks and haystacks.[20][31] Construction of tall haystacks is sometimes aided with a ramp, ranging from simple poles to a device for building large loose stacks called a beaverslide.[20][32]\\r\\nFarmer's lung (not to be confused with silo-filler's disease) is a hypersensitivity pneumonitis induced by the inhalation of biologic dusts coming from hay dust or mold spores or other agricultural products.[33] Exposure to hay can also trigger Allergic rhinitis for people who are hypersensitive to airborne allergens.\\r\\nHay baled before it is fully dry can produce enough heat to start a fire. Haystacks produce internal heat due to bacterial fermentation. If hay is stacked with wet grass, the heat produced can be sufficient to ignite the hay causing a fire. Farmers have to be careful about moisture levels to avoid spontaneous combustion, which is a leading cause of haystack fires.[34] Heat is produced by the respiration process, which occurs until the moisture content of drying hay drops below 40%. Hay is considered fully dry when it reaches 20% moisture. Combustion problems typically occur within five days to seven days of baling. A bale cooler than 120?F (49?C) is in little danger, but bales between 120 and 140?F (49 and 60?C) need to be removed from a barn or structure and separated so that they can cool off. If the temperature of a bale exceeds more than 140?F (60?C), it can combust.[35]\\r\\nDue to its weight, hay can cause a number of injuries to humans, particularly those related to lifting and moving bales, as well as risks related to stacking and storing. Hazards include the danger of having a poorly constructed stack collapse, causing either falls to people on the stack or injuries to people on the ground who are struck by falling bales. Large round hay bales present a particular danger to those who handle them, because they can weigh over 1,000 pounds (450?kg) and cannot be moved without special equipment. Nonetheless, because they are cylindrical in shape, and thus can roll easily, it is not uncommon for them to fall from stacks or roll off the equipment used to handle them. From 1992 to 1998, 74 farm workers in the United States were killed in large round hay bale accidents, usually when bales were being moved from one location to another, such as when feeding animals.[36][37]\\r\\nHay is generally one of the safest feeds to provide to domesticated grazing herbivores. However, some precautions are needed. Amount must be monitored so that animals do not get too fat or too thin. Supplemental feed may be required for working animals with high energy requirements. Animals who eat spoiled hay may develop a variety of illnesses, from coughs related to dust and mold, to various other illnesses, the most serious of which may be botulism, which can occur if a small animal, such as a rodent or snake, is killed by the baling equipment, then rots inside the bale, causing a toxin to form. Some animals are sensitive to particular fungi or molds that may grow on living plants. For example, an endophytic fungus that sometimes grows on fescue can cause abortion in pregnant mares.[38] Some plants themselves may also be toxic to some animals. For example, Pimelea, a native Australian plant, also known as flax weed, is highly toxic to cattle.[39]\\r\\noids\\r\\nFiber\\r\\n Media related to Hay at Wikimedia Commons","input":"What do you call a bundle of hay?"},{"output":"September 4, 2013","context":"Futurama is an American animated science fiction comedy series created by Matt Groening for the Fox Broadcasting Company. The series follows the adventures of a late-20th-century New York City pizza delivery boy, Philip J. Fry, who finds employment at Planet Express, an interplanetary delivery company in the retro-futuristic 31st century after being unwittingly cryogenically frozen for one thousand years. The series was envisioned by Groening in the mid-1990s while working on The Simpsons; he later brought David X. Cohen aboard to develop storylines and characters to pitch the show to Fox.\\r\\nIn the United States, the series aired on Fox from March 28, 1999, to August 10, 2003, before ceasing production. Futurama also aired in reruns on Cartoon Network's Adult Swim from 2003 to 2007, until the network's contract expired. It was revived in 2007 as four direct-to-video films; the last of which was released in early 2009. Comedy Central entered into an agreement with 20th Century Fox Television to syndicate the existing episodes and air the films as 16 new, half-hour episodes, constituting a fifth season.[1][2]\\r\\nIn June 2009, producing studio 20th Century Fox announced that Comedy Central had picked up the show for 26 new half-hour episodes, which began airing in 2010 and 2011.[3][4] The show was renewed for a seventh season, with the first half airing in June 2012 and the second set for mid-2013.[5][6] It was later revealed that the seventh season would be the final season, as Comedy Central announced that they would not be commissioning any further episodes. The series finale aired on September 4, 2013.[7] While Groening has said he will try to get it picked up by another network,[8] David X. Cohen stated that the episode \\"Meanwhile\\" would be the last episode of season 7 and also the series finale.[9] A 42-minute audio-only episode featuring its original cast members was released on September 14, 2017, as an episode of The Nerdist Podcast entitled Futurama: Worlds of Tomorrow Presents, RADIORAMA!.[10]\\r\\nThroughout its run, Futurama has received critical acclaim. The show has been nominated for 17 Annie Awards and 12 Emmy Awards, winning seven of the former and six of the latter. It has also been nominated four times for a Writers Guild of America Award, winning two for the episodes \\"Godfellas\\" and \\"The Prisoner of Benda\\", been nominated for a Nebula Award and has received Environmental Media Awards for episodes \\"The Problem with Popplers\\" and \\"The Futurama Holiday Spectacular\\".[11] Futurama-related merchandise has also been released, including a tie-in comic book series, video games, calendars, clothes and figurines. In 2013, TV Guide ranked Futurama as one of the top 60 Greatest TV Cartoons of All Time.[12]\\r\\n\\r\\n\\r\\nThe television network Fox expressed a strong desire in the mid-1990s for Matt Groening to create a new series, and he began conceiving Futurama during this period. In 1996, he enlisted David X. Cohen, then a writer and producer for The Simpsons, to assist in developing the show. The two spent time researching science fiction books, television shows, and films. When they pitched the series to Fox in April 1998, Groening and Cohen had composed many characters and story lines; Groening claimed they had gone \\"overboard\\" in their discussions.[13] Groening described trying to get the show on the air as \\"by far the worst experience of my grown-up life\\".[14]\\r\\nFox ordered thirteen episodes. Immediately after, however, Fox feared the themes of the show were not suitable for the network and Groening and Fox executives argued over whether the network would have any creative input into the show.[15] With The Simpsons, the network has no input.[16] Fox was particularly disturbed by the concept of suicide booths, Doctor Zoidberg, and Bender's anti-social behavior.[17] Groening explains, \\"When they tried to give me notes on Futurama, I just said: 'No, we're going to do this just the way we did Simpsons.' And they said, 'Well, we don't do business that way anymore.' And I said, 'Oh, well, that's the only way I do business.'\\"[18] The episode \\"I, Roommate\\" was produced to address Fox's concerns, with the script written to their specifications.[17][19] Fox strongly disliked the episode, but after negotiations, Groening received the same independence with Futurama.[20]\\r\\nThe name Futurama comes from a pavilion at the 1939 New York World's Fair. Designed by Norman Bel Geddes, the Futurama pavilion depicted how he imagined the world would look in 1959.[21] Many other titles were considered for the series, including \\"Aloha, Mars!\\" and \\"Doomsville\\", which Groening notes were \\"resoundly rejected, by everyone concerned with it\\".[22][23] It takes approximately six to nine months to produce an episode of Futurama.[24][25] The long production time results in several episodes being worked on simultaneously.[26]\\r\\nGroening and Cohen served as executive producers and showrunners during the show's entire run, and also functioned as creative consultants. Ken Keeler became an executive producer for Season 4 and subsequent seasons.\\r\\nThe planning for each episode began with a table meeting of writers, who discussed the plot ideas as a group. The writers are given index cards with plot points that they are required to use as the center of activity in each episode. A single staff writer wrote an outline and then produced a script. Once the first draft of a script was finished, the writers and executive producers called in the actors for a table read.[15] After this script reading, the writers collaborated to rewrite the script as a group before sending it to the animation team.[27] At this point the voice recording was also started and the script was out of the writers' hands.[25]\\r\\nThe writing staff held three Ph.D.s, seven master's degrees, and cumulatively had more than 50 years at Harvard University. Series writer Patric M. Verrone stated, \\"we were easily the most overeducated cartoon writers in history\\".[28]\\r\\nFuturama had eight main cast members. Billy West performed the voices of Philip J. Fry, Professor Farnsworth, Doctor Zoidberg, Zapp Brannigan and many other incidental characters. West auditioned for \\"just about every part\\", landing the roles of the Professor and Doctor Zoidberg.[29] Although West read for Fry, his friend Charlie Schlatter was initially given the role of Fry.[29] Due to a casting change, West was called back to audition again and was given the role. West claims that the voice of Fry is deliberately modeled on his own, so as to make it difficult for another person to replicate the voice.[29] Doctor Zoidberg's voice was based on Lou Jacobi and George Jessel.[30] The character of Zapp Brannigan was originally created and intended to be performed by Phil Hartman.[29][30] Hartman insisted on auditioning for the role, and \\"just nailed it\\" according to Groening. Due to Hartman's death, West was given the role. West states that his version of Zapp Brannigan was an imitation of Hartman and also \\"modeled after a couple of big dumb announcers I knew\\".[29][30]\\r\\nKatey Sagal voiced Leela, and is the only member of the main cast to voice only one character. The role of Leela was originally assigned to Nicole Sullivan.[29] In an interview in June 2010, Sagal remarked that she did not know that another person was to originally voice Leela until many years after the show first began.[31]\\r\\nJohn DiMaggio performed the voice of the robot Bender Bending Rodrguez and other, more minor, characters. Bender was the most difficult character to cast, as the show's creators had not decided what a robot should sound like.[32] DiMaggio originally auditioned for the role of Professor Farnsworth, using the voice he uses to perform Bender, and also auditioned for Bender using a different voice.[33] DiMaggio described Bender's voice as a combination of a sloppy drunk, Slim Pickens and a character his college friend created named \\"Charlie the sausage-lover\\".[31]\\r\\nPhil LaMarr voices Hermes Conrad, his son Dwight, Ethan Bubblegum Tate, and Reverend Preacherbot. Lauren Tom voiced Amy Wong, and Tress MacNeille voices Mom and various other characters. Maurice LaMarche voices Kif Kroker and several supporting characters. LaMarche won the Emmy Award for Outstanding Voice-Over Performance in 2011 for his performances as Lrrr and Orson Welles in the episode \\"Lrrreconcilable Ndndifferences\\".[34] David Herman voiced Scruffy and various supporting characters. During seasons 1ÿ4, LaMarche is billed as supporting cast and Tom, LaMarr and Herman billed as guest stars, despite appearing in most episodes. LaMarche was promoted to main cast and Tom, LaMarr and Herman to supporting cast in Season 5, and promoted again to main cast in Season 6.\\r\\nIn addition to the main cast, Frank Welker voiced Nibbler and Kath Soucie voiced Cubert and several supporting and minor characters. Like The Simpsons, many episodes of Futurama feature guest voices from a wide range of professions, including actors, entertainers, bands, musicians, and scientists. Many guest-stars voiced supporting characters, although many voiced themselves, usually as their own head preserved in a jar. Recurring guest stars included Dawnn Lewis (as Hermes' wife LaBarbara), Tom Kenny, Dan Castellaneta (as the Robot Devil), Al Gore, and George Takei, among others.\\r\\nRough Draft Studios animated Futurama. The studio would receive the completed script of an episode and create a storyboard consisting of more than 100 drawings. It would then produce a pencil-drawn animatic with 1,000 frames. Rough Draft's sister studio in South Korea would render the 30,000-frame finished episode.[15]\\r\\nIn addition to traditional cartoon drawing, Rough Draft Studios often used CGI for fast or complex shots, such as the movement of spaceships, explosions, nebulae, large crowds, and snow scenes. The opening sequence was entirely rendered in CGI. The CGI was rendered at 24 frames per second (as opposed to hand-drawn often done at 12 frames per second) and the lack of artifacts made the animation appear very smooth and fluid. CGI characters looked slightly different due to spatially \\"cheating\\" hand-drawn characters by drawing slightly out of proportion or off-perspective features to emphasize traits of the face or body, improving legibility of an expression. PowerAnimator was used to draw the comic-like CGI.[35]\\r\\nThe series began high-definition production in season 5, with Bender's Big Score. The opening sequence was re-rendered and scaled to adapt to the show's transition to 16:9 widescreen format.\\r\\nFor the final episode of season 6, Futurama was completely reanimated in three different styles: the first segment of the episode features black-and-white Fleischer- and Walter Lantz-style animation, the second was drawn in the style of a low-resolution video game, and the final segment was in the style of Japanese anime.[36]\\r\\nGroening and Cohen wanted Futurama to be shown at 8:30?pm on Sunday, following The Simpsons. The Fox network disagreed, opting instead to show two episodes in the Sunday night lineup before moving the show to a regular time slot on Tuesday.[37] Beginning with its second broadcast season Futurama was again placed in the 8:30 Sunday spot,[38] but by mid-season the show was moved again, this time to 7:00?pm on Sunday, its third position in under a year.[39] Even by the fourth season Futurama was still being aired erratically.[40] Due to being regularly pre-empted by sporting events, it became difficult to predict when new episodes would air. This erratic schedule resulted in Fox not airing several episodes that had been produced for seasons three and four, instead holding them over for a fifth broadcast season. According to Groening, Fox executives were not supporters of the show.[41] Although Futurama was never officially canceled, midway through the production of the fourth season, Fox decided to stop buying episodes of Futurama, letting it go out of production before the fall 2003 lineup.[42][43]\\r\\nIn 2002, the Cartoon Network acquired syndication rights to Futurama and Family Guy, another animated show Fox had canceled, for its Adult Swim block. The run on Adult Swim revived interest in both series, and when Family Guy found success in direct-to-DVD productions, Futurama's producers decided to try the same.[44][45] In 2005, Comedy Central entered negotiations to take over the syndication rights, during which they discussed the possibility of producing new episodes. In 2006, it was announced that four straight-to-DVD films would be produced, and later split into 16 episodes comprising a fifth season of the show.[46] Since no new Futurama projects were in production at the time of release, the final movie release Into the Wild Green Yonder was designed to stand as the Futurama series finale. However, Groening had expressed a desire to continue the franchise in some form, including as a theatrical film.[47] In an interview with CNN, Groening said that \\"we have a great relationship with Comedy Central and we would love to do more episodes for them, but I don't know... We're having discussions and there is some enthusiasm but I can't tell if it's just me.\\"[48]\\r\\nIn June 2009, 20th Century Fox announced that Comedy Central had picked up the show for 26 new half-hour episodes that began airing on June 24, 2010.[49][50][51] The returning writing crew was smaller than the original crew.[52] It was originally announced that main voice actors West, DiMaggio, and Sagal would return as well, but on July 17, 2009, it was announced that a casting notice was posted to replace the entire cast when 20th Century Fox Television would not meet their salary demands.[53] The situation was later resolved, and the entire original voice-cast returned for the new episodes.\\r\\nNear the end of a message from Maurice LaMarche sent to members of the \\"Save the Voices of Futurama\\" group on Facebook, LaMarche announced that the original cast would be returning for the new episodes.[54] The Toronto Star confirmed, announcing on their website that the original cast of Futurama signed contracts with Fox to return for 26 more episodes.[55] Similarly, an email sent to fans from Cohen and Groening reported that West, Sagal, DiMaggio, LaMarche, MacNeille, Tom, LaMarr, and Herman would all be returning for the revival.[56]\\r\\nCohen told Newsday in August 2009 that the reported 26-episode order means \\"[i]t will be up to 26. I can't guarantee it will be 26. But I think there's a pretty good chance it'll be exactly 26. Fox has been a little bit cagey about it, even internally. But nobody's too concerned. We're plunging ahead\\".[57] Two episodes were in the process of being voice-recorded at that time, with an additional \\"six scripts ... in the works, ranging in scale from 'it's a crazy idea that someone's grandmother thought of' to 'it's all on paper'.[57]\\r\\nWhen Futurama aired June 24, 2010, on Comedy Central, it helped the network to its highest-rated night in 2010 and its highest-rated Thursday primetime in the network's history.[58] In March 2011, it was announced that Futurama had been renewed for a seventh season, consisting of at least 26 episodes, scheduled to air in 2012 and 2013.[5][6] The first episode of season 7 premiered June 20, 2012, on Comedy Central.[59]\\r\\nIn July 2011, it was reported that the show had been picked up for syndication by both local affiliates and WGN America. Broadcast of old episodes began in September 2011.[60] On September 19, 2011, WGN America began re-running Futurama, and now airs the series weeknights during the overnight hours, and once on Saturday nights.[61] Futurama has since doubled its viewership in syndication.[62]\\r\\nDue to the uncertain future of the series, there have been four designated series finales. \\"The Devil's Hands Are Idle Playthings\\", Into the Wild Green Yonder, and \\"Overclockwise\\" have all been written to serve as a final episode for the show.[63][64] The episode \\"Meanwhile\\" currently stands as the show's official series finale.\\r\\nComedy Central announced in April 2013 that they would be airing the final episode on September 4, 2013.[65] The producers said that they are exploring options for the future of the series as \\"[they] have many more stories to tell\\", but would gauge fan reaction to the news.[66] Groening and Cohen have previously expressed a desire to produce a theatrical film or another direct-to-video film upon conclusion of the series.[67]\\r\\nIn an August 2013 interview with Milwaukee Journal Sentinel, Katey Sagal said regarding the series finale, \\"So I don't believe it... I just hold out hope for it because it has such a huge fan base, it's such a smart show, and why wouldn't somebody want to keep making that show; so that's my thought, I'm just in denial that it's over\\". Sagal also mentioned during the same interview that Groening told her at Comic-Con that \\"we'll find a place\\" and \\"don't worry, it's not going to end\\" (in Sagal's words).[68]\\r\\nThe Simpsons episode \\"Simpsorama\\" is an official crossover with Futurama. It originally aired during the twenty-sixth season of The Simpsons on Fox on November 9, 2014, over a year after the series finale aired on Comedy Central.[69][70][71]\\r\\nFuturama is essentially a workplace sitcom, the plot of which revolves around the Planet Express interplanetary delivery company and its employees,[72] a small group that largely fails to conform to future society.[73] Episodes usually feature the central trio of Fry, Leela, and Bender, though occasional storylines center on the other main characters.\\r\\nFuturama is set in New New York at the turn of the 31st century, in a time filled with technological wonders. The city of New New York has been built over the ruins of present-day New York City, which has become a catacomb like space that acts as New New York's sewer, referred to as \\"Old New York\\". Various devices and architecture are similar to the Populuxe style. Global warming, inflexible bureaucracy, and substance abuse are a few of the subjects given a 31st-century exaggeration in a world where the problems have become both more extreme and more common. Just as New York has become a more extreme version of itself in the future, other Earth locations are given the same treatment; Los Angeles, for example, is depicted as a smog-filled apocalyptic wasteland.\\r\\nNumerous technological advances have been made between the present day and the 31st century. The Head Museum, which keeps a collection of heads alive in jars and was invented by Ron Popeil (who has a guest cameo in \\"A Big Piece of Garbage\\"), has resulted in many historical figures and current celebrities being present, including Groening himself; this became the writers' device to feature and poke fun at contemporary celebrities in the show. Curiously, several of the preserved heads shown are those of people who were already dead well before the advent of this technology; one of the most prominent examples of this anomaly is Earth president Richard Nixon, who died in 1994 and appears in numerous episodes. The Internet, while being fully immersive and encompassing all senses? even featuring its own digital world (similar to Tron or The Matrix)? is slow and largely consists of pornography, pop-up ads, and \\"filthy\\" (or Filthy Filthy) chat rooms. Some of it is edited to include educational material ostensibly for youth. Television is still a primary form of entertainment. Self-aware robots are a common sight, and are the main cause of global warming thanks to the exhaust from their alcohol-powered systems. The wheel is obsolete (no one but Fry even seems to recognize the design),[78] having been forgotten and replaced by hover cars and a network of large, clear pneumatic transportation tubes.\\r\\nEnvironmentally, common animals still remain, alongside mutated, cross-bred (sometimes with humans) and extraterrestrial animals. Ironically, spotted owls are often shown to have replaced rats as common household pests. Although rats still exist, sometimes rats act like pigeons, though pigeons still exist, as well. Pine trees, anchovies and poodles have been extinct for 800 years. Earth still suffers the effects of greenhouse gases, although in one episode Leela states that its effects have been counteracted by nuclear winter. In another episode, the effects of global warming have been somewhat mitigated by the dropping of a giant ice cube into the ocean, and later by pushing Earth farther away from the sun, which also extended the year by one week.\\r\\nFuturama's setting is a backdrop, and the writers are not above committing continuity errors if they serve to further the gags. For example, while the pilot episode implies that the previous Planet Express crew was killed by a space wasp, the later episode \\"The Sting\\" is based on the crew having been killed by space bees instead.[79] The \\"world of tomorrow\\" setting is used to highlight and lampoon issues of today and to parody the science fiction genre.[32]\\r\\nReligion is a prominent part of society, although the dominant religions have evolved. A merging of the major religious groups of the 20th century has resulted in the First Amalgamated Church,[80] while Voodoo is now mainstream. New religions include Oprahism, Robotology, and the banned religion of Star Trek fandom. Religious figures include Father Changstein-El-Gamal, the Robot Devil, Reverend Lionel Preacherbot, and passing references to the Space Pope, who appears to be a large crocodile-like creature. Several major holidays have robots associated with them, including the murderous Robot Santa and Kwanzaa-bot. While very few episodes focus exclusively on religion within the Futurama universe, they do cover a wide variety of subjects including predestination, prayer, the nature of salvation, and religious conversion.[80]\\r\\nMuch like the opening sequence in The Simpsons with its chalkboard, sax solo, and couch gags, Futurama has a distinctive opening sequence featuring minor gags. As the show begins, blue lights fill the screen and the Planet Express Ship flies across the screen with the title of the show being spelled out in its wake. Underneath the title is a joke caption such as \\"Painstakingly drawn before a live audience\\" or \\"When you see the robot: DRINK!\\"[81] After flying through downtown New New York and past various recurring characters, the Planet Express ship crashes into a large screen showing a short clip from a classic cartoon. These have included clips from Quasi at the Quackadero, Looney Tunes shorts, cartoons produced by Max Fleischer, a short of The Simpsons from a Tracey Ullman episode,[82] the show's own opening sequence in \\"The Devil's Hands Are Idle Playthings\\" or a scene from the episode. Most episodes in Season 6 use an abridged opening sequence, omitting the brief clip of a classic cartoon. \\"That Darn Katz!\\", \\"Benderama\\" and \\"Yo Leela Leela\\" have been the only episodes since \\"Spanish Fry\\" to feature a classic cartoon clip. Several episodes begin with a cold opening before the opening sequence, although these scenes do not always correspond with the episode's plot. The opening sequence has been lampooned several times within the show, in episodes including \\"That's Lobstertainment!\\", \\"The Problem with Popplers\\", as \\"Future-roma\\" in \\"The Duh-Vinci Code\\" and as \\"Futurella\\" in \\"Lrrreconcilable Ndndifferences\\".\\r\\nSeries director Scott Vanzo has remarked on the difficulty of animating the sequence. It took four to five weeks to fully animate the sequence, and it consists of over 80 levels of 3D animation composited together.[83] It takes approximately one hour to render a single frame, and each second of the sequence consists of around 30 frames.[84]\\r\\nBender's Big Score has an extended opening sequence, introducing each of the main characters. In The Beast with a Billion Backs and Bender's Game the ship passes through the screen's glass and temporarily becomes part of the environment depicted thereina pastiche of Disney's Steamboat Willie and Yellow Submarine respectivelybefore crashing through the screen glass on the way out. In Into the Wild Green Yonder, a completely different opening sequence involves a trip through a futuristic version of Las Vegas located on Mars. The theme tune is sung by Seth MacFarlane and is different from the standard theme tune. The end of the film incorporates a unique variation of the opening sequence; as the Planet Express Ship enters a wormhole, it converts into a pattern of lights similar to the lights that appear in the opening sequence.\\r\\nThe Futurama theme was created by Christopher Tyng. The theme is played on the tubular bells but is occasionally remixed for use in specific episodes, including a version by the Beastie Boys used for the episode \\"Hell Is Other Robots\\", in which they guest starred.[81] The theme also samples a drum break originating from \\"Amen, Brother\\" by American soul group The Winstons; however, the drum break is replaced in Season 6. A remixed rendition of the theme is used in Season 5, which features altered instruments and a lower pitch. Season 6 also uses this remix, but it has been reduced again in pitch and tempo. The theme has been noted for its similarities to Pierre Henry's 1967 Psych Rock.[85]\\r\\nIt was originally intended for the Futurama theme to be remixed in every episode.[86] This was first trialled in the opening sequence for \\"Mars University\\", however it was realized upon broadcast that the sound did not transmit well through most television sets and the idea was subsequently abandoned.[87] Despite this, beatbox renditions of the theme performed by Billy West and John DiMaggio are used for the episodes \\"Bender Should Not Be Allowed on TV\\" and \\"Spanish Fry\\".\\r\\nThere are three alternative alphabets that appear often in the background of episodes, usually in the forms of graffiti, advertisements, or warning labels. Nearly all messages using alternative scripts transliterate directly into English. The first alphabet consists of abstract characters and is referred to as Alienese,[74] a simple substitution cipher from the Latin alphabet.[88] The second alphabet uses a more complex modular addition code, where the \\"next letter is given by the summation of all previous letters plus the current letter\\".[89] The codes often provide additional jokes for fans dedicated enough to decode the messages.[32] The third language sometimes used is Hebrew. Aside from these alphabets, most of the displayed wording on the show uses the Latin alphabet.\\r\\nSeveral English expressions have evolved since the present day. For example, the word Christmas has been replaced with Xmas (pronounced \\"ex-mas\\"), and the word ask with aks (pronounced axe). According to David X. Cohen it is a running joke that the French language is extinct in the Futurama universe (though the culture remains alive), much like Latin is in the present.[90] In the French dubbing of the show, German is used as the extinct language instead.\\r\\nAlthough the series uses a wide range of styles of humor, including self-deprecation, black comedy, off-color humor, slapstick, and surreal humor, its primary source of comedy is its satirical depiction of everyday life in the future and its parodical comparisons to the present.[72] Groening notes that, from the show's conception, his goal was to make what was, on the surface, a goofy comedy that would have underlying \\"legitimate literary science fiction concepts\\".[91] The series contrasted \\"low culture\\" and \\"high culture\\" comedy; for example, Bender's catchphrase is the insult \\"Bite my shiny metal ass\\" while his most terrifying nightmare is a vision of the number 2, a joke referring to the binary numeral system (Fry assures him, \\"there's no such thing as two\\").[72]\\r\\nThe series developed a cult following partially due to the large number of in-jokes it contains, most of which are aimed at \\"nerds\\".[72] In commentary on the DVD releases, David X. Cohen points out and sometimes explains his \\"nerdiest joke[s]\\".[92] These included mathematical jokes? such as \\"Loew's \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n?\\r\\n\\r\\n0\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n{\\\\displaystyle \\\\aleph _{0}}\\r\\n\\r\\n-plex\\" (aleph-null-plex) movie theater,[92]? as well as various forms of science humor? for example, Professor Farnsworth, at a racetrack, complains about the use of a quantum finish to decide the winner, exclaiming \\"No fair! You changed the outcome by measuring it\\", a reference to the Heisenberg Uncertainty Principle.[72][93] In the season six episode \\"Law and Oracle\\", Fry and the robot peace officer URL track down a traffic violator who turns out to be Erwin Schr?dinger, the 20th-century quantum physicist. On the front seat of the car is a box, and when questioned about the contents, Schr?dinger replies \\"A cat, some poison, and a cesium atom\\". Fry asks if the cat is alive or dead, and Schr?dinger answers \\"It's a superposition of both states until you open the box and collapse the wave function.\\" When Fry opens the box, the cat jumps out and attacks him. The run is a reference to the Schr?dinger's cat thought experiment of quantum mechanics. The series makes passing references to quantum chromodynamics (the appearance of Strong Force-brand glue),[94] computer science (two separate books in a closet labeled P and NP respectively, referring to the possibility that P and NP-complete problem classes are distinct),[95] electronics (an X-ray? or more accurately, an \\"F-ray\\"? of Bender's head reveals a 6502 microprocessor),[96] and genetics (a mention of Bender's \\"robo- or R-NA\\").[97] The show often features subtle references to classic science fiction. These are most often to Star Trek? many soundbites are used in homage[72]? but also include the reference to the origin of the word robot made in the name of the robot-dominated planet Chapek 9,[98] and the black rectangular monolith labeled \\"Out of Order\\" in orbit around Jupiter (a reference to Arthur C. Clarke's Space Odyssey series).[99] Bender and Fry sometimes watch a television show called The Scary Door, a humorous parody of The Twilight Zone.[100]\\r\\nJournalist/critic Frank Lovece in Newsday contrasted the humor tradition of Groening's two series, finding that, \\"The Simpsons echoes the strains of American-Irish vaudeville humor? the beer-soaked, sneaking-in-late-while-the-wife's-asleep comedy of Harrigan and Hart, McNulty and Murray, the Four Cohans (which, yes, included George M.) and countless others: knockabout yet sentimental, and ultimately about the bonds of blood family. Futurama, conversely, stems from Jewish-American humor, and not just in the obvious archetype of Dr. Zoidberg. From vaudeville to the Catskills to Woody Allen, it's that distinctly rueful humor built to ward away everything from despair to petty annoyance? the 'You gotta do what you gotta do' philosophy that helps the 'Futurama' characters cope in a mega-corporate world where the little guy is essentially powerless.\\"[57] Animation maven Jerry Beck concurred: \\"I'm Jewish, and I know what you're saying. Fry has that [type of humor], Dr. Zoidberg, all the [vocal artist] Billy West characters. I see it. The bottom line is, the producers are trying to make sure the shows are completely different entities.\\"[57]\\r\\nFuturama's 7:00?pm Sunday timeslot caused the show to often be pre-empted by sports and usually have a later than average season premiere. It also allowed the writers and animators to get ahead of the broadcast schedule so that episodes intended for one season were not aired until the following season. By the beginning of the fourth broadcast season, all the episodes to be aired that season had already been completed and writers were working at least a year in advance.[25]\\r\\nWhen Futurama debuted in the Fox Sunday night line-up at 8:30?pm between The Simpsons and The X-Files on March 28, 1999, it managed 19?million viewers, tying for 11th overall in that week's Nielsen ratings.[101] The following week, airing at the same time, Futurama drew 14.2?million viewers. The third episode, the first airing on Tuesday, drew 8.85?million viewers.[102] Though its ratings were well below The Simpsons, the first season of Futurama rated higher than competing animated series: King of the Hill, Family Guy, Dilbert, South Park, and The PJs.[103]\\r\\nWhen Futurama was effectively canceled in 2003, it had averaged 6.4?million viewers for the first half of its fourth broadcast season.[104]\\r\\nIn late 2002, Cartoon Network acquired exclusive cable syndication rights to Futurama for a reported ten million dollars.[105] In January 2003,[105] the network began airing Futurama episodes as the centerpiece to the expansion of their Adult Swim cartoon block. In October 2005, Comedy Central picked up the cable syndication rights to air Futurama's 72-episode run at the start of 2008, following the expiration of Cartoon Network's contract.[106] A Comedy Central teaser trailer announced the return of Futurama March 23, 2008,[107] which was Bender's Big Score divided into four episodes followed by the other three movies. The series also airs in syndication in many countries around the world.[citation needed]\\r\\nOn June 24, 2010, the season six premiere, \\"Rebirth\\", drew 2.92 million viewers in the 10?pm timeslot on Comedy Central.[108] The second episode of the sixth season, \\"In-A-Gadda-Da-Leela\\", aired at 10:30?pm, immediately following the season premiere. \\"In-A-Gadda-Da-Leela\\" drew 2.78 million viewers.[108] This was the series' premiere on the network, with original episodesthe fifth season had previously aired on the network, but it had originally been released in the form of the four direct-to-video films.\\r\\nIn January 2009, IGN named Futurama as the eighth best in the \\"Top 100 Animated TV Series\\".[123]\\r\\nAt the 2010 San Diego Comic-Con International, Guinness World Records presented Futurama with the record for \\"Current Most Critically Acclaimed Animated Series\\".[124]\\r\\nIn 2014, WatchMojo.com ranked Futurama as the second best cartoon to have been cancelled.[125]\\r\\nIn 2016, Rolling Stone ranked it as the thirtieth best science fiction television show ever.[126]\\r\\nFirst started in November 2000, Futurama Comics is a comic book series published by Bongo Comics based in the Futurama universe.[127] While originally published only in the US, a UK, German and Australian version of the series is also available.[128] In addition, three issues were published in Norway. Other than a different running order and presentation, the stories are the same in all versions. While the comics focus on the same characters in the Futurama fictional universe, the comics may not be canonical as the events portrayed within them do not necessarily have any effect upon the continuity of the show.\\r\\nLike the TV series, each comic (except US comic #20) has a caption at the top of the cover. For example: \\"Made In The USA! (Printed in Canada).\\" Some of the UK and Australian comics have different captions on the top of their comics (for example, the Australian version of #20 says \\"A 21st Century Comic Book\\" across the cover, while the US version does not have a caption on that issue). All series contain a letters page, artwork from readers, and previews of other upcoming Bongo comics.\\r\\nWhen Comedy Central began negotiating for the rights to air Futurama reruns, Fox suggested that there was a possibility of also creating new episodes. Negotiations were already underway with the possibility of creating two or three straight-to-DVD films. When Comedy Central committed to sixteen new episodes, it was decided that four films would be produced.[46] On April 26, 2006, Groening noted in an interview that co-creator David X. Cohen and numerous writers from the original series would be returning to work on the movies.[129] All the original voice actors participated. In February 2007, Groening explained the format of the new stories: \\"[The crew is] writing them as movies and then we're going to chop them up, reconfigure them, write new material and try to make them work as separate episodes.\\"[130]\\r\\nThe first movie, Bender's Big Score, was written by Ken Keeler and Cohen, and includes return appearances by the Nibblonians, Seymour, Barbados Slim, Robot Santa, the \\"God\\" space entity, Al Gore, and Zapp Brannigan.[131] It was animated in widescreen and was released on standard DVD on November 27, 2007, with a possible Blu-ray Disc release to follow.[132] A release on HD DVD was rumored but later officially denied. Futurama: Bender's Big Score was the first DVD release for which 20th Century Fox implemented measures intended to reduce the total carbon footprint of the production, manufacturing, and distribution processes. Where it was not possible to completely eliminate carbon, output carbon offsets were used, thus making the complete process carbon neutral.[133]\\r\\nThe second movie, The Beast with a Billion Backs, was released on June 24, 2008. The third movie, Bender's Game, was released on DVD and Blu-ray Disc[134] on November 3, 2008, in the UK, November 4, 2008, in the USA, and December 10, 2008, in Australia. The fourth movie, Into the Wild Green Yonder, was released on DVD and Blu-ray Disc on February 24, 2009.[135]\\r\\nOn September 15, 2000, Unique Development Studios acquired the license to develop a Futurama video game for consoles and handheld systems. Fox Interactive signed on to publish the game.[136] Sierra Entertainment later became the game's publisher, and it was released on August 14, 2003.[137] Versions are available for PlayStation 2 and Xbox, both of which use cel-shading technology. However, the game was subsequently canceled on the GameCube and Game Boy Advance in North America and Europe.\\r\\nFuturama: Worlds of Tomorrow was released for Android and iOS in 2017.[138]\\r\\nFuturama premiered and originally aired in the United States on the Fox network, March 28, 1999?ÿ August 10, 2003. Adult Swim carried the series in the US January 1, 2003?ÿ December 31, 2007, followed by Comedy Central March 23, 2008?ÿ September 4, 2013. Syndicated broadcast of the series in the US began in Fall 2011.[139] Futurama began airing on Syfy on November 11, 2017. It has also aired on TBS for a short time[140]\\r\\nCanadian networks YTV, Teletoon at Night and Global Television broadcast Futurama March 28, 1999?ÿ August 10, 2003.[citation needed]\\r\\nThe series was broadcast in Australia on the following stations: Seven Network aired the series from December 2, 1999?ÿ 2004, Fox8 from 2000ÿpresent, Network Ten between 2005ÿ2010, 2012ÿ2014 and on Eleven January 11, 2011 ÿ October 2017.\\r\\nAudiences in New Zealand received the series on the following stations: TV2 March 28, 1999?ÿ 2005, the BOX from 2000ÿ2010, C4 from 2005ÿ2011, Comedy Central between 2010ÿpresent, on Four from 2011ÿ2013 and Duke (2017-present).\\r\\nFuturama currently airs in Ireland on networks 3e, Comedy Central, Pick and Sky1.\\r\\nThe series was carried by the following networks in the United Kingdom: Sky1 from September 21, 1999?ÿ present, Channel 4 from 2000ÿ2006, FX UK from 2004ÿ2005, Sky Living from 2005, Sky Two (until 2016), and Pick from 2006ÿ2016.\\r\\nThe series is shown on Fox in Latin America and in the Caribbean.\\r\\nWhile relatively uncommon, several action and tin figurines of various characters and items from the show have been made and are being sold by various hobby/online stores. When the show was initially licensed, plans were made with Rocket USA to produce wind-up, walking tin figurines of both Bender and Nibbler with packaging artwork done by the original artists for the series.[141] The Bender toy included a cigar and bottle of \\"Olde Fortran Malt Liquor\\" and featured moving eyes, antenna, and a functioning compartment door; it received an \\"A\\" rating from Sci Fi Weekly.[142] A can of Slurm actually contains a deck of cards featuring the Planet Express crew as the face cards. A two-deck pack of cards was also released.\\r\\nI-Men released five two-packs of 2.5-inch (64?mm) high figures: Fry and Calculon; Zoidberg and Morbo; Professor Farnsworth and URL; Robot Devil and Bender; Leela and Roberto. Each figure comes with a corresponding collectable coin that can also double as a figure stand.\\r\\nThe collectible releases include a set of bendable action figures, including Lieutenant Kif Kroker, Turanga Leela, and Bender. There have also been a few figures released by Moore Action Collectibles, including Fry, Turanga Leela, Bender, and the Planet Express Ship. In late 2006, Rocket USA brought out a limited edition \\"super\\" heavyweight die-cast Bender. Another special edition Bender figure was released at the San Diego Comic Con (SDCC) in 2006; the figure was called \\"Glorious Golden Bender\\".\\r\\nToynami produced new Futurama figures.[143] The first series of the Toynami figures is separated into 3 waves: wave one, released in September 2007, featured Fry and Zoidberg; wave two, released in January 2008, consisted of Leela and Zapp (who comes with Richard Nixon's head-in-a-jar); the third wave, released in June 2008, includes Bender and Kif. Each figure comes with a build-a-figure piece to assemble the Robot Devil. The second series of Toynami figures includes Captain Yesterday (A Fry variant from \\"Less Than Hero\\") and Nudar in the first wave. The second wave includes Super-King (Bender from \\"Less Than Hero\\") and Calculon, and the third wave includes Clobberella (Leela from \\"Less Than Hero\\") and Amy Wong. The figures in series 2 include pieces to build Robot Santa. The third, and current, series of the Toynami line includes Professor Farnsworth (who comes with Nibbler), and Hermes. Wave 2 was released in February 2010 and includes Chef Bender and Mom, who comes with a removable fat-suit. Series 3 figures come with pieces to build Roberto. Series 9 will include URL and Wooden Bender (from \\"Obsoletely Fabulous\\") and Series 10 will include Clamps and Joey Mousepad. Series 11 consists of The Donbot and Flexo. That wave will not have a specific Build A Bot character, planned Morbo. All figures feature multiple points of articulation and character-specific accessories.\\r\\nIn August 2009 Kidrobot released 3-inch vinyl mini figurines of some of the cast. These are sold in \\"blind\\" box form and each comes with an accessory. Probability of receiving each of the characters is printed on the side, with two special mystery characters having unknown probabilities. 6-inch versions of some of the figures are also available as limited editions, but these are not sold as \\"blind\\" boxes.","input":"When did the last episode of futurama air?"},{"output":"August 1978","context":"National Commission for Scheduled Castes (NCSC) is an Indian constitutional body established with a view to provide safeguards against the exploitation of Scheduled Castes to promote and protect their social, educational, economic and cultural interests, special provisions were made in the Constitution.[1]\\r\\n\\r\\n\\r\\nThe first Commission for Scheduled Castes and Scheduled Tribes was set up in August 1978 with Bhola Paswan Shastri as Chairman and other four Members. In 1990 the Commission for SCs and STs was renamed as the National Commission for Scheduled Castes and Scheduled Tribes were formed as per 1987[2] and it was set up as a National Level Advisory Body to advise the Government on broad policy issues and levels of development of Scheduled Castes and Scheduled Tribes.\\r\\nThe first Commission was constituted in 1992 with S. H. Ramdhan as Chairman.\\r\\nThe second Commission was constituted in October 1995 with H. Hanumanthappa as chairman.\\r\\nThe third Commission was constituted in December 1998 with Dileep Singh Bhuria as the Chairman.\\r\\nThe fourth Commission was constituted in March 2002 with Dr. Bizay Sonkar Shastri as the Chairperson.\\r\\nConsequent upon the Constitution (Eighty-Ninth Amendment) Act, 2003 the erstwhile National Commission for Scheduled Castes and Scheduled Tribes has been replaced by\\r\\n(1) National Commission for Scheduled Castes and\\r\\n(2) National Commission for Scheduled Tribes.\\r\\nThe first NCSC was constituted on 2004 with Suraj Bhan as the Chairperson. The second was constituted on May 2007 (chairperson: Buta Singh); the third from October 2010 (P. L. Punia); and the fourth from 2013, also with Punia as chairperson. The fifth NCSC began work in 2017 under chairmanship of Ram Shankar Katheria.[3]\\r\\nThe following are the functions of the commission:[4]","input":"When was the commission fir sc/st established?"},{"output":"January 1898","context":"USS Maine (ACR-1) is an American naval ship that sank in Havana Harbor during the Cuban revolt against Spain, an event that became a major political issue in the United States.\\r\\nCommissioned in 1895, this was the first United States Navy ship to be named after the state of Maine.[a][1] Originally classified as an armored cruiser, she was built in response to the Brazilian battleship?Riachuelo and the increase of naval forces in Latin America. Maine and her near-sister ship Texas reflected the latest European naval developments, with the layout of her main armament resembling that of the British ironclad Inflexible and comparable Italian ships. Her two gun turrets were staggered en chelon, rather than on the centerline, with the fore gun sponsoned out on the starboard side of the ship and the aft gun on the port side,[2] with cutaways in the superstructure to allow both to fire ahead, astern or across her deck. She dispensed with full masts thanks to the increased reliability of steam engines by the time of her construction.\\r\\nDespite these advances, Maine was out of date by the time she entered service, due to her protracted construction period and changes in the role of ships of her type, naval tactics and technology. It took nine years to complete, and nearly three years for the armor plating alone.[2] The general use of steel in warship construction precluded the use of ramming without danger to the attacking vessel. The potential for blast damage from firing end on or cross-deck discouraged en chelon gun placement. The changing role of the armored cruiser from a small, heavily armored substitute for the battleship to a fast, lightly armored commerce raider also hastened her obsolescence. Despite these disadvantages, Maine was seen as an advance in American warship design.\\r\\nMaine is best known for her loss in Havana Harbor on the evening of 15 February 1898. Sent to protect U.S. interests during the Cuban revolt against Spain, she exploded suddenly, without warning, and sank quickly, killing nearly three quarters of her crew. The cause and responsibility for her sinking remained unclear after a board of inquiry investigated. Nevertheless, popular opinion in the U.S., fanned by inflammatory articles printed in the \\"yellow press\\" by William Randolph Hearst and Joseph Pulitzer, blamed Spain. The phrase, \\"Remember the Maine! To hell with Spain!\\", became a rallying cry for action, which came with the SpanishÿAmerican War later that year. While the sinking of Maine was not a direct cause for action, it served as a catalyst, accelerating the approach to a diplomatic impasse between the U.S. and Spain.\\r\\nThe cause of Maine's sinking remains a subject of speculation. In 1898, an investigation of the explosion was carried out by a naval board appointed under the McKinley Administration. The consensus of the board was that Maine was destroyed by an external explosion from a mine. However, the validity of this investigation has been challenged. George W. Melville, a chief engineer in the Navy, proposed that a more likely cause for the sinking was from a magazine explosion within the vessel. The Navy's leading ordnance expert, Philip R. Alger, took this theory further by suggesting that the magazines were ignited by a spontaneous fire in a coal bunker.[3] The coal used in Maine was bituminous coal, which is known for releasing firedamp, a gas that is prone to spontaneous explosions. There is stronger evidence that the explosion of Maine was caused by an internal coal fire which ignited the magazines. This was a likely cause of the explosion, rather than the initial hypothesis of a mine. The ship lay at the bottom of the harbor until 1911. A cofferdam was then built around the wreck.[4] The hull was patched up until the ship was afloat, then towed to sea and sunk. The Maine now lies on the sea-bed 3,600 feet (1,100?m) below the surface.\\r\\n\\r\\n\\r\\nThe delivery of the Brazilian battleship?Riachuelo in 1883 and the acquisition of other modern armored warships from Europe by Brazil, Argentina and Chile shortly afterwards, alarmed the United States government, as the Brazilian Navy was now the most powerful in the Americas.[5] The chairman of the House Naval Affairs Committee, Hilary A. Herbert, stated to Congress: \\"if all this old navy of ours were drawn up in battle array in mid-ocean and confronted by Riachuelo it is doubtful whether a single vessel bearing the American flag would get into port.\\"[6] These developments helped bring to a head a series of discussions that had been taking place at the Naval Advisory Board since 1881. The board knew at that time that the U.S. Navy could not challenge any major European fleet; at best, it could wear down an opponent's merchant fleet and hope to make some progress through general attrition there. Moreover, projecting naval force abroad through the use of battleships ran counter to the government policy of isolationism. While some on the board supported a strict policy of commerce raiding, others argued it would be ineffective against the potential threat of enemy battleships stationed near the American coast. The two sides remained essentially deadlocked until Riachuelo manifested.[7]\\r\\nThe board, now confronted with the concrete possibility of hostile warships operating off the American coast, began planning for ships to protect it in 1884. The ships had to fit within existing docks and had to have a shallow draft to enable them to use all the major American ports and bases. The maximum beam was similarly fixed, and the board concluded that at a length of about 300 feet (91?m), the maximum displacement would be about 7,000 tons. A year later the Bureau of Construction and Repair (C & R) presented two designs to Secretary of the Navy William Collins Whitney, one for a 7,500-ton battleship and one for a 5,000-ton armored cruiser. Whitney decided instead to ask Congress for two 6,000-ton warships, and they were authorized in August 1886. A design contest was held, asking naval architects to submit designs for the two ships: armored cruiser Maine and battleship Texas. It was specified that Maine had to have a speed of 17 knots (31?km/h; 20?mph), a ram bow, and a double bottom, and be able to carry two torpedo boats. Her armament was specified as: four 10-inch (254?mm) guns, six 6-inch (152?mm) guns, various light weapons, and four torpedo tubes. It was specifically stated that the main guns \\"must afford heavy bow and stern fire.\\"[8] Armor thickness and many details were also defined. Specifications for Texas were similar, but demanded a main battery of two 12-inch (305?mm) guns and slightly thicker armor.[9]\\r\\nThe winning design for Maine was from Theodore D. Wilson, who served as chief constructor for C & R and was a member on the Naval Advisory Board in 1881. He had designed a number of other warships for the navy.[10] The winning design for Texas was from a British designer, William John, who was working for the Barrow Shipbuilding Company at that time. Both designs resembled the Brazilian battleship Riachuelo, having the main gun turrets sponsoned out over the sides of the ship and echeloned.[11] The winning design for Maine, though conservative and inferior to other contenders, may have received special consideration due to a requirement that one of the two new ships be Americanÿdesigned.[12]\\r\\nCongress authorized construction of Maine on 3 August 1886, and her keel was laid down on 17 October 1888, at the Brooklyn Navy Yard. She was the largest vessel built in a U.S. Navy yard up to that time.[13]\\r\\nMaine's building time of nine years was unusually protracted, due to the limits of U.S. industry at the time. (The delivery of her armored plating took three years and a fire in the drafting room of the building yard, where Maine's working set of blueprints were stored, caused further delay.) In those nine years, naval tactics and technology changed radically and left Maine's actual role in the navy ill-defined. At the time she was laid down, armored cruisers such as Maine were intended to serve as small battleships on overseas service and were built with heavy belt armor. Great Britain, France and Russia had constructed such ships to serve this purpose and sold others of this type, including Riachuelo, to second-rate navies. Within a decade, this role had changed to commerce raiding, for which fast, long-range vessels, with only limited armor protection, were needed. The advent of lightweight armor, such as Harvey steel, made this transformation possible.[14]\\r\\nAs a result of these changing priorities, Maine was caught between two separate positions and could not perform either one adequately. She lacked both the armor and firepower to serve as a ship-of-the-line against enemy battleships and the speed to serve as a cruiser. Nevertheless, she was expected to fulfill more than one tactical function.[15] In addition, because of the potential of a warship sustaining blast damage to herself from cross-deck and end-on fire, Maine's main-gun arrangement was obsolete by the time she entered service.[11]\\r\\nMaine was 324?feet 4?inches (98.9?m) long overall, with a beam of 57 feet (17.4?m), a maximum draft of 22?feet 6?inches (6.9?m) and a displacement of 6,682 long tons (6,789.2?t).[16] She was divided into 214 watertight compartments.[17] A centerline longitudinal watertight bulkhead separated the engines and a double bottom covered the hull only from the foremast to the aft end of the armored citadel, a distance of 196 feet (59.7?m). She had a metacentric height of 3.45 feet (1.1?m) as designed and was fitted with a ram bow.[18]\\r\\nMaine's hull was long and narrow, more like a cruiser than that of Texas, which was wide-beamed. Normally, this would have made Maine the faster ship of the two. However, Maine's weight distribution was ill-balanced, which slowed her considerably. Her main turrets, awkwardly situated on a cut-away gundeck, were nearly awash in bad weather. Because they were mounted toward the ends of the ship, away from its center of gravity, Maine was also prone to greater motion in heavy seas. While she and Texas were both considered seaworthy, the latter's high hull and guns mounted on her main deck made her the drier ship.[19]\\r\\nThe two main gun turrets were sponsoned out over the sides of the ship and echeloned to allow both to fire fore and aft. The practice of en echelon mounting had begun with Italian battleships designed in the 1870s by Benedetto Brin and followed by the British Navy with HMS?Inflexible, which was laid down in 1874 but not commissioned until October 1881.[20] This gun arrangement met the design demand for heavy end-on fire in a ship-to-ship encounter, tactics which involved ramming the enemy vessel.[11] The wisdom of this tactic was purely theoretical at the time it was implemented. A drawback of an en echelon layout limited the ability for a ship to fire broadside, a key factor when employed in a line of battle. To allow for at least partial broadside fire, Maine's superstructure was separated into three structures. This technically allowed both turrets to fire across the ship's deck (cross-deck fire), between the sections. However, this ability was still significantly limited as the superstructure restricted each turret's arc of fire.[8]\\r\\nThis plan and profile view show Maine with eight six-pounder guns (one is not seen on the port part of the bridge but that is due to the bridge being cut away in the drawing). Another early published plan shows the same. In both cases the photographs show a single extreme bow mounted six-pounder. However, careful examination of Maine photographs confirm that she did not carry that gun. Maine's armament set up in the bow was not identical to the stern which had a single six-pounder mounted at extreme aft of the vessel. Maine carried two six-pounders forward, two on the bridge and three on the stern section, all one level above the abbreviated gun deck that permitted the ten-inch guns to fire across the deck. The six-pounders located in the bow were positioned more forward than the pair mounted aft which necessitated the far aft single six-pounder.\\r\\nMaine was the first U.S. capital ship to have its power plant given as high a priority as its fighting strength.[21] Her machinery, built by the N. F. Palmer Jr. & Company's Quintard Iron Works of New York,[22] was the first designed for a major ship under the direct supervision of Arctic explorer and soon-to-be commodore, George Wallace Melville.[23] She had two inverted vertical triple-expansion steam engines, mounted in watertight compartments and separated by a fore-to-aft bulkhead, with a total designed output of 9,293 indicated horsepower (6,930?kW). Cylinder diameters were 35.5 inches (900?mm) (high-pressure), 57 inches (1,400?mm) (intermediate-pressure) and 88 inches (2,200?mm) (low-pressure). Stroke for all three pistons was 36 inches (910?mm).[17]\\r\\nMelville mounted Maine's engines with the cylinders in vertical mode, a departure from conventional practice. Previous ships had had their engines mounted in horizontal mode, so that they would be completely protected below the waterline. Melville believed a ship's engines needed ample room to operate and that any exposed parts could be protected by an armored deck. He therefore opted for the greater efficiency, lower maintenance costs and higher speeds offered by the vertical mode.[24][25] Also, the engines were constructed with the high-pressure cylinder aft and the low-pressure cylinder forward. This was done, according to the ship's chief engineer, A. W. Morley, so the low-pressure cylinder could be disconnected when the ship was under low power. This allowed the high and intermediate-power cylinders to be run together as a compound engine for economical running.[clarification needed]\\r\\nEight single-ended Scotch marine boilers provided steam to the engines at a working pressure of 135 pounds per square inch (930?kPa; 9.5?kgf/cm2) at a temperature 364?F (184?C). On trials, she reached a speed of 16.45 knots (30.47?km/h; 18.93?mph), failing to meet her contract speed of 17 knots (31?km/h; 20?mph). She carried a maximum load of 896 long tons (910?t) of coal[26] in 20 bunkers, 10 on each side, which extended below the protective deck. Wing bunkers at each end of each fire room extended inboard to the front of the boilers.[17] This was actually a very low capacity for a ship of Maine's rating, which limited her time at sea and her ability to run at flank speed, when coal consumption increased dramatically. Maine's overhanging main turrets also prevented coaling at sea, except in the calmest of waters; otherwise, the potential for damage to a collier, herself or both vessels was extremely great.\\r\\nMaine also carried two small dynamos to power her searchlights and provide interior lighting.[27]\\r\\nMaine was designed initially with a three-mast barque rig for auxiliary propulsion, in case of engine failure and to aid long-range cruising.[28] This arrangement was limited to \\"two-thirds\\" of full sail power, determined by the ship's tonnage and immersed cross-section.[29] The mizzen mast was removed in 1892, after the ship had been launched, but before her completion.[28] Maine was completed with a two-mast military rig and the ship never spread any canvas.[30]\\r\\nMaine's main armament consisted of four 10-inch (254?mm)/30 caliber Mark II guns, which had a maximum elevation of 15 and could depress to ?3. Ninety rounds per gun were carried. The ten-inch guns fired a 510 pounds (231?kg) shell at a muzzle velocity of 2,000 feet per second (610?m/s) to a range of 20,000 yards (18,000?m) at maximum elevation.[31] These guns were mounted in twin hydraulically powered Mark 3 turrets, the fore turret sponsoned to starboard and the aft turret sponsoned to port.[5]\\r\\nThe 10\\" guns were initially to be mounted in open barbettes (the C & R proposal blueprint shows them as such). During Maine's extended construction, the development of rapid-fire intermediate-caliber guns, which could fire high-explosive shells, became a serious threat and the navy redesigned Maine with enclosed turrets. Because of the corresponding weight increase, the turrets were mounted one deck lower than planned originally.[30][32] Even with this modification, the main guns were high enough to fire unobstructed for 180 on one side and 64 on the other side.[17] They could also be loaded at any angle of train; initially the main guns of Texas, by comparison, with external rammers, could be loaded only when trained on the centerline or directly abeam, a common feature in battleships built before 1890.[11] However, by 1897, Texas' turrets had been modified with internal rammers to permit much faster reloading.\\r\\nThe en echelon arrangement proved problematic. Because Maine's turrets were not counterbalanced, she heeled over if both were pointed in the same direction, which reduced the range of the guns. Also, cross-deck firing damaged her deck and superstructure significantly due to the vacuum from passing shells.[33] Because of this, and the potential for undue hull stress if the main guns were fired end-on, the en echelon arrangement was not used in U.S. Navy designs after Maine and Texas.[11][33]\\r\\nThe six 6-inch (152?mm)/30 caliber Mark 3 guns were mounted in casemates in the hull, two each at the bow and stern and the last two amidships.[22] Data is lacking, but they could probably depress to ?7 and elevate to +12. They fired shells that weighed 105 pounds (48?kg) with a muzzle velocity of about 1,950 feet per second (590?m/s). They had a maximum range of 9,000 yards (8,200?m) at full elevation.[34]\\r\\nThe anti-torpedo boat armament consisted of seven 57-millimeter (2.2?in) Driggs-Schroeder six-pounder guns mounted on the superstructure deck.[22] They fired a shell weighing about 6?lb (2.7?kg) at a muzzle velocity of about 1,765 feet per second (538?m/s) at a rate of 20 rounds per minute to a maximum range of 8,700 yards (7,955?m).[35] The lighter armament comprised four each 37-millimeter (1.5?in) Hotchkiss and Driggs-Schroeder one-pounder guns. Four of these were mounted on the superstructure deck, two were mounted in small casemates at the extreme stern and one was mounted in each fighting top.[22] They fired a shell weighing about 1.1 pounds (0.50?kg) at a muzzle velocity of about 2,000 feet per second (610?m/s) at a rate of 30 rounds per minute to a range about 3,500 yards (3,200?m).[36]\\r\\nMaine had four 18-inch (457?mm) above-water torpedo tubes, two on each broadside. In addition, she was designed to carry two 14.8 long tons (15.0?t) steam-powered torpedo boats, each with a single 14-inch (356?mm) torpedo tube and a one-pounder gun. Only one was built, but it had a top speed of only a little over 12 knots (22?km/h; 14?mph) so it was transferred to the Naval Torpedo Station at Newport, Rhode Island, as a training craft.[b][37]\\r\\nThe main waterline belt, made of nickel steel, had a maximum thickness of 12 inches (305?mm) and tapered to 7 inches (178?mm) at its lower edge. It was 180 feet (54.9?m) long and covered the machinery spaces and the 10-inch magazines. It was 7 feet (2.1?m) high, of which 3 feet (0.9?m) was above the design waterline. It angled inwards for 17 feet (5.2?m) at each end, thinning to 8 inches (203?mm), to provide protection against raking fire. A 6-inch transverse bulkhead closed off the forward end of the armored citadel. The forward portion of the 2-inch-thick (51?mm) protective deck ran from the bulkhead all the way to the bow and served to stiffen the ram. The deck sloped downwards to the sides, but its thickness increased to 3 inches (76?mm). The rear portion of the protective deck sloped downwards towards the stern, going below the waterline, to protect the propeller shafts and steering gear. The sides of the circular turrets were 8 inches thick. The barbettes were 12 inches thick, with their lower portions reduced to 10 inches. The conning tower had 10-inch walls. The ship's voicepipes and electrical leads were protected by an armored tube 4.5 inches (114?mm) thick.[38]\\r\\nTwo flaws emerged in Maine's protection, both due to technological developments between her laying-down and her completion. The first was a lack of adequate topside armor to counter the effects of rapid-fire intermediate-caliber guns and high-explosive shells. This was a flaw she shared with Texas.[33] The second was the use of nickel-steel armor. Introduced in 1889, nickel steel was the first modern steel alloy armor and, with a figure of merit of 0.67, was an improvement over the 0.6 rating of mild steel used until then. Harvey steel and Krupp armors, both of which appeared in 1893, had merit figures of between 0.9 and 1.2, giving them roughly twice the tensile strength of nickel steel. Although all three armors shared the same density (about 40 pounds per square foot for a one-inch-thick plate), six inches of Krupp or Harvey steel gave the same protection as 10?inches of nickel. The weight thus saved could be applied either to additional hull structure and machinery or to achieving higher speed. The navy would incorporate Harvey armor in the Indiana-class battleships, designed after Maine, but commissioned at roughly the same time.[39][40]\\r\\nMaine was launched on 18 November 1889, sponsored by Alice Tracey Wilmerding, the granddaughter of Navy Secretary Benjamin F. Tracy. Not long afterwards, a reporter wrote for Marine Engineer and Naval Architect magazine, \\"it cannot be denied that the navy of the United States is making rapid strides towards taking a credible position among the navies of the world, and the launch of the new armoured battleship Maine from the Brooklyn Navy Yard ... has added a most powerful unit to the United States fleet of turret ships.\\"[41] In his 1890 annual report to congress, the Secretary of the Navy wrote, \\"the Maine ... stands in a class by herself\\" and expected the ship to be commissioned by July 1892.[13]\\r\\nA three-year delay ensued, while the shipyard waited for nickel steel plates for Maine's armor. Bethlehem Steel Company had promised the navy 300 tons per month by December 1889 and had ordered heavy castings and forging presses from the British firm of Armstrong Whitworth in 1886 to fulfil its contract. This equipment did not arrive until 1889, pushing back Bethlehem's timetable. In response, Navy Secretary Benjamin Tracy secured a second contractor, the newly expanded Homestead mill of Carnegie, Phipps & Company. In November 1890, Tracy and Andrew Carnegie signed a contract for Homestead to supply 6000 tons of nickel steel.[42] However, Homestead was, what author Paul Krause calls, \\"the last union stronghold in the steel mills of the Pittsburgh district.\\" The mill had already weathered one strike in 1882 and a lockout in 1889 in an effort to break the union there. Less than two years later, came the Homestead Strike of 1892, one of the largest, most serious disputes in U.S. labor history.[43]\\r\\nA photo of the christening shows Mrs. Wilmerding striking the bow near the plimsoll line depth of 13 which lead to many comments (much later of course) that the ship was \\"unlucky\\" from the launching.\\r\\nMaine was commissioned on 17 September 1895, under the command of Captain Arent S. Crowninshield.[44] On 5 November 1895, Maine steamed to Sandy Hook Bay, New Jersey. She anchored there two days, then proceeded to Newport, Rhode Island, for fitting out and test firing of her torpedoes. After a trip, later that month, to Portland, Maine, she reported to the North Atlantic Squadron for operations, training manoeuvres and fleet exercises. Maine spent her active career with the North Atlantic Squadron, operating from Norfolk, Virginia along the East Coast of the United States and the Caribbean. On 10 April 1897, Captain Charles Dwight Sigsbee relieved Captain Crowninshield as commander of Maine.[45]\\r\\nThe ship's crew consisted of 355: 26 officers, 290 sailors, and 39 marines. Of these, there were 261 fatalities:\\r\\nOf the 94 survivors, 16 were uninjured.[46]\\r\\nIn January 1898, Maine was sent from Key West, Florida, to Havana, Cuba, to protect U.S. interests during the Cuban War of Independence. Three weeks later, at 21:40, on 15 February, an explosion on board Maine occurred in the Havana Harbor (coordinates: 230807N 822038W).[47] Later investigations revealed that more than 5 long tons (5.1?t) of powder charges for the vessel's six- and ten-inch guns had detonated, obliterating the forward third of the ship.[48] The remaining wreckage rapidly settled to the bottom of the harbor. Most of Maine's crew were sleeping or resting in the enlisted quarters, in the forward part of the ship, when the explosion occurred. In total, 260[49] men lost their lives as a result of the explosion or shortly thereafter, and six[49] more died later from injuries. Captain Sigsbee and most of the officers survived, because their quarters were in the aft portion of the ship. Altogether there were 89 survivors, 18 of whom were officers.[50] On 21 March, the U.S. Naval Court of Inquiry, in Key West, declared that a naval mine caused the explosion.[51]\\r\\nThe New York Journal and New York World, owned respectively by William Randolph Hearst and Joseph Pulitzer, gave Maine intense press coverage, but employed tactics that would later be labeled \\"yellow journalism.\\" Both papers exaggerated and distorted any information they could attain, sometimes even fabricating news when none that fit their agenda was available. For a week following the sinking, the Journal devoted a daily average of eight and a half pages of news, editorials and pictures to the event. Its editors sent a full team of reporters and artists to Havana, including Frederic Remington,[52] and Hearst announced a reward of $50,000 \\"for the conviction of the criminals who sent 258 American sailors to their deaths.\\"[53] The World, while overall not as lurid or shrill in tone as the Journal, nevertheless indulged in similar theatrics, insisting continually that Maine had been bombed or mined. Privately, Pulitzer believed that \\"nobody outside a lunatic asylum\\" really believed that Spain sanctioned Maine's destruction. Nevertheless, this did not stop the World from insisting that the only \\"atonement\\" Spain could offer the U.S. for the loss of ship and life, was the granting of complete Cuban independence. Nor did it stop the paper from accusing Spain of \\"treachery, willingness, or laxness\\" for failing to ensure the safety of Havana Harbor.[54] The American public, already agitated over reported Spanish atrocities in Cuba, was driven to increased hysteria.[55]\\r\\nMaine's destruction did not result in an immediate declaration of war with Spain. However, the event created an atmosphere that virtually precluded a peaceful solution.[56] The SpanishÿAmerican War began in April 1898, two months after the sinking. Advocates of the war used the rallying cry, \\"Remember the Maine! To hell with Spain!\\"[57][58][59][60][61] The episode focused national attention on the crisis in Cuba, but was not cited by the William McKinley administration as a casus belli, though it was cited by some already inclined to go to war with Spain over perceived atrocities and loss of control in Cuba.[62][63]\\r\\nIn addition to the inquiry commissioned by the Spanish government to naval officers Del Peral and De Salas, two Naval Courts of Inquiry were ordered: The Sampson Board in 1898 and the Vreeland board in 1911. In 1976, Admiral Hyman G. Rickover commissioned a private investigation into the explosion, and the National Geographic Society did an investigation in 1999, using computer simulations. All investigations agreed that an explosion of the forward magazines caused the destruction of the ship, but different conclusions were reached as to how the magazines could have exploded.[63][64]\\r\\nThe Spanish inquiry, conducted by Del Peral and De Salas, collected evidence from officers of naval artillery, who had examined the remains of Maine. Del Peral and De Salas identified the spontaneous combustion of the coal bunker, located adjacent to the munition stores in Maine, as the likely cause of the explosion. However, the possibility of other combustibles causing the explosion such as paint or drier products was not discounted. Additional observations included that:\\r\\nThe conclusions of the report were not reported at that time by the American press.[65]\\r\\nIn order to find the cause of the explosion, a naval inquiry was ordered by the United States shortly after the incident, headed by Captain William T. Sampson. Ram܇n Blanco y Erenas, Spanish governor of Cuba, had proposed instead a joint Spanish-American investigation of the sinking.[66] Captain Sigsbee had written that \\"many Spanish officers, including representatives of General Blanco, now with us to express sympathy.\\"[67] In a cable, the Spanish minister of colonies, Segismundo Moret, had advised Blanco \\"to gather every fact you can, to prove the Maine catastrophe cannot be attributed to us.\\"[68]\\r\\nAccording to Dana Wegner, who worked with U.S. Admiral Hyman G. Rickover on his 1974 investigation of the sinking, the Secretary of the Navy had the option of selecting a board of inquiry personally. Instead, he fell back on protocol and assigned the commander-in-chief of the North Atlantic Squadron to do so. The commander produced a list of junior line officers for the board. The fact that the officer proposed to be court president was junior to the captain of Maine, Wegner writes, \\"would indicate either ignorance of navy regulations or that, in the beginning, the board did not intend to examine the possibility that the ship was lost by accident and the negligence of her captain.\\"[this quote needs a citation] Eventually, navy regulations prevailed in leadership of the board; Captain Sampson being senior to Captain Sigsbee.[69]\\r\\nThe board arrived on 21 February and took testimony from survivors, witnesses and divers (who were sent down to investigate the wreck). The Sampson Board produced its findings in two parts: the proceedings, which consisted mainly of testimonies, and the findings, which were the facts, as determined by the court. Between the proceedings and the findings, there was, what Wegner calls, \\"a broad gap\\", where the court \\"left no record of the reasoning that carried it from the oftenÿinconsistent witnesses to [its] conclusion.\\" Another inconsistency, according to Wegner, was that of only one technical witness, Commander George Converse, from the Torpedo Station at Newport, Rhode Island. Captain Sampson read Commander Converse a hypothetical situation of a coal bunker fire igniting the reserve six-inch ammunition, with a resulting explosion sinking the ship. He then asked Commander Converse about the feasibility of such a scenario. Commander Converse \\"simply stated, without elaboration, that he could not realize such an event happening\\".[70]\\r\\nThe board concluded that Maine had been blown up by a mine, which, in turn, caused the explosion of her forward magazines. They reached this conclusion, based on the fact that the majority of witnesses stated that they had heard two explosions and that that part of the keel was bent inwards.[63] The official report from the board, which was presented to the Navy Department in Washington, D.C. on 21 March, specifically stated the following:\\r\\nAt frame 18 the vertical keel is broken in two and the flat keel is bent at an angle similar to the angle formed by the outside bottom plating. [...] In the opinion of the court, this effect could have been produced only by the explosion of a mine situated under the bottom of the ship at about frame 18, and somewhat on the port side of the ship.\\" (part of the court's 5th finding)\\r\\n\\"In the opinion of the court, the Maine was destroyed by the explosion of a submarine mine, which caused the partial explosion of two or more of her forward magazines.\\" (the court's 7th finding) and\\r\\n\\"The court has been unable to obtain evidence fixing the responsibility for the destruction of the Maine upon any person or persons.\\" (the court's 8th finding).[51]\\r\\nIn 1910, the decision was made to do a second Court of Inquiry. The reasons for this were the recovery of the bodies of the victims, so they could be buried in the United States and also a desire for a more thorough investigation. The fact that the Cuban government wanted the wreck removed from Havana Harbor might also have played a role: it at least offered the opportunity to examine the wreck in greater detail than had been possible in 1898, while simultaneously obliging the Cubans. Wegner suggests that the fact that this inquiry could be held without the pending risk of war, which had been the case in 1898, lent it the potential for greater objectivity than had been possible previously. Moreover, since several of the members of the 1910 board would be certified engineers, they would be better qualified to evaluate their findings than the line officers of the 1898 board had been.[71]\\r\\nBeginning in December 1910, a cofferdam was built around the wreck and water was pumped out, exposing the wreck by late 1911. Between 20 November and 2 December 1911, a court of inquiry headed by Rear Admiral Charles E. Vreeland inspected the wreck. They concluded that an external explosion had triggered the explosion of the magazines. However, this explosion was farther aft and lower powered than concluded by the Sampson Board. The Vreeland Board also found that the bending of frame 18 was caused by the explosion of the magazines, not by the external explosion.[63] After the investigation, the newly located dead were buried in Arlington National Cemetery and the hollow, intact portion of the hull of Maine was refloated and ceremoniously scuttled at sea on 16 March 1912.[72]\\r\\nAdmiral Hyman G. Rickover became intrigued with the disaster and began a private investigation, in 1974. Using information from the two official inquiries, newspapers, personal papers and information on the construction and ammunition of Maine, it was concluded that the explosion was not caused by a mine. Instead, spontaneous combustion of coal in the bunker, next to magazine, was speculated to be the most likely cause. Rickover published a book about this investigation, How the Battleship Maine Was Destroyed, in 1976.[73]\\r\\nIn the 2001 book Theodore Roosevelt, the U.S. Navy and the SpanishÿAmerican War, Wegner revisits the Rickover investigation and offers additional details. According to Wegner, Rickover inquired with naval historians, at the Energy Research and Development Agency, about Maine, after reading an article in the Washington Star-News in which its author, John M. Taylor, claimed the U.S. Navy \\"made little use of its technically trained officers during its investigation of the tragedy.\\" The historians, then working with the admiral on a study of the U.S. Navy's nuclear propulsion program, said they knew no details of Maine's sinking. When Rickover asked whether they could investigate the matter, the historians, now intrigued, agreed. Knowing of Rickover's \\"insistence on thoroughness,\\" Wegner says, all relevant documents were obtained and studied. These included the ship's plans and weekly reports of the unwatering of Maine, in 1912, by the chief engineer for the project, William Furgueson. These reports included numerous photos, annotated by Furgueson with frame and strake numbers on corresponding parts of the wreckage. Two experts on naval demolitions and ship explosions were brought in. Since the photos showed \\"no plausible evidence of penetration from the outside,\\" they believed the explosion originated inside the ship.[74]\\r\\nWegner suggests that a combination of naval ship design, and a change in the type of coal used to fuel naval ships, might have facilitated the explosion postulated by the Rickover study. Up to the time of Maine's building, he explains, common bulkheads separated coal bunkers from ammunition lockers and American naval ships burned primarily smokeless anthracite coal. With an increase in the number of steel ships, the U.S. Navy switched to bituminous coal, which burned at a hotter temperature than anthracite coal, and allowed ships to steam faster. However, Wegner explains, while anthracite coal is not subject to spontaneous combustion, bituminous coal is considerably more volatile. In fact, bituminous coal is known for releasing the largest amounts of firedamp, a dangerous and explosive mixture of gases (chiefly methane). Firedamp is explosive at concentrations between 4% and 16%, with most violence at around 10%. In addition, there was another potential contributing factor in the bituminous coal ÿ this was iron sulfide, also known as pyrite, that was likely present. The presence of pyrites presents two additional risk factors. The first involves oxidation. Pyrite oxidation is sufficiently exothermic that underground coal mines in high-sulfur coal seams have occasionally had serious problems with spontaneous combustion in the mined-out areas of the mine. This process can result from the disruption caused by mining from the seams, or other processing, which then exposes the sulfides in the ore to air and water. The presence of pyrites in coal has been recognized to be self-heating. The second risk factor involves an additional capability of pyrites to provide fire ignition under certain conditions. Pyrites, which derive their name from the Greek root word pyr, which means fire, can cause sparks when struck by steel or other sufficiently hard surfaces. Before the use of flintlock guns, for example, pyrites were used to strike sparks to ignite gunpowder in an earlier model type gun, known as a wheellock. In the presence of combustible gasses issuing from the bituminous coal, the pyrites could therefore have provided the ignition capability needed to create an explosion. A number of bunker fires of this type had, in fact, been reported aboard U.S. warships before Maine's explosion, in several cases nearly sinking the ships. Wegner also cites a 1997 heat transfer study which concluded that a coal bunker fire, of the type suggested by Rickover, could have taken place and ignited the ship's ammunition.[75]\\r\\nIn 1998, National Geographic magazine commissioned an analysis by Advanced Marine Enterprises (AME). This investigation, done to commemorate the centennial of the sinking of USS Maine, was based on computer modeling, a technique unavailable for previous investigations. The results reached were inconclusive. National Geographic reported that \\"a fire in the coal bunker could have generated sufficient heat to touch off an explosion in the adjacent magazine [but] on the other hand, computer analysis also shows that even a small, handmade mine could have penetrated the ship's hull and set off explosions within.\\"[76] The AME investigation, however, did note that \\"the size and location of the soil depression beneath the Maine 'is more readily explained by a mine explosion than by magazine explosions alone'\\".[64] The team noted that this was not \\"definitive in proving that a mine was the cause of the sinking\\" although it did \\"strengthen the case\\".[64]\\r\\nSome experts, including Admiral Rickover's team and several analysts at AME, do not agree with the conclusion.[64] Wegner claims that technical opinion among the Geographic team was divided between its younger members, who focused on computer modeling results, and its older ones, who weighed their inspection of photos of the wreck with their own experience. He adds that the data AME used for its findings were flawed concerning Maine's design and ammunition storage. Wegner was also critical of the fact that participants in the Rickover study were not consulted until AME's analysis was essentially complete, far too late to confirm the veracity of data being used or engage in any other meaningful cooperation.[77]\\r\\nIn 2002, the Discovery Channel produced an episode of the Unsolved History documentaries titled \\"Death of the U.S.S. Maine\\" that used photographic evidence, naval experts, and archival information to determine the cause of the explosion. Its conclusion was that a coal bunker fire caused the explosion, and it identified a weakness or gap in the bulkhead separating the coal and powder bunkers that allowed the fire to spread from the coal bunker to the powder bunker.\\r\\nIt has been suggested by some that the sinking was a false flag operation conducted by the U.S. This is the official view in Cuba. Cuban officials argue that the U.S. may have deliberately sunk the ship to create a pretext for military action against Spain. The wording on the Maine monument in Havana describes Maine's sailors as \\"victims sacrificed to the imperialist greed in its fervor to seize control of Cuba\\",[78] which alludes to the theory that U.S. agents deliberately blew up their own ship.[79]\\r\\nEliades Acosta, a prominent Cuban historian, head of the Cuban Communist Party's Committee on Culture and former director of the Jose Marti National Library in Havana, offered the standard Cuban interpretation of the sinking of the Maine (that the United States itself probably did it) in an interview to The New York Times. But Acosta adds that \\"Americans died for the freedom of Cuba, and that should be recognized. But others wanted to annex Cuba, and that should be criticized. If relations with the United States improve, all these things can be re-examined more fairly\\".[80] This claim has also been made in Russia. Mikhail Khazin, a Russian economist who once ran the cultural section at Komsomolskaya Pravda, speaking in a 2008 Pravda interview of the need in troubled times to change the psychology of society, to unite it, said that \\"the Americans blew up their own battleship Maine.\\"[81]\\r\\nOperation Northwoods was a series of proposals prepared by Pentagon officials for the Joint Chiefs of Staff in 1962, setting out a number of proposed false flag operations that could be blamed on the Cuban Communists in order to rally support against them.[82][83] One of these suggested that a U.S. Navy ship be blown up in Guantanamo Bay deliberately. In an echo of the yellow press headlines of the earlier period, the specific phrase \\"A 'Remember the Maine' incident\\" was used.[83][84]\\r\\nFor several years, Maine was left where she sank in Havana Harbor, although it was evident she would have to be removed sometime. Maine took up valuable space and the buildup of silt around her hull threatened to create a shoal. In addition, various patriotic groups wanted mementos of the ship. On 9 May 1910, Congress authorized funds for the removal of Maine, the proper interment in Arlington National Cemetery of the estimated 70 bodies still inside, and the removal and transport of the main mast to Arlington. Congress did not demand a new investigation into the sinking at that time.[85]\\r\\nThe Army Corps of Engineers built a cofferdam around Maine and pumped water out from inside it.[4] By 30 June 1911, Maine's main deck was exposed. The ship forward of frame 41 was entirely destroyed; a twisted mass of steel out of line with the rest of the hull, all that was left of the bow, bore no resemblance to a ship. The rest of the wreck was badly corroded. Army engineers dismantled the damaged superstructure and decks, which were then dumped at sea. About halfway between bow and stern, they built a concrete and wooden bulkhead to seal the after-section, then cut away what was left of the forward portion. Holes were cut in the bottom of the after-section, through which jets of water were pumped, to break the mud seal holding the ship, then plugged, with flood cocks, which would later be used for sinking the ship.[86]\\r\\nThe Maine had been outfitted with Worthington steam pumps. Although lying on the bottom of Havana Harbor for fourteen years these pumps were found to be still operational, and were subsequently used to raise the ship. (Worthington Pump History, 1840ÿ1940)\\r\\nOn 13 February 1912, the engineers let water back into the interior of the cofferdam. Three days later, the interior of the cofferdam was full and Maine floated. Two days after that, Maine was towed out by the tug Osceola. The bodies of its crew were then removed to the armored cruiser North Carolina for repatriation. On 16 March, Maine was towed four miles from the Cuban coast by Osceola, escorted by North Carolina and the light cruiser Birmingham. Its sea cocks were opened and it sank in 600 fathoms (3,600?ft; 1,100?m) of water to the salutes of Birmingham and North Carolina.[87][88] During the salvage, remains of 66 more were found, of whom only one (an engineering officer) was identified and returned to his home town; the rest were reburied at Arlington Cemetery making a total of 229 buried there.[89]\\r\\nIn 2000, the wreck of Maine was rediscovered by Advanced Digital Communications, a Toronto-based expedition company, in about 3,770 feet (1,150 m) of water roughly 3 miles (4.8?km) northeast of Havana Harbor. The company had been working with Cuban scientists and oceanographers from the University of South Florida College of Marine Science, on testing underwater exploration technology. The ship had been discovered east of where it was believed it had been scuttled; according to the researchers, during the sinking ceremony and the time it took the wreck to founder, currents pushed the Maine east until it came to rest at its present location. Before the team identified the site as Maine, they referred to the location as the \\"square\\" due to its unique shape, and at first they did not believe it was the ship, due to its unexpected location. The site was explored with an ROV. According to Dr. Frank Muller-Karger, the hull was not oxidized and the crew could \\"see all of its structural parts\\".[90] The expedition was able to identify the ship due to the doors and hatches on the wreck, as well as the anchor chain, the shape of the propellers, and the holes where the bow was cut off. Due to the 1912 raising of the ship, the wreck was completely missing its bow; this tell-tale feature was instrumental in identifying the ship. The team also located a boiler nearby, and a debris field of coal.[90]\\r\\nIn February 1898, the recovered bodies of sailors who died on Maine were interred in the Colon Cemetery, Havana. Some injured sailors were sent to hospitals in Havana and Key West, Florida. Those who died in hospitals were buried in Key West. In December 1899, the bodies in Havana were disinterred and brought back to the United States for burial at Arlington National Cemetery.[91] In 1915, President Woodrow Wilson dedicated the USS Maine Mast Memorial to those who died. The memorial includes the ship's main mast. Roughly 165 were buried at Arlington, although the remains of one sailor were exhumed for his home town, Indianapolis, Indiana. Of the rest, only 62 were known.[89] Nine bodies were never recovered and 19 crewmen, several unidentified, are buried in Key West Cemetery under a statue of a U.S. Sailor holding an oar.[c]\\r\\nMemorial at Arlington National Cemetery centered on the ship's main mast\\r\\nThe Cuban Friendship Urn on Ohio Drive, Southwest, Washington, D.C., East Potomac Park\\r\\nMonument to victims of Maine in Havana, Cuba, c. 1930\\r\\nA gun from Maine at Fort Allen Park, Portland, Maine\\r\\nU.S. Battleship Maine Monument Key West Cemetery, Florida\\r\\nThe explosion-bent fore mast of Maine is located at the United States Naval Academy at Annapolis, Maryland.[92][93]\\r\\nIn 1926, the Cuban government erected a memorial to the victims of Maine on the Malecon, near the Hotel Nacional, to commemorate United States assistance in acquiring Cuban independence from Spain. The memorial was damaged by crowds, following the Bay of Pigs Invasion in 1961, and the eagle on top was broken and removed.[94] The Communist government then added its own inscription blaming \\"imperialist voracity in its eagerness to seize the island of Cuba\\" for Maine's sinking.[94][95] The monument was cleaned and restored in 2013. However, the eagle's head was retained by the U.S. Interests Section in Havana, and the body by the city's museum.[96]\\r\\nUSS Maine Monument in New York City\\r\\nUSS Maine Monument, Columbus Circle, NYC\\r\\nColumbia Triumphant\\r\\nMemorial plaque by Charles Keck, USS Maine Memorial\\r\\nSculpture group by Attilio Piccirilli at USS Maine Memorial\\r\\nColumbia Triumphant sculpture group atop USS Maine Memorial\\r\\nA 6-inch deck gun from Maine is on the North lawn of the South Carolina State House in Columbia, SC.\\r\\nA bronze torpedo tube and armoured hatch form part of a memorial in West Park, Pittsburgh, Pennsylvania, just south of West North Avenue, http://www.waymarking.com/waymarks/WM769B_Maine_Memorial_Pittsburgh_PA\\r\\nThere is also a U.S.S. Maine Memorial plaque<visible in photographs and physically in situ> at the south door of the Jefferson County Courthouse, in Steubenville, OH.\\r\\nCoordinates: 231153N 822118W? / ?23.198N 82.355W? / 23.198; -82.355? (USS Maine)[102]\\r\\n?This article incorporates?public domain material from the United States Navy website https://web.archive.org/web/20010204074000/http://www.history.navy.mil/faqs/faq71-1.htm.\\r\\nBibliography","input":"When was the uss maine sent to cuba?"},{"output":"California","context":"Lettuce (Lactuca sativa) is an annual plant of the daisy family, Asteraceae. It is most often grown as a leaf vegetable, but sometimes for its stem and seeds. Lettuce is most often used for salads, although it is also seen in other kinds of food, such as soups, sandwiches and wraps; it can also be grilled.[3] One variety, the woju (), or asparagus lettuce (celtuce), is grown for its stems, which are eaten either raw or cooked. In addition to its main use as a leafy green, it has also gathered religious and medicinal significance over centuries of human consumption. Europe and North America originally dominated the market for lettuce, but by the late 20th century the consumption of lettuce had spread throughout the world. World production of lettuce and chicory for calendar year 2015 was 26.1 million tonnes, 56% of which came from China.[4]\\r\\nLettuce was first cultivated by the ancient Egyptians who turned it from a weed whose seeds were used to produce oil, into a food plant grown for its succulent leaves and oil-rich seeds. Lettuce spread to the Greeks and Romans, the latter of whom gave it the name lactuca, from which the English lettuce is ultimately derived. By 50 AD, many types were described, and lettuce appeared often in medieval writings, including several herbals. The 16th through 18th centuries saw the development of many varieties in Europe, and by the mid-18th century cultivars were described that can still be found in gardens.\\r\\nGenerally grown as a hardy annual, lettuce is easily cultivated, although it requires relatively low temperatures to prevent it from flowering quickly. It can be plagued by numerous nutrient deficiencies, as well as insect and mammal pests, and fungal and bacterial diseases. L. sativa crosses easily within the species and with some other species within the genus Lactuca. Although this trait can be a problem to home gardeners who attempt to save seeds, biologists have used it to broaden the gene pool of cultivated lettuce varieties.\\r\\nLettuce is a rich source of vitamin K and vitamin A, and a moderate source of folate and iron. Contaminated lettuce is often a source of bacterial, viral, and parasitic outbreaks in humans, including E. coli and Salmonella.\\r\\n\\r\\n\\r\\nLactuca sativa is a member of the Lactuca (lettuce) genus and the Asteraceae (sunflower or aster) family.[5] The species was first described in 1753 by Carl Linnaeus in the second volume of his Species Plantarum.[6] Synonyms for L.?sativa include Lactuca scariola var. sativa,[1] L.?scariola var. integrata and L.?scariola var. integrifolia.[7] L.?scariola is itself a synonym for L.?serriola, the common wild or prickly lettuce.[2] L.?sativa also has many identified taxonomic groups, subspecies and varieties, which delineate the various cultivar groups of domesticated lettuce.[8] Lettuce is closely related to several Lactuca species from southwest Asia; the closest relationship is to L.?serriola, an aggressive weed common in temperate and subtropical zones in much of the world.[9]\\r\\nThe Romans referred to lettuce as lactuca (lac meaning milk in Latin), an allusion to the white substance, now called latex, exuded by cut stems.[10] This word has become the genus name, while sativa (meaning \\"sown\\" or \\"cultivated\\") was added to create the species name.[11] The current word lettuce, originally from Middle English, came from the Old French letues or laitues, which derived from the Roman name.[12] The name romaine came from that type's use in the Roman papal gardens, while cos, another term for romaine lettuce, came from the earliest European seeds of the type from the Greek island of Cos, a center of lettuce farming in the Byzantine period.[13]\\r\\nLettuce's native range spreads from the Mediterranean to Siberia, although it has been transported to almost all areas of the world. Plants generally have a height and spread of 15 to 30?cm (6 to 12?in).[14] The leaves are colorful, mainly in the green and red color spectrums, with some variegated varieties.[15] There are also a few varieties with yellow, gold or blue-teal leaves.[16] Lettuces have a wide range of shapes and textures, from the dense heads of the iceberg type to the notched, scalloped, frilly or ruffly leaves of leaf varieties.[15] Lettuce plants have a root system that includes a main taproot and smaller secondary roots. Some varieties, especially those found in the United States and Western Europe, have long, narrow taproots and a small set of secondary roots. Longer taproots and more extensive secondary systems are found in varieties from Asia.[16]\\r\\nDepending on the variety and time of year, lettuce generally lives 65ÿ130 days from planting to harvesting. Because lettuce that flowers (through the process known as \\"bolting\\") becomes bitter and unsaleable, plants grown for consumption are rarely allowed to grow to maturity. Lettuce flowers more quickly in hot temperatures, while freezing temperatures cause slower growth and sometimes damage to outer leaves.[17] Once plants move past the edible stage, they develop flower stalks up to 1?m (3?ft 3?in) high with small yellow blossoms.[18] Like other members of the tribe Cichorieae, lettuce inflorescences (also known as flower heads or capitula) are composed of multiple florets, each with a modified calyx called a pappus (which becomes the feathery \\"parachute\\" of the fruit), a corolla of five petals fused into a ligule or strap, and the reproductive parts. These include fused anthers that form a tube which surrounds a style and bipartite stigma. As the anthers shed pollen, the style elongates to allow the stigmas, now coated with pollen, to emerge from the tube.[16][19] The ovaries form compressed, obovate (teardrop-shaped) dry fruits that do not open at maturity, measuring 3 to 4?mm long. The fruits have 5ÿ7 ribs on each side and are tipped by two rows of small white hairs. The pappus remains at the top of each fruit as a dispersal structure. Each fruit contains one seed, which can be white, yellow, gray or brown depending on the variety of lettuce.[1]\\r\\nThe domestication of lettuce over the centuries has resulted in several changes through selective breeding: delayed bolting, larger seeds, larger leaves and heads, better taste and texture, a lower latex content, and different leaf shapes and colors. Work in these areas continues through the present day.[20] Scientific research into the genetic modification of lettuce is ongoing, with over 85 field trials taking place between 1992 and 2005 in the European Union and United States to test modifications allowing greater herbicide tolerance, greater resistance to insects and fungi and slower bolting patterns. However, genetically modified lettuce is not currently used in commercial agriculture.[21]\\r\\nLettuce was first cultivated in ancient Egypt for the production of oil from its seeds. This plant was probably selectively bred by the Egyptians into a plant grown for its edible leaves,[22] with evidence of its cultivation appearing as early as 2680 BC.[10] Lettuce was considered a sacred plant of the reproduction god Min, and it was carried during his festivals and placed near his images. The plant was thought to help the god \\"perform the sexual act untiringly.\\"[23] Its use in religious ceremonies resulted in the creation of many images in tombs and wall paintings. The cultivated variety appears to have been about 75?cm (30?in) tall and resembled a large version of the modern romaine lettuce. These upright lettuces were developed by the Egyptians and passed to the Greeks, who in turn shared them with the Romans. Circa 50 AD, Roman agriculturalist Columella described several lettuce varieties?ÿ some of which may have been ancestors of today's lettuces.[10]\\r\\nLettuce appears in many medieval writings, especially as a medicinal herb. Hildegard of Bingen mentioned it in her writings on medicinal herbs between 1098 and 1179, and many early herbals also describe its uses. In 1586, Joachim Camerarius provided descriptions of the three basic modern lettuces?ÿ head lettuce, loose-leaf lettuce, and romaine (or cos) lettuce.[13] Lettuce was first brought to the Americas from Europe by Christopher Columbus in the late 15th century.[24][25] Between the late 16th century and the early 18th century, many varieties were developed in Europe, particularly Holland. Books published in the mid-18th and early 19th centuries describe several varieties found in gardens today.[26]\\r\\nDue to its short lifespan after harvest, lettuce was originally sold relatively close to where it was grown. The early 20th century saw the development of new packing, storage and shipping technologies that improved the lifespan and transportability of lettuce and resulted in a significant increase in availability.[27] During the 1950s, lettuce production was revolutionized with the development of vacuum cooling, which allowed field cooling and packing of lettuce, replacing the previously used method of ice-cooling in packing houses outside the fields.[28]\\r\\nLettuce is very easy to grow, and as such has been a significant source of sales for many seed companies. Tracing the history of many varieties is complicated by the practice of many companies, particularly in the US, of changing a variety's name from year to year. This was done for several reasons, the most prominent being to boost sales by promoting a \\"new\\" variety or to prevent customers from knowing that the variety had been developed by a competing seed company. Documentation from the late 19th century shows between 65 and 140 distinct varieties of lettuce, depending on the amount of variation allowed between types?ÿ a distinct difference from the 1,100 named lettuce varieties on the market at the time. Names also often changed significantly from country to country.[29] Although most lettuce grown today is used as a vegetable, a minor amount is used in the production of tobacco-free cigarettes; however, domestic lettuce's wild relatives produce a leaf that visually more closely resembles tobacco.[30]\\r\\nA hardy annual, some varieties of lettuce can be overwintered even in relatively cold climates under a layer of straw, and older, heirloom varieties are often grown in cold frames.[26] Lettuces meant for the cutting of individual leaves are generally planted straight into the garden in thick rows. Heading varieties of lettuces are commonly started in flats, then transplanted to individual spots, usually 20 to 36?cm (7.9 to 14.2?in) apart, in the garden after developing several leaves. Lettuce spaced further apart receives more sunlight, which improves color and nutrient quantities in the leaves. Pale to white lettuce, such as the centers in some iceberg lettuce, contain few nutrients.[18]\\r\\nLettuce grows best in full sun in loose, nitrogen-rich soils with a pH of between 6.0 and 6.8. Heat generally prompts lettuce to bolt, with most varieties growing poorly above 24?C (75?F); cool temperatures prompt better performance, with 16 to 18?C (61 to 64?F) being preferred and as low as 7?C (45?F) being tolerated.[31] Plants in hot areas that are provided partial shade during the hottest part of the day will bolt more slowly. Temperatures above 27?C (81?F) will generally result in poor or non-existent germination of lettuce seeds.[31] After harvest, lettuce lasts the longest when kept at 0?C (32?F) and 96 percent humidity. Lettuce quickly degrades when stored with fruit such as apples, pears and bananas that release the ripening agent ethylene gas. The high water content of lettuce (94.9 percent) creates problems when attempting to preserve the plant?ÿ it cannot be successfully frozen, canned or dried and must be eaten fresh.[32]\\r\\nLettuce varieties will cross with each other, making spacing of 1.5 to 6?m (60 to 240?in) between varieties necessary to prevent contamination when saving seeds. Lettuce will also cross with Lactuca serriola (wild lettuce), with the resulting seeds often producing a plant with tough, bitter leaves. Celtuce, a lettuce variety grown primarily in Asia for its stems, crosses easily with lettuces grown for their leaves.[18] This propensity for crossing, however, has led to breeding programs using closely related species in Lactuca, such as L. serriola, L. saligna, and L. virosa, to broaden the available gene pool. Starting in the 1990s, such programs began to include more distantly related species such as L. tatarica.[33] Seeds keep best when stored in cool conditions, and, unless stored cryogenically, remain viable the longest when stored at ?20?C (?4?F); they are relatively short lived in storage.[1] At room temperature, lettuce seeds remain viable for only a few months. However, when newly harvested lettuce seed is stored cryogenically, this life increases to a half-life of 500 years for vaporized nitrogen and 3,400 years for liquid nitrogen; this advantage is lost if seeds are not frozen promptly after harvesting.[34]\\r\\nThere are several types of lettuce, but three (leaf, head and cos or romaine) are the most common.[31] There are seven main cultivar groups of lettuce, each including many varieties:\\r\\nThe butterhead and crisphead types are sometimes known together as \\"cabbage\\" lettuce, because their heads are shorter, flatter, and more cabbage-like than romaine lettuces.[38]\\r\\nSoil nutrient deficiencies can cause a variety of plant problems that range from malformed plants to a lack of head growth.[31] Many insects are attracted to lettuce, including cutworms, which cut seedlings off at the soil line; wireworms and nematodes, which cause yellow, stunted plants; tarnished plant bugs and aphids, which cause yellow, distorted leaves; leafhoppers, which cause stunted growth and pale leaves; thrips, which turn leaves gray-green or silver; leafminers, which create tunnels within the leaves; flea beetles, which cut small holes in leaves and caterpillars, slugs and snails, which cut large holes in leaves. For example, the larvae of the ghost moth is a common pest of lettuce plants.[39] Mammals, including rabbits and groundhogs, also eat the plants.[40] Lettuce contains several defensive compounds, including sesquiterpene lactones, and other natural phenolics such as flavonol and glycosides, which help to protect it against pests. Certain varieties contain more than others, and some selective breeding and genetic modification studies have focused on using this trait to identify and produce commercial varieties with increased pest resistance.[41]\\r\\nLettuce also suffers from several viral diseases, including big vein, which causes yellow, distorted leaves, and mosaic virus, which is spread by aphids and causes stunted plant growth and deformed leaves. Aster yellows are a disease-causing bacteria carried by leafhoppers, which causes deformed leaves. Fungal diseases include powdery mildew and downy mildew, which cause leaves to mold and die and bottom rot, lettuce drop and gray mold, which cause entire plants to rot and collapse.[40] Crowding lettuce tends to attract pests and diseases.[18] Weeds can also be an issue, as cultivated lettuce is generally not competitive with them, especially when directly seeded into the ground. Transplanted lettuce (started in flats and later moved to growing beds) is generally more competitive initially, but can still be crowded later in the season, causing misshapen lettuce and lower yields. Weeds also act as homes for insects and disease and can make harvesting more difficult.[42] Herbicides are often used to control weeds in commercial production. However, this has led to the development of herbicide-resistant weeds and prompted environmental and health concerns.[20]\\r\\nIn 2015, world production of lettuce (report combined with chicory) was 26.1 million tonnes, with China alone producing 14.6 million tonnes or 56% of the world total (table).\\r\\nLettuce is the only member of the genus Lactuca to be grown commercially.[43] Although China is the top world producer of lettuce, the majority of the crop is consumed domestically. Spain is the world's largest exporter of lettuce, with the US ranking second.[27]\\r\\nWestern Europe and North America were the original major markets for large-scale lettuce production. By the late 1900s, Asia, South America, Australia and Africa became more substantial markets. Different locations tended to prefer different types of lettuce, with butterhead prevailing in northern Europe and Great Britain, romaine in the Mediterranean and stem lettuce in China and Egypt. By the late 20th century, the preferred types began to change, with crisphead, especially iceberg, lettuce becoming the dominant type in northern Europe and Great Britain and more popular in western Europe. In the US, no one type predominated until the early 20th century, when crisphead lettuces began gaining popularity. After the 1940s, with the development of iceberg lettuce, 95 percent of the lettuce grown and consumed in the US was crisphead lettuce. By the end of the century, other types began to regain popularity and eventually made up over 30 percent of production.[44] Stem lettuce was first developed in China, and remains primarily cultivated in that country.[45]\\r\\nIn the early 21st century, bagged salad products increased in the lettuce market, especially in the US where innovative packaging and shipping methods prolonged freshness.[46][47][48]\\r\\nIn the United States in 2013, California (71%) and Arizona (29%) produced nearly all of the country's fresh head and leaf lettuce, with head lettuce yielding $9400 of value per acre and leaf lettuce $8000 per acre.[47]\\r\\nAs described around 50 AD, lettuce leaves were often cooked and served by the Romans with an oil-and-vinegar dressing; however, smaller leaves were sometimes eaten raw. During the 81ÿ96 AD reign of Domitian, the tradition of serving a lettuce salad before a meal began. Post-Roman Europe continued the tradition of poaching lettuce, mainly with large romaine types, as well as the method of pouring a hot oil and vinegar mixture over the leaves.[10] Today, the majority of lettuce is grown for its leaves, although one type is grown for its stem and one for its seeds, which are made into an oil.[22] Most lettuce is used in salads, either alone or with other greens, vegetables, meats and cheeses. Romaine lettuce is often used for Caesar salads, with a dressing that includes anchovies and eggs. Lettuce leaves can also be found in soups, sandwiches and wraps, while the stems are eaten both raw and cooked.[11] The consumption of lettuce in China developed differently from in Western countries, due to health risks and cultural aversion to eating raw leaves. In that country, \\"salads\\" were created from cooked vegetables and served hot or cold. Lettuce was also used in a larger variety of dishes than in Western countries, contributing to a range of dishes including bean curd and meat dishes, soups and stir-frys plain or with other vegetables. Stem lettuce, widely consumed in China, is eaten either raw or cooked, the latter primarily in soups and stir-frys.[45] Lettuce is also used as a primary ingredient in the preparation of lettuce soup.\\r\\nDepending on the variety, lettuce is an excellent source (20% of the Daily Value, DV, or higher) of vitamin K (97% DV) and vitamin A (21% DV) (table), with higher concentrations of the provitamin A compound, beta-carotene, found in darker green lettuces, such as Romaine.[32] With the exception of the iceberg variety, lettuce is also a good source (10-19% DV) of folate and iron (table).[32]\\r\\nFood-borne pathogens that can survive on lettuce include Listeria monocytogenes, the causative agent of listeriosis, which multiplies in storage. However, despite high levels of bacteria being found on ready-to-eat lettuce products, a 2008 study found no incidences of food-borne illness related to listeriosis, possibly due to the product's short shelf life, indigenous microflora competing with the Listeria bacteria or inhibition of bacteria to cause listeriosis.[49]\\r\\nOther bacteria found on lettuce include Aeromonas species, which have not been linked to any outbreaks; Campylobacter species, which cause campylobacteriosis; and Yersinia intermedia and Yersinia kristensenii (species of Yersinia), which have been found mainly in lettuce.[50] Lettuce has been linked to numerous outbreaks of the bacteria E. coli O157:H7 and Shigella; the plants were most likely contaminated through contact with animal feces.[51] A 2007 study determined that the vacuum cooling method, especially prevalent in the California lettuce industry, increased the uptake and survival rates of E. coli O157:H7.[52] Salmonella bacteria, including the uncommon Salmonella braenderup type, have also caused outbreaks traced to contaminated lettuce.[53] Viruses, including hepatitis A, calicivirus and a Norwalk-like strain, have been found in lettuce. The vegetable has also been linked to outbreaks of parasitic infestations, including Giardia lamblia.[50]\\r\\nIn addition to its usual purpose as an edible leafy vegetable, lettuce has had a number of uses in ancient (and even some more modern) times as a medicinal herb and religious symbol. For example, ancient Egyptians thought lettuce to be a symbol of sexual prowess[44] and a promoter of love and childbearing in women. The Romans likewise claimed that it increased sexual potency.[54] In contrast, the ancient Greeks connected the plant with male impotency,[10] and served it during funerals (probably due to its role in the myth of Adonis' death), and British women in the 19th century believed it would cause infertility and sterility. Lettuce has mild narcotic properties; it was called \\"sleepwort\\" by the Anglo-Saxons because of this attribute, although the cultivated L. sativa has lower levels of the narcotic than its wild cousins.[54] This narcotic effect is a property of two sesquiterpene lactones which are found in the white liquid (latex) in the stems of lettuce,[30] called lactucarium or \\"lettuce opium\\".\\r\\nLettuce is also eaten as part of the Jewish Passover Seder, where it is considered the optimal choice for use as the bitter herb, which is eaten together with the matzah.\\r\\nSome American settlers claimed that smallpox could be prevented through the ingestion of lettuce,[54] and an Iranian belief suggested consumption of the seeds when afflicted with typhoid.[55] Folk medicine has also claimed it as a treatment for pain, rheumatism, tension and nervousness, coughs and insanity; scientific evidence of these benefits in humans has not been found. The religious ties of lettuce continue into the present day among the Yazidi people of northern Iraq, who have a religious prohibition against eating the plant.[56]","input":"Where is lettuce grown in the united states?"},{"output":"a direct tax on the Thirteen Colonies","context":"\\r\\n\\r\\nThe Stamp Act of 1765 (short title Duties in American Colonies Act 1765; 5 George III, c. 12) was an Act of the Parliament of Great Britain that imposed a direct tax on the Thirteen Colonies and required that many printed materials in the colonies be produced on stamped paper produced in London, carrying an embossed revenue stamp.[1][2] Printed materials included legal documents, magazines, playing cards, newspapers, and many other types of paper used throughout the colonies.  Like previous taxes, the stamp tax had to be paid in valid British currency, not in colonial paper money.[3]\\r\\n\\r\\nThe purpose of the tax was to pay for British military troops stationed in the American colonies after the French and Indian War, which was the North American theater of the Seven Years' War. However, the colonists had never feared a French invasion to begin with, and they contended that they had already paid their share of the war expenses.[4]  They suggested that it was actually a matter of British patronage to surplus British officers and career soldiers who should be paid by London.\\r\\n\\r\\nThe Stamp Act was very unpopular among colonists. A majority considered it a violation of their rights as Englishmen to be taxed without their consentconsent that only the colonial legislatures could grant. Their slogan was \\"No taxation without representation.\\" Colonial assemblies sent petitions and protests, and the Stamp Act Congress held in New York City was the first significant joint colonial response to any British measure when it petitioned Parliament and the King.\\r\\n\\r\\nOne member of the British Parliament argued that the colonials were no different from the 90% residents of Great Britain who did not own property and thus could not vote, but who were nevertheless \\"virtually\\" represented by land-owning electors and representatives who had common interests with them.[5]  An American attorney refuted this by pointing out that the relations between the Americans and the English electors were \\"a knot too infirm to be relied on\\" for proper representation, \\"virtual\\" or otherwise.[6] Local protest groups established Committees of Correspondence which created a loose coalition from New England to Maryland.  Protests and demonstrations increased, often initiated by the Sons of Liberty and occasionally involving hanging of effigies.  Very soon, all stamp tax distributors were intimidated into resigning their commissions, and the tax was never effectively collected.[7]\\r\\n\\r\\nOpposition to the Stamp Act was not limited to the colonies. British merchants and manufacturers pressured Parliament because their exports to the colonies were threatened by boycotts. The Act was repealed on 18 March 1766 as a matter of expedience, but Parliament affirmed its power to legislate for the colonies \\"in all cases whatsoever\\" by also passing the Declaratory Act. A series of new taxes and regulations then ensuedlikewise opposed by the colonists.\\r\\n\\r\\nThe episode played a major role in defining the grievances that were clearly stated within the text of the Indictment of George III section of the United States Declaration of Independence, enabling the organized colonial resistance that led to the American Revolution in 1775.[8][9]\\r\\n\\r\\nThe British victory in the Seven Years' War (1756ÿ1763), known in America as the French and Indian War, had been won only at a great financial cost. During the war, the British national debt nearly doubled, rising from S72,289,673 in 1755 to almost S129,586,789 by 1764.[10] Post-war expenses were expected to remain high because the Bute ministry decided in early 1763 to keep ten thousand British regular soldiers in the American colonies, which would cost about S225,000 per year, equal to S30 million today.[11] The primary reason for retaining such a large force was that demobilizing the army would put 1,500 officers out of work, many of whom were well-connected in Parliament.[12] This made it politically prudent to retain a large peacetime establishment, but Britons were averse to maintaining a standing army at home so it was necessary to garrison most of the troops elsewhere.[13]\\r\\n\\r\\nStationing 10,000 troops to separate American Indians and frontiersmen was one role. The outbreak of Pontiac's Rebellion in May 1763 apparently reinforced the logic of this decision, as it was an American Indian uprising against the British expansion.[14] The main reason to send 10,000 troops deep into the wilderness was to provide billets for the officers who were part of the British patronage system.[15] John Adams said, \\"Revenue is still demanded from America, and appropriated to the maintenance of swarms of officers and pensioners in idleness and luxury.\\"[16]\\r\\n\\r\\nGeorge Grenville became prime minister in April 1763 after the failure of the short-lived Bute Ministry, and he had to find a way to pay for this large peacetime army. Raising taxes in Britain was out of the question, since there had been virulent protests in England against the Bute ministry's 1763 cider tax, with Bute being hanged in effigy.[17] The Grenville ministry therefore decided that Parliament would raise this revenue by taxing the American colonists without their consent. This was something new; Parliament had previously passed measures to regulate trade in the colonies, but it had never before directly taxed the colonies to raise revenue.[18]\\r\\n\\r\\nPoliticians in London had always expected American colonists to contribute to the cost of their own defense. So long as a French threat existed, there was little trouble convincing colonial legislatures to provide assistance. Such help was normally provided through the raising of colonial militias, which were funded by taxes raised by colonial legislatures. Also, the legislatures were sometimes willing to help maintain regular British units defending the colonies. So long as this sort of help was forthcoming, there was little reason for the British Parliament to impose its own taxes on the colonists. But after the peace of 1763, colonial militias were quickly stood down. Militia officers were tired of the disdain shown to them by regular British officers, and were frustrated by the near-impossibility of obtaining regular British commissions; they were unwilling to remain in service once the war was over. In any case, they had no military role, as the Indian threat was minimal and there was no foreign threat. Colonial legislators saw no need for the British troops.\\r\\n\\r\\nThe Sugar Act of 1764 was the first tax in Grenville's program to raise a revenue in America, which was a modification of the Molasses Act of 1733. The Molasses Act had imposed a tax of 6 pence per gallon (equal to S3.81 today) on foreign molasses imported into British colonies. The purpose of the Molasses Act was not actually to raise revenue, but instead to make foreign molasses so expensive that it effectively gave a monopoly to molasses imported from the British West Indies.[19] It did not work; colonial merchants avoided the tax by smuggling or, more often, bribing customs officials.[20] The Sugar Act reduced the tax to 3 pence per gallon (equal to S1.63 today) in the hope that the lower rate would increase compliance and thus increase the amount of tax collected.[21] The Act also taxed additional imports and included measures to make the customs service more effective.[22]\\r\\n\\r\\nAmerican colonists initially objected to the Sugar Act for economic reasons, but before long they recognized that there were constitutional issues involved.[23] The British Constitution guaranteed that British subjects could not be taxed without their consent, which came in the form of representation in Parliament. The colonists elected no members of Parliament, and so it was seen as a violation of the British Constitution for Parliament to tax them. There was little time to raise this issue in response to the Sugar Act, but it came to be a major objection to the Stamp Act the following year.\\r\\n\\r\\nParliament announced in April 1764 when the Sugar Act was passed that they would also consider a stamp tax in the colonies.[24] Opposition from the colonies was soon forthcoming to this possible tax, but neither members of Parliament nor American agents in Great Britain (such as Benjamin Franklin) anticipated the intensity of the protest that the tax generated.[25]\\r\\n\\r\\nStamp acts had been a very successful method of taxation within Great Britain; they generated over S100,000 in tax revenue with very little in collection expenses.  By requiring an official stamp on most legal documents, the system was almost self-regulating; a document would be null and void under British law without the required stamp.  Imposition of such a tax on the colonies had been considered twice before the Seven Years' War and once again in 1761.  Grenville had actually been presented with drafts of colonial stamp acts in September and October 1763, but the proposals lacked the specific knowledge of colonial affairs to adequately describe the documents subject to the stamp. At the time of the passage of the Sugar Act in April 1764, Grenville made it clear that the right to tax the colonies was not in question, and that additional taxes might follow, including a stamp tax.[26]\\r\\n\\r\\nThe Glorious Revolution had established the principle of parliamentary supremacy.  Control of colonial trade and manufactures extended this principle across the ocean. This belief had never been tested on the issue of colonial taxation, but the British assumed that the interests of the thirteen colonies were so disparate that a joint colonial action was unlikely to occur against such a taxÿan assumption that had its genesis in the failure of the Albany Conference in 1754.  By the end of December 1764, the first warnings of serious colonial opposition were provided by pamphlets and petitions from the colonies protesting both the Sugar Act and the proposed stamp tax.[27]\\r\\n\\r\\nFor Grenville, the first issue was the amount of the tax.  Soon after his announcement of the possibility of a tax, he had told American agents that he was not opposed to the Americans suggesting an alternative way of raising the money themselves. However, the only other alternative would be to requisition each colony and allow them to determine how to raise their share.  This had never worked before, even during the French and Indian War, and there was no political mechanism in place that would have ensured the success of such cooperation. On 2 February 1765, Grenville met to discuss the tax with Benjamin Franklin, Jared Ingersoll from New Haven, Richard Jackson, agent for Connecticut, and Charles Garth, the agent for South Carolina (Jackson and Garth were also members of Parliament).  These colonial representatives had no specific alternative to present; they simply suggested that the determination be left to the colonies.  Grenville replied that he wanted to raise the money \\"by means the most easy and least objectionable to the Colonies\\". Thomas Whately had drafted the Stamp Act, and he said that the delay in implementation had been \\"out of Tenderness to the colonies\\", and that the tax was judged as \\"the easiest, the most equal and the most certain.\\"[28]\\r\\n\\r\\nThe debate in Parliament began soon after this meeting.  Petitions submitted by the colonies were officially ignored by Parliament. In the debate, Charles Townshend said, \\"and now will these Americans, children planted by our care, nourished up by our Indulgence until they are grown to a degree of strength and opulence, and protected by our arms, will they grudge to contribute their mite to relieve us from heavy weight of the burden which we lie under?\\"[29]  This led to Colonel Isaac Barrȣs response:\\r\\n\\r\\nThey planted by your care? No! Your oppression planted em in America. They fled from your tyranny to a then uncultivated and unhospitable country where they exposed themselves to almost all the hardships to which human nature is liable, and among others to the cruelties of a savage foe, the most subtle, and I take upon me to say, the most formidable of any people upon the face of Gods earth....\\r\\n\\r\\nThey nourished by your indulgence? They grew by your neglect of em. As soon as you began to care about em, that care was exercised in sending persons to rule over 'em, in one department and another, who were perhaps the deputies of deputies to some member of this house, sent to spy out their liberty, to misrepresent their actions and to prey upon 'em; men whose behaviour on many occasions has caused the blood of those sons of liberty to recoil within them....\\r\\n\\r\\nThey protected by your arms? They have nobly taken up arms in your defence, have exerted a valour amidst their constant and laborious industry for the defence of a country whose frontier while drenched in blood, its interior parts have yielded all its little savings to your emolument?.... The people I believe are as truly loyal as any subjects the king has, but a people jealous of their liberties and who will vindicate them if ever they should be violated; but the subject is too delicate and I will say no more.\\"[30]\\r\\n\\r\\nThe Stamp Act was passed by Parliament on 22 March 1765 with an effective date of 1 November 1765. It passed 205ÿ49 in the House of Commons and unanimously in the House of Lords.[31]  Historians Edmund and Helen Morgan describe the specifics of the tax:\\r\\n\\r\\nThe highest tax, S10, was placed ... on attorney licenses.  Other papers relating to court proceedings were taxed in amounts varying from 3d. to 10s.  Land grants under a hundred acres were taxed 1s. 6d., between 100 and 200 acres 2s., and from 200 to 320 acres 2s. 6d., with an additional 2s 6d. for every additional 320 acres (1.3?km2).  Cards were taxed a shilling a pack, dice ten shillings, and newspapers and pamphlets at the rate  of a penny for a single sheet and a shilling for every sheet in pamphlets or papers totaling more than one sheet and fewer than six sheets in octavo, fewer than twelve in quarto, or fewer than twenty in folio (in other words, the tax on pamphlets grew in proportion to their size but ceased altogether if they became large enough to qualify as a book).[32]\\r\\n\\r\\nThe high taxes on lawyers and college students were designed to limit the growth of a professional class in the colonies.[33] The stamps had to be purchased with hard currency, which was scarce, rather than the more plentiful colonial paper currency. To avoid draining currency out of the colonies, the revenues were to be expended in America, especially for supplies and salaries of British Army units who were stationed there.[34]\\r\\n\\r\\nTwo features of the Stamp Act involving the courts attracted special attention.  The tax on court documents specifically included courts \\"exercising ecclesiastical jurisdiction.\\" These type of courts did not currently exist in the colonies and no bishops were currently assigned to the colonies, who would preside over the courts.  Many colonists or their ancestors had fled England specifically to escape the influence and power of such state-sanctioned religious institutions, and they feared that this was the first step to reinstating the old ways in the colonies.  Some Anglicans in the northern colonies were already openly advocating the appointment of such bishops, but they were opposed by both southern Anglicans and the non-Anglicans  who made up the majority in the northern colonies.[35]\\r\\n\\r\\nThe Stamp Act allowed admiralty courts to have jurisdiction for trying violators, following the example established by the Sugar Act.  However, admiralty courts had traditionally been limited to cases involving the high seas.  The Sugar Act seemed to fall within this precedent, but the Stamp Act did not, and the colonists saw this as a further attempt to replace their local courts with courts controlled by England.[36]\\r\\n\\r\\nGrenville started appointing Stamp Distributors almost immediately after the Act passed Parliament.  Applicants were not hard to come by because of the anticipated income that the positions promised, and he appointed local colonists to the post.  Benjamin Franklin even suggested the appointment of John Hughes as the agent for Pennsylvania, indicating that even Franklin was not aware of the turmoil and impact that the tax was going to generate on American-British relations or that these distributors would become the focus of colonial resistance.[37]\\r\\n\\r\\nDebate in the colonies had actually begun in the spring of 1764 over the Stamp Act when Parliament passed a resolution that contained the assertion, \\"That, towards further defraying the said Expences, it may be proper to charge certain Stamp Duties in the said Colonies and Plantations.\\"  Both the Sugar Act and the proposed Stamp Act were designed principally to raise revenue from the colonists.  The Sugar Act, to a large extent, was a continuation of past legislation related primarily to the regulation of trade (termed an external tax), but its stated purpose was entirely new: to collect revenue directly from the colonists for a specific purpose.  The novelty of the Stamp Act was that it was the first internal tax (a tax based entirely on activities within the colonies) levied directly on the colonies by Parliament. It was judged by the colonists to be a more dangerous assault on their rights than the Sugar Act was, because of its potential wide application to the colonial economy.[38]\\r\\n\\r\\nThe theoretical issue that soon held center stage was the matter of taxation without representation. Benjamin Franklin had raised this as far back as 1754 at the Albany Congress when he wrote, \\"That it is supposd an undoubted Right of Englishmen not to be taxed but by their own Consent given thro their Representatives. That the Colonies have no Representatives in Parliament.\\"[39]  The counter to this argument was the theory of virtual representation. Thomas Whately enunciated this theory in a pamphlet that readily acknowledged that there could be no taxation without consent, but the facts were that at least 75% of British adult males were not represented in Parliament because of property qualifications or other factors.  Members of Parliament were bound to represent the interests of all British citizens and subjects, so colonists were the recipients of virtual representation in Parliament, like those disenfranchised subjects in the British Isles.[40]  This theory, however, ignored a crucial difference between the unrepresented in Britain and the colonists.  The colonists enjoyed actual representation in their own legislative assemblies, and the issue was whether these legislatures, rather than Parliament, were in fact the sole recipients of the colonists' consent with regard to taxation.[41]\\r\\n\\r\\nIn May 1764, Samuel Adams of Boston drafted the following that stated the common American position:\\r\\n\\r\\nFor if our Trade may be taxed why not our Lands?  Why not the Produce of our Lands & every thing we possess or make use of?  This we apprehend annihilates our Charter Right to govern & tax ourselves?ÿ It strikes our British Privileges, which as we have never forfeited them, we hold in common with our Fellow Subjects who are Natives of Britain: If Taxes are laid upon us in any shape without our having a legal Representation where they are laid, are we not reduced from the Character of free Subjects to the miserable State of tributary Slaves.[42]\\r\\n\\r\\nMassachusetts appointed a five-member Committee of Correspondence in June 1764 to coordinate action and exchange information regarding the Sugar Act, and Rhode Island formed a similar committee in October 1764.  This attempt at unified action represented a significant step forward in colonial unity and cooperation. The Virginia House of Burgesses sent a protest of the taxes to London in December 1764, arguing that they did not have the specie required to pay the tax.[43]  Massachusetts, New York, New Jersey, Rhode Island, and Connecticut also sent protest to England in 1764.  The content of the messages varied, but they all emphasized that taxation of the colonies without colonial assent was a violation of their rights.  By the end of 1765, all of the Thirteen Colonies except Georgia and North Carolina had sent some sort of protest passed by colonial legislative assemblies.[44]\\r\\n\\r\\nThe Virginia House of Burgesses reconvened in early May 1765 after news was received of the passage of the Act. By the end of May, it appeared that they would not consider the tax, and many legislators went home, including George Washington. Only 30 out of 116 Burgesses remained, but one of those remaining was Patrick Henry who was attending his first session.  Henry led the opposition to the Stamp Act; he proposed his resolutions on 30 May 1765, and they were passed in the form of the Virginia Resolves.[45]  The Resolves stated:\\r\\n\\r\\nResolved, That the first Adventurers and Settlers of this his majesty's colony and Dominion of Virginia brought with them, and transmitted to their Posterity, and all other his Majesty's subjects since inhabiting in this his Majesty's said Colony, all the Liberties, privileges, Franchises, and Immunities that have at any Time been held, enjoyed, and possessed, by the People of Great Britain.\\r\\n\\r\\nResolved, That by the two royal Charters, granted by King James the First, the Colonists aforesaid are declared entitled to all Liberties, Privileges, and Immunities of Denizens and natural Subjects, to all Intents and Purposes, as if they had been abiding and born within the Realm of England.\\r\\n\\r\\nResolved, That the Taxation of the People by themselves, or by Persons chosen by themselves to represent them, who could only know what Taxes the People are able to bear, or the easiest method of raising them, and must themselves be affected by every Tax laid on the People, is the only Security against a burdensome Taxation, and the distinguishing characteristick of British Freedom, without which the ancient Constitution cannot exist.\\r\\n\\r\\nResolved, That his majesty's liege people of this his most ancient and loyal Colony have without interruption enjoyed the inestimable Right of being governed by such Laws, respecting their internal Polity and Taxation, as are derived from their own Consent, with the Approbation of their Sovereign, or his Substitute; and that the same hath never been forfeited or yielded up, but hath been constantly recognized by the King and People of Great Britain.[46]\\r\\n\\r\\nOn 6 June 1765, the Massachusetts Lower House proposed a meeting for the 1st Tuesday of October in New York City:\\r\\n\\r\\nThat it is highly expedient there should be a Meeting as soon as may be, of Committees from the Houses of Representatives or Burgesses in the several Colonies on this Continent to consult together on the present Circumstances of the Colonies, and the difficulties to which they are and must be reduced by the operation of the late Acts of Parliament for levying Duties and Taxes on the Colonies, and to consider of a general and humble Address to his Majesty and the Parliament to implore Relief.[47]\\r\\n\\r\\nThere was no attempt to keep this meeting a secret; Massachusetts promptly notified Richard Jackson of the proposed meeting, their agent in England and a member of Parliament.[48]\\r\\n\\r\\nWhile the colonial legislatures were acting, the ordinary citizens of the colonies were also voicing their concerns outside of this formal political process.  Historian Gary B. Nash wrote:\\r\\n\\r\\nWhether stimulated externally or ignited internally, ferment during the years  from 1761 to 1766 changed the dynamics of social and political relations in the colonies and set in motion currents of reformist sentiment with the force of a mountain wind.  Critical to this half decade was the colonial response to Englands Stamp Act, more the reaction of common colonists than that of their presumed leaders.[51]\\r\\n\\r\\nBoth loyal supporters of English authority and well-established colonial protest leaders underestimated the self-activating capacity of ordinary colonists.  By the end of 1765 ... people in the streets had astounded, dismayed, and frightened their social superiors.[52]\\r\\n\\r\\nEarly street protests were most notable in Boston. Andrew Oliver was a distributor of stamps for Massachusetts who was hanged in effigy on 14 August 1765 \\"from a giant elm tree at the crossing of Essex and Orange Streets in the citys South End.\\"  Also hung was a jackboot painted green on the bottom (\\"a Green-ville sole\\"), a pun on both Grenville and the Earl of Bute, the two people most blamed by the colonists.[53] Lieutenant Governor Thomas Hutchinson ordered sheriff Stephen Greenleaf to take down the effigy, but he was opposed by a large crowd.  All day the crowd detoured merchants on Orange Street to have their goods symbolically stamped under the elm tree, which later became known as the \\"Liberty Tree\\".\\r\\n\\r\\nEbenezer MacIntosh was a veteran of the Seven Years' War and a shoemaker. One night, he led a crowd which cut down the effigy of Andrew Oliver and took it in a funeral procession to the Town House where the legislature met.  From there, they went to Oliver's officewhich they tore down and symbolically stamped the timbers. Next, they took the effigy to Olivers home at the foot of Fort Hill, where they beheaded it and then burned italong with Olivers stable house and coach and chaise.  Greenleaf and Hutchinson were stoned when they tried to stop the mob, which then looted and destroyed the contents of Oliver's house.  Oliver asked to be relieved of his duties the next day.[54] This resignation, however, was not enough.  Oliver was ultimately forced by MacIntosh to be paraded through the streets and to publicly resign under the Liberty Tree.[55]\\r\\n\\r\\nAs news spread of the reasons for Andrew Oliver's resignation, violence and threats of aggressive acts increased throughout the colonies, as did organized groups of resistance.  Throughout the colonies, members of the middle and upper classes of society formed the foundation for these groups of resistance and soon called themselves the Sons of Liberty.  These colonial groups of resistance burned effigies of royal officials, forced Stamp Act collectors to resign, and were able to get businessmen and judges to go about without using the proper stamps demanded by Parliament.[56]\\r\\n\\r\\nOn 16 August, a mob damaged the home and official papers of William Story, the deputy register of the Vice-Admiralty, who then moved to Marblehead, Massachusetts. Benjamin Hallowell, the comptroller of customs, suffered the almost total loss of his home.[57]\\r\\n\\r\\nOn 26 August, MacIntosh led an attack on Hutchinson's mansion.  The mob evicted the family, destroyed the furniture, tore down the interior walls, emptied the wine cellar, scattered Hutchinson's collection of Massachusetts historical papers, and pulled down the building's cupola.  Hutchinson had been in public office for three decades; he estimated his loss at S2,218[58] (in today's money, at nearly $250,000).  Nash concludes that this attack was more than just a reaction to the Stamp Act:\\r\\n\\r\\nBut it is clear that the crowd was giving vent to years of resentment at the accumulation of wealth and power by the haughty prerogative faction led by Hutchinson.  Behind every swing of the ax and every hurled stone, behind every shattered crystal goblet and splintered mahogany chair, lay the fury of a plain Bostonian who had read or heard the repeated references to impoverished people as \\"rable\\" and to Bostons popular caucus, led by Samuel Adams, as a \\"herd of fools, tools, and synchophants.\\"[59]\\r\\n\\r\\nGovernor Francis Bernard offered a S300 reward for information on the leaders of the mob, but no information was forthcoming. MacIntosh and several others were arrested, but were either freed by pressure from the merchants or released by mob action.[60]\\r\\n\\r\\nThe street demonstrations originated from the efforts of respectable public leaders such as James Otis, who commanded the Boston Gazette, and Samuel Adams of the \\"Loyal Nine\\" of the Boston Caucus, an organization of Boston merchants. They made efforts to control the people below them on the economic and social scale, but they were often unsuccessful in maintaining a delicate balance between mass demonstrations and riots.  These men needed the support of the working class, but also had to establish the legitimacy of their actions to have their protests to England taken seriously.[61]  At the time of these protests, the Loyal Nine was more of a social club with political interests but, by December 1765, it began issuing statements as the Sons of Liberty.[62]\\r\\n\\r\\nRhode Island also experienced street violence. A crowd built a gallows near the Town House in Newport on 27 August, where they carried effigies of three officials appointed as stamp distributors: Augustus Johnson, Dr. Thomas Moffat, and lawyer Martin Howard. The crowd at first was led by merchants William Ellery, Samuel Vernon, and Robert Crook, but they soon lost control. That night, the crowd was led by a poor man named John Weber, and they attacked the houses of Moffat and Howard, where they destroyed walls, fences, art, furniture, and wine.  The local Sons of Liberty were publicly opposed to violence, and they refused at first to support Weber when he was arrested.  They were persuaded to come to his assistance, however, when retaliation was threatened against their own homes.  Weber was released and faded into obscurity.[63]\\r\\n\\r\\nHoward became the only prominent American to publicly support the Stamp Act in his pamphlet \\"A Colonist's Defence of Taxation\\" (1765). After the riots, Howard had to leave the colony, but he was rewarded by the Crown with an appointment as Chief Justice of North Carolina at a salary of ?1,000.[64]\\r\\n\\r\\nIn New York, James McEvers resigned his distributorship four days after the attack on Hutchinson's house.  The stamps arrived in New York Harbor on 24 October for several of the northern colonies.  Placards appeared throughout the city warning that \\"the first man that either distributes or makes use of stamped paper let him take care of his house, person, and effects.\\"  New York merchants met on 31 October and agreed not to sell any English goods until the Act was repealed.  Crowds took to the streets for four days of demonstrations, uncontrolled by the local leaders, culminating in an attack by two thousand people on Governor Cadwallader Colden's home and the burning of two sleighs and a coach. Unrest in New York City continued through the end of the year, and the local Sons of Liberty had difficulty in controlling crowd actions.[65]\\r\\n\\r\\nIn Frederick, Maryland, a court of 12 magistrates ruled the Stamp Act invalid on 23 November 1765, and directed that businesses and colonial officials proceed in all matters without use of the stamps.  A week later, a crowd conducted a mock funeral procession for the act in the streets of Frederick.  The magistrates have been dubbed the \\"12 Immortal Justices,\\" and 23 November has been designated \\"Repudiation Day\\" by the Maryland state legislature.  On 1 October 2015, Senator Cardin (D-MD) read into the Congressional Record a statement noting 2015 as the 250th anniversary of the event.  Among the 12 magistrates was William Luckett, who later served as lieutenant colonel in the Maryland Militia at the battle of Germantown.\\r\\n\\r\\nOther popular demonstrations occurred in Portsmouth, New Hampshire, Annapolis, Maryland, Wilmington and New Bern, North Carolina, and Charleston, South Carolina.  In Philadelphia, Pennsylvania, demonstrations were subdued but even targeted Benjamin Franklin's home, although it was not vandalized.[66] By 16 November, twelve of the stamp distributors had resigned.  The Georgia distributor did not arrive in America until January 1766, but his first and only official action was to resign.[67]\\r\\n\\r\\nThe overall effect of these protests was to both anger and unite the American people like never before.  Opposition to the Act inspired both political and constitutional forms of literature throughout the colonies, strengthened the colonial political perception and involvement, and created new forms of organized resistance.  These organized groups quickly learned that they could force royal officials to resign by employing violent measures and threats.[68]\\r\\n\\r\\nThe main issue was constitutional rights of Englishmen, so the French in Quebec did not react.  Some English-speaking merchants were opposed, but were in a fairly small minority. The Quebec Gazette ceased publication until the act was repealed, apparently over the unwillingness to use stamped paper.[69]  In neighboring Nova Scotia a number of former New England residents objected, but recent British immigrants and London-oriented business interests based in Halifax, the provincial capital were more influential.  The only major public protest was the hanging in effigy of the stamp distributor and Lord Bute.  The act was implemented in both provinces, but Nova Scotia's stamp distributor resigned in January 1766, beset by ungrounded fears for his safety.  Authorities there were ordered to allow ships bearing unstamped papers to enter its ports, and business continued unabated after the distributors ran out of stamps.[70]  The Act occasioned some protests in Newfoundland, and the drafting of petitions opposing not only the Stamp Act, but the existence of the customhouse at St. John's, based on legislation dating back to the reign of Edward VI forbidding any sort of duties on the importation of goods related to its fisheries.[71]\\r\\n\\r\\nViolent protests were few in the Caribbean colonies.  Political opposition was expressed in a number of colonies, including Barbados and Antigua, and by absentee landowners living in Britain.  The worst political violence took place on St. Kitts and Nevis.  Riots took place on 31 October 1765, and again on 5 November, targeting the homes and offices of stamp distributors; the number of participants suggests that the percentage of St. Kitts' white population involved matched that of Bostonian involvement in its riots.  The delivery of stamps to St. Kitts was successfully blocked, and they were never used there.  Montserrat and Antigua also succeeded in avoiding the use of stamps; some correspondents thought that rioting was prevented in Antigua only by the large troop presence.  Despite vocal political opposition, Barbados used the stamps, to the pleasure of King George.  In Jamaica there was also vocal opposition, which included threats of violence.  There was much evasion of the stamps, and ships arriving without stamped papers were allowed to enter port.  Despite this, Jamaica produced more stamp revenue (S2,000) than any other colony.[72]\\r\\n\\r\\nIt was during this time of street demonstrations that locally organized groups started to merge into an inter-colonial organization of a type not previously seen in the colonies.  The term \\"sons of liberty\\" had been used in a generic fashion well before 1765, but it was only around February 1766 that its influence extended throughout the colonies as an organized group using the formal name \\"Sons of Liberty\\", leading to a pattern for future resistance to the British that carried the colonies towards 1776.[73] Historian John C. Miller noted that the name was adopted as a result of Barre's use of the term in his February 1765 speech.[74]\\r\\n\\r\\nThe organization spread month by month after independent starts in several different colonies. By 6 November, a committee was set up in New York to correspond with other colonies, and in December an alliance was formed between groups in New York and Connecticut.  In January, a correspondence link was established between Boston and Manhattan, and by March, Providence had initiated connections with New York, New Hampshire, and Newport. By March, Sons of Liberty organizations had been established in New Jersey, Maryland, and Norfolk, Virginia, and a local group established in North Carolina was attracting interest in South Carolina and Georgia.[75]\\r\\n\\r\\nThe officers and leaders of the Sons of Liberty \\"were drawn almost entirely from the middle and upper ranks of colonial society,\\" but they recognized the need to expand their power base to include \\"the whole of political society, involving all of its social or economic subdivisions.\\" To do this, the Sons of Liberty relied on large public demonstrations to expand their base.[76]  They learned early on that controlling such crowds was problematical, although they strived to control \\"the possible violence of extra-legal gatherings.\\"  The organization professed its loyalty to both local and British established government, but possible military action as a defensive measure was always part of their considerations.  Throughout the Stamp Act Crisis, the Sons of Liberty professed continued loyalty to the King because they maintained a \\"fundamental confidence\\" that Parliament would do the right thing and repeal the tax.[77]\\r\\n\\r\\nColonial newspapers were a major source of public unrest after the passage of the Stamp Act. Some of the earliest forms of American propaganda appeared in these printings in response to the law. The articles written in colonial newspapers were particularly critical of the act because of the Stamp Act's disproportionate effect on printers. David Ramsay, a patriot and historian from South Carolina, wrote of this phenomenon shortly after the American Revolution:\\r\\n\\r\\nIt was fortunate for the liberties of America, that newspapers were the subject of a heavy stamp duty. Printers, when influenced by government, have genereally arranged themselves on the side of liberty, nor are they less remarkable for attention to the profits of their profession. A stamp duty, which openly invaded the first, and threatened a great diminution of the last, provoked their united zealous opposition.[78]\\r\\n\\r\\nMost printers were critical of the Stamp Act, although a few Loyalist voices did exist. Some of the more subtle Loyalist sentiments can be seen in publications such as The Boston Evening Post, which was run by British sympathizers John and Thomas Fleet. The article detailed a violent protest that occurred in New York in December, 1765, then described the riot's participants as \\"imperfect\\" and labeled the group's ideas as \\"contrary to the general sense of the people.\\"[79] These Loyalists beliefs can be seen in some of the early newspaper articles about the Stamp Act, but the anti-British writings were more prevalent and seem to have had a more powerful effect.[80]\\r\\n\\r\\nMany papers assumed a relatively conservative tone before the act went into effect, implying that they might close if it wasn't repealed. However, as time passed and violent demonstrations ensued, the authors became more vitriolic. Several newspaper editors were involved with the Sons of Liberty, such as William Bradford of The Pennsylvania Journal and Benjamin Edes of The Boston Gazette, and they echoed the group's sentiments in their publications.[81] The Stamp Act went into effect that November, and many newspapers ran editions with imagery of tombstones and skeletons, emphasizing that their papers were \\"dead\\" and would no longer be able to print because of the Stamp Act.[82] However, most of them returned in the upcoming months, defiantly appearing without the stamp of approval that was deemed necessary by the Stamp Act. Printers were greatly relieved when the law was nullified in the following spring, and the repeal asserted their positions as a powerful voice (and compass) for public opinion.[83]\\r\\n\\r\\nThe Stamp Act Congress was held in New York in October 1765.  Twenty-seven delegates from nine colonies were the members of the Congress, and their responsibility was to draft a set of formal petitions stating why Parliament had no right to tax them.[84]  Among the delegates were many important men in the colonies.  Historian John Miller observes, \\"The composition of this Stamp Act Congress ought to have been convincing proof to the British government that resistance to parliamentary taxation was by no means confined to the riffraff of colonial seaports.\\"[85]\\r\\n\\r\\nThe youngest delegate was 26-year-old John Rutledge of South Carolina, and the oldest was 65-year-old Hendrick Fisher of New Jersey.  Ten of the delegates were lawyers, ten were merchants, and seven were planters or land-owning farmers; all had served in some type of elective office, and all but three were born in the colonies.  Four died before the colonies declared independence, and four signed the Declaration of Independence; nine attended the first and second Continental Congresses, and three were Loyalists during the Revolution.[86]\\r\\n\\r\\nNew Hampshire declined to send delegates, and North Carolina, Georgia, and Virginia were not represented because their governors did not call their legislatures into session, thus preventing the selection of delegates.  Despite the composition of the congress, each of the Thirteen Colonies eventually affirmed its decisions.[87] Six of the nine colonies represented at the Congress agreed to sign the petitions to the King and Parliament produced by the Congress. The delegations from New York, Connecticut, and South Carolina were prohibited from signing any documents without first receiving approval from the colonial assemblies that had appointed them.[88]\\r\\n\\r\\nMassachusetts governor Francis Bernard believed that his colonys delegates to the Congress would be supportive of Parliament.  Timothy Ruggles in particular was Bernard's man, and was elected chairman of the Congress.  Ruggles' instructions from Bernard were to \\"recommend submission to the Stamp Act until Parliament could be persuaded to repeal it.\\"[89]  Many delegates felt that a final resolution of the Stamp Act would actually bring Britain and the colonies closer together. Robert Livingston of New York stressed the importance of removing the Stamp Act from the public debate, writing to his colony's  agent in England, \\"If I really wished to see America in a state of independence I should desire as one of the most effectual means to that end that the stamp act should be enforced.\\"[90]\\r\\n\\r\\nThe Congress met for 12 consecutive days, including Sundays.  There was no audience at the meetings, and no information was released about the deliberations.[91]  The meeting's final product was called \\"The Declaration of Rights and Grievances\\", and was drawn up by delegate John Dickinson of  Pennsylvania. This Declaration raised fourteen points of colonial protest. It asserted that colonists possessed all the rights of Englishmen in addition to protesting the Stamp Act issue, and that Parliament could not represent the colonists since they had no voting rights over Parliament. Only the colonial assemblies had a right to tax the colonies. They also asserted that the extension of authority of the admiralty courts to non-naval matters represented an abuse of power.[92]\\r\\n\\r\\nIn addition to simply arguing for their rights as Englishmen, the congress also asserted that they had certain natural rights solely because they were human beings.  Resolution 3 stated, \\"That it is inseparably essential to the freedom of a people, and the undoubted right of Englishmen, that no taxes be imposed on them, but with their own consent, given personally, or by their representatives.\\"  Both Massachusetts and Pennsylvania brought forth the issue in separate resolutions even more directly when they respectively referred to \\"the Natural rights of Mankind\\" and \\"the common rights of mankind\\".[93]\\r\\n\\r\\nChristopher Gadsden of South Carolina had proposed that the Congress' petition should go only to the king, since the rights of the colonies did not originate with Parliament. This radical proposal went too far for most delegates and was rejected. The \\"Declaration of Rights and Grievances\\" was duly sent to the king, and petitions were also sent to both Houses of Parliament.[94]\\r\\n\\r\\nGrenville was replaced by Lord Rockingham as Prime Minister on 10 July 1765.  News of the mob violence began to reach England in October. Conflicting sentiments were taking hold in Britain at the same time that resistance was building and accelerating in America. Some wanted to strictly enforce the Stamp Act over colonial resistance, wary of the precedent that would be set by backing down.[95]  Others felt the economic effects of reduced trade with America after the Sugar Act and an inability to collect debts while the colonial economy suffered, and they began to lobby for a repeal of the Stamp Act.[96] The colonial protest had included various non-importation agreements among merchants who recognized that a significant portion of British industry and commerce was dependent on the colonial market.  This movement had also spread through the colonies; 200 merchants had met in New York City and agreed to import nothing from England until the Stamp Act was repealed.[97]\\r\\n\\r\\nWhen Parliament met in December 1765, it rejected a resolution offered by Grenville that would have condemned colonial resistance to the enforcement of the Act.  Outside of Parliament, Rockingham and his secretary Edmund Burke, a member of Parliament himself, organized London merchants who started a committee of correspondence to support repeal of the Stamp Act by urging merchants throughout the country to contact their local representatives in Parliament.  When Parliament reconvened on 14 January 1766, the Rockingham ministry formally proposed repeal.  Amendments were considered that would have lessened the financial impact on the colonies by allowing colonists to pay the tax in their own scrip, but this was viewed to be too little and too late.[98]\\r\\n\\r\\nWilliam Pitt stated in the Parliamentary debate that everything done by the Grenville ministry \\"has been entirely wrong\\" with respect to the colonies.  He further stated, \\"It is my opinion that this Kingdom has no right to lay a tax upon the colonies.\\" Pitt still maintained \\"the authority of this kingdom over the colonies, to be sovereign and supreme, in every circumstance of government and legislature whatsoever,\\" but he made the distinction that taxes were not part of governing, but were \\"a voluntary gift and grant of the Commons alone.\\"  He rejected the notion of virtual representation, as \\"the most contemptible idea that ever entered into the head of man.\\"[99]\\r\\n\\r\\nGrenville responded to Pitt:\\r\\n\\r\\nProtection and obedience are reciprocal.  Great Britain protects America; America is bound to yield obedience.  If, not, tell me when the Americans were emancipated?  When they want the protection of this kingdom, they are always ready to ask for it.  That protection has always been afforded them in the most full and ample manner.  The nation has run itself into an immense debt to give them their protection; and now they are called upon to contribute a small share towards the public expence, and expence arising from themselves, they renounce your authority, insult your officers, and break out, I might also say, into open rebellion.[100]\\r\\n\\r\\nPitts response to Grenville included, \\"I rejoice that America has resisted.  Three millions of people, so dead to all the feelings of liberty as voluntarily to submit to be slaves, would have been fit instruments to make slaves of the rest.\\"[101]\\r\\n\\r\\nBetween 17 and 27 January, Rockingham shifted the attention from constitutional arguments to economic by presenting petitions complaining of the economic repercussions felt throughout the country.  On 7 February, the House of Commons rejected a resolution by 274ÿ134, saying that it would back the King in enforcing the Act.  Henry Seymour Conway, the government's leader in the House of Commons, introduced the Declaratory Act in an attempt to address both the constitutional and the economic issues, which affirmed the right of Parliament to legislate for the colonies \\"in all cases whatsoever\\", while admitting the inexpediency of attempting to enforce the Stamp Act.  Only Pitt and three or four others voted against it. Other resolutions passed which condemned the riots and demanded compensation from the colonies for those who suffered losses because of the actions of the mobs.[102]\\r\\n\\r\\nThe House of Commons heard testimony between 11 and 13 February, the most important witness being Benjamin Franklin on the last day of the hearings. He responded to the question about how the colonists would react if the Act was not repealed: \\"A total loss of the respect and affection the people of America bear to this country, and of all the commerce that depends on that respect and affection.\\" A Scottish journalist observed Franklin's answers to Parliament and his affect on the repeal; he later wrote to Franklin, \\"To this very Examination, more than to any thing else, you are indebted to the speedy and total Repeal of this odious Law.\\"[103]\\r\\n\\r\\nA resolution was introduced on 21 February to repeal the Stamp Act, and it passed by a vote of 276ÿ168.  The King gave royal assent on 18 March 1766.[104][105]\\r\\n\\r\\nSome aspects of the resistance to the act provided a sort of rehearsal for similar acts of resistance to the 1767 Townshend Acts, particularly the activities of the Sons of Liberty and merchants in organizing opposition.  The Stamp Act Congress was a predecessor to the later Continental Congresses, notably the Second Continental Congress which oversaw the establishment of American independence.  The Committees of Correspondence used to coordinate activities were revived between 1772 and 1774 in response to a variety of controversial and unpopular affairs, and the colonies that met at the 1774 First Continental Congress established a non-importation agreement known as the Continental Association in response to Parliamentary passage of the Intolerable Acts.[citation needed]","input":"What was the purpose of the stamp act?"},{"output":"first film","context":"","input":"Why was star wars episode iv released first?"},{"output":"on September 11","context":"\\r\\n\\r\\nSailor Moon,[10][11] known in Japan as Pretty Soldier Sailor Moon (Japanese: ˇW?ؿc؂\`ةμ, Hepburn: Bishjo Senshi Sr Mn), is a 1992 Japanese anime television series produced by Toei Animation using Super Sentai motifs. It is based on the manga of the same title written by Naoko Takeuchi that was published from 1991 to 1997 in Nakayoshi. Sailor Moon first aired in Japan on TV Asahi from March 7, 1992, to February 8, 1997, and was dubbed into various territories around the world, including the United States, Australia, Europe and Latin America.\\r\\n\\r\\nThe series follows the adventures of the protagonist Usagi Tsukino, a middle school student who is given the power to become the titular Sailor Soldier. Joined by other Sailor Soldiers, they defend Earth against an assortment of evil villains. The anime also parallels the maturation of Usagi from an emotional middle school girl to a responsible young adult.\\r\\n\\r\\nDue to the success of the anime in the United States, the manga comprising its story was released by Tokyopop. Additional manga works, called animanga, were released which adapt the animation to manga form.[not verified in body] Sailor Moon's popularity has spawned numerous releases which have come to represent most of the content in the Sailor Moon universe, including 3 films, 39 video games, and numerous soundtracks stemming from this material. A second animated adaptation, Sailor Moon Crystal, began streaming worldwide from July 2014 onwards.\\r\\n\\r\\nA 14-year-old underachieving young sailor-suited schoolgirl named Usagi Tsukino meets a magical talking cat named Luna. Luna gives Usagi the ability to transform into her magical alter ego  Sailor Moon  tasked with locating the moon princess and battling the evil forces of the Dark Kingdom. The Dark Kingdom  led by Queen Beryl  summons various monsters called Youma in order to sap energy from humans and feed it to an evil entity known as Queen Metaria. They also seek the Silver Crystal (ͼni, Maboroshi no Ginzuish, lit. \\"Phantom Silver Crystal\\"), a gem capable of limitless power.\\r\\n\\r\\nAs Usagi battles against the Dark Kingdom, she is joined by other girls also awakening as Sailor Soldiers: the timid but intelligent Ami Mizuno (Sailor Mercury), the hot-headed miko Rei Hino (Sailor Mars), the tomboyish but romantic Makoto Kino (Sailor Jupiter), and the aspiring idol Minako Aino (Sailor Venus). Minako is joined by Artemis, her feline advisor and Luna's partner. The Sailor Soldiers are often supported by the mysterious Tuxedo Mask whose civilian form is Mamoru Chiba, a college student with whom Usagi eventually becomes romantically involved.\\r\\n\\r\\nAfter continually thwarting the Dark Kingdom and defeating several of its generals, Usagi awakens as the moon princess  Princess Serenity  and acquires the Silver Crystal. However, Mamoru is captured by the Dark Kingdom and brainwashed to work for them. The Sailor Soldiers learn of their past lives on Silver Millennium, an ancient kingdom on the moon. The Sailor Soldiers served as Serenity's friends and bodyguards, and Serenity fell in love with a prince from Earth named Endymion (Mamoru's past identity). However, the Dark Kingdom attacked and destroyed Silver Millennium, resulting in the deaths of Serenity, Endymion, and the Sailor Soldiers. Serenity's mother  Queen Serenity  used the power of the Silver Crystal to vanquish Queen Metaria and end the war. She also used the crystal to send the fallen into the future to be reborn on Earth, hoping to give them a second chance at peace.\\r\\n\\r\\nThe Sailor Soldiers eventually pinpoint the location of the Dark Kingdom at the North Pole and travel there. However, Usagi's friends are killed trying to protect her from Queen Beryl's monsters. Usagi faces Mamoru alone and is forced to strike him down. Using the Silver Crystal, she then faces Queen Beryl (who has fused with Queen Metaria). Defeating her with the help of the fallen Sailor Soldiers spirits and the Silver Crystal's power. She then uses the last of the Silver Crystal's power  to resurrect the Sailor Soldiers and Mamoru with one wish that they all get to live normal lives again. Everything on Earth is returned to normal, and no one (but Luna and Artemis) retain any memories of these events.\\r\\n\\r\\nSome time later, a pair of extraterrestrials named Ail and Ann descend onto Earth with the Hell Tree which feeds on human energy. Ail and Ann summon monsters from cards  called Cardians  to prey on humans. In order to defend against these attacks, Luna and Artemis restore the Sailor Soldiers' memories. Eventually, Ail and Ann are defeated, see the error of their ways, and return to space with the Makai Tree. During these events, Mamoru is able to reclaim his lost memories and begins a romantic relationship with Usagi.\\r\\n\\r\\nShortly after these events, a pink-haired girl named Chibiusa falls from the sky. Chibiusa traveled from the future in order to find the Silver Crystal and use it to save her parents. She is followed by the Black Moon Clan, a new enemy force that is trying to kill her. Eventually, the Sailor Soldiers and Tuxedo Mask travel with Chibiusa to the future where Usagi rules Crystal Tokyo as Neo-Queen Serenity. They learn that Chibiusa is actually Usagi and Mamoru's future daughter, and they also meet Sailor Pluto who guards the Door of Space-Time. Eventually, the Sailor Soldiers battle against Wiseman, a dark force that was manipulating the Black Moon Clan with the intention of destroying Earth. Chibiusa is able to summon the Silver Crystal of the future and aids in the destruction of Wiseman. Afterwards, Chibiusa returns to her own time, now freed from the Black Moon Clan's corruption.\\r\\n\\r\\nSome time later, the Sailor Soldiers encounter the Death Busters, an evil organization that is summoning monsters called Daimons to steal Heart Crystals from humans. Their intention is to locate three specific Heart Crystals that contain special Talismans. Joining the Sailor Soldiers are Haruka Tenoh and Michiru Kaioh, who operate as Sailor Uranus and Sailor Neptune respectively. The two are also seeking the Talismans for different purposes and come into conflict with the other Sailor Soldiers. Sailor Pluto returns to the present day as Setsuna Meioh; Chibiusa also returns, now donning her own magical girl identity of Sailor Chibi Moon.\\r\\n\\r\\nThe Death Busters eventually discover that Haruka and Michiru hold two of the Talismans and acquire them at the cost of their lives, but Setsuna  who holds the third  revives them. The Talismans create the Holy Grail, allowing Usagi to acquire a second form: Super Sailor Moon. The Death Busters' intentions then change to harvesting Heart Crystals en masse to resurrect the malevolent entity known as Mistress 9. Chibiusa also befriends a sickly girl named Hotaru, unaware that she is the daughter of the Death Busters' leader, Professor Tomoe. Unknown to her, Hotaru is also Sailor Saturn, a Sailor Soldier capable of destroying and rebirthing entire planets. Haruka, Michiru and Setsuna fear that her awakening will result in Earth's destruction and plead for Usagi to kill her.\\r\\n\\r\\nMistress 9 is revealed to have been residing within Hotaru's body and awakens upon stealing Chibiusa's Heart Crystal. She then tricks Usagi into handing over the Holy Grail, allowing her to summon Pharaoh 90 to destroy the Earth. Hotaru awakens as Sailor Saturn and intends to sacrifice herself to stop Pharaoh 90, but Usagi is able to activate her Super form to both destroy Pharaoh 90 and rescue Hotaru. Afterwards, Hotaru is reborn as a baby and returned to her father, now freed from the influence of the Death Busters.\\r\\n\\r\\nChibiusa remains in the present day to train as a Sailor Soldier. She meets an alicorn named Pegasus who forms a secret relationship with her through her dreams. Pegasus also aids the Sailor Soldiers by upgrading them to permanent Super forms and lending his power when summoned by Chibiusa. The new powers are used to combat the Dead Moon Circus, a mysterious circus troupe that targets humans with beautiful dreams. By looking into their Dream Mirrors, they hope to find the dream in which Pegasus is hiding, believing Pegasus possesses the Golden Crystal. With this crystal, the Dead Moon Circus's ruler  Queen Nehelenia  can be freed from the mirror she was sealed in.\\r\\n\\r\\nQueen Nehelenia was once a queen of her own kingdom that was absorbed by vanity. In fear of losing her beauty, she consumed the dreams of her subjects to stay young. She sought the Golden Crystal in the possession of a priest named Helios (Pegasus's true form) and was sealed within a mirror by Queen Serenity as a result. Queen Nehelenia formed the Dead Moon Circus and used Zirconia as a proxy to track Pegasus down. Although she obtains the Golden Crystal, she is betrayed by the Amazoness Quartet who gives the crystal to Chibiusa. Using the crystal, Queen Nehelenia is defeated and begins to wither with age, forcing her back into the mirror she was once sealed within. Helios returns to his home world of Elysion.\\r\\n\\r\\nQueen Nehelenia returns when Sailor Galaxia frees her and encourages her to seek revenge against the Sailor Soldiers. She targets Mamoru and places a curse on him that will ultimately kill him and erase Chibiusa from existence. The Sailor Soldiers enter Queen Nehelenia's nightmare dimension to stop her. Usagi eventually comes to pity Queen Nehelenia's plight and is able to rid her of her negativity by activating her final form, Eternal Sailor Moon.\\r\\n\\r\\nShortly after these events, Mamoru leaves for the United States to study abroad while Usagi and her friends enter high school. Chibiusa also returns to her own time. A group of enemies called the Sailor Animamates  led by Sailor Galaxia  begin targeting humans for their Star Seeds (which serve as a human's life force). Usagi is also aided by the Sailor Starlights  Kou Seiya (Sailor Star Fighter), Kou Taiki (Sailor Star Maker), and Kou Yaten (Sailor Star Healer)  who disguise themselves as an idol group named the Three Lights. The Starlights are searching for their ruler, Princess Kakyuu. A young girl  nicknamed Chibichibi because of her inability to say anything other than \\"chibi\\"  also appears and begins living with Usagi.\\r\\n\\r\\nSailor Galaxia's past is eventually revealed. She once ended the Sailor Wars by sealing Chaos  the source of all malice  within her body. Unable to resist Chaos's influence, she separated her Star Seed from her body, and it took the form of Chibichibi. Sailor Galaxia steals the Star Seeds of Usagi's companions, resulting in their deaths. This includes Mamoru who was targeted before he arrived in the United States. Chibichibi transforms into the Sword of Sealing and urges Usagi to kill Sailor Galaxia. However, Usagi instead uses the kindness in her own heart to free Sailor Galaxia of Chaos's corruption, effectively resurrecting all of the Sailor Soldiers whose Star Seeds were taken. With normalcy restored, Usagi and Mamoru share a kiss under a full moon.\\r\\n\\r\\nNaoko Takeuchi developed the Sailor Moon anime for one season. Due to the season's popularity, Toei Animation asked Takeuchi to keep drawing her manga. At first, she struggled with developing another storyline to extend the series due to Toei's request. The basic idea of the second season, introducing the daughter of Sailor Moon from the future, came from her editor, Fumio Osano.[12] Sailor Moon is adapted from the 52 chapters of the series which was published in Nakayoshi from 1991ÿ1997 and was directed by Junichi Sat, Kunihiko Ikuhara and Takuya Igarashi.[13] It premiered in Japan on TV Asahi on March 7, 1992, taking over the timeslot previously held by Goldfish Warning!,[citation needed] and ran for 200 episodes until its conclusion on February 8, 1997.\\r\\n\\r\\nBecause the manga was often published during the anime's production, the anime would only lag the manga by a month or two.[14]:93 As a result, \\"the anime follows the storyline of the manga fairly closely.\\"[15] Takeuchi has stated that due to Toei's largely male production staff, she feels that the anime version has \\"a slight male perspective.\\"[15]\\r\\n\\r\\nSailor Moon sparked a highly successful merchandising campaign of over 5,000 items,[16] which contributed to demand internationally and translation into numerous languages. Sailor Moon has since become one of the most famous anime properties in the world.[17][18] Due to its resurgence of popularity in Japan, the series was rebroadcast on September 1, 2009. The series also began rebroadcasting in Italy in Autumn 2010, receiving permission from Naoko Takeuchi, who released new artwork to promote its return.[19]\\r\\n\\r\\nPretty Soldier Sailor Moon consists of five separate seasons, titled Sailor Moon, Sailor Moon R, Sailor Moon S, Sailor Moon SuperS and Sailor Moon: Sailor Stars, respectively. The seasons each roughly correspond to one of the five major story arcs of the manga, following the same general storyline and including most of the same characters.[14]:93 Toei also developed five special animated shorts.\\r\\n\\r\\nThe anime series was sold as 20 volumes in Japan. By the end of 1995, each volume had sold approximately 300,000 copies.[14]:95\\r\\n\\r\\nIn 1995, after a bidding war with Toon Makers, who wanted to produce an American live-action/animated hybrid adaptation,[20] DIC Entertainment (now DHX Media) licensed the first two seasons of Sailor Moon for an English-language release in North America.[21] The Mississauga-based Optimum Productions was hired to dub the anime. Bob Summers wrote a new background score.[note 1] DIC had mandated cuts to content and length, which reduced the first 89 episodes into 82.[note 2] Their adaptation was created to capitalize on the success of Mighty Morphin Power Rangers.[22][23]\\r\\n\\r\\nThe series premiered in Canada on August 28, 1995 on YTV and in first-run syndication in the U.S. on September 11, but halted production in November 1995 after two seasons due to low ratings.[24][25] Despite moderate success in Canada, the U.S. airing struggled in early morning \\"dead\\" timeslots;[26] the series originally aired in the U.S. in morning and afternoon timeslots which Anne Allison describes as unsuitable for the target audience.[22] In contrast, due to the dubbing process being done in Canada, the series was considered Canadian enough to be screened in primetime as local content.[27] After the series was cancelled, a fan petition that garnered over 12,500 signatures was created.[28] This was later considered an early example of successful fan activism.[27] In 1997, re-runs of this cancelled dub began airing on USA Network. That same year, production on the series' English dub was resumed with the last 17 episodes of the second season, Sailor Moon R, and was broadcast in Canada from September 20 to November 21, 1997 to wrap up lingering plot lines.[29] The series finished airing on YTV in January 2004.\\r\\n\\r\\nOn June 1, 1998, reruns of the series began airing on Cartoon Network's weekday afternoon programming block, Toonami. Due to the success of these reruns, the remaining seventeen episodes also aired on the block. In 1999, Cloverway Inc. once again contracted Optimum Productions to produce English-language adaptations of Sailor Moon S and Sailor Moon SuperS, with Pioneer Entertainment handling home video distribution. This dub featured less censorship and was first broadcast on YTV in Canada, and later on Toonami in the United States. The dub finished airing on Toonami on September 13, 2002; in 2003, ADV and Pioneer lost the distribution rights to the first 159/166 episodes, as well as the three films.[30][unreliable source]\\r\\n\\r\\nDue to the series' resurgence of popularity in Japan, re-runs of the Sailor Moon series began on September 1, 2009 on Animax.[19] In 2010, Toei negotiated to license and broadcast Sailor Moon in Italy on Mediaset, resulting in an international revival.[31] Later, Toei licensed Sailor Moon episodes to countries which the show has not been aired before. On May 16, 2014, North American manga and anime distributor Viz Media announced that it had acquired the Sailor Moon anime series, as well as the three films and specials for an English-language release in North America, allowing Viz to restore the removed content from the first 89 episodes. The Studio City, Los Angeles-based Studiopolis was also hired by Viz to re-dub the entire series.[32][33] The series began streaming in the United States on Neon Alley and Hulu on May 19, 2014,[32] and in Canada on Tubi TV on July 15, 2016.[34]  On November 28, 2014, Australian manga and anime publisher Madman Entertainment announced that they had re-acquired the rights to the \\"Sailor Moon\\" anime series for Australia & New Zealand and will release the series in uncut format with the Viz Media English adaptation in 2015.[35] Madman Entertainment had previously held the Australian licence for Sailor Moon on VHS & DVD until DiC lost the English-language rights.[citation needed]\\r\\n\\r\\nSailor Moon's original North American release was the subject of heavy editing which resulted in large amounts of removed content and alterations that greatly changed the original work.[36] Much of these changes included altering every aspect of the show from character names, clothing, scenes and dialogue of the show. Some scenes of brief nudity and bathing were also censored,[37] and any type of violence including violence against children were also removed.[22][38] Homosexual characters, including Zoisite, Fisheye, Kunzite, Sailor Uranus, and Sailor Neptune were also censored, with the former two's gender changed from male to female, and the latter two being explained as relatives rather than lovers.[39]  Changing evil characters' genders to female also had the side-effect of creating more diverse female characterizations, as the evil female characters did not have the same body type.[27]\\r\\n\\r\\nViz Media's release restores all of the content that was cut from the original Japanese version, including scenes that were censored by Optimum Productions at the request of DiC and Cloverway.[citation needed]\\r\\n\\r\\nTakanori Arisawa composed the score for Pretty Soldier Sailor Moon. Arisawa earned the Golden Disk Grand Prize from Columbia Records for his work on the first series soundtrack in 1993. In 1998, 2000, and 2001 Arisawa won three consecutive JASRAC International Awards for most international royalties, owing largely to the popularity of Sailor Moon music in other nations.[40]\\r\\n\\r\\nThe opening theme, titled \\"Moonlight Densetsu\\" (ةμ?wh, Mnraito Densetsu, lit. \\"Moonlight Legend\\"), was used for the first 166 episodes. \\"Moonlight Densetsu\\" was initially performed by DALI for the first two seasons,[41][42] and then by Moon Lips for the next two seasons.[43][44] The second opening theme, used for the remaining episodes, is Sailor Star Song performed by Kae Hanazawa.[45] The last ending theme, used for the series finale at episode 200, is Moon Lips's version of \\"Moonlight Densetsu\\".[13]\\r\\n\\r\\nThe DiC/Cloverway/Optimum English adaptation of the anime series used the melody of \\"Moonlight Densetsu\\", but with very different lyrics. At the time, it was unusual for anime theme songs to be translated, and this was one of the first such themes to be redone in English since Star Blazers.[46] The English theme has been described as \\"inane but catchy.\\"[47] The Japanese theme is a love song based on the relationship between Usagi and Mamoru (\\"born on the same Earth\\"), whereas the English Sailor Moon theme rather resembles a superhero anthem.\\r\\n\\r\\n\\"Moonlight Densetsu\\" was released as a CD single in March 1992, and was an \\"explosive hit.\\"[48] \\"Moonlight Densetsu\\" won first place in the Song category in Animage's 15th and 16th Anime Grand Prix.[49][50] It came seventh in the 17th Grand Prix, and \\"Moon Revenge\\" from Sailor Moon R: The Movie, came eighth.[51] Rashiku Ikimasho, the second closing song for SuperS, placed eighteenth in 1996.[52] In 1997, \\"Sailor Star Song\\", the new opening theme for Sailor Stars, came eleventh, and \\"Moonlight Densetsu\\" came sixteenth.[53]\\r\\n\\r\\nIn Japan, Sailor Moon received VHS releases during its run. The first VHS was released on July 25, 1993.[54] Sailor Moon did not receive a DVD release until 2002. Mass-produced individual 6-episode DVDs were released beginning on May 21, 2002.[55]\\r\\n\\r\\nThe international home release structure of Sailor Moon is complicated by the licensing and release of the companies involved in producing and distributing the work.[citation needed] In North America, Buena Vista Home Video distributed part of DiC's edited dub in six VHS tapes, containing two selected episodes from the first season, between 1996 and 1997.[citation needed] These tapes were originally available exclusively through Toys 'R' Us stores, but later saw wider distribution in other chains. A single VHS boxset titled The Doom Tree Series containing the first 13 episodes of Sailor Moon R was also released.[citation needed] ADV Films later licensed the home video rights to the first two seasons, and released the DiC episodes to VHS and DVD beginning in 2001, and later released the episodes in Japanese with English subtitles in two DVD boxsets in 2003.[citation needed] Pioneer Entertainment (later Geneon) held the home video rights to the third and fourth seasons, and released them to VHS in three formats (edited English dubbed, uncut English dubbed, and Japanese with English subtitles) alongside uncut bilingual DVDs beginning in 2000.[citation needed] They later released both seasons in collected bilingual boxsets. Both ADV and Geneon's licenses expired in 2004 and 2006 respectively.[citation needed]\\r\\n\\r\\nIn 2014, Viz Media announced plans to release the series in both Blu-ray Disc and DVD format, with the first set released on November 11, 2014.[56] In addition, the first twenty-three episodes of their redub premiered on the streaming sites, Hulu and Neon Alley, beginning September 5, 2014.[57] The first part of season one was released on DVD and Limited Edition Blu-ray on November 11, 2014 and the second part was released on February 10, 2015.[58][59] As of August 15, 2017, Viz's redub cannot be seen on any legal streaming sites available in Canada.[citation needed] Tubi TV's carriage of Sailor Moon in Canada is limited to Japanese audio with English subtitles.[citation needed]\\r\\n\\r\\nThe first half of Sailor Moon R was released on Blu-ray and DVD on July 14, 2015[60] and the second half of Sailor Moon R was released on Blu-ray and DVD on October 27, 2015.[citation needed]\\r\\n\\r\\nDuring its broadcast run, three theatrical animated Sailor Moon films were produced. The films were usually released in December in accordance with the winter vacations of Japanese schools. They were typically double features paired up with other anime films, and were thus, usually an hour or less in length. The films themselves offer contradictions in both chronology and design that make them incompatible with a single continuity. The first was Sailor Moon R: The Movie in 1993, followed by Sailor Moon S: The Movie in 1994, and finally Sailor Moon SuperS: The Movie in 1995.[61][62][63]\\r\\n\\r\\nThe three films were released in the US on home video by Pioneer Entertainment, who released all three to subtitled VHS, edited dubbed VHS, and uncut bilingual DVD from 1999ÿ2000.[citation needed] They were also shown on YTV in Canada and Cartoon Network in the US. All three films were later rescued for an uncut home video release by Viz Media.[citation needed]\\r\\n\\r\\nOriginally planned to run for only six months, the Sailor Moon anime repeatedly continued due to its popularity, concluding after a five-year run.[64] In Japan, it aired every Saturday night in prime time at 7 p.m,[16][65] and its run there was very popular, with an average viewer ratings of 11ÿ12% for most of the series run.[16][66] Commentators detect in the anime adaptation of Sailor Moon \\"a more shonen tone\\", appealing to a wider audience than the manga, which aimed squarely at teenage girls.[67] The media franchise became one of the most successful Japan has ever had, reaching $1.5 billion in merchandise sales during the first three years. Ten years after the series completion, the series featured among the top thirty of TV Asahi's Top 100 anime polls in 2005 and 2006.[17][18] The anime series won the Animage Anime Grand Prix prize in 1993.[49] Sales of Sailor Moon fashion-dolls overtook those of Licca-chan in the 1990s; Mattel attributed this to the \\"fashion-action\\" blend of the Sailor Moon storyline. Doll accessories included both fashion items and the Sailor Soldiers' weapons.[22]\\r\\n\\r\\nSailor Moon has also become popular internationally. Spain and France became the first countries outside Japan to air Sailor Moon, beginning in December 1993.[61] Other countries followed suit, including Australia, South Korea, the Philippines (Sailor Moon became one of its carrier network's main draws, helping it to become the third-biggest network in the country), Poland, Italy, Mexico, Brazil, Sweden and Hong Kong, before North America picked up the franchise for adaptation.[68]:10ÿ11 In 2001, the Sailor Moon manga was Tokyopop's best selling property, outselling the next-best selling titles by at least a factor of 1.5.[69]\\r\\n\\r\\nCritics have commended the anime series for its portrayal of strong friendships,[70] as well as for its large cast of \\"strikingly different\\" characters who have different dimensions and aspects to them as the story continues,[71] and for an ability to appeal to a wide audience.[72] Writer Nicolas Penedo attributes the success of Sailor Moon to its fusion of the shjo manga genre of magical girls with the Super Sentai fighting teams.[67] According to Martha Cornog and Timothy Perper, Sailor Moon became popular because of its \\"strongly-plotted action with fight scenes, rescues\\" and its \\"emphasis on feelings and relationships\\", including some \\"sexy romance\\" between Usagi and Mamoru.[73] Usagi and Mamoru's romance has been seen as an archetype where the lovers \\"become more than the sum of their parts\\", promising to be together forever.[74] In contrast, others see Sailor Moon as campy[75] and melodramatic. Criticism has singled out its use of formulaic plots, monsters of the day,[76] and stock footage.[77]\\r\\n\\r\\nPatrick Drazen states that Sailor Moon has two kinds of villains, the \\"monster of the day\\" and the \\"thinking, feeling humans.\\" Although this is common in anime and manga, it is \\"almost unheard of in the West.\\"[68]:284 Despite the series' apparent popularity among Western anime fandom, the dubbed version of the series received poor ratings in the United States when it was initially broadcast in syndication and did not do well in DVD sales in the United Kingdom.[78] Anne Allison attributes the lack of popularity in the United States primarily to poor marketing (in the United States, the series was initially broadcast at times which did not suit the target audience ÿ weekdays at 9:00 a. m. and 2:00 pm). Executives connected with Sailor Moon suggest that poor localization played a role.[22] British authors Helen McCarthy and Jonathan Clements go further, calling the dub \\"indifferent\\", and suggesting that Sailor Moon was put in \\"dead\\" timeslots due to local interests.[26] The British distributor, MVM Films, attributed the low sales to the United Kingdom release being of the dub only, and that major retailers refused to support the show leading to the DVD release appealing to neither children nor older anime fans.[78]\\r\\n\\r\\nBoth the manga editorial vid and the anime series were released in Mexico twice in a quite accurate translation in Imevisi܇n (what is now Azteca), which also aired almost complete versions of Saint Seiya, Senki, Candy Candy, Remi, Nobody's Girl, Card Captor Sakura and Detective Conan.[citation needed]\\r\\n\\r\\nDue to anti-Japanese sentiment, most Japanese media other than anime was banned for several years in South Korea. A producer in KBS \\"did not even try to buy\\" Sailor Moon because the producer thought it would not pass the censorship laws, but as of May 1997, Sailor Moon was airing on KBS 2 without issues and was \\"enormously\\" popular.[79]","input":"When did sailor moon first air in america?"},{"output":"19 November 2013","context":"Khil Raj Regmi\\r\\nIndependent\\r\\nSushil Koirala\\r\\nNepali Congress\\r\\nConstituent Assembly elections were held in Nepal on 19 November 2013.[1] The vote was repeatedly delayed,[2] having previously been planned for 22 November 2012 following the dissolution of the 1st Constituent Assembly on 27 May 2012, but it was put off by the election commission.[3] The Nepali Congress emerged as the largest party in the 2nd Nepalese Constituent Assembly, winning 196 of the 575 elected seats.\\r\\n\\r\\n\\r\\nFollowing King Gyanendra's suspension of Parliament and government takeover during the Nepalese Civil War, mass protests led to him to re-instate Parliament and end the war fought by the government against the Communist Party of Nepal (Maoist), on the condition that the constitution would be re-written. The king's powers were also removed and an election was held in 2008 to elect a Constituent Assembly. The Constituent Assembly was tasked with writing a new constitution; however, its deadline was extended several times, with the last one set for 27 May 2012.\\r\\nIn the lead up to the deadline, there were several violent protests by a variety of ethnic groups outside the Parliament building. Rallies were then banned in the area and around the PM's office with riot police guarding against protests and the Nepali Army on high alert in case the situation could not be controlled. Prime Minister Baburam Bhattarai called for a new election on 22 November after the deadline passed, with a possibility of a state of emergency. A member of his party, Post Bahadur Bogati, announced that \\"it is not possible to promulgate the constitution within the deadline now. That possibility is out, 100 percent.\\"\\r\\nOn the deadline day there were large protests as talks between the CPN (Maoist), Nepali Congress, Communist Party of Nepal (Unified Marxist-Leninist) and the Madhesi Front were ongoing. The talks broke down after the incumbent CPN (Maoist)'s demands for 10 to 14 new provinces largely along ethnic groups lines, which was supported by several small Madhesi parties calling for autonomy, was opposed by the Nepali Congress and the CPN (UML). CPN (Maoist) member Narayankaji Shrestha said that \\"a constitution is not possible without federal states recognising the identity of ethnic groups.\\" The opponents of the proposal said the move could lead to tensions amongst different castes. Ram Sharan Mahat of the Nepali Congress said that the CPN (Maoist) \\"want[ed] to kill the assembly, not make the constitution\\" in order to stay in power. At a cabinet session that night CPN (UML) general secretary and Deputy Prime Minister Ishwor Pokhrel walked out saying that the move was \\"unconstitutional, neither is it based on political consensus.\\" However, the Madhesi leader Laxman Lal Karna said that \\"in the afternoon, the NC and the [CPN-]UML had said there was no chance of a deal. Let us go for polls. We have done the democratic thing.\\"[4][5] The CPN (Maoist)'s Barsha Man Pun then announced the election saying that \\"we had no other alternative. We apologise for not being able to prepare the constitution.\\"[6]\\r\\nThe Nepali Congress claimed the delays were a ploy by the UCPN (M) to remain in power and that Maoist-led government's \\"unilateral decision was unexpected\\".[7] However, according to an AFP interview on Rajkishore Yadav, the Maoist-led government \\"wanted to conduct elections in November 22\\" but the election commission insisted that \\"the lack of a workable constitution meant there were no legal provisions for holding a vote\\".[8]\\r\\nIn mid-September 2013, an opposition one-day strike called for the cancellation of the election.[9]\\r\\nIn mid-2011, an opinion indicated that 45% of respondents opposed an extension of the CA's mandate. A majority of respondents were uncertain about who they would vote for. Similarly, there were calls for a fresh election by opposition politicians at the time. Most respondents also said a new constitution was the top most priority.[10]\\r\\nIn the Himal Media opinion poll conducted in March 2013, voters expressed a slight preference for the Nepali Congress,14.9%, over the CPN (UML), 11.3%, and UCPN (Maoist), 7.3%.[11]\\r\\nIn the morning of the election, a bomb exploded near a voting station wounding three people after a boy picked up what he though was a toy that then exploded. It also follows days of similar attacks by those opposed to the election.[12] On December 16, Mohan Baidya, Chairman of the breakaway CPN(Maoist) which had boycotted the elections publicly stated his party had planted bombs across the country prior to the elections.[13]\\r\\nVoters turned out in record numbers with nationwide turnout averaging 78.34% [14] breaking the previous record of 68.15% in the 1991 general elections.[15] The highest turnout was in Dolpa-1 at 89.5% and the lowest in Baitadi-2 at 67.32%.\\r\\nInitial results showed the Nepali Congress winning a plurality of the first-past-the-post seats with 105 of the 240 seats; the CPM-UML close behind with 91; and the CPN (Maoist) far behind, winning just 26. Smaller parties and two independent candidates won the remaining 18 seats.[16] 335 seats were allotted by proportional representation using a modified Sainte-Lagu? method of allocation.\\r\\nThe UCPN (Maoist) leader Prachanda protested the conduct of the election, alleging fraud, and threatening to withdraw from the Constituent Assembly. However domestic and international pressure mounted and various political leaders from Nepali Congress and CPN UML urged Unified Maoist to accept the peoples verdict and get involved in the process of a peaceful CA.[17] Subsequently, an internal assessment by the party concluded vote-rigging was not the cause of the party's defeat and mentioned \\"misrepresentation of the party on issue of federalism and the partys split\\" as reasons for defeat.[18] On December 25, 2013, the UCPN (Maoist) offered unconditional support to the Nepali Congress to form the next government following the signing of a four-point deal between the NC, CPN(UML), UCPN (Maoist) and Madesbadi parties that agreed to form a parliamentary body to investigate election irregularities.[19]\\r\\nIn response to the allegations of fraud leveled by the Maoist and smaller parties, Chief Election Commissioner Nilkantha Upreti affirmed the elections were \\"concluded in a free, fair , impartial and credible manner\\" and urged voters \\"not to believe in such misleading publicity\\" about the fairness of the elections.[20]","input":"When was the second constitutional election held in nepal?"},{"output":"Paris","context":"","input":"What part of france is the eiffel tower located?"},{"output":"uranium","context":"\\"Little Boy\\" was the codename for the atomic bomb dropped on the Japanese city of Hiroshima on 6 August 1945 during World War II by the Boeing B-29 Superfortress Enola Gay, piloted by Colonel Paul W. Tibbets, Jr., commander of the 509th Composite Group of the United States Army Air Forces. It was the first atomic bomb to be used in warfare. The Hiroshima bombing was the second artificial nuclear explosion in history, after the Trinity test, and the first uranium-based detonation. It exploded with an energy of approximately 15 kilotons of TNT (63?TJ). The bomb caused significant destruction to the city of Hiroshima and its occupants.\\r\\nLittle Boy was developed by Lieutenant Commander Francis Birch's group of Captain William S. Parsons's Ordnance (O) Division at the Manhattan Project's Los Alamos Laboratory during World War II. Parsons flew on the Hiroshima mission as weaponeer. The Little Boy was a development of the unsuccessful Thin Man nuclear bomb. Like Thin Man, it was a gun-type fission weapon, but derived its explosive power from the nuclear fission of uranium-235, whereas Thin Man was based on fission of plutonium-239. Fission was accomplished by shooting a hollow cylinder of enriched uranium (the \\"bullet\\") onto a solid cylinder of the same material (the \\"target\\") by means of a charge of nitrocellulose propellant powder. It contained 64?kg (141?lb) of enriched uranium, of which less than a kilogram underwent nuclear fission. Its components were fabricated at three different plants so that no one would have a copy of the complete design.\\r\\nAfter the war ended, it was not expected that the inefficient Little Boy design would ever again be required, and many plans and diagrams were destroyed. However, by mid-1946 the Hanford Site reactors were suffering badly from the Wigner effect, the dislocation of atoms in a solid caused by neutron radiation, so six Little Boy assemblies were produced at Sandia Base. The Navy Bureau of Ordnance built another 25 Little Boy assemblies in 1947 for use by the Lockheed P2V Neptune nuclear strike aircraft (which could be launched from, but not land on, the Midway-class aircraft carriers). All the Little Boy units were withdrawn from service by the end of January 1951.\\r\\n\\r\\n\\r\\nThe names for the first two atomic bomb design projects during World War IIFat Man and Thin Manwere created by Robert Serber, a former student of Los Alamos Laboratory director Robert Oppenheimer who worked on the Manhattan Project. According to Serber, he chose the two names based on their design shapes. The \\"Thin Man\\" was a long device, and its name came from the Dashiell Hammett detective novel and series of movies of the same name. The \\"Fat Man\\" was round and fat, and was named after Kasper Gutman, Sydney Greenstreet's character in The Maltese Falcon, based on the Hammett novel of that name. Little Boy, being a newer version of Thin Man, was named by others in comparison.[1]\\r\\nBecause uranium-235 was known to be fissionable, it was the first material pursued in the approach to bomb development. As the first design developed (as well as the first deployed for combat), it is sometimes known as the Mark I.[2] The vast majority of the work came in the form of the isotope enrichment of the uranium necessary for the weapon, since uranium-235 makes up only 1 part in 140 of natural uranium.[3] Enrichment was performed at Oak Ridge, Tennessee, where the electromagnetic separation plant, known as Y-12, became fully operational in March 1944.[4] The first shipments of highly enriched uranium were sent to the Los Alamos Laboratory in June 1944.[5]\\r\\nMost of the uranium necessary for the production of the bomb came from the Shinkolobwe mine and was made available thanks to the foresight of the CEO of the High Katanga Mining Union, Edgar Sengier, who had 1,000 long tons (1,000?t) of uranium ore transported to a New York warehouse in 1939.[6] At least part of the 1,200 long tons (1,200?t) of uranium ore and uranium oxide captured by the Alsos Mission in 1944 and 1945 was used in the bomb.[7]\\r\\nLittle Boy was a simplification of Thin Man, the previous gun-type fission weapon design. Thin Man, 17 feet (5.2?m) long, was designed to use plutonium, so it was also more than capable of using enriched uranium. The Thin Man design was abandoned after experiments by Emilio G. Segr and his P-5 Group at Los Alamos on the newly reactor-produced plutonium from Oak Ridge and the Hanford site showed that it contained impurities in the form of the isotope plutonium-240. This has a far higher spontaneous fission rate and radioactivity than the cyclotron-produced plutonium on which the original measurements had been made, and its inclusion in reactor-bred plutonium (needed for bomb-making due to the quantities required) appeared unavoidable. This meant that the background fission rate of the plutonium was so high that it would be highly likely the plutonium would predetonate and blow itself apart in the initial forming of a critical mass.[8]\\r\\nIn July 1944, almost all research at Los Alamos was redirected to the implosion-type plutonium weapon. Overall responsibility for the uranium gun-type weapon was assigned to Captain William S. Parsons's Ordnance (O) Division. All the design, development, and technical work at Los Alamos was consolidated under Lieutenant Commander Francis Birch's group.[9]\\r\\nIn contrast to the plutonium implosion-type nuclear weapon and the plutonium gun-type fission weapon, the uranium gun-type weapon was straightforward if not trivial to design. The concept was pursued so that in case of a failure to develop a plutonium bomb, it would still be possible to use the gun principle. The gun-type design henceforth had to work with enriched uranium only, and this allowed the Thin Man design to be greatly simplified. A high-velocity gun was no longer required, and a simpler weapon could be substituted. The simplified weapon was short enough to fit into a B-29 bomb bay.[10]\\r\\nThe design specifications were completed in February 1945, and contracts were let to build the components. Three different plants were used so that no one would have a copy of the complete design. The gun and breech were made by the Naval Gun Factory in Washington, D.C.; the target case and some other components were by the Naval Ordnance Plant in Center Line, Michigan; and the tail fairing and mounting brackets by the Expert Tool and Die Company in Detroit, Michigan.[11] The bomb, except for the uranium payload, was ready at the beginning of May 1945.[12] The uranium-235 projectile was completed on 15 June, and the target on 24 July.[13] The target and bomb pre-assemblies (partly assembled bombs without the fissile components) left Hunters Point Naval Shipyard, California, on 16 July aboard the heavy cruiser USS?Indianapolis, arriving on 26 July.[14] The target inserts followed by air on 30 July.[13]\\r\\nAlthough all of its components had been tested,[13] no full test of a gun-type nuclear weapon occurred before the Little Boy was dropped over Hiroshima. The only test explosion of a nuclear weapon concept had been of an implosion-type device employing plutonium as its fissile material, and took place on 16 July 1945 at the Trinity nuclear test. There were several reasons for not testing a Little Boy type of device. Primarily, there was little uranium-235 as compared with the relatively large amount of plutonium which, it was expected, could be produced by the Hanford Site reactors.[15] Additionally, the weapon design was simple enough that it was only deemed necessary to do laboratory tests with the gun-type assembly. Unlike the implosion design, which required sophisticated coordination of shaped explosive charges, the gun-type design was considered almost certain to work.[16]\\r\\nThe danger of accidental detonation made safety a concern. Little Boy incorporated basic safety mechanisms, but an accidental detonation could still occur. Tests were conducted to see whether a crash could drive the hollow \\"bullet\\" onto the \\"target\\" cylinder resulting in a massive release of radiation, or possibly nuclear detonation. These showed that this required an impact of 500 times the force of gravity, which made it highly unlikely.[17] There was still concern that a crash and a fire could trigger the explosives.[18] If immersed in water, the uranium halves were subject to a neutron moderator effect. While this would not have caused an explosion, it could have created widespread radioactive contamination. For this reason, pilots were advised to crash on land rather than at sea.[17]\\r\\nThe Little Boy was 120 inches (300?cm) in length, 28 inches (71?cm) in diameter and weighed approximately 9,700 pounds (4,400?kg).[19] The design used the gun method to explosively force a hollow sub-critical mass of uranium-235 and a solid target cylinder together into a super-critical mass, initiating a nuclear chain reaction. This was accomplished by shooting one piece of the uranium onto the other by means of four cylindrical silk bags of cordite. The bomb contained 64?kg (141?lb) of enriched uranium. Most was enriched to 89% but some was only 50% uranium-235, for an average enrichment of 80%.[20] Less than a kilogram of uranium underwent nuclear fission, and of this mass only 0.6?g (0.021?oz) was transformed into several forms of energy, mostly kinetic energy, but also heat and radiation.[21]\\r\\nInside the weapon, the uranium-235 material was divided into two parts, following the gun principle: the \\"projectile\\" and the \\"target\\". The projectile was a hollow cylinder with 60% of the total mass (38.5?kg (85?lb)). It consisted of a stack of 9 uranium rings, each 6.25-inch (159?mm) in diameter with a 4-inch (100?mm) bore in the center, and a total length of 7 inches (180?mm), pressed together into the front end of a thin-walled projectile 16.25 inches (413?mm) long. Filling in the remainder of the space behind these rings in the projectile was a tungsten carbide disc with a steel back. At ignition, the projectile slug was pushed 42 inches (1,100?mm) along the 72-inch (1,800?mm) long, 6.5-inch (170?mm) smooth-bore gun barrel. The slug \\"insert\\" was a 4 inches (100?mm) cylinder, 7 inches (180?mm) in length with a 1 inch (25?mm) axial hole. The slug comprised 40% of the total fissile mass (25.6?kg or 56?lb). The insert was a stack of 6 washer-like uranium discs somewhat thicker than the projectile rings that were slid over a 1 inch (25?mm) rod. This rod then extended forward through the tungsten carbide tamper plug, impact-absorbing anvil, and nose plug backstop, eventually protruding out of the front of the bomb casing. This entire target assembly was secured at both ends with locknuts.[22][23]\\r\\nWhen the hollow-front projectile reached the target and slid over the target insert, the assembled super-critical mass of uranium would be completely surrounded by a tamper and neutron reflector of tungsten carbide and steel, both materials having a combined mass of 2,300?kg (5,100?lb).[24] Neutron initiators at the base of the projectile were activated by the impact.[25]\\r\\nFor the first fifty years after 1945, every published description and drawing of the Little Boy mechanism assumed that a small, solid projectile was fired into the center of a larger, stationary target.[26] However, critical mass considerations dictated that in Little Boy the larger, hollow piece would be the projectile. The assembled fissile core had more than two critical masses of uranium-235. This required one of the two pieces to have more than one critical mass, with the larger piece avoiding criticality prior to assembly by means of shape and minimal contact with the neutron-reflecting tungsten carbide tamper.\\r\\nA hole in the center of the larger piece dispersed the mass and increased the surface area, allowing more fission neutrons to escape, thus preventing a premature chain reaction.[27] But, for this larger, hollow piece to have minimal contact with the tamper, it must be the projectile, since only the projectile's back end was in contact with the tamper prior to detonation. The rest of the tungsten carbide surrounded the sub-critical mass target cylinder (called the \\"insert\\" by the designers) with air space between it and the insert. This arrangement packs the maximum amount of fissile material into a gun-assembly design.[27]\\r\\nThe bomb employed a fuzing system that was designed to detonate the bomb at the most destructive altitude. Calculations showed that for the largest destructive effect, the bomb should explode at an altitude of 580 metres (1,900?ft). The resultant fuze design was a three-stage interlock system:[28]\\r\\nThe Little Boy pre-assemblies were designated L-1, L-2, L-3, L-4, L-5, L-6, L-7, and L-11. L-1, L-2, L-5, and L-6 were expended in test drops. The first drop test was conducted with L-1 on 23 July 1945. It was dropped over the sea near Tinian in order to test the radar altimeter by the B-29 later known as Big Stink, piloted by Colonel Paul W. Tibbets, the commander of the 509th Composite Group. Two more drop tests over the sea were made on 24 and 25 July, using the L-2 and L-5 units in order to test all components. Tibbets was the pilot for both missions, but this time the bomber used was the one subsequently known as Jabit. L-6 was used as a dress rehearsal on 29 July. The B-29 Next Objective, piloted by Major Charles W. Sweeney, flew to Iwo Jima, where emergency procedures for loading the bomb onto a standby aircraft were practiced. This rehearsal was repeated on 31 July, but this time L-6 was reloaded onto a different B-29, Enola Gay, piloted by Tibbets, and the bomb was test dropped near Tinian. L-11 was the assembly used for the Hiroshima bomb.[29][30]\\r\\nParsons, the Enola Gay's weaponeer, was concerned about the possibility of an accidental detonation if the plane crashed on takeoff, so he decided not to load the four cordite powder bags into the gun breech until the aircraft was in flight. Parsons and his assistant, Second Lieutenant Morris R. Jeppson, made their way into the bomb bay along the narrow catwalk on the port side. Jeppson held a flashlight while Parsons disconnected the primer wires, removed the breech plug, inserted the powder bags, replaced the breech plug, and reconnected the wires. Before climbing to altitude on approach to the target, Jeppson switched the three safety plugs between the electrical connectors of the internal battery and the firing mechanism from green to red. The bomb was then fully armed. Jeppson monitored the bomb's circuits.[31]\\r\\nThe bomb was dropped at approximately 08:15 (JST) 6 August 1945. After falling for 44.4 seconds, the time and barometric triggers started the firing mechanism. The detonation happened at an altitude of 1,968?I?50 feet (600?I?15?m). It was less powerful than the Fat Man, which was dropped on Nagasaki, but the damage and the number of victims at Hiroshima were much higher, as Hiroshima was on flat terrain, while the hypocenter of Nagasaki lay in a small valley. According to figures published in 1945, 66,000 people were killed as a direct result of the Hiroshima blast, and 69,000 were injured to varying degrees.[32] Of those deaths, 20,000 were members of the Imperial Japanese Army.[33]\\r\\nThe exact measurement of the yield was problematic since the weapon had never been tested. President Harry S. Truman officially announced that the yield was 20 kilotons of TNT (84?TJ). This was based on Parsons's visual assessment that the blast was greater than what he had seen at the Trinity nuclear test. Since that had been estimated at 18 kilotons of TNT (75?TJ), speech writers rounded up to 20 kilotons. Further discussion was then suppressed, for fear of lessening the impact of the bomb on the Japanese. Data had been collected by Luis Alvarez, Harold Agnew, and Lawrence H. Johnston on the instrument plane, The Great Artiste, but this was not used to calculate the yield at the time.[34]\\r\\nAfter hostilities ended, a survey team from the Manhattan Project that included William Penney, Robert Serber, and George T. Reynolds was sent to Hiroshima to evaluate the effects of the blast. From evaluating the effects on objects and structures, Penney concluded that the yield was 12 I 1 kilotons.[35] Later calculations based on charring pointed to a yield of 13 to 14 kilotons.[36] In 1953, Frederick Reines calculated the yield as 13 kilotons.[34] This figure became the official yield.[37]\\r\\nIn 1962, scientists at Los Alamos created a mockup of Little Boy known as \\"Project Ichiban\\" in order to answer some of the unanswered questions, but it failed to clear up all the issues. In 1982, Los Alamos created a replica Little Boy from the original drawings and specifications. This was then tested with enriched uranium but in a safe configuration that would not cause a nuclear explosion. A hydraulic lift was used to move the projectile, and experiments were run to assess neutron emission.[38] Based on this and the data from The Great Artiste, the yield was estimated at 16.6 I 0.3 kilotons.[39] After considering many estimation methods, a 1985 report concluded that the yield was 15 kilotons I 20%.[37]\\r\\nWhen 1 pound (0.45?kg) of uranium-235 undergoes complete fission, the yield is 8 kilotons. The 16 kiloton yield of the Little Boy bomb was therefore produced by the fission of 2 pounds (0.91?kg) of uranium-235, out of the 141 pounds (64?kg) in the pit. The remaining 139 pounds (63?kg), 98.5% of the total, contributed nothing to the energy yield.[40]\\r\\nAfter being selected in April 1945, Hiroshima was spared conventional bombing to serve as a pristine target, where the effects of a nuclear bomb on an undamaged city could be observed.[41] While damage could be studied later, the energy yield of the untested Little Boy design could be determined only at the moment of detonation, using instruments dropped by parachute from a plane flying in formation with the one that dropped the bomb. Radio-transmitted data from these instruments indicated a yield of about 15 kilotons.[37]\\r\\nComparing this yield to the observed damage produced a rule of thumb called the 5 psi lethal area rule. Approximately 100% of people inside the area where the shock wave carries an overpressure of 5 psi or greater would be killed.[42] At Hiroshima, that area was 3.5 kilometres (2.2?mi) in diameter.[43]\\r\\nThe damage came from three main effects: blast, fire, and radiation.[44]\\r\\nThe blast from a nuclear bomb is the result of X-ray-heated air (the fireball) sending a shock wave or pressure wave in all directions, initially at a velocity greater than the speed of sound,[45] analogous to thunder generated by lightning. Knowledge about urban blast destruction is based largely on studies of Little Boy at Hiroshima. Nagasaki buildings suffered similar damage at similar distances, but the Nagasaki bomb detonated 3.2 kilometres (2.0?mi) from the city center over hilly terrain that was partially bare of buildings.[46]\\r\\nIn Hiroshima almost everything within 1.6 kilometres (1.0?mi) of the point directly under the explosion was completely destroyed, except for about 50 heavily reinforced, earthquake-resistant concrete buildings, only the shells of which remained standing. Most were completely gutted, with their windows, doors, sashes, and frames ripped out.[47] The perimeter of severe blast damage approximately followed the 5?psi (34?kPa) contour at 1.8 kilometres (1.1?mi).\\r\\nLater test explosions of nuclear weapons with houses and other test structures nearby confirmed the 5 psi overpressure threshold. Ordinary urban buildings experiencing it will be crushed, toppled, or gutted by the force of air pressure. The picture at right shows the effects of a nuclear-bomb-generated 5 psi pressure wave on a test structure in Nevada in 1953.[48]\\r\\nA major effect of this kind of structural damage was that it created fuel for fires that were started simultaneously throughout the severe destruction region.\\r\\nThe first effect of the explosion was blinding light, accompanied by radiant heat from the fireball. The Hiroshima fireball was 370 metres (1,200?ft) in diameter, with a surface temperature of 6,000?C (10,830?F).[49] Near ground zero, everything flammable burst into flame. One famous, anonymous Hiroshima victim, sitting on stone steps 260 metres (850?ft) from the hypocenter, left only a shadow, having absorbed the fireball heat that permanently bleached the surrounding stone.[50] Simultaneous fires were started throughout the blast-damaged area by fireball heat and by overturned stoves and furnaces, electrical shorts, etc. Twenty minutes after the detonation, these fires had merged into a firestorm, pulling in surface air from all directions to feed an inferno which consumed everything flammable.[51]\\r\\nThe Hiroshima firestorm was roughly 3.2 kilometres (2.0?mi) in diameter, corresponding closely to the severe blast damage zone. (See the USSBS[52] map, right.) Blast-damaged buildings provided fuel for the fire. Structural lumber and furniture were splintered and scattered about. Debris-choked roads obstructed fire fighters. Broken gas pipes fueled the fire, and broken water pipes rendered hydrants useless.[51] At Nagasaki, the fires failed to merge into a single firestorm, and the fire-damaged area was only one fourth as great as at Hiroshima, due in part to a southwest wind that pushed the fires away from the city.[53]\\r\\nAs the map shows, the Hiroshima firestorm jumped natural firebreaks (river channels), as well as prepared firebreaks. The spread of fire stopped only when it reached the edge of the blast-damaged area, encountering less available fuel.[54]\\r\\nAccurate casualty figures are impossible to determine, because many victims were cremated by the firestorm, along with all record of their existence. The Manhattan Project report on Hiroshima estimated that 60% of immediate deaths were caused by fire, but with the caveat that \\"many persons near the center of explosion suffered fatal injuries from more than one of the bomb effects.\\"[55] In particular, many fire victims also received lethal doses of nuclear radiation.\\r\\nLocal fallout is dust and ash from a bomb crater, contaminated with radioactive fission products. It falls to earth downwind of the crater and can produce, with radiation alone, a lethal area much larger than that from blast and fire. With an air burst, the fission products rise into the stratosphere, where they dissipate and become part of the global environment. Because Little Boy was an air burst 580 metres (1,900?ft) above the ground, there was no bomb crater and no local radioactive fallout.[56]\\r\\nHowever, a burst of intense neutron and gamma radiation came directly from the fireball. Its lethal radius was 1.3 kilometres (0.8?mi),[43] covering about half of the firestorm area. An estimated 30% of immediate fatalities were people who received lethal doses of this direct radiation, but died in the firestorm before their radiation injuries would have become apparent. Over 6,000 people survived the blast and fire, but died of radiation injuries.[55] Among injured survivors, 30% had radiation injuries[57] from which they recovered, but with a lifelong increase in cancer risk.[58] To date, no radiation-related evidence of heritable diseases has been observed among the survivors' children.[59][60][61]\\r\\nAlthough Little Boy exploded with the energy equivalent of 16,000 tons of TNT, the Strategic Bombing Survey estimated that the same blast and fire effect could have been caused by 2,100 tons of conventional bombs: \\"220 B-29s carrying 1,200 tons of incendiary bombs, 400 tons of high-explosive bombs, and 500 tons of anti-personnel fragmentation bombs.\\"[62] Since the target was spread across a two-dimensional plane, the vertical component of a single spherical nuclear explosion was largely wasted. A cluster bomb pattern of smaller explosions would have been a more energy-efficient match to the target.[62]\\r\\nWhen the war ended, it was not expected that the inefficient Little Boy design would ever again be required, and many plans and diagrams were destroyed. However, by mid-1946 the Hanford Site reactors were suffering badly from the Wigner effect. Faced with the prospect of no more plutonium for new cores and no more polonium for the initiators for the cores that had already been produced, the Director of the Manhattan Project, Major General Leslie R. Groves, ordered that some Little Boys be prepared as an interim measure until a cure could be found. No Little Boy assemblies were available, and no comprehensive set of diagrams of the Little Boy could be found, although there were drawings of the various components, and stocks of spare parts.[63][64]\\r\\nAt Sandia Base, three Army officers, Captains Albert Bethel, Richard Meyer, and Bobbie Griffin attempted to re-create the Little Boy. They were supervised by Harlow W. Russ, an expert on Little Boy who served with Project Alberta on Tinian, and was now leader of the Z-11 Group of the Los Alamos Laboratory's Z Division at Sandia. Gradually, they managed to locate the correct drawings and parts, and figured out how they went together. Eventually, they built six Little Boy assemblies. Although the casings, barrels, and components were tested, no enriched uranium was supplied for the bombs. By early 1947, the problem caused by the Wigner effect was on its way to solution, and the three officers were reassigned.[63][64]\\r\\nThe Navy Bureau of Ordnance built 25 Little Boy assemblies in 1947 for use by the nuclear-capable Lockheed P2V Neptune aircraft carrier aircraft (which could be launched from but not land on the Midway-class aircraft carriers). Components were produced by the Naval Ordnance Plants in Pocatello, Idaho, and Louisville, Kentucky. Enough fissionable material was available by 1948 to build ten projectiles and targets, although there were only enough initiators for six.[65] All the Little Boy units were withdrawn from service by the end of January 1951.[66][67]\\r\\nThe Smithsonian Institution displayed a Little Boy (complete, except for enriched uranium), until 1986. The Department of Energy took the weapon from the museum to remove its inner components, so the bombs could not be stolen and detonated with fissile material. The government returned the emptied casing to the Smithsonian in 1993. Three other disarmed bombs are on display in the United States; another is at the Imperial War Museum in London.[26]","input":"What was the first atomic bomb made out of?"},{"output":"dating back to the most recent ice age and probably earlier","context":"The Ogallala Aquifer is a shallow water table aquifer surrounded by sand, silt, clay and gravel located beneath the Great Plains in the United States. One of the world's largest aquifers, it underlies an area of approximately 174,000?sq?mi (450,000?km2) in portions of eight states (South Dakota, Nebraska, Wyoming, Colorado, Kansas, Oklahoma, New Mexico, and Texas).[1] It was named in 1898 by geologist N. H. Darton from its type locality near the town of Ogallala, Nebraska. The aquifer is part of the High Plains Aquifer System, and rests on the Ogallala Formation, which is the principal geologic unit underlying 80% of the High Plains.[2][3]\\r\\nLarge scale extraction for agricultural purposes started after World War II due partially to center pivot irrigation and to the adaptation of automotive engines for groundwater wells.[4] Today about 27% of the irrigated land in the entire United States lies over the aquifer, which yields about 30% of the ground water used for irrigation in the United States.[5] The aquifer is at risk for over-extraction and pollution. Since 1950, agricultural irrigation has reduced the saturated volume of the aquifer by an estimated 9%. Once depleted, the aquifer will take over 6,000 years to replenish naturally through rainfall.[6]\\r\\nThe aquifer system supplies drinking water to 82% of the 2.3 million people (1990 census) who live within the boundaries of the High Plains study area.[7]\\r\\n\\r\\n\\r\\nThe deposition of aquifer material dates back two to six million years, from the late Miocene to early Pliocene ages when the southern Rocky Mountains were still tectonically active. From the uplands to the west, rivers and streams cut channels in a generally west to east or southeast direction. Erosion of the Rockies provided alluvial and aeolian sediment that filled the ancient channels and eventually covered the entire area of the present-day aquifer, forming the water-bearing Ogallala Formation.[8][9] In that respect, the process is similar to those currently prevailing in other modern rivers of the area, such as the Kansas River and its tributaries. The major differences are time and depth.\\r\\nThe depth of the Ogallala varies with the shape of then-prevailing surface, being deepest where it fills ancient valleys and channels. The Ogallala Formation consists mostly of coarse sedimentary rocks in its deeper sections, which transition upward into finer-grained material.[10]\\r\\nThe water-saturated thickness of the Ogallala Formation ranges from a few feet to more than 1,000?feet (300?m) and is generally greater in the Northern Plains.[11] The depth of the water below the surface of the land ranges from almost 400 feet (120?m) in parts of the north to between 100 and 200 feet (30 and 61?m) throughout much of the south. Present-day recharge of the aquifer with fresh water occurs at an exceedingly slow rate, suggesting that much of the water in its pore spaces is paleowater, dating back to the most recent ice age and probably earlier.\\r\\nGroundwater within the Ogallala generally flows from west to east at an average rate of a foot per day. Hydraulic conductivity, or the ability for a fluid (water) to move through porous material, ranges from 25 to 300 feet (7.6 to 91.4?m) per day.[12] Water quality within the Ogallala varies with the highest quality for drinking and irrigation in the northern region while the southern region had the poorest.[13] Human and natural processes over the past 60 to 70 years, including irrigation density, climate, and nitrogen applications, have caused higher concentrations of contaminants including nitrates. Nitrate levels generally meet USGS water quality standards, but continue to gradually increase over time.[13] This trend can impact the future groundwater sustainability for portions of the aquifer.\\r\\nAn aquifer is a groundwater storage reservoir in the water cycle. While groundwater is a renewable source, reserves replenish relatively slowly. The USGS has performed several studies of the aquifer, to determine what is coming in (groundwater recharge from the surface), what is leaving (water pumped out and baseflow to streams), and what the net changes in storage are (rise, fall or no change).\\r\\nWithdrawals from the Ogallala Aquifer for irrigation amounted to 26?km3 (21,000,000?acre?ft) in 2000. As of 2005, the total depletion since before development amounted to 253,000,000 acre feet (312?km3).[1] Some estimates indicate the remaining volume could be depleted as soon as 2028. Many farmers in the Texas High Plains, which rely particularly on the underground source, are now turning away from irrigated agriculture as they become aware of the hazards of overpumping.[14]\\r\\nThe rate at which recharge water enters the aquifer is limited by several factors. Much of the plains region is semiarid, with steady winds that hasten evaporation of surface water and precipitation. In many locations, the aquifer is overlain, in the vadose zone, with a shallow layer of caliche that is practically impermeable; this limits the amount of water able to recharge the aquifer from the land surface. However, the soil of the playa lakes is different and not lined with caliche, making these some of the few areas where the aquifer can recharge. The destruction of playas by farmers and development decreases the available recharge area. The prevalence of the caliche is partly due to the ready evaporation of soil moisture and the semiarid climate; the aridity increases the amount of evaporation, which in turn increases the amount of caliche in the soil. Both mechanisms reduce the amount of recharge water that reaches the water table.\\r\\nRecharge in the aquifer ranges from 0.024 inches (0.61?mm) per year in parts of Texas and New Mexico to 6 inches (150?mm) per year in south-central Kansas.[15]\\r\\nThe regions overlying the Ogallala Aquifer are some of the most productive regions in the United States for ranching livestock, and growing corn, wheat, and soybeans. The success of large-scale farming in areas that do not have adequate precipitation and do not always have perennial surface water for diversion has depended heavily on pumping groundwater for irrigation.\\r\\nEarly settlers of the semiarid High Plains were plagued by crop failures due to cycles of drought, culminating in the disastrous Dust Bowl of the 1930s. Only after World War II, when center pivot irrigation became available, was the land mass of the High Plains aquifer system transformed into one of the most agriculturally productive regions in the world.\\r\\nGround water levels decline when the rate of extraction by irrigation exceeds the rate of recharge. At places, the water table was measured to drop more than 5?ft (1.5?m) per year at the time of maximum extraction. In extreme cases, the deepening of wells was required to reach the steadily falling water table. In the 21st century, recognition of the significance of the aquifer has led to increased coverage from regional and international journalists.[16][17][18][19]\\r\\nThe USGS estimated that total water storage was about 2,925,000,000 acre feet (3,608?km3) in 2005. This is a decline of about 253,000,000 acre feet (312?km3), or 9%, since substantial groundwater irrigation development began in the 1950s.[1]\\r\\nWater conservation practices (terracing and crop rotation), more efficient irrigation methods (center pivot and drip), and reduced area under irrigation have helped to slow depletion of the aquifer, but levels are generally still dropping in areas including southwestern Kansas and the Texas Panhandle. In other areas, such as parts of eastern and central Nebraska and of the region south of Lubbock, Texas, water levels have risen since 1980.\\r\\nThe center-pivot irrigator was described as the \\"villain\\"[20] in a New York Times article, \\"Wells Dry, Fertile Plains Turn to Dust\\" recounting the relentless decline of parts of the Ogallala Aquifer. Sixty years of intensive farming using huge center-pivot irrigators has emptied parts of the High Plains Aquifer.[20] Hundreds to thousands of years of rainfall would be needed to replace the groundwater in the depleted aquifer. In 1950, irrigated cropland covered 250,000 acres (100,000?ha). With the use of center-pivot irrigation, nearly three million acres of land were irrigated.[20] In some places in the Texas Panhandle, the water table has been drained (dewatered). \\"Vast stretches of Texas farmland lying over the aquifer no longer support irrigation. In west-central Kansas, up to a fifth of the irrigated farmland along a 100-mile swath (160?km) of the aquifer has already gone dry.\\"[20]\\r\\nThe center-pivot irrigation system is considered to be a highly efficient system which helps conserve water. However, by 2013, as the water consumption efficiency of the center-pivot irrigator improved over the years, farmers chose to plant more intensively, irrigate more land, and grow thirstier crops rather than reduce water consumption.[20] One approach to reducing the amount of groundwater used is to employ treated recycled water for irrigation; another approach is to change to crops that require less water, such as sunflowers.[21]\\r\\nSeveral rivers, such as the Platte, run below the water level of the aquifer. Because of this, the rivers receive groundwater flow (baseflow), carrying it out of the region rather than recharging the aquifer.\\r\\nThe $46.1-million Optima Lake dam in western Oklahoma was rendered useless when the dropping level of the aquifer drastically reduced flow of the Beaver River, the lake's intended source of water.[22]\\r\\nThe depletion between 2001 and 2008, inclusive, is about 32% of the cumulative depletion during the entire 20th century.[23] In the United States, the biggest users of water from aquifers include agricultural irrigation and oil and coal extraction.[24]\\"Cumulative total groundwater depletion in the United States accelerated in the late 1940s and continued at an almost steady linear rate through the end of the century. In addition to widely recognized environmental consequences, groundwater depletion also adversely impacts the long-term sustainability of groundwater supplies to help meet the nations water needs.\\"[23]\\r\\nSince the 1940s, pumping from the Ogallala has drawn the aquifer down more than 300 feet (90?m) in some areas. Producers have taken steps to reduce their reliance on irrigated water. Streamlined operations allow them to produce significantly greater yield using roughly the same amount of water needed four decades ago. Still, losses to the aquifer between 2001 and 2011 equated to a third of its cumulative depletion during the entire 20th century. The Ogallala is recharged primarily by rainwater, but only about one inch of precipitation actually reaches the aquifer annually. Rainfall in most of the Texas High Plains is minimal, evaporation is high, and infiltration rates are slow.[25]\\r\\nIn 2008, TransCanada Corporation proposed the construction of the 1,661-mile (2,673?km) Keystone XL pipeline to carry oil from the Athabasca oil sands of Alberta to refineries near Houston, Texas.[26][27] The proposed route of the pipeline crosses the eastern part of the Nebraska Sandhills; opponents of the route cite the risk to the Ogallala Aquifer posed by the possibility of contamination from spilled dilute bitumen.[28][29]\\r\\nResearch hydrogeologist James Goeke, professor emeritus at the University of Nebraska, who has spent more than 40 years studying the Ogallala Aquifer, phoned TransCanada officials and quizzed them on the project, and satisfied himself that danger to the aquifer was small, because he believes that a spill would be unlikely to penetrate down into the aquifer, and if it did, he believes that the contamination would be localized. He noted: \\"A lot of people in the debate about the pipeline talk about how leakage would foul the water and ruin the entire water supply in the state of Nebraska and thats just a false\\", [30] Goeke said \\"... a leak from the XL pipeline would pose a minimal risk to the aquifer as a whole.\\"[31]\\r\\nPipeline industry spokesmen have noted that thousands of miles of existing pipelines carrying crude oil and refined liquid hydrocarbons have crossed over the Ogallala Aquifer for years, in southeast Wyoming, eastern Colorado and New Mexico, western Nebraska, Kansas, Oklahoma, and Texas.[32][33][34][35][36] The Pioneer crude oil pipeline crosses east-west across Nebraska, and the Pony Express pipeline, which crosses the Ogallala Aquifer in Colorado, Nebraska, and Kansas, was being converted as of 2013 from natural gas to crude oil, under a permit from the Federal Energy Regulatory Commission.[37]\\r\\nAs the lead agency in the transboundary pipeline project, the U.S. State Department commissioned an environmental-impact assessment as required by the National Environmental Policy Act of 1969. The Environmental Impact Statement concluded that the project posed little threat of \\"adverse environmental impacts\\",[28][38] the report was drafted by Cardno Entrix, a company that assisted both the Department of State and the Federal Energy Regulatory Commission in preparing environmental impact statements for other proposed TransCanda projects. Although it is \\"common for companies applying to build government projects to be involved in assigning and paying for the impact analysis\\",[39] several opponents of the project suggested there could be a conflict of interest. In response to that concern, the Department of State's Office of the Inspector General conducted an investigation of the potential conflict of interest. The February 2012 report of that investigation states no conflict of interest existed either in the selection of the contractor or in the preparation of the environmental impact statement.[40]\\r\\nU.S. President Barack Obama \\"initially rejected the Keystone XL pipeline in January 2012, saying he wanted more time for an environmental review.\\"[41] On February 17, 2013, a rally at the National Mall drew an estimated 40,000 in protest of Keystone XL.[41] In January 2014, the U.S. State Department released its Keystone pipeline Final Supplemental Environmental Impact Statement for the Keystone XL Project Executive Summary, which concluded that, according to models, a large crude oil spill from the pipeline that reached the Ogallala could spread as far as 1,214 feet (370?m), with dissolved components spreading as much as 1,050?ft (320?m) further.[42]\\r\\nSince 2010, the North Plains Groundwater Conservation District, which encompasses eight counties north of Amarillo, including Moore and Dallam Counties, has offered a $300,000 annual demonstration project to conserve water that farmers pump from the Ogallala Aquifer. Participating farmers grow corn with just over half of the water that they would normally require to irrigate the fields, or they plant several weeks later than customary. Pivot sprinklers are used in the project, rather than the more expensive drip irrigation. According to district manager Steve Walthour, conservation is essential considering declining levels of the aquifer.[43] The local non-profit organization Ogallala Commons, named for the aquifer itself, which not only collaborates and supports the local communicates, also works to conserve the Ogallala Aquifer and the surrounding area.[44][45][46]\\r\\nEleven farmers in 2013 participated in the conservation program, with some planting in dry earth, rather than watered soil. They are leaving more space between plants, a technique that retains moisture for a longer period of time. Soil sensors permit farmers to gather accurate information about the moisture level of their crops. The motivation to save water comes from the district's regulations on extracting water from the aquifer. The United States Geological Survey determined the water level in the aquifer has dropped more in Texas than in any other state in the basin.[43]\\r\\nFarmers on their own land may draw water without charge from the aquifer. Pumping costs are low because the fuel used, natural gas, is inexpensive. The North Plains district first established limits on pumping in 2005 and tightened the regulations four years later. Certain wells are now required to have meters. Yet another challenge facing the district is that higher prices for crops[when?] have prompted some to plant additional fields and further increase the use of water from the aquifer.[43]\\r\\nCoordinates: 365926N 1012652W? / ?36.99056N 101.44778W? / 36.99056; -101.44778\\r\\nEnvironmental Science","input":"How long did it take to accumulate all the water that is currently in the ogallala aquifer?"},{"output":"Donald Trump","context":"\\r\\n\\r\\n\\r\\n\\r\\n \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nThe President of the United States (POTUS)[note 2] is the head of state and head of government of the United States of America. The president directs the executive branch of the federal government and is the commander-in-chief of the United States Armed Forces.\\r\\n\\r\\nIn contemporary times, the president is looked upon as one of the world's most powerful political figures and as the leader of the only remaining global superpower.[12][13][14][15] The role includes responsibility for the world's most expensive military that has the second largest nuclear arsenal. The president also leads the nation with the largest economy by nominal GDP. The president possesses significant domestic and international hard and soft power.\\r\\n\\r\\nArticle II of the Constitution establishes the executive branch of the federal government. It vests the executive power of the United States in the president. The power includes the execution and enforcement of federal law, alongside the responsibility of appointing federal executive, diplomatic, regulatory and judicial officers, and concluding treaties with foreign powers with the advice and consent of the Senate. The president is further empowered to grant federal pardons and reprieves, and to convene and adjourn either or both houses of Congress under extraordinary circumstances.[16] The president directs the foreign and domestic policies of the United States, and takes an active role in promoting his policy priorities to members of Congress.[17] In addition, as part of the system of checks and balances, Article One of the United States Constitution gives the president the power to sign or veto federal legislation. Since the office of president was established in 1789, its power has grown substantially, as has the power of the federal government as a whole.[18]\\r\\n\\r\\nThrough the Electoral College, the registered voters indirectly elect the president and vice president to a four-year term. This is the only federal election in the United States which is not decided by popular vote.[19] Nine vice presidents became president by virtue of a president's intra-term death or resignation.[note 3]\\r\\n\\r\\nThe Twenty-second Amendment precludes any United States citizen from being elected president for a third term. It also prohibits a person from being elected to the presidency more than once if that person previously had served as president, or acting president, for more than two years of another person's term as president. In all, 44 individuals have served 45 presidencies spanning 57 full four-year terms.[20] Grover Cleveland served two non-consecutive terms, so he is counted twice; as the 22nd and 24th presidents.[21]\\r\\n\\r\\nDonald Trump of New York is the 45th and current president. He assumed office on January 20, 2017.\\r\\n\\r\\nDuring the American Revolution in 1776, the Thirteen Colonies, acting through the Second Continental Congress, declared political independence from Great Britain. The new states were independent of each other as nation states[22] and recognized the necessity of closely coordinating their efforts against the British.[23] Congress desired to avoid anything that remotely resembled a monarchy and negotiated the Articles of Confederation to establish an alliance between the states.[22] Under the Articles, Congress was a central authority without any legislative power. It could make its own resolutions, determinations, and regulations, but not any laws, and could not impose any taxes or enforce local commercial regulations upon its citizens.[23] This institutional design reflected how Americans believed the deposed British system of Crown and Parliament ought to have functioned with respect to the royal dominion: a superintending body for matters that concerned the entire empire.[23] The states were out from under any monarchy and assigned some formerly royal prerogatives (e.g., making war, receiving ambassadors, etc.) to Congress; the remaining prerogatives were lodged within their own respective state governments. The states agreed to a resolution that settled competing western land claims. The Articles took effect on March 1, 1781, when Maryland became the final state to ratify them.\\r\\n\\r\\nIn 1783, the Treaty of Paris secured independence for each of the former colonies. With peace at hand, the states each turned toward their own internal affairs.[22] By 1786, Americans found their continental borders besieged and weak and their respective economies in crises as neighboring states agitated trade rivalries with one another. They witnessed their hard currency pouring into foreign markets to pay for imports, their Mediterranean commerce preyed upon by North African pirates, and their foreign-financed Revolutionary War debts unpaid and accruing interest.[22] Civil and political unrest loomed.\\r\\n\\r\\nFollowing the successful resolution of commercial and fishing disputes between Virginia and Maryland at the Mount Vernon Conference in 1785, Virginia called for a trade conference between all the states, set for September 1786 in Annapolis, Maryland, with an aim toward resolving further-reaching interstate commercial antagonisms. When the convention failed for lack of attendance due to suspicions among most of the other states, Alexander Hamilton led the Annapolis delegates in a call for a convention to offer revisions to the Articles, to be held the next spring in Philadelphia. Prospects for the next convention appeared bleak until James Madison and Edmund Randolph succeeded in securing George Washington's attendance to Philadelphia as a delegate for Virginia.[22][24]\\r\\n\\r\\nWhen the Constitutional Convention convened in May 1787, the 12 state delegations in attendance (Rhode Island did not send delegates) brought with them an accumulated experience over a diverse set of institutional arrangements between legislative and executive branches from within their respective state governments. Most states maintained a weak executive without veto or appointment powers, elected annually by the legislature to a single term only, sharing power with an executive council, and countered by a strong legislature.[22] New York offered the greatest exception, having a strong, unitary governor with veto and appointment power elected to a three-year term, and eligible for reelection to an indefinite number of terms thereafter.[22] It was through the closed-door negotiations at Philadelphia that the presidency framed in the U.S. Constitution emerged.\\r\\n\\r\\nThe Presentment Clause requires that any bill passed by Congress must be presented to the president before it can become law. Once the legislation has been presented, the president has three options:\\r\\n\\r\\nIn 1996, Congress attempted to enhance the president's veto power with the Line Item Veto Act. The legislation empowered the president to sign any spending bill into law while simultaneously striking certain spending items within the bill, particularly any new spending, any amount of discretionary spending, or any new limited tax benefit. Congress could then repass that particular item. If the president then vetoed the new legislation, Congress could override the veto by its ordinary means, a two-thirds vote in both houses. In Clinton v. City of New York, 524 U.S. 417 (1998), the U.S. Supreme Court ruled such a legislative alteration of the veto power to be unconstitutional.\\r\\n\\r\\n\\r\\nOne of the most important of all executive powers is the president's role as Commander-in-Chief of the United States Armed Forces. The power to declare war is constitutionally vested in Congress, but the president has ultimate responsibility for the direction and disposition of the military. The present-day operational command of the Armed Forces is delegated to the Department of Defense and is normally exercised through the Secretary of Defense. The Chairman of the Joint Chiefs of Staff  and the Combatant Commands assist with the operation as outlined in the presidentially approved Unified Command Plan (UCP).[25][26][27] The framers of the Constitution took care to limit the president's powers regarding the military; Alexander Hamilton explained this in Federalist No. 69:\\r\\nThe President is to be commander-in-chief of the army and navy of the United States. ... It would amount to nothing more than the supreme command and direction of the military and naval forces ... while that [the power] of the British king extends to the DECLARING of war and to the RAISING and REGULATING of fleets and armies, all [of] which ... would appertain to the legislature.[28] [Emphasis in the original.]\\r\\n\\r\\n Pursuant to the War Powers Resolution, Congress must authorize any troop deployments longer than 60 days, although that process relies on triggering mechanisms that have never been employed, rendering it ineffectual.[29] Additionally, Congress provides a check to presidential military power through its control over military spending and regulation. Presidents have historically initiated the process for going to war,[30][31] but critics have charged that there have been several conflicts in which presidents did not get official declarations, including Theodore Roosevelt's military move into Panama in 1903,[30] the Korean War,[30] the Vietnam War,[30] and the invasions of Grenada in 1983[32] and Panama in 1989.[33]\\r\\n\\r\\nThe constitution also empowers the President to propose and chiefly negotiate agreements between the United States and other countries, which, upon receiving the advice and consent of a two-thirds supermajority vote of the United States Senate, become binding with the force of federal law.\\r\\n\\r\\nNixon v. General Services Administration, 433 U.S. 425 (1977) (Rehnquist, J., dissenting)\\r\\n\\r\\nThe president is the head of the executive branch of the federal government and is constitutionally obligated to \\"take care that the laws be faithfully executed\\".[34] The executive branch has over four million employees, including members of the military.[35]\\r\\n\\r\\nPresidents make numerous executive branch appointments: an incoming president may make up to 6,000 before taking office and 8,000 more while serving. Ambassadors, members of the Cabinet, and other federal officers, are all appointed by a president with the \\"advice and consent\\" of a majority of the Senate. When the Senate is in recess for at least ten days, the president may make recess appointments.[36] Recess appointments are temporary and expire at the end of the next session of the Senate.\\r\\n\\r\\nThe power of a president to fire executive officials has long been a contentious political issue. Generally, a president may remove executive officials purely at will.[37] However, Congress can curtail and constrain a president's authority to fire commissioners of independent regulatory agencies and certain inferior executive officers by statute.[38]\\r\\n\\r\\nTo manage the growing federal bureaucracy, presidents have gradually surrounded themselves with many layers of staff, who were eventually organized into the Executive Office of the President of the United States. Within the Executive Office, the president's innermost layer of aides (and their assistants) are located in the White House Office.\\r\\n\\r\\nAdditionally, the president possesses the power to manage operations of the federal government through issuing various types of directives, such as presidential proclamation and executive orders. When the president is lawfully exercising one of his constitutionally conferred responsibilities, the scope of this power is broad.[39] Even so, these directives are subject to judicial review by U.S. federal courts, which can find them to be unconstitutional. Moreover, Congress can overturn an executive order though legislation (e.g., Congressional Review Act).\\r\\n\\r\\nThe president also has the power to nominate federal judges, including members of the United States courts of appeals and the Supreme Court of the United States. However, these nominations require Senate confirmation. Securing Senate approval can provide a major obstacle for presidents who wish to orient the federal judiciary toward a particular ideological stance. When nominating judges to U.S. district courts, presidents often respect the long-standing tradition of senatorial courtesy. Presidents may also grant pardons and reprieves. Gerald Ford pardoned Richard Nixon a month after taking office. Bill Clinton pardoned Patty Hearst on his last day in office, as is often done just before the end of a second presidential term, but not without controversy.[40][41][42]\\r\\n\\r\\nHistorically, two doctrines concerning executive power have developed that enable the president to exercise executive power with a degree of autonomy. The first is executive privilege, which allows the president to withhold from disclosure any communications made directly to the president in the performance of executive duties. George Washington first claimed the privilege when Congress requested to see Chief Justice John Jay's notes from an unpopular treaty negotiation with Great Britain. While not enshrined in the Constitution, or any other law, Washington's action created the precedent for the privilege. When Nixon tried to use executive privilege as a reason for not turning over subpoenaed evidence to Congress during the Watergate scandal, the Supreme Court ruled in United States v. Nixon, 418 U.S. 683 (1974), that executive privilege did not apply in cases where a president was attempting to avoid criminal prosecution. When President Clinton attempted to use executive privilege regarding the Lewinsky scandal, the Supreme Court ruled in Clinton v. Jones, 520 U.S. 681 (1997), that the privilege also could not be used in civil suits. These cases established the legal precedent that executive privilege is valid, although the exact extent of the privilege has yet to be clearly defined. Additionally, federal courts have allowed this privilege to radiate outward and protect other executive branch employees, but have weakened that protection for those executive branch communications that do not involve the president.[43]\\r\\n\\r\\nThe state secrets privilege allows the president and the executive branch to withhold information or documents from discovery in legal proceedings if such release would harm national security. Precedent for the privilege arose early in the 19th century when Thomas Jefferson refused to release military documents in the treason trial of Aaron Burr and again in Totten v. United States 92 U.S. 105 (1876), when the Supreme Court dismissed a case brought by a former Union spy.[44] However, the privilege was not formally recognized by the U.S. Supreme Court until United States v. Reynolds 345 U.S. 1 (1953), where it was held to be a common law evidentiary privilege.[45] Before the September 11 attacks, use of the privilege had been rare, but increasing in frequency.[46] Since 2001, the government has asserted the privilege in more cases and at earlier stages of the litigation, thus in some instances causing dismissal of the suits before reaching the merits of the claims, as in the Ninth Circuit's ruling in Mohamed v. Jeppesen Dataplan, Inc.[45][47][48] Critics of the privilege claim its use has become a tool for the government to cover up illegal or embarrassing government actions.[49][50]\\r\\n\\r\\nThe Constitution's Ineligibility Clause prevents the president (and all other executive officers) from simultaneously being a member of Congress. Therefore, the president cannot directly introduce legislative proposals for consideration in Congress. However, the president can take an indirect role in shaping legislation, especially if the president's political party has a majority in one or both houses of Congress. For example, the president or other officials of the executive branch may draft legislation and then ask senators or representatives to introduce these drafts into Congress. The president can further influence the legislative branch through constitutionally or statutorily mandated, periodic reports to Congress. These reports may be either written or oral, but today the greatest in importance are given as the oral State of the Union addresses, which often outline the president's legislative proposals for the coming year. Additionally, the president may attempt to have Congress alter proposed legislation by threatening to veto that legislation unless requested changes are made.\\r\\n\\r\\nIn the 20th century, critics charged that too many legislative and budgetary powers that should have belonged to Congress had slid into the hands of presidents. As the head of the executive branch, presidents control a vast array of agencies that can issue regulations with little oversight from Congress. One critic charged that presidents could appoint a \\"virtual army of 'czars' ÿ each wholly unaccountable to Congress yet tasked with spearheading major policy efforts for the White House\\".[51] Presidents have been criticized for making signing statements when signing congressional legislation about how they understand a bill or plan to execute it.[52] This practice has been criticized by the American Bar Association as unconstitutional.[53] Conservative commentator George Will wrote of an \\"increasingly swollen executive branch\\" and \\"the eclipse of Congress\\".[54]\\r\\n\\r\\nAccording to Article II, Section 3 of the Constitution, the president may convene either or both houses of Congress. If both houses cannot agree on a date of adjournment, the president may appoint a date for Congress to adjourn. For example, Franklin Delano Roosevelt convened a special session of Congress immediately after the December 7, 1941, Japanese sneak attack on Pearl Harbor and asked for a declaration of war.\\r\\n\\r\\nAs head of state, the president can fulfill traditions established by previous presidents. William Howard Taft started the tradition of throwing out the ceremonial first pitch in 1910 at Griffith Stadium, Washington, D.C., on the Washington Senators' Opening Day. Every president since Taft, except for Jimmy Carter, threw out at least one ceremonial first ball or pitch for Opening Day, the All-Star Game, or the World Series, usually with much fanfare.[55]\\r\\n\\r\\nThe President of the United States has served as the honorary president of the Boy Scouts of America since the founding of the organization.[56]\\r\\n\\r\\nOther presidential traditions are associated with American holidays. Rutherford B. Hayes began in 1878 the first White House egg rolling for local children.[57] Beginning in 1947, during the Harry S. Truman administration, every Thanksgiving the president is presented with a live domestic turkey during the annual National Thanksgiving Turkey Presentation held at the White House. Since 1989, when the custom of \\"pardoning\\" the turkey was formalized by George H. W. Bush, the turkey has been taken to a farm where it will live out the rest of its natural life.[58]\\r\\n\\r\\nPresidential traditions also involve the president's role as head of government. Many outgoing presidents since James Buchanan traditionally give advice to their successor during the presidential transition.[59] Ronald Reagan and his successors have also left a private message on the desk of the Oval Office on Inauguration Day for the incoming president.[60]\\r\\n\\r\\nDuring a state visit by a foreign head of state, the president typically hosts a State Arrival Ceremony held on the South Lawn, a custom begun by John F. Kennedy in 1961.[61] This is followed by a state dinner given by the president which is held in the State Dining Room later in the evening.[62]\\r\\n\\r\\nThe modern presidency holds the president as one of the nation's premier celebrities. Some argue that images of the presidency have a tendency to be manipulated by administration public relations officials as well as by presidents themselves. One critic described the presidency as \\"propagandized leadership\\" which has a \\"mesmerizing power surrounding the office\\".[63] Administration public relations managers staged carefully crafted photo-ops of smiling presidents with smiling crowds for television cameras.[64] One critic wrote the image of John F. Kennedy was described as carefully framed \\"in rich detail\\" which \\"drew on the power of myth\\" regarding the incident of PT 109[65] and wrote that Kennedy understood how to use images to further his presidential ambitions.[66] As a result, some political commentators have opined that American voters have unrealistic expectations of presidents: voters expect a president to \\"drive the economy, vanquish enemies, lead the free world, comfort tornado victims, heal the national soul and protect borrowers from hidden credit-card fees\\".[67]\\r\\n\\r\\nThe nation's Founding Fathers expected the Congresswhich was the first branch of government described in the Constitutionto be the dominant branch of government; they did not expect a strong executive department.[68] However, presidential power has shifted over time, which has resulted in claims that the modern presidency has become too powerful,[69][70] unchecked, unbalanced,[71] and \\"monarchist\\" in nature.[72] Professor Dana D. Nelson believes presidents over the past thirty years have worked towards \\"undivided presidential control of the executive branch and its agencies\\".[73] She criticizes proponents of the unitary executive for expanding \\"the many existing uncheckable executive powers ÿ such as executive orders, decrees, memorandums, proclamations, national security directives and legislative signing statements ÿ that already allow presidents to enact a good deal of foreign and domestic policy without aid, interference or consent from Congress\\".[73] Bill Wilson, board member of Americans for Limited Government, opined that the expanded presidency was \\"the greatest threat ever to individual freedom and democratic rule\\".[74]\\r\\n\\r\\nArticle II, Section 1, Clause 5 of the Constitution sets three qualifications for holding the presidency. To serve as president, one must:\\r\\n\\r\\nA person who meets the above qualifications would, however, still be disqualified from holding the office of president under any of the following conditions:\\r\\n\\r\\nThe modern presidential campaign begins before the primary elections, which the two major political parties use to clear the field of candidates before their national nominating conventions, where the most successful candidate is made the party's nominee for president. Typically, the party's presidential candidate chooses a vice presidential nominee, and this choice is rubber-stamped by the convention. The most common previous profession of U.S. presidents is lawyer.[80]\\r\\n\\r\\nNominees participate in nationally televised debates, and while the debates are usually restricted to the Democratic and Republican nominees, third party candidates may be invited, such as Ross Perot in the 1992 debates. Nominees campaign across the country to explain their views, convince voters and solicit contributions. Much of the modern electoral process is concerned with winning swing states through frequent visits and mass media advertising drives.\\r\\n\\r\\nThe president is elected indirectly by the voters of each state and the District of Columbia through the Electoral College, a body of electors formed every four years for the sole purpose of electing the president and vice president to concurrent four-year terms. As prescribed by the Twelfth Amendment, each state is entitled to a number of electors equal to the size of its total delegation in both houses of Congress. Additionally, the Twenty-third Amendment provides that the District of Columbia is entitled to the number it would have if it were a state, but in no case more than that of the least populous state.[81] Currently, all states and D.C. select their electors based on a popular election held on Election Day.[82] In all but two states, the party whose presidential-vice presidential ticket receives a plurality of popular votes in the state has its entire slate of elector nominees chosen as the state's electors.[83] Maine and Nebraska deviate from this winner-take-all practice, awarding two electors to the statewide winner and one to the winner in each congressional district.[84][85]\\r\\n\\r\\nOn the first Monday after the second Wednesday in December, about six weeks after the election, the electors convene in their respective state capitals (and in Washington D.C.) to vote for president and, on a separate ballot, for vice president. They typically vote for the candidates of the party that nominated them. While there is no constitutional mandate or federal law requiring them to do so, the District of Columbia and 30 states have laws requiring that their electors vote for the candidates to whom they are pledged.[82][86] Following the vote, each state then sends a certified record of their electoral votes to Congress. The votes of the electors are opened and counted during a joint session of Congress, held in the first week of January. If a candidate has received an absolute majority of electoral votes for president (currently 270 of 538), that person is declared the winner. Otherwise, the House of Representatives must meet to elect a president using a contingent election procedure in which representatives, voting by state delegation, with each state casting a single vote, choose between the top electoral vote-getters for president. For a candidate to win, he or she must receive the votes of an absolute majority of states (currently 26 of 50).[82]\\r\\n\\r\\nThere have been two contingent presidential elections in the nation's history. A 73ÿ73 electoral vote tie between Thomas Jefferson and fellow Democratic-Republican Aaron Burr in the election of 1800 necessitated the first. Conducted under the original procedure established by Article II, Section 1, Clause 3 of the Constitution, which stipulates that if two or three persons received a majority vote and an equal vote, the House of Representatives would choose one of them for president; the runner up would become Vice President.[87] On February 17, 1801, Jefferson was elected president on the 36th ballot, and Burr became vice president. Afterward, the system was overhauled through the Twelfth Amendment in time to be used in the 1804 election.[88] A quarter-century later, the choice for president again devolved to the House when no candidate won an absolute majority of electoral votes (131 of 261) in the election of 1824. Under the Twelfth Amendment, the House was required to choose a president from among the top three electoral vote recipients: Andrew Jackson, John Quincy Adams, and William H. Crawford. Held February 9, 1825, this second and most recent contingent election resulted in John Quincy Adams being elected president on the first ballot.[89]\\r\\n\\r\\nPursuant to the Twentieth Amendment, the four-year term of office for both the president and vice president begins at noon on January 20.[90] The first presidential and vice presidential terms to begin on this date, known as Inauguration Day, were the second terms of President Franklin D. Roosevelt and Vice President John Nance Garner in 1937.[91] Previously, Inauguration Day was on March 4. As a result of the date change, the first term (1933ÿ37) of both men had been shortened by 43 days.[92]\\r\\n\\r\\nBefore executing the powers of the office, a president is required to recite the presidential oath of office, found in Article II, Section 1, Clause 8. This is the only component in the inauguration ceremony mandated by the Constitution:\\r\\n\\r\\nI do solemnly swear (or affirm) that I will faithfully execute the Office of President of the United States, and will to the best of my Ability, preserve, protect, and defend the Constitution of the United States.[93]\\r\\n\\r\\nPresidents have traditionally placed one hand upon a Bible while taking the oath, and have added \\"So help me God\\" to the end of the oath.[94][95] Although the oath may be administered by any person authorized by law to administer oaths, presidents are traditionally sworn in by the Chief Justice of the United States.[93]\\r\\n\\r\\nWhen the first president, George Washington, announced in his Farewell Address that he was not running for a third term, he established a \\"two-terms then out\\" precedent. Precedent became tradition after Thomas Jefferson publicly embraced the principle a decade later during his second term, as did his two immediate successors, James Madison and James Monroe.[96] In spite of the strong two-term tradition, Ulysses S. Grant sought a non-consecutive third term in 1880,[97] as did Theodore Roosevelt in 1912 (though it would have been only his second full term).[98] Both were unsuccessful.\\r\\n\\r\\nIn 1940, after leading the nation through the Great Depression, Franklin Roosevelt was elected to a third term, breaking the self-imposed precedent. Four years later, with the U.S. engaged in World War II, he was re-elected again despite his declining physical health; he died 82 days into his fourth term on April 12, 1945.[99]\\r\\n\\r\\nIn response to the unprecedented length of Roosevelt's presidency, the Twenty-second Amendment was adopted in 1951. The amendment bars anyone from being elected president more than twice, or once if that person served more than two years (24 months) of another president's four-year term. Harry S. Truman, president when this term limit came into force, was exempted from its limitations, and briefly sought a second full termto which he would have otherwise been inelegible for election to, as he had been president for more than two years of Roosevelt's fourth termbefore he withdrew from the 1952 election.[99]\\r\\n\\r\\nSince the amendment's adoption, five presidents have served two full terms: Dwight D. Eisenhower, Ronald Reagan, Bill Clinton, George W. Bush, and Barack Obama. Both Jimmy Carter and George H. W. Bush sought a second term, but were defeated. Richard Nixon was elected to a second term, but resigned before completing it. Lyndon B. Johnson, having held the presidency for one full term in addition to only 14 months of John F. Kennedy's unexpired term, was eligible for a second full term in 1968, but withdrew from Democratic Primary. Additionally, Gerald Ford, who served out the last two years and five months of Nixon's second term, sought a full term, but was defeated by Jimmy Carter in the 1976 election.\\r\\n\\r\\nArticle II, Section 4 of the Constitution allows for the removal of high federal officials, including the president, from office for \\"treason, bribery, or other high crimes and misdemeanors.\\" Article I, Section 2, Clause 5 authorizes the House of Representatives to serve as a \\"grand jury\\" with the power to impeach said officials by a majority vote.[100] Article I, Section 3, Clause 6 authorizes the Senate to serve as a court with the power to remove impeached officials from office, by a two-thirds vote to convict.[101]\\r\\n\\r\\nTwo presidents have been impeached by the House of Representatives: Andrew Johnson in 1868, and Bill Clinton in 1998. Both were acquitted by the senate: Johnson by one vote, and Clinton by 17 votes. Additionally, the House Judiciary Committee commenced impeachment proceedings against Richard Nixon in 1974; however, he resigned from office before the full House voted on the articles of impeachment.[100]\\r\\n\\r\\nSuccession to or vacancies in the office of president may arise under several possible circumstances: death, resignation, and removal from office. Deaths have occurred a number of times, resignation has occurred only once, and removal from office has never occurred.\\r\\n\\r\\nUnder Section 3 of the Twenty-fifth Amendment, the president may transfer the presidential powers and duties to the vice president, who then becomes acting president, by transmitting a statement to the Speaker of the House and the President pro tempore of the Senate stating the reasons for the transfer. The president resumes the discharge of the presidential powers and duties upon transmitting, to those two officials, a written declaration stating that resumption. Such a transfer of power has occurred on three occasions: Ronald Reagan to George H. W. Bush once, on July 13, 1985, and George W. Bush to Dick Cheney twice, on June 29, 2002, and on July 21, 2007.[102]\\r\\n\\r\\nUnder Section 4 of the Twenty-fifth Amendment, the vice president, in conjunction with a majority of the Cabinet, may transfer the presidential powers and duties from the president to the vice president by transmitting a written declaration to the Speaker of the House and the president pro tempore of the Senate that the president is incapacitatedunable to discharge their presidential powers and duties. If this occurs, then the vice president will assume the presidential powers and duties as acting president; however, the president can declare that no such inability exists and resume the discharge of the presidential powers and duties. If the vice president and Cabinet contest this claim, it is up to Congress, which must meet within two days if not already in session, to decide the merit of the claim.\\r\\n\\r\\nSection 1 of the Twenty-fifth Amendment states that the vice president becomes president upon the removal from office, death, or resignation of the preceding president. Article II, Section 1, Clause 6 authorizes Congress to declare who shall become acting president in the \\"Case of Removal, Death, Resignation or Inability, both of the President and Vice President.\\"[103] The Presidential Succession Act of 1947, (codified as 3 U.S.C.??19) provides that if both the president and vice president have left office or are both otherwise unavailable to serve during their terms of office, the presidential line of succession follows the order of: Speaker of the House, then, if necessary, the President pro tempore of the Senate, and then if necessary, the eligible heads of federal executive departments who form the president's Cabinet. The Cabinet currently has 15 members, of which the Secretary of State is first in line; the other Cabinet secretaries follow in the order in which their department (or the department of which their department is the successor) was created. Those department heads who are constitutionally ineligible to be elected to the presidency are also disqualified from assuming the powers and duties of the presidency through succession. No statutory successor has yet been called upon to act as president.[104]\\r\\n\\r\\nThroughout most of its history, politics of the United States have been dominated by political parties. Political parties had not been anticipated when the U.S. Constitution was drafted in 1787, nor did they exist at the time of the first presidential election in 1788ÿ1789. Organized political parties developed in the U.S. in the midÿ1790s, but political factions, from which organized parties evolved, began to appear almost immediately after the Federal government came into existence. Those who supported the Washington administration were referred to as \\"pro-administration\\" and would eventually form the Federalist Party, while those in opposition joined the emerging Democratic-Republican Party.[105]\\r\\n\\r\\nGreatly concerned about the very real capacity of political parties to destroy the fragile unity holding the nation together, Washington remained unaffiliated with any political faction or party throughout his eight-year presidency. He was, and remains, the only U.S. president never to be affiliated with a political party.[106] Since George Washington, 43 persons have been sworn into the office of president, and each has been affiliated with a political party at the time of assuming office. The number of presidents per political party (at the time of entry into office) are:[107][108]\\r\\n\\r\\nSince 2001, the president's annual salary has been $400,000 annual salary, along with a: $50,000 expense allowance; $100,000 nontaxable travel account, and $19,000 entertainment account. The president's salary is set by Congress, and under Article II, Section 1, Clause 7 of the Constitution, may not be increased or reduced during his or her current term of office.[109][110]\\r\\n\\r\\nThe White House in Washington, D.C. serves as the official residence of the president. The site was selected by George Washington, and the cornerstone was laid in 1792. Every president since John Adams (in 1800) has lived there. At various times in U.S. history, it has been known as the \\"President's Palace,\\" the \\"Presidents House,\\" and the \\"Executive Mansion.\\" Theodore Roosevelt officially gave the White House its current name in 1901.[113] Facilities that are available to the president include access to the White House staff, medical care, recreation, housekeeping, and security services. The federal government pays for state dinners and other official functions, but the president pays for personal, family, and guest dry cleaning and food.[114]\\r\\n\\r\\nCamp David, officially titled Naval Support Facility Thurmont, a mountain-based military camp in Frederick County, Maryland, is the president's country residence. A place of solitude and tranquility, the site has been used extensively to host foreign dignitaries since the 1940s.[115]\\r\\n\\r\\nBlair House, located next to the Eisenhower Executive Office Building at the White House Complex and Lafayette Park, serves as the president's official guest house and as a secondary residence for the president if needed. Four interconnected, 19th century housesBlair House, Lee House, and 700 and 704 Jackson Placewith a combined floor space exceeding 70,000 square feet (6,500?m2) comprise the property.[116]\\r\\n\\r\\nThe primary means of long distance air travel for the president is one of two identical Boeing VC-25 aircraft, which are extensively modified Boeing 747 airliners and are referred to as Air Force One while the president is on board (although any U.S. Air Force aircraft the president is aboard is designated as \\"Air Force One\\" for the duration of the flight). In-country trips are typically handled with just one of the two planes, while overseas trips are handled with both, one primary and one backup. The president also has access to smaller Air Force aircraft, most notably the Boeing C-32, which are used when the president must travel to airports that cannot support a jumbo jet. Any civilian aircraft the president is aboard is designated Executive One for the flight.[117][118]\\r\\n\\r\\nFor short distance air travel, the president has access to a fleet of U.S. Marine Corps helicopters of varying models, designated Marine One when the president is aboard any particular one in the fleet. Flights are typically handled with as many as five helicopters all flying together and frequently swapping positions as to disguise which helicopter the president is actually aboard to any would-be threats.\\r\\n\\r\\nFor ground travel, the president uses the presidential state car, which is an armored limousine designed to look like a Cadillac sedan, but built on a truck chassis.[119][120] The US Secret Service operates and maintains the fleet of several limousines. The president also has access to two armored motorcoaches, which are primarily used for touring trips.[121]\\r\\n\\r\\nThe presidential limousine\\r\\n\\r\\nThe presidential plane, called Air Force One when the president is inside.\\r\\n\\r\\nMarine One helicopter, when the president is aboard\\r\\n\\r\\nThe U.S. Secret Service is charged with protecting the president and the first family. As part of their protection, presidents, first ladies, their children and other immediate family members, and other prominent persons and locations are assigned Secret Service codenames.[122] The use of such names was originally for security purposes and dates to a time when sensitive electronic communications were not routinely encrypted; today, the names simply serve for purposes of brevity, clarity, and tradition.[123]\\r\\n\\r\\nUnder the Former Presidents Act, all living former presidents are granted a pension, an office, and a staff. The pension has increased numerous times with Congressional approval. Retired presidents now receive a pension based on the salary of the current administration's cabinet secretaries, which was $199,700 each year in 2012.[124] Former presidents who served in Congress may also collect congressional pensions.[125] The act also provides former presidents with travel funds and franking privileges. Prior to 1997, all former presidents, their spouses, and their children until age 16 were protected by the Secret Service until the president's death.[126][127] In 1997, Congress passed legislation limiting secret service protection to no more than 10 years from the date a president leaves office.[128] On January 10, 2013, President Obama signed legislation reinstating lifetime secret service protection for him, George W. Bush, and all subsequent presidents.[129] A spouse who remarries is no longer eligible for secret service protection.[128]\\r\\n\\r\\nSome presidents have had significant careers after leaving office. Prominent examples include William Howard Taft's tenure as Chief Justice of the United States and Herbert Hoover's work on government reorganization after World War II. Grover Cleveland, whose bid for reelection failed in 1888, was elected president again four years later in 1892. Two former presidents served in Congress after leaving the White House: John Quincy Adams was elected to the House of Representatives, serving there for seventeen years, and Andrew Johnson returned to the Senate in 1875. John Tyler served in the provisional Congress of the Confederate States during the Civil War and was elected to the Confederate House of Representatives, but died before that body first met.\\r\\n\\r\\nPresidents may use their predecessors as emissaries to deliver private messages to other nations or as official representatives of the United States to state funerals and other important foreign events.[130][131] Richard Nixon made multiple foreign trips to countries including China and Russia and was lauded as an elder statesman.[132] Jimmy Carter has become a global human rights campaigner, international arbiter, and election monitor, as well as a recipient of the Nobel Peace Prize. Bill Clinton has also worked as an informal ambassador, most recently in the negotiations that led to the release of two American journalists, Laura Ling and Euna Lee, from North Korea. Clinton has also been active politically since his presidential term ended, working with his wife Hillary on her 2008 and 2016 presidential bids and President Obama on his 2012 reelection campaign.\\r\\n\\r\\nThere are currently (since January 20, 2017) five living former presidents. In order of office they are:\\r\\n\\r\\nJimmy Carter (age 93)since 1981\\r\\n\\r\\nGeorge H. W. Bush (age 94)since 1993\\r\\n\\r\\nBill Clinton (age 72)since 2001\\r\\n\\r\\nGeorge W. Bush (age 72)since 2009\\r\\n\\r\\nBarack Obama (age 57)since 2017\\r\\n\\r\\nEvery president since Herbert Hoover has created a repository known as a presidential library for preserving and making available his papers, records, and other documents and materials. Completed libraries are deeded to and maintained by the National Archives and Records Administration (NARA); the initial funding for building and equipping each library must come from private, non-federal sources.[133] There are currently thirteen presidential libraries in the NARA system. There are also presidential libraries maintained by state governments and private foundations and Universities of Higher Education, such as the Abraham Lincoln Presidential Library and Museum, which is run by the State of Illinois, the George W. Bush Presidential library and Museum, which is run by Southern Methodist University, the George H. W. Bush Presidential Library and Museum, which is run by Texas A&M University, and the Lyndon Baines Johnson Presidential Library and Museum, which is run by the University of Texas at Austin.\\r\\n\\r\\nA number of presidents have lived for many years after leaving office, and several of them have personally overseen the building and opening of their own presidential libraries. Some have even made arrangements for their own burial at the site. Several presidential libraries contain the graves of the president they document, including the Dwight D. Eisenhower Presidential Library, Museum and Boyhood Home in Abilene, Kansas, Richard Nixon Presidential Library and Museum in Yorba Linda, California, and the Ronald Reagan Presidential Library in Simi Valley, California. These gravesites are open to the general public.","input":"Who is the current leader of the usa?"},{"output":"named by Los Angeles police officer and businessman Guy McAfee, after his hometown's Sunset Strip","context":"The Las Vegas Strip is a stretch of South Las Vegas Boulevard in Clark County, Nevada, known for its concentration of resort hotels and casinos. The Strip is approximately 4.2 miles (6.8?km) in length,[1] located immediately south of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. However, the Strip is often referred to as being in Las Vegas. Most of the Strip has been designated an All-American Road,[2][3] and is considered a scenic route at night.[4] Many of the largest hotel, casino, and resort properties in the world are located on the Las Vegas Strip.\\r\\nThe Las Vegas Strip cityscape is highlighted by its use of contemporary architecture, lights and wide variety of attractions. Its hotels, casinos, restaurants, residential high-rises, entertainment offerings, and skyline have established the Las Vegas Strip as one of the most popular and iconic tourist destinations in the United States, and the world.[5]\\r\\n\\r\\n\\r\\nHistorically, the casinos that were not in Downtown Las Vegas along Fremont Street were limited to outside of the city limits on Las Vegas Boulevard. In 1959 the Welcome to Fabulous Las Vegas sign was constructed exactly 4.5 miles (7.2?km) outside of the city limits. The sign is today about 0.4 miles (0.64?km) south of the southernmost entrance to Mandalay Bay (the southernmost casino).[6]\\r\\nIn the strictest sense, \\"the Strip\\" refers only to the stretch of Las Vegas Boulevard that is roughly between Sahara Avenue and Russell Road, a distance of 4.2 miles (6.8?km).[7][8] However, the term is often used to refer not only to the road but also to the various casinos and resorts that line the road, and even to properties that are not on the road but in proximity. Phrases such as Strip Area, Resort Corridor or Resort District are sometimes used to indicate a larger geographical area, including properties 1 mile (1.6?km) or more away from Las Vegas Boulevard, such as the Hard Rock, Rio, Palms, and Hooters casinos.\\r\\nThe traditional definition considers the Strip's northern terminus as the SLS, though travel guides typically extend it to include the Stratosphere, 0.4 miles (0.64?km) to the north. Mandalay Bay, located just north of Russell Road, is the southernmost resort considered to be on the Strip (the Klondike was the southernmost until 2006, when it was closed, although it was not included in Las Vegas Strip on some definitions and travel guides).\\r\\nBecause of the number and size of the resorts, the Resort Corridor can be quite wide. Interstate 15 runs roughly parallel and 0.5 to 0.8 miles (0.80 to 1.29?km) to the west of Las Vegas Boulevard for the entire length of the Strip. Paradise Road runs to the east in a similar fashion, and ends at St. Louis Avenue. The eastern side of the Strip is bounded by McCarran International Airport south of Tropicana Avenue.\\r\\nNorth of this point, the Resort Corridor can be considered to extend as far east as Paradise Road, although some consider Koval Lane as a less inclusive boundary. Interstate 15 is sometimes considered the western edge of the Resort Corridor from Interstate 215 to Spring Mountain Road. North of this point, Industrial Road serves as the western edge.\\r\\nThe famous \\"Welcome to Fabulous Las Vegas\\" sign is located in the median just south of Russell Road, across from the now-demolished Klondike Hotel & Casino. Another similar (and newer) \\"Welcome to Fabulous Downtown Las Vegas\\" sign is in the median a mile north of the Strip at the intersection of Las Vegas Blvd and South 4th St. Newer resorts such as South Point and the M Resort are on Las Vegas Boulevard South as distant as 8 miles south of the \\"Welcome to Las Vegas\\" sign. Marketing for these casinos usually states that they are on southern Las Vegas Boulevard and not \\"Strip\\" properties.\\r\\nThe first casino to be built on Highway 91 was the Pair-o-Dice Club in 1931, but the first on what is currently the Strip was the El Rancho Vegas, opening on April 3, 1941, with 63 rooms. That casino stood for almost 20 years before being destroyed by a fire in 1960. Its success spawned a second hotel on what would become the Strip, the Hotel Last Frontier, in 1942. Organized crime figures such as New York's Bugsy Siegel took interest in the growing gaming center leading to other resorts such as the Flamingo, which opened in 1946, and the Desert Inn, which opened in 1950. The funding for many projects was provided through the American National Insurance Company, which was based in the then notorious gambling empire of Galveston, Texas.[9][10]\\r\\nLas Vegas Boulevard South was previously called Arrowhead Highway, or Los Angeles Highway. The Strip was named by Los Angeles police officer and businessman Guy McAfee, after his hometown's Sunset Strip.[11]\\r\\nCaesars Palace was established in 1966. In 1968, Kirk Kerkorian purchased the Flamingo and hired Sahara Hotels Vice President Alex Shoofey as President. Alex Shoofey brought along 33 of Sahara's top executives. The Flamingo was used to train future employees of the International Hotel, which was under construction. Opening in 1969, the International Hotel, with 1,512 rooms, began the era of mega-resorts. The International is known as Westgate Las Vegas today. The first MGM Grand Hotel and Casino, also a Kerkorian property, opened in 1973 with 2,084 rooms. At the time, this was one of the largest hotels in the world by number of rooms. The Rossiya Hotel built in 1967 in Moscow, for instance, had 3,200 rooms; however, most of the rooms in the Rossiya Hotel were single rooms of 118 sq. ft (roughly 1/4 size of a standard room at the MGM Grand Resort). On November 21, 1980, the MGM Grand suffered the worst resort fire in the history of Las Vegas as a result of electrical problems, killing 87 people. It reopened eight months later. In 1986, Kerkorian sold the MGM Grand to Bally Manufacturing, and it was renamed Bally's.\\r\\nThe Wet 'n Wild water park opened in 1985 and was located on the south side of the Sahara hotel. The park closed at the end of the 2004 season and was later demolished. The opening of The Mirage in 1989 set a new level to the Las Vegas experience, as smaller hotels and casinos made way for the larger mega-resorts. The Rio and the Excalibur opened in 1990. These huge facilities offer entertainment and dining options, as well as gambling and lodging. This change affected the smaller, well-known and now historic hotels and casinos, like The Dunes, The Sands, the Stardust, and the Sahara.\\r\\nThe lights along the Strip have been dimmed in a sign of respect to six performers and one other major Las Vegas figure upon their deaths. They are Elvis Presley (1977), Sammy Davis Jr. (1990),[12] Dean Martin (1995), George Burns (1996), Frank Sinatra (1998), former UNLV basketball head coach Jerry Tarkanian (2015), [13] and Don Rickles (2017). [14] In 2005, Clark County renamed a section of Industrial Road (south of Twain Avenue) as Dean Martin Drive, also as a tribute to the famous Rat Pack singer, actor, and frequent Las Vegas entertainer.\\r\\nIn an effort to attract families, resorts offered more attractions geared toward youth, but had limited success. The (current) MGM Grand opened in 1993 with MGM Grand Adventures Theme Park, but the park closed in 2000 due to lack of interest. Similarly, in 2003 Treasure Island closed its own video arcade and abandoned the previous pirate theme, adopting the new ti name.[15]\\r\\nIn addition to the large hotels, casinos and resorts, the Strip is home to a few smaller casinos and other attractions, such as M&M World, Adventuredome and the Fashion Show Mall. Starting in the mid-1990s, the Strip became a popular New Year's Eve celebration destination.\\r\\nWith the opening of Bellagio, Venetian, Palazzo, Wynn and Encore resorts, the strip trended towards the luxurious high end segment through most of the 2000s, while some older resorts added major expansions and renovations, including some de-theming of the earlier themed hotels. High end dining, specialty retail, spas and nightclubs increasingly became options for visitors in addition to gambling at most Strip resorts. There was also a trend towards expensive residential condo units on the strip.\\r\\nIn 2004, MGM Mirage announced plans for CityCenter, a 66-acre (27?ha), $7?billion multi-use project on the site of the Boardwalk hotel and adjoining land. It consists of hotel, casino, condo, retail, art, business and other uses on the site. City Center is currently the largest such complex in the world. Construction began in April 2006, with most elements of the project opened in late 2009. Also in 2006, the Las Vegas Strip lost its longtime status as the world's highest-grossing gambling center, falling to second place behind Macau.[16]\\r\\nIn 2012, the High Roller Ferris wheel and a retail district called The LINQ Promenade broke ground, in an attempt to diversify attractions beyond that of casino resorts. Renovations and rebrandings such as The Cromwell Las Vegas and the SLS Las Vegas continued to transform The Strip in 2014. The Las Vegas Festival Grounds opened in 2015. In 2016, the T-Mobile Arena, The Park, the Lucky Dragon Hotel and Casino, and the Park Theatre opened. Smaller changes and developments are taking place as well.[17]\\r\\nRTC Transit (previously Citizens Area Transit, or CAT) provides bus service on the Strip with double decker buses known as The Deuce. The Deuce runs between Mandalay Bay at the southern end of the Strip (and to the Welcome to Fabulous Las Vegas sign and South Strip Transfer Terminal after midnight) to the Bonneville Transit Center (BTC) and the Fremont Street Experience in Downtown Las Vegas, with stops near every casino. RTC also operates an express bus called the Strip and Downtown Express (SDX). This route connects the Strip to the Las Vegas Convention Center and Downtown Las Vegas to the north, with stops at selected hotels and shopping attractions (Las Vegas Premium Outlets North & South).\\r\\nWhile not on the Strip itself, the Las Vegas Monorail runs on the east side of the Strip corridor from Tropicana Avenue to Sahara Avenue.[27]\\r\\nSeveral free trams operate on the west side of the Strip:\\r\\nPrior to CAT bus service beginning operations in 1992, mass transit on the Strip was provided by a private transit company, Las Vegas Transit. The Strip route was their only profitable route and supported the whole bus system.[citation needed]\\r\\nThe Deuce bus (CAT Enviro500)\\r\\nAria Express\\r\\nMandalay Bay Tram\\r\\nConcerning pedestrian safety and to help alleviate traffic congestion at popular intersections, several pedestrian footbridges were erected in 1990s. Some feature designs that match the theme of the nearby resorts. The Tropicana ÿ Las Vegas Boulevard footbridges were the first to be installed, and based on the success of this project additional footbridges have been built on Las Vegas Boulevard at the Flamingo Road intersection connecting Bellagio, Caesars Palace, Bally's, and The Cromwell; between The Mirage/Treasure Island and The Venetian, and at the Las Vegas Boulevard-Spring Mountain and Sands Avenue intersection connecting the Wynn with the Fashion Show Mall, The Palazzo and Treasure Island. The latest to be completed connects Planet Hollywood, CityCenter and The Cosmopolitan at the Harmon Avenue intersection.[28]\\r\\nAccording to the Las Vegas Convention and Visitors Authority's annual Las Vegas Visitor Profile Study, only 36% of people said they walked around the Strip, a figure that is a drop from 2013 (52%). [29]\\r\\nIn 2000, Bali Hai Golf Club opened just south of Mandalay Bay and the Strip.[30]\\r\\nIn recent years, all golf courses on the Strip but the Desert Inn Golf Course have been removed to make way for building projects. Even though many golf courses along the Strip were being torn down, such as the Tropicana Country Club and the Dunes golf course, developer Steve Wynn, founder of previously owned Mirage Resorts, purchased the Desert Inn and golf course for his new company Wynn Resorts. The Wynn Golf Club is \\"...the only golf course attached to a resort on the Las Vegas Strip...\\".[31] In 2005, he opened Wynn Las Vegas, complete with remodeled golf course providing tee times to hotel guests only.\\r\\nThe strip is home to many amusement parks and rides. These include:\\r\\nThe Las Vegas Strip is well known for its lounges, showrooms, theaters and nightclubs;[34] most of the attractions and shows on the Strip are located on the hotel casino properties. Some of the more popular free attractions visible from the Strip include the water fountains at Bellagio, the volcano at The Mirage, and the Fall of Atlantis and Festival Fountain at Caesars Palace. There are several Cirque du Soleil shows, such as K at the MGM Grand, O at Bellagio, Mystre at Treasure Island, Zumanity (for ages 18 and older) at New York-New York, Criss Angel Mindfreak at the Luxor, and Michael Jackson: One at Mandalay Bay.[35]\\r\\nMany notable artists have performed in Las Vegas, including Elvis Presley, Frank Sinatra, Judy Garland, Wayne Newton, Liza Minnelli, Dean Martin, Sammy Davis Jr. and Liberace,[36] and in more recent years Celine Dion, Britney Spears, Barry Manilow, Cher, Elton John, Bette Midler, Donny and Marie Osmond, Garth Brooks, Jennifer Lopez, Reba McEntire, Mariah Carey and Olivia Newton-John have had residencies in the various resorts on the Strip. Currently, the only movie theatre directly on the Strip is the 10-screen Regal Showcase Theatre in the Showcase Mall next to the MGM Grand (opened in 1997 and operated by Regal Entertainment Group).[37]\\r\\nGambling has become less of a mainstay in recent years with only 4% of visitors in 2016 saying they came to Las Vegas to gamble, down from 15% in 2013, 12% in 2014 and 10% in 2015.[29]\\r\\nThe Strip is home to many entertainment venues. Most of the resorts have a showroom, nightclub and/or live music venue on the property and a few have large multipurpose arenas. Major venues include:\\r\\n\\r\\nWelcome to Fabulous Las Vegas sign\\r\\nSouth towards Interstate 215 \\r\\n\\r\\nSouth towards Interstate 215 \\r\\nThe iconic Welcome to Las Vegas sign was built in 1959.\\r\\nThe Strip in 2009.\\r\\nA view of the southern end of the Strip. Looking northward from Tropicana Avenue.\\r\\nView of the Strip from the Eiffel Tower of the Paris Las Vegas.\\r\\nPhoto taken May 21, 2010, a view of the Strip from the Renaissance Hotel.\\r\\nView of Monte Carlo Resort and Casino with City Center in the background\\r\\nThe Bellagio Fountains as seen from the hotel\\r\\nThe Cosmopolitan\\r\\nThe Las Vegas High Roller is the tallest Ferris wheel in the world\\r\\nLas Vegas Boulevard at night\\r\\nWynn Las Vegas\\r\\nRoute map: Google","input":"How did the las vegas strip get its name?"},{"output":"nitrogen","context":"The abundance of the chemical elements is a measure of the occurrence of the chemical elements relative to all other elements in a given environment. Abundance is measured in one of three ways: by the mass-fraction (the same as weight fraction); by the mole-fraction (fraction of atoms by numerical count, or sometimes fraction of molecules in gases); or by the volume-fraction. Volume-fraction is a common abundance measure in mixed gases such as planetary atmospheres, and is similar in value to molecular mole-fraction for gas mixtures at relatively low densities and pressures, and ideal gas mixtures. Most abundance values in this article are given as mass-fractions.\\r\\nFor example, the abundance of oxygen in pure water can be measured in two ways: the mass fraction is about 89%, because that is the fraction of water's mass which is oxygen. However, the mole-fraction is 33.3333...% because only 1 atom of 3 in water, H2O, is oxygen. As another example, looking at the mass-fraction abundance of hydrogen and helium in both the Universe as a whole and in the atmospheres of gas-giant planets such as Jupiter, it is 74% for hydrogen and 23ÿ25% for helium; while the (atomic) mole-fraction for hydrogen is 92%, and for helium is 8%, in these environments. Changing the given environment to Jupiter's outer atmosphere, where hydrogen is diatomic while helium is not, changes the molecular mole-fraction (fraction of total gas molecules), as well as the fraction of atmosphere by volume, of hydrogen to about 86%, and of helium to 13%.[Note 1]\\r\\nThe abundance of chemical elements in the universe is dominated by the large amounts of hydrogen and helium which were produced in the Big Bang. Remaining elements, making up only about 2% of the universe, were largely produced by supernovae and certain red giant stars. Lithium, beryllium and boron are rare because although they are produced by nuclear fusion, they are then destroyed by other reactions in the stars.[1][2] The elements from carbon to iron are relatively more common in the universe because of the ease of making them in supernova nucleosynthesis. Elements of higher atomic number than iron (element 26) become progressively more rare in the universe, because they increasingly absorb stellar energy in being produced. Elements with even atomic numbers are generally more common than their neighbors in the periodic table, also due to favorable energetics of formation.\\r\\nThe abundance of elements in the Sun and outer planets is similar to that in the universe. Due to solar heating, the elements of Earth and the inner rocky planets of the Solar System have undergone an additional depletion of volatile hydrogen, helium, neon, nitrogen, and carbon (which volatilizes as methane). The crust, mantle, and core of the Earth show evidence of chemical segregation plus some sequestration by density. Lighter silicates of aluminum are found in the crust, with more magnesium silicate in the mantle, while metallic iron and nickel compose the core. The abundance of elements in specialized environments, such as atmospheres, or oceans, or the human body, are primarily a product of chemical interactions with the medium in which they reside.\\r\\n\\r\\n\\r\\nThe elements ÿ that is, ordinary (baryonic) matter made of protons, neutrons, and electrons, are only a small part of the content of the Universe. Cosmological observations suggest that only 4.6% of the universe's energy (including the mass contributed by energy, E = mc2 ? m = E / c2) comprises the visible baryonic matter that constitutes stars, planets, and living beings. The rest is thought to be made up of dark energy (68%) and dark matter (27%).[4] These are forms of matter and energy believed to exist on the basis of scientific theory and observational deductions, but they have not been directly observed and their nature is not well understood.\\r\\nMost standard (baryonic) matter is found in intergalactic gas, stars, and interstellar clouds, in the form of atoms or ions (plasma), although it can be found in degenerate forms in extreme astrophysical settings, such as the high densities inside white dwarfs and neutron stars.\\r\\nHydrogen is the most abundant element in the Universe; helium is second. However, after this, the rank of abundance does not continue to correspond to the atomic number; oxygen has abundance rank 3, but atomic number 8. All others are substantially less common.\\r\\nThe abundance of the lightest elements is well predicted by the standard cosmological model, since they were mostly produced shortly (i.e., within a few hundred seconds) after the Big Bang, in a process known as Big Bang nucleosynthesis. Heavier elements were mostly produced much later, inside of stars.\\r\\nHydrogen and helium are estimated to make up roughly 74% and 24% of all baryonic matter in the universe respectively. Despite comprising only a very small fraction of the universe, the remaining \\"heavy elements\\" can greatly influence astronomical phenomena. Only about 2% (by mass) of the Milky Way galaxy's disk is composed of heavy elements.\\r\\nThese other elements are generated by stellar processes.[5][6][7] In astronomy, a \\"metal\\" is any element other than hydrogen or helium. This distinction is significant because hydrogen and helium are the only elements that were produced in significant quantities in the Big Bang. Thus, the metallicity of a galaxy or other object is an indication of stellar activity, after the Big Bang.\\r\\nIn general, elements up to iron are made in large stars in the process of becoming supernovae. Iron-56 is particularly common, since it is the most stable element that can easily be made from alpha particles (being a product of decay of radioactive nickel-56, ultimately made from 14 helium nuclei). Elements heavier than iron are made in energy-absorbing processes in large stars, and their abundance in the universe (and on Earth) generally decreases with increasing atomic number.\\r\\nThe following graph (note log scale) shows abundance of elements in the Solar System. The table shows the twelve most common elements in our galaxy (estimated spectroscopically), as measured in parts per million, by mass.[3] Nearby galaxies that have evolved along similar lines have a corresponding enrichment of elements heavier than hydrogen and helium. The more distant galaxies are being viewed as they appeared in the past, so their abundances of elements appear closer to the primordial mixture. Since physical laws and processes are uniform throughout the universe, however, it is expected that these galaxies will likewise have evolved similar abundances of elements.\\r\\nThe abundance of elements is in keeping with their origin from the Big Bang and nucleosynthesis in a number of progenitor supernova stars. Very abundant hydrogen and helium are products of the Big Bang, while the next three elements are rare since they had little time to form in the Big Bang and are not made in stars (they are, however, produced in small quantities by breakup of heavier elements in interstellar dust, as a result of impact by cosmic rays).\\r\\nBeginning with carbon, elements have been produced in stars by buildup from alpha particles (helium nuclei), resulting in an alternatingly larger abundance of elements with even atomic numbers (these are also more stable). The effect of odd-numbered chemical elements generally being more rare in the universe was empirically noticed in 1914, and is known as the Oddo-Harkins rule.\\r\\nLoose correlations have been observed between estimated elemental abundances in the universe and the nuclear binding energy curve. Roughly speaking, the relative stability of various atomic nuclides has exerted a strong influence on the relative abundance of elements formed in the Big Bang, and during the development of the universe thereafter. [9] See the article about nucleosynthesis for the explanation on how certain nuclear fusion processes in stars (such as carbon burning, etc.) create the elements heavier than hydrogen and helium.\\r\\nA further observed peculiarity is the jagged alternation between relative abundance and scarcity of adjacent atomic numbers in the elemental abundance curve, and a similar pattern of energy levels in the nuclear binding energy curve. This alternation is caused by the higher relative binding energy (corresponding to relative stability) of even atomic numbers compared with odd atomic numbers and is explained by the Pauli Exclusion Principle.[10] The semi-empirical mass formula (SEMF), also called Weizs?cker's formula or the Bethe-Weizs?cker mass formula, gives a theoretical explanation of the overall shape of the curve of nuclear binding energy.[11]\\r\\nThe Earth formed from the same cloud of matter that formed the Sun, but the planets acquired different compositions during the formation and evolution of the solar system. In turn, the natural history of the Earth caused parts of this planet to have differing concentrations of the elements.\\r\\nThe mass of the Earth is approximately 5.98G1024?kg. In bulk, by mass, it is composed mostly of iron (32.1%), oxygen (30.1%), silicon (15.1%), magnesium (13.9%), sulfur (2.9%), nickel (1.8%), calcium (1.5%), and aluminium (1.4%); with the remaining 1.2% consisting of trace amounts of other elements.[12]\\r\\nThe bulk composition of the Earth by elemental-mass is roughly similar to the gross composition of the solar system, with the major differences being that Earth is missing a great deal of the volatile elements hydrogen, helium, neon, and nitrogen, as well as carbon which has been lost as volatile hydrocarbons. The remaining elemental composition is roughly typical of the \\"rocky\\" inner planets, which formed in the thermal zone where solar heat drove volatile compounds into space. The Earth retains oxygen as the second-largest component of its mass (and largest atomic-fraction), mainly from this element being retained in silicate minerals which have a very high melting point and low vapor pressure.\\r\\nThe mass-abundance of the nine most abundant elements in the Earth's crust is approximately: oxygen 46%, silicon 28%, aluminum 8.2%, iron 5.6%, calcium 4.2%, sodium 2.5%, magnesium 2.4%, potassium 2.0%, and titanium 0.61%. Other elements occur at less than 0.15%. For a complete list, see abundance of elements in Earth's crust.\\r\\nThe graph at right illustrates the relative atomic-abundance of the chemical elements in Earth's upper continental crust the part that is relatively accessible for measurements and estimation.\\r\\nMany of the elements shown in the graph are classified into (partially overlapping) categories:\\r\\nNote that there are two breaks where the unstable (radioactive) elements technetium (atomic number: 43) and promethium (atomic number: 61) would be. These elements are surrounded by stable elements, yet both have relatively short half lives (~ 4 million years and ~ 18 years respectively). These are thus extremely rare, since any primordial initial fractions of these in pre-Solar System materials have long since decayed and disappeared. These two elements are now only produced naturally through the spontaneous fission of very heavy radioactive elements (for example, uranium, thorium, or the trace amounts of plutonium that exist in uranium ores), or by the interaction of certain other elements with cosmic rays. Both technetium and promethium have been identified spectroscopically in the atmospheres of stars, where they are produced by ongoing nucleosynthetic processes.\\r\\nThere are also breaks in the abundance graph where the six noble gases would be, since they are not chemically bound in the Earth's crust, and they are only generated by decay chains from radioactive elements in the crust, and are therefore extremely rare there.\\r\\nThe eight naturally occurring very rare, highly radioactive elements (polonium, astatine, francium, radium, actinium, protactinium, neptunium, and plutonium) are not included, since any of these elements that were present at the formation of the Earth have decayed away eons ago, and their quantity today is negligible and is only produced from the radioactive decay of uranium and thorium.\\r\\nOxygen and silicon are notably the most common elements in the crust. On Earth and in rocky planets in general, silicon and oxygen are far more common than their cosmic abundance. The reason is that they combine with each other to form silicate minerals. In this way, they are the lightest of all of the two-percent \\"astronomical metals\\" (i.e., non-hydrogen and helium elements) to form a solid that is refractory to the Sun's heat, and thus cannot boil away into space. All elements lighter than oxygen have been removed from the crust in this way.\\r\\n\\"Rare\\" earth elements is a historical misnomer. The persistence of the term reflects unfamiliarity rather than true rarity. The more abundant rare earth elements are similarly concentrated in the crust compared to commonplace industrial metals such as chromium, nickel, copper, zinc, molybdenum, tin, tungsten, or lead. The two least abundant rare earth elements (thulium and lutetium) are nearly 200 times more common than gold. However, in contrast to the ordinary base and precious metals, rare earth elements have very little tendency to become concentrated in exploitable ore deposits. Consequently, most of the world's supply of rare earth elements comes from only a handful of sources. Furthermore, the rare earth metals are all quite chemically similar to each other, and they are thus quite difficult to separate into quantities of the pure elements.\\r\\nDifferences in abundances of individual rare earth elements in the upper continental crust of the Earth represent the superposition of two effects, one nuclear and one geochemical. First, the rare earth elements with even atomic numbers (58Ce, 60Nd, ...) have greater cosmic and terrestrial abundances than the adjacent rare earth elements with odd atomic numbers (57La, 59Pr, ...). Second, the lighter rare earth elements are more incompatible (because they have larger ionic radii) and therefore more strongly concentrated in the continental crust than the heavier rare earth elements. In most rare earth ore deposits, the first four rare earth elements ÿ lanthanum, cerium, praseodymium, and neodymium ÿ constitute 80% to 99% of the total amount of rare earth metal that can be found in the ore.\\r\\nThe mass-abundance of the eight most abundant elements in the Earth's mantle (see main article above) is approximately: oxygen 45%, magnesium 23%, silicon 22%, iron 5.8%, calcium 2.3%, aluminum 2.2%, sodium 0.3%, potassium 0.3%.\\r\\nThe mantle differs in elemental composition from the crust in having a great deal more magnesium and significantly more iron, while having much less aluminum and sodium.\\r\\nDue to mass segregation, the core of the Earth is believed to be primarily composed of iron (88.8%), with smaller amounts of nickel (5.8%), sulfur (4.5%), and less than 1% trace elements.[12]\\r\\nThe most abundant elements in the ocean by proportion of mass in percent are oxygen (85.84), hydrogen (10.82), chlorine (1.94), sodium (1.08), magnesium (0.1292), sulfur (0.091), calcium (0.04), potassium (0.04), bromine (0.0067), carbon (0.0028), and boron (0.00043).\\r\\nThe order of elements by volume-fraction (which is approximately molecular mole-fraction) in the atmosphere is nitrogen (78.1%), oxygen (20.9%),[14] argon (0.96%), followed by (in uncertain order) carbon and hydrogen because water vapor and carbon dioxide, which represent most of these two elements in the air, are variable components. Sulfur, phosphorus, and all other elements are present in significantly lower proportions.\\r\\nAccording to the abundance curve graph (above right), argon, a significant if not major component of the atmosphere, does not appear in the crust at all. This is because the atmosphere has a far smaller mass than the crust, so argon remaining in the crust contributes little to mass-fraction there, while at the same time buildup of argon in the atmosphere has become large enough to be significant.\\r\\nFor a complete list of the abundance of elements in urban soils, see Abundances of the elements (data page)#Urban soils.\\r\\nBy mass, human cells consist of 65ÿ90% water (H2O), and a significant portion of the remainder is composed of carbon-containing organic molecules. Oxygen therefore contributes a majority of a human body's mass, followed by carbon. Almost 99% of the mass of the human body is made up of six elements: oxygen, carbon, hydrogen, nitrogen, calcium, and phosphorus. The next 0.75% is made up of the next five elements: potassium, sulfur, chlorine, sodium, and magnesium. Only 17 elements are known for certain to be necessary to human life, with one additional element (fluorine) thought to be helpful for tooth enamel strength. A few more trace elements may play some role in the health of mammals. Boron and silicon are notably necessary for plants but have uncertain roles in animals. The elements aluminium and silicon, although very common in the earth's crust, are conspicuously rare in the human body.[15]\\r\\nBelow is a periodic table highlighting nutritional elements.[16]","input":"What is the most common element in our air?"},{"output":"11 January 1896","context":"X-rays make up X-radiation, a form of electromagnetic radiation. Most X-rays have a wavelength ranging from 0.01 to 10 nanometers, corresponding to frequencies in the range 30 petahertz to 30 exahertz (3G1016 Hz to 3G1019 Hz) and energies in the range 100 eV to 100 keV. X-ray wavelengths are shorter than those of UV rays and typically longer than those of gamma rays. In many languages, X-radiation is referred to with terms meaning R?ntgen radiation, after the German scientist Wilhelm R?ntgen,[1] who usually is credited as its discoverer, and who had named it X-radiation to signify an unknown type of radiation.[2] Spelling of X-ray(s) in the English language includes the variants x-ray(s), xray(s), and X ray(s).[3]\\r\\n\\r\\n\\r\\nX-rays with high photon energies (above 5ÿ10 keV, below 0.2ÿ0.1?nm wavelength) are called hard X-rays, while those with lower energy are called soft X-rays.[4] Due to their penetrating ability, hard X-rays are widely used to image the inside of objects, e.g., in medical radiography and airport security. The term X-ray is metonymically used to refer to a radiographic image produced using this method, in addition to the method itself. Since the wavelengths of hard X-rays are similar to the size of atoms they are also useful for determining crystal structures by X-ray crystallography. By contrast, soft X-rays are easily absorbed in air; the attenuation length of 600 eV (~2?nm) X-rays in water is less than 1 micrometer.[5]\\r\\nThere is no consensus for a definition distinguishing between X-rays and gamma rays. One common practice is to distinguish between the two types of radiation based on their source: X-rays are emitted by electrons, while gamma rays are emitted by the atomic nucleus.[6][7][8][9] This definition has several problems: other processes also can generate these high-energy photons, or sometimes the method of generation is not known. One common alternative is to distinguish X- and gamma radiation on the basis of wavelength (or, equivalently, frequency or photon energy), with radiation shorter than some arbitrary wavelength, such as 10?11 m (0.1 ?), defined as gamma radiation.[10] This criterion assigns a photon to an unambiguous category, but is only possible if wavelength is known. (Some measurement techniques do not distinguish between detected wavelengths.) However, these two definitions often coincide since the electromagnetic radiation emitted by X-ray tubes generally has a longer wavelength and lower photon energy than the radiation emitted by radioactive nuclei.[6] Occasionally, one term or the other is used in specific contexts due to historical precedent, based on measurement (detection) technique, or based on their intended use rather than their wavelength or source. Thus, gamma-rays generated for medical and industrial uses, for example radiotherapy, in the ranges of 6ÿ20 MeV, can in this context also be referred to as X-rays.[citation needed]\\r\\nX-ray photons carry enough energy to ionize atoms and disrupt molecular bonds. This makes it a type of ionizing radiation, and therefore harmful to living tissue. A very high radiation dose over a short period of time causes radiation sickness, while lower doses can give an increased risk of radiation-induced cancer. In medical imaging this increased cancer risk is generally greatly outweighed by the benefits of the examination. The ionizing capability of X-rays can be utilized in cancer treatment to kill malignant cells using radiation therapy. It is also used for material characterization using X-ray spectroscopy.\\r\\nHard X-rays can traverse relatively thick objects without being much absorbed or scattered. For this reason, X-rays are widely used to image the inside of visually opaque objects. The most often seen applications are in medical radiography and airport security scanners, but similar techniques are also important in industry (e.g. industrial radiography and industrial CT scanning) and research (e.g. small animal CT). The penetration depth varies with several orders of magnitude over the X-ray spectrum. This allows the photon energy to be adjusted for the application so as to give sufficient transmission through the object and at the same time provide good contrast in the image.\\r\\nX-rays have much shorter wavelengths than visible light, which makes it possible to probe structures much smaller than can be seen using a normal microscope. This property is used in X-ray microscopy to acquire high resolution images, and also in X-ray crystallography to determine the positions of atoms in crystals.\\r\\nX-rays interact with matter in three main ways, through photoabsorption, Compton scattering, and Rayleigh scattering. The strength of these interactions depends on the energy of the X-rays and the elemental composition of the material, but not much on chemical properties, since the X-ray photon energy is much higher than chemical binding energies. Photoabsorption or photoelectric absorption is the dominant interaction mechanism in the soft X-ray regime and for the lower hard X-ray energies. At higher energies, Compton scattering dominates.\\r\\nThe probability of a photoelectric absorption per unit mass is approximately proportional to Z3/E3, where Z is the atomic number and E is the energy of the incident photon.[11] This rule is not valid close to inner shell electron binding energies where there are abrupt changes in interaction probability, so called absorption edges. However, the general trend of high absorption coefficients and thus short penetration depths for low photon energies and high atomic numbers is very strong. For soft tissue, photoabsorption dominates up to about 26 keV photon energy where Compton scattering takes over. For higher atomic number substances this limit is higher. The high amount of calcium (Z=20) in bones together with their high density is what makes them show up so clearly on medical radiographs.\\r\\nA photoabsorbed photon transfers all its energy to the electron with which it interacts, thus ionizing the atom to which the electron was bound and producing a photoelectron that is likely to ionize more atoms in its path. An outer electron will fill the vacant electron position and produce either a characteristic photon[clarification needed] or an Auger electron. These effects can be used for elemental detection through X-ray spectroscopy or Auger electron spectroscopy.\\r\\nCompton scattering is the predominant interaction between X-rays and soft tissue in medical imaging.[12] Compton scattering is an inelastic scattering of the X-ray photon by an outer shell electron. Part of the energy of the photon is transferred to the scattering electron, thereby ionizing the atom and increasing the wavelength of the X-ray. The scattered photon can go in any direction, but a direction similar to the original direction is more likely, especially for high-energy X-rays. The probability for different scattering angles are described by the KleinÿNishina formula. The transferred energy can be directly obtained from the scattering angle from the conservation of energy and momentum.\\r\\nRayleigh scattering is the dominant elastic scattering mechanism in the X-ray regime.[13] Inelastic forward scattering gives rise to the refractive index, which for X-rays is only slightly below 1.[14]\\r\\nWhenever charged particles (electrons or ions) of sufficient energy hit a material, X-rays are produced.\\r\\nX-rays can be generated by an X-ray tube, a vacuum tube that uses a high voltage to accelerate the electrons released by a hot cathode to a high velocity. The high velocity electrons collide with a metal target, the anode, creating the X-rays.[17] In medical X-ray tubes the target is usually tungsten or a more crack-resistant alloy of rhenium (5%) and tungsten (95%), but sometimes molybdenum for more specialized applications, such as when softer X-rays are needed as in mammography. In crystallography, a copper target is most common, with cobalt often being used when fluorescence from iron content in the sample might otherwise present a problem.\\r\\nThe maximum energy of the produced X-ray photon is limited by the energy of the incident electron, which is equal to the voltage on the tube times the electron charge, so an 80?kV tube cannot create X-rays with an energy greater than 80?keV. When the electrons hit the target, X-rays are created by two different atomic processes:\\r\\nSo the resulting output of a tube consists of a continuous bremsstrahlung spectrum falling off to zero at the tube voltage, plus several spikes at the characteristic lines. The voltages used in diagnostic X-ray tubes range from roughly 20 kV to 150 kV and thus the highest energies of the X-ray photons range from roughly 20 keV to 150 keV.[18]\\r\\nBoth of these X-ray production processes are inefficient, with a production efficiency of only about one percent, and thus most of the electric power consumed by the tube is released as waste heat. When producing a usable flux of X-rays, the X-ray tube must be designed to dissipate the excess heat.\\r\\nShort nanosecond bursts of X-rays peaking at 15-keV in energy may be reliably produced by peeling pressure-sensitive adhesive tape from its backing in a moderate vacuum. This is likely to be the result of recombination of electrical charges produced by triboelectric charging. The intensity of X-ray triboluminescence is sufficient for it to be used as a source for X-ray imaging.[19]\\r\\nA specialized source of X-rays which is becoming widely used in research is synchrotron radiation, which is generated by particle accelerators. Its unique features are X-ray outputs many orders of magnitude greater than those of X-ray tubes, wide X-ray spectra, excellent collimation, and linear polarization.[20]\\r\\nX-rays can also be produced by fast protons or other positive ions. The proton-induced X-ray emission or particle-induced X-ray emission is widely used as an analytical procedure. For high energies, the production cross section is proportional to Z12Z2?4, where Z1 refers to the atomic number of the ion, Z2 to that of the target atom.[21] An overview of these cross sections is given in the same reference.\\r\\nX-ray detectors vary in shape and function depending on their purpose. Imaging detectors such as those used for radiography were originally based on photographic plates and later photographic film, but are now mostly replaced by various digital detector types such as image plates and flat panel detectors. For radiation protection direct exposure hazard is often evaluated using ionization chambers, while dosimeters are used to measure the radiation dose a person has been exposed to. X-ray spectra can be measured either by energy dispersive or wavelength dispersive spectrometers.\\r\\nSince R?ntgen's discovery that X-rays can identify bone structures, X-rays have been used for medical imaging. The first medical use was less than a month after his paper on the subject.[22] Up to 2010, 5?billion medical imaging examinations had been conducted worldwide.[23] Radiation exposure from medical imaging in 2006 made up about 50% of total ionizing radiation exposure in the United States.[24]\\r\\nProjectional radiography is the practice of producing two-dimensional images using x-ray radiation. Bones contain much calcium, which due to its relatively high atomic number absorbs x-rays efficiently. This reduces the amount of X-rays reaching the detector in the shadow of the bones, making them clearly visible on the radiograph. The lungs and trapped gas also show up clearly because of lower absorption compared to tissue, while differences between tissue types are harder to see.\\r\\nProjectional radiographs are useful in the detection of pathology of the skeletal system as well as for detecting some disease processes in soft tissue. Some notable examples are the very common chest X-ray, which can be used to identify lung diseases such as pneumonia, lung cancer, or pulmonary edema, and the abdominal x-ray, which can detect bowel (or intestinal) obstruction, free air (from visceral perforations) and free fluid (in ascites). X-rays may also be used to detect pathology such as gallstones (which are rarely radiopaque) or kidney stones which are often (but not always) visible. Traditional plain X-rays are less useful in the imaging of soft tissues such as the brain or muscle.\\r\\nDental radiography is commonly used in the diagnoses of common oral problems, such as cavities.\\r\\nIn medical diagnostic applications, the low energy (soft) X-rays are unwanted, since they are totally absorbed by the body, increasing the radiation dose without contributing to the image. Hence, a thin metal sheet, often of aluminium, called an X-ray filter, is usually placed over the window of the X-ray tube, absorbing the low energy part in the spectrum. This is called hardening the beam since it shifts the center of the spectrum towards higher energy (or harder) x-rays.\\r\\nTo generate an image of the cardiovascular system, including the arteries and veins (angiography) an initial image is taken of the anatomical region of interest. A second image is then taken of the same region after an iodinated contrast agent has been injected into the blood vessels within this area. These two images are then digitally subtracted, leaving an image of only the iodinated contrast outlining the blood vessels. The radiologist or surgeon then compares the image obtained to normal anatomical images to determine whether there is any damage or blockage of the vessel.\\r\\nComputed tomography (CT scanning) is a medical imaging modality where tomographic images or slices of specific areas of the body are obtained from a large series of two-dimensional X-ray images taken in different directions.[25] These cross-sectional images can be combined into a three-dimensional image of the inside of the body and used for diagnostic and therapeutic purposes in various medical disciplines.\\r\\nFluoroscopy is an imaging technique commonly used by physicians or radiation therapists to obtain real-time moving images of the internal structures of a patient through the use of a fluoroscope. In its simplest form, a fluoroscope consists of an X-ray source and a fluorescent screen, between which a patient is placed. However, modern fluoroscopes couple the screen to an X-ray image intensifier and CCD video camera allowing the images to be recorded and played on a monitor. This method may use a contrast material. Examples include cardiac catheterization (to examine for coronary artery blockages) and barium swallow (to examine for esophageal disorders).\\r\\nThe use of X-rays as a treatment is known as radiation therapy and is largely used for the management (including palliation) of cancer; it requires higher radiation doses than those received for imaging alone. X-rays beams are used for treating skin cancers using lower energy x-ray beams while higher energy beams are used for treating cancers within the body such as brain, lung, prostate, and breast.[26][27]\\r\\nDiagnostic X-rays (primarily from CT scans due to the large dose used) increase the risk of developmental problems and cancer in those exposed.[28][29][30] X-rays are classified as a carcinogen by both the World Health Organization's International Agency for Research on Cancer and the U.S. government.[23][31] It is estimated that 0.4% of current cancers in the United States are due to computed tomography (CT scans) performed in the past and that this may increase to as high as 1.5-2% with 2007 rates of CT usage.[32]\\r\\nExperimental and epidemiological data currently do not support the proposition that there is a threshold dose of radiation below which there is no increased risk of cancer.[33] However, this is under increasing doubt.[34] It is estimated that the additional radiation will increase a person's cumulative risk of getting cancer by age 75 by 0.6ÿ1.8%.[35] The amount of absorbed radiation depends upon the type of X-ray test and the body part involved.[36] CT and fluoroscopy entail higher doses of radiation than do plain X-rays.\\r\\nTo place the increased risk in perspective, a plain chest X-ray will expose a person to the same amount from background radiation that people are exposed to (depending upon location) every day over 10 days, while exposure from a dental X-ray is approximately equivalent to 1 day of environmental background radiation.[37] Each such X-ray would add less than 1 per 1,000,000 to the lifetime cancer risk. An abdominal or chest CT would be the equivalent to 2ÿ3 years of background radiation to the whole body, or 4ÿ5 years to the abdomen or chest, increasing the lifetime cancer risk between 1 per 1,000 to 1 per 10,000.[37] This is compared to the roughly 40% chance of a US citizen developing cancer during their lifetime.[38] For instance, the effective dose to the torso from a CT scan of the chest is about 5 mSv, and the absorbed dose is about 14 mGy.[39] A head CT scan (1.5mSv, 64mGy)[40] that is performed once with and once without contrast agent, would be equivalent to 40 years of background radiation to the head. Accurate estimation of effective doses due to CT is difficult with the estimation uncertainty range of about I19% to I32% for adult head scans depending upon the method used.[41]\\r\\nThe risk of radiation is greater to a fetus, so in pregnant patients, the benefits of the investigation (X-ray) should be balanced with the potential hazards to the fetus.[42][43] In the US, there are an estimated 62?million CT scans performed annually, including more than 4?million on children.[36] Avoiding unnecessary X-rays (especially CT scans) reduces radiation dose and any associated cancer risk.[44]\\r\\nMedical X-rays are a significant source of man-made radiation exposure. In 1987, they accounted for 58% of exposure from man-made sources in the United States. Since man-made sources accounted for only 18% of the total radiation exposure, most of which came from natural sources (82%), medical X-rays only accounted for 10% of total American radiation exposure; medical procedures as a whole (including nuclear medicine) accounted for 14% of total radiation exposure. By 2006, however, medical procedures in the United States were contributing much more ionizing radiation than was the case in the early 1980s. In 2006, medical exposure constituted nearly half of the total radiation exposure of the U.S. population from all sources. The increase is traceable to the growth in the use of medical imaging procedures, in particular computed tomography (CT), and to the growth in the use of nuclear medicine.[24][45]\\r\\nDosage due to dental X-rays varies significantly depending on the procedure and the technology (film or digital). Depending on the procedure and the technology, a single dental X-ray of a human results in an exposure of 0.5 to 4 mrem. A full mouth series of X-rays may result in an exposure of up to 6 (digital) to 18 (film) mrem, for a yearly average of up to 40 mrem.[46][47][48][49][50][51][52]\\r\\nOther notable uses of X-rays include\\r\\nGerman physicist Wilhelm R?ntgen is usually credited as the discoverer of X-rays in 1895, because he was the first to systematically study them, though he is not the first to have observed their effects. He is also the one who gave them the name \\"X-rays\\" (signifying an unknown quantity[57]) though many others referred to these as \\"R?ntgen rays\\" (and the associated X-ray radiograms as, \\"R?ntgenograms\\") for several decades after their discovery and even to this day in some languages, including R?ntgen's native German.\\r\\nX-rays were found emanating from Crookes tubes, experimental discharge tubes invented around 1875, by scientists investigating the cathode rays, that is energetic electron beams, that were first created in the tubes. Crookes tubes created free electrons by ionization of the residual air in the tube by a high DC voltage of anywhere between a few kilovolts and 100 kV. This voltage accelerated the electrons coming from the cathode to a high enough velocity that they created X-rays when they struck the anode or the glass wall of the tube. Many of the early Crookes tubes undoubtedly radiated X-rays, because early researchers noticed effects that were attributable to them, as detailed below. Wilhelm R?ntgen was the first to systematically study them, in 1895.[60]\\r\\nThe discovery of X-rays stimulated a veritable sensation. R?ntgen's biographer Otto Glasser estimated that, in 1896 alone, as many as 49 essays and 1044 articles about the new rays were published.[61] This was probably a conservative estimate, if one considers that nearly every paper around the world extensively reported about the new discovery, with a magazine such as Science dedicating as many as 23 articles to it in that year alone.[62] Sensationalist reactions to the new discovery included publications linking the new kind of rays to occult and paranormal theories, such as telepathy.[63][64]\\r\\nThe earliest known experimenter with X-rays was actuary William Morgan. In 1785 he presented a paper to the Royal Society of London describing the effects of passing electrical currents through a partially evacuated glass tube, the first X-ray tube.[65] This work was further extended by Humphry Davy and his assistant Michael Faraday.\\r\\nIn 1876, Eugen Goldstein proved that they came from the cathode, and named them cathode rays (Kathodenstrahlen).[66] Both William Crookes (in the 1880s)[67] and German physicist Johann Hittorf,[68] a co-inventor and early researcher of the Crookes tube, found that paper wrapped photographic plates placed near the tube became unaccountably fogged or flawed by shadows, although they had not been exposed to light. Neither found the cause nor investigated this effect.\\r\\nIn 1877 Ukrainian-born Ivan Pulyui, a lecturer in experimental physics at the University of Vienna, constructed various designs of vacuum discharge tube to investigate their properties.[69] He continued his investigations when appointed professor at the Prague Polytechnic and in 1886 he found that sealed photographic plates became dark when exposed to the emanations from the tubes. Early in 1896, just a few weeks after R?ntgen published his first X-ray photograph, Pulyui published high-quality X-ray images in journals in Paris and London.[69] Although Pulyui had studied with R?ntgen at the University of Strasbourg in the years 1873ÿ75, his biographer Gaida (1997) asserts that his subsequent research was conducted independently.[69]\\r\\nX-rays were generated and detected by Fernando Sanford (1854ÿ1948), the foundation Professor of Physics at Stanford University, in 1891. From 1886 to 1888 he had studied in the Hermann Helmholtz laboratory in Berlin, where he became familiar with the cathode rays generated in vacuum tubes when a voltage was applied across separate electrodes, as previously studied by Heinrich Hertz and Philipp Lenard. His letter of January 6, 1893 (describing his discovery as \\"electric photography\\") to The Physical Review was duly published and an article entitled Without Lens or Light, Photographs Taken With Plate and Object in Darkness appeared in the San Francisco Examiner.[70]\\r\\nStarting in 1888, Philipp Lenard, a student of Heinrich Hertz, conducted experiments to see whether cathode rays could pass out of the Crookes tube into the air. He built a Crookes tube (later called a \\"Lenard tube\\") with a \\"window\\" in the end made of thin aluminum, facing the cathode so the cathode rays would strike it. He found that something came through, that would expose photographic plates and cause fluorescence. He measured the penetrating power of these rays through various materials. It has been suggested that at least some of these \\"Lenard rays\\" were actually X-rays.[71]\\r\\nHermann von Helmholtz formulated mathematical equations for X-rays. He postulated a dispersion theory before R?ntgen made his discovery and announcement. It was formed on the basis of the electromagnetic theory of light.[72] However, he did not work with actual X-rays.\\r\\nIn 1894 Nikola Tesla noticed damaged film in his lab that seemed to be associated with Crookes tube experiments and began investigating this radiant energy of \\"invisible\\" kinds.[73][74] After R?ntgen identified the X-ray Tesla began making X-ray images of his own using high voltages and tubes of his own design,[75] as well as Crookes tubes.\\r\\nOn November 8, 1895, German physics professor Wilhelm R?ntgen stumbled on X-rays while experimenting with Lenard and Crookes tubes and began studying them. He wrote an initial report \\"On a new kind of ray: A preliminary communication\\" and on December 28, 1895 submitted it to Wrzburg's Physical-Medical Society journal.[76] This was the first paper written on X-rays. R?ntgen referred to the radiation as \\"X\\", to indicate that it was an unknown type of radiation. The name stuck, although (over R?ntgen's great objections) many of his colleagues suggested calling them R?ntgen rays. They are still referred to as such in many languages, including German, Danish, Polish, Swedish, Finnish, Estonian, Russian, Japanese, Dutch, and Norwegian. R?ntgen received the first Nobel Prize in Physics for his discovery.[77]\\r\\nThere are conflicting accounts of his discovery because R?ntgen had his lab notes burned after his death, but this is a likely reconstruction by his biographers:[78][79] R?ntgen was investigating cathode rays from a Crookes tube which he had wrapped in black cardboard so that the visible light from the tube would not interfere, using a fluorescent screen painted with barium platinocyanide. He noticed a faint green glow from the screen, about 1 meter away. R?ntgen realized some invisible rays coming from the tube were passing through the cardboard to make the screen glow. He found they could also pass through books and papers on his desk. R?ntgen threw himself into investigating these unknown rays systematically. Two months after his initial discovery, he published his paper.[citation needed]\\r\\nR?ntgen discovered their medical use when he made a picture of his wife's hand on a photographic plate formed due to X-rays. The photograph of his wife's hand was the first photograph of a human body part using X-rays. When she saw the picture, she said \\"I have seen my death.\\"[80]\\r\\nIn 1895, Thomas Edison investigated materials' ability to fluoresce when exposed to X-rays, and found that calcium tungstate was the most effective substance. Around March 1896, the fluoroscope he developed became the standard for medical X-ray examinations. Nevertheless, Edison dropped X-ray research around 1903, even before the death of Clarence Madison Dally, one of his glassblowers. Dally had a habit of testing X-ray tubes on his hands, and acquired a cancer in them so tenacious that both arms were amputated in a futile attempt to save his life.\\r\\nThe first use of X-rays under clinical conditions was by John Hall-Edwards in Birmingham, England on 11 January 1896, when he radiographed a needle stuck in the hand of an associate.[81] On 14 February 1896 Hall-Edwards was also the first to use X-rays in a surgical operation.[82] In early 1896, several weeks after R?ntgen's discovery, Ivan Romanovich Tarkhanov irradiated frogs and insects with X-rays, concluding that the rays \\"not only photograph, but also affect the living function\\".[83]\\r\\nThe first medical X-ray made in the United States was obtained using a discharge tube of Pulyui's design. In January 1896, on reading of R?ntgen's discovery, Frank Austin of Dartmouth College tested all of the discharge tubes in the physics laboratory and found that only the Pulyui tube produced X-rays. This was a result of Pulyui's inclusion of an oblique \\"target\\" of mica, used for holding samples of fluorescent material, within the tube. On 3 February 1896 Gilman Frost, professor of medicine at the college, and his brother Edwin Frost, professor of physics, exposed the wrist of Eddie McCarthy, whom Gilman had treated some weeks earlier for a fracture, to the X-rays and collected the resulting image of the broken bone on gelatin photographic plates obtained from Howard Langill, a local photographer also interested in R?ntgen's work.[22]\\r\\nIn 1901, U.S. President William McKinley was shot twice in an assassination attempt. While one bullet only grazed his sternum, another had lodged somewhere deep inside his abdomen and could not be found. \\"A worried McKinley aide sent word to inventor Thomas Edison to rush an X-ray machine to Buffalo to find the stray bullet. It arrived but wasn't used.\\" While the shooting itself had not been lethal, \\"gangrene had developed along the path of the bullet, and McKinley died of septic shock due to bacterial infection\\" six days later.[84]\\r\\nWith the widespread experimentation with x?rays after their discovery in 1895 by scientists, physicians, and inventors came many stories of burns, hair loss, and worse in technical journals of the time. In February 1896, Professor John Daniel and Dr. William Lofland Dudley of Vanderbilt University reported hair loss after Dr. Dudley was X-rayed. A child who had been shot in the head was brought to the Vanderbilt laboratory in 1896. Before trying to find the bullet an experiment was attempted, for which Dudley \\"with his characteristic devotion to science\\"[85][86][87] volunteered. Daniel reported that 21 days after taking a picture of Dudley's skull (with an exposure time of one hour), he noticed a bald spot 2 inches (5.1?cm) in diameter on the part of his head nearest the X-ray tube: \\"A plate holder with the plates towards the side of the skull was fastened and a coin placed between the skull and the head. The tube was fastened at the other side at a distance of one-half inch from the hair.\\"[88]\\r\\nIn August 1896 Dr. HD. Hawks, a graduate of Columbia College, suffered severe hand and chest burns from an x-ray demonstration. It was reported in Electrical Review and led to many other reports of problems associated with x-rays being sent in to the publication.[89] Many experimenters including Elihu Thomson at Edison's lab, William J. Morton, and Nikola Tesla also reported burns. Elihu Thomson deliberately exposed a finger to an x-ray tube over a period of time and suffered pain, swelling, and blistering.[90] Other effects were sometimes blamed for the damage including ultraviolet rays and (according to Tesla) ozone.[91] Many physicians claimed there were no effects from x-ray exposure at all.[90] On 3 August 1905 at San Francisco, California, Elizabeth Fleischman, American woman X-ray pioneer, died from complications as a result of her work with X-rays.[92][93][94]\\r\\nThe many applications of X-rays immediately generated enormous interest. Workshops began making specialized versions of Crookes tubes for generating X-rays and these first-generation cold cathode or Crookes X-ray tubes were used until about 1920.\\r\\nCrookes tubes were unreliable. They had to contain a small quantity of gas (invariably air) as a current will not flow in such a tube if they are fully evacuated. However, as time passed, the X-rays caused the glass to absorb the gas, causing the tube to generate \\"harder\\" X-rays until it soon stopped operating. Larger and more frequently used tubes were provided with devices for restoring the air, known as \\"softeners\\". These often took the form of a small side tube which contained a small piece of mica, a mineral that traps relatively large quantities of air within its structure. A small electrical heater heated the mica, causing it to release a small amount of air, thus restoring the tube's efficiency. However, the mica had a limited life, and the restoration process was difficult to control.\\r\\nIn 1904, John Ambrose Fleming invented the thermionic diode, the first kind of vacuum tube. This used a hot cathode that caused an electric current to flow in a vacuum. This idea was quickly applied to X-ray tubes, and hence heated-cathode X-ray tubes, called \\"Coolidge tubes\\", completely replaced the troublesome cold cathode tubes by about 1920.\\r\\nIn about 1906, the physicist Charles Barkla discovered that X-rays could be scattered by gases, and that each element had a characteristic X-ray spectrum. He won the 1917 Nobel Prize in Physics for this discovery.\\r\\nIn 1912, Max von Laue, Paul Knipping, and Walter Friedrich first observed the diffraction of X-rays by crystals. This discovery, along with the early work of Paul Peter Ewald, William Henry Bragg, and William Lawrence Bragg, gave birth to the field of X-ray crystallography.\\r\\nThe Coolidge X-ray tube was invented during the following year by William D. Coolidge. It made possible the continuous emissions of X-rays. X-ray tubes similar to this are still in use in 2012.\\r\\nThe use of X-rays for medical purposes (which developed into the field of radiation therapy) was pioneered by Major John Hall-Edwards in Birmingham, England. Then in 1908, he had to have his left arm amputated because of the spread of X-ray dermatitis on his arm.[95]\\r\\nThe X-ray microscope was developed during the 1950s.\\r\\nThe Chandra X-ray Observatory, launched on July 23, 1999, has been allowing the exploration of the very violent processes in the universe which produce X-rays. Unlike visible light, which gives a relatively stable view of the universe, the X-ray universe is unstable. It features stars being torn apart by black holes, galactic collisions, and novae, and neutron stars that build up layers of plasma that then explode into space.\\r\\nAn X-ray laser device was proposed as part of the Reagan Administration's Strategic Defense Initiative in the 1980s, but the only test of the device (a sort of laser \\"blaster\\" or death ray, powered by a thermonuclear explosion) gave inconclusive results. For technical and political reasons, the overall project (including the X-ray laser) was de-funded (though was later revived by the second Bush Administration as National Missile Defense using different technologies).\\r\\nPhase-contrast X-ray imaging refers to a variety of techniques that use phase information of a coherent x-ray beam to image soft tissues. It has become an important method for visualizing cellular and histological structures in a wide range of biological and medical studies. There are several technologies being used for x-ray phase-contrast imaging, all utilizing different principles to convert phase variations in the x-rays emerging from an object into intensity variations.[96][97] These include propagation-based phase contrast,[98] talbot interferometry,[97] refraction-enhanced imaging,[99] and x-ray interferometry.[100] These methods provide higher contrast compared to normal absorption-contrast x-ray imaging, making it possible to see smaller details. A disadvantage is that these methods require more sophisticated equipment, such as synchrotron or microfocus x-ray sources, X-ray optics, and high resolution x-ray detectors.\\r\\nWhile generally considered invisible to the human eye, in special circumstances X-rays can be visible. Brandes, in an experiment a short time after R?ntgen's landmark 1895 paper, reported after dark adaptation and placing his eye close to an X-ray tube, seeing a faint \\"blue-gray\\" glow which seemed to originate within the eye itself.[101] Upon hearing this, R?ntgen reviewed his record books and found he too had seen the effect. When placing an X-ray tube on the opposite side of a wooden door R?ntgen had noted the same blue glow, seeming to emanate from the eye itself, but thought his observations to be spurious because he only saw the effect when he used one type of tube. Later he realized that the tube which had created the effect was the only one powerful enough to make the glow plainly visible and the experiment was thereafter readily repeatable. The knowledge that X-rays are actually faintly visible to the dark-adapted naked eye has largely been forgotten today; this is probably due to the desire not to repeat what would now be seen as a recklessly dangerous and potentially harmful experiment with ionizing radiation. It is not known what exact mechanism in the eye produces the visibility: it could be due to conventional detection (excitation of rhodopsin molecules in the retina), direct excitation of retinal nerve cells, or secondary detection via, for instance, X-ray induction of phosphorescence in the eyeball with conventional retinal detection of the secondarily produced visible light.\\r\\nThough X-rays are otherwise invisible, it is possible to see the ionization of the air molecules if the intensity of the X-ray beam is high enough. The beamline from the wiggler at the ID11 at the European Synchrotron Radiation Facility is one example of such high intensity.[102]\\r\\nThe measure of X-rays ionizing ability is called the exposure:\\r\\nHowever, the effect of ionizing radiation on matter (especially living tissue) is more closely related to the amount of energy deposited into them rather than the charge generated. This measure of energy absorbed is called the absorbed dose:\\r\\nThe equivalent dose is the measure of the biological effect of radiation on human tissue. For X-rays it is equal to the absorbed dose.","input":"When was the x ray first used in medicine?"},{"output":"University of Alabama","context":"Big Al is the costumed elephant mascot of the University of Alabama Crimson Tide in Tuscaloosa, Alabama.\\r\\n\\r\\n\\r\\nThe origin of the mascot according to Skip dates back to 1930. On October 8, 1930, a sportswriter for the Atlanta Journal, Everett Strupper, wrote about the previous weekend's Alabama-Ole Miss football game. He wrote, \\"That Alabama team of 1930 is a typical [Coach Wallace] Wade machine, powerful, big, tough, fast, aggressive, well-schooled in fundamentals, and the best blocking team for this early in the season that I have ever seen. When those big brutes hit you I mean you go down and stay down, often for an additional two minutes.\\"\\r\\nStrupper, using the flair for the dramatic common in sportswriting at the time, wrote, \\"At the end of the quarter, the earth started to tremble, there was a distant rumble that continued to grow. Some excited fan in the stands bellowed, 'Hold your horses, the elephants are coming!' and out stamped this Alabama varsity.\\"[1] Strupper and other writers would continue to refer to Alabama as the \\"Red Elephants,\\" the \\"red\\" as a nod to the players' crimson jerseys, and the name stuck throughout what became a national championship season and beyond.[1]\\r\\nDespite the nickname, it would be nearly five decades before Alabama recognized the animal as its official mascot. However, elephants featured prominently to gameday tradition long before this point. [2] Throughout the 1940s, for instance, the University kept a live elephant mascot named \\"Alamite\\" that was a regular sight on game days, and it would carry the year's Homecoming queen onto the field every year prior to kickoff at the Homecoming game.[3] By the 1950s, keeping a live elephant year-round proved to be too expensive for the university. Instead, the UA spirit committee started hiring elephants, often from traveling circuses passing through or by Tuscaloosa, for every homecoming.[3]\\r\\nIn the early 1960s, Melford Espey, Jr., then a student, was the first to wear an elephant head costume to portray the Crimson Tide's unofficial mascot. Espey later became a university administrator, and football coach Paul \\"Bear\\" Bryant asked him to take responsibility when student groups asked to resurrect the costumed mascot in the late 1970s.[4]\\r\\nThe mascot known as \\"Big Al\\" today was the brainchild of University of Alabama student Walt Tart. He was meeting with the homecoming chairman Ann Paige in 1979 as they were trying to come up with something different for the school's homecoming parade. He told Ann that several schools in the Southeastern Conference had obtained mascot costumes and proposed that the University of Alabama should get one as well. After contacting the University of Kentucky and a few other schools, Walt was able to discover that their mascots were designed and constructed by the Disney company. He contacted Disney and received a price quote for the design and construction of the elephant costume. Since funding for the mascot costume would have to come from the athletic department, Walt and Ann set up a meeting with Coach Bryant, as he was not only the football coach, but also the athletic director at the University. Bryant teased them about having an elephant on the field and the mess it would make. They assured him that it was just a person in an elephant costume and not a real one, to which the Coach gave a big grin and said he knew all along. He said he thought elephants were very smart but a little slow, but overall, the meeting went very well as Coach Bryant said they could have the funds for the elephant costume.\\r\\nThe \\"Big Al\\" mascot officially debuted at the 1980 Sugar Bowl, when the 1979 Alabama Crimson Tide football team defeated the Arkansas Razorbacks.[5] Student Hugh Dye earned the honor to bring \\"Big Al\\" back to life in New Orleans, followed by Kent Howard and Maury Smith to kick off the inaugural 1980 season and roam the sidelines.[6]\\r\\nBig Al celebrated his first year with Bear Bryant's 300th win against the Kentucky Wildcats and a victory against the Baylor Bears in the 1981 Cotton Bowl. Since then, the elephant mascot has been a fan favorite among Tide fans. As the Crimson Tide does not feature a prominent logo on their helmets or uniforms, Big Al's likeness appears on much of the merchandise.\\r\\nBig Al was named by a student vote. At the time of the vote, there was a popular DJ on campus by the name of Al Brown, who DJ'd many of the largest campus parties, including those hosted by members of the football team. As a result of DJ Al's popularity, a campaign was started on campus to name the mascot after him, and that campaign succeeded at the polls.\\r\\nEvery April during the weekend of the A-Day spring football game, there is a three-day tryout process for UA students who want to become Big Al. The first day consists of an interview and clinic, where the candidates learn to emulate the character and walk of Big Al. The second day consists of more clinic, as well as being judged on the walk and participating in a band cheer. Later that afternoon, the candidates come either prepared with a minute-and-a-half skit or they can make an impromptu one at tryouts. Each candidate performs their skits for a score, and then there is a final cut before A-Day. Whoever makes the final cut is invited to A-Day for the final tryout, which consists of a field walk before the game. This is where they are scored for going in public in a non-athletic event setting and interacting with the public. After this, they perform for 10-15 minutes each during the game, mimicking a normal gameday atmosphere. The final announcement of the next year's mascot team happens immediately following the spring game.[7]\\r\\nWhile allowed to do some planned photo-ops with other mascots (such as Aubie from archrival Auburn University), Big Al, as per University rule, is generally not allowed to interact on the field with opponent mascots. This is due to an incident in 2002 that took place between Big Al and Seymour from Southern Miss during a game in Tuscaloosa. A \\"fight\\" was scripted before the game, in which the rules were that Big Al loses the fight in front of the visitors section, and Big Al dominates in front of his student section.[7] The scripted fight suddenly turned unscripted after Seymour deviated from the set rules, and a raucous fight on the sidelines between the two ensued.[8]\\r\\nBig Al is sometimes joined by a female counterpart, an elephant named \\"Big Alice,\\" at athletics events.[9]","input":"What college football team has an elephant mascot?"},{"output":"briefly during the Civil War","context":"The history of taxation in the United States begins with the colonial protest against British taxation policy in the 1760s, leading to the American Revolution. The independent nation collected taxes on imports (\\"tariffs\\"), whiskey, and (for a while) on glass windows. States and localities collected poll taxes on voters and property taxes on land and commercial buildings. There are state and federal excise taxes. State and federal inheritance taxes began after 1900, while the states (but not the federal government) began collecting sales taxes in the 1930s. The United States imposed income taxes briefly during the Civil War and the 1890s. In 1913, the 16th amendment was ratified.\\r\\n\\r\\n\\r\\nTaxes were low at the local, colonial and imperial levels throughout the colonial era.[1] The issue that led to the Revolution was whether parliament had the right to impose taxes on the Americans when they were not represented in parliament.\\r\\nThe Stamp Act of 1765 was the fourth Stamp Act to be passed by the Parliament of Great Britain and required all legal documents, permits, commercial contracts, newspapers, wills, pamphlets, and playing cards in the American colonies to carry a tax stamp. The exact date the Act was enacted was on November 1, 1765. The Act was enacted in order to defray the cost of maintaining the military presence protecting the colonies. Americans rose up in strong protest, arguing in terms of \\"No Taxation without Representation\\". Boycotts forced Britain to repeal the stamp tax, while convincing many British leaders it was essential to tax the colonists on something in order to demonstrate the sovereignty of Parliament.\\r\\nThe Townshend Revenue Act were two tax laws passed by Parliament in 1767; they were proposed by Charles Townshend, Chancellor of the Exchequer. They placed a tax on common products imported into the American Colonies, such as lead, paper, paint, glass, and tea. In contrast to the Stamp Act of 1765, the laws were not a direct tax that people paid daily, but a tax on imports that was collected from the ship's captain when he unloaded the cargo. The Townshend Acts also created three new admiralty courts to try Americans who ignored the laws.[2]\\r\\nThe tax on sugar, cloth and coffee. These were non-British exports.\\r\\nThe Tea Act of 1773 received the royal assent on May 10, 1773. This act was a \\"drawback on duties and tariffs\\" on tea. The act was designed to undercut tea smugglers to the benefit of the East India Company.\\r\\nThe Boston Tea Party was an act of protest by the American colonists against Great Britain for the Tea Act in which they dumped many chests of tea into Boston Harbor. The cuts to taxation on tea undermined American smugglers, who destroyed the tea in retaliation for its exemption from taxes. Britain reacted harshly, and the conflict escalated to war in 1775.\\r\\nAn assessment levied by the government upon a person at a fixed rate regardless of income or worth.\\r\\nTariffs have played different roles in trade policy and the economic history of the United States. Tariffs were the largest source of federal revenue from the 1790s to the eve of World War I, until it was surpassed by income taxes. Since the revenue from the tariff was considered essential and easy to collect at the major ports, it was agreed the nation should have a tariff for revenue purposes.[3][4]\\r\\nAnother role the tariff played was in the protection of local industry; it was the political dimension of the tariff. From the 1790s to the present day, the tariff (and closely related issues such as import quotas and trade treaties) generated enormous political stresses. These stresses lead to the Nullification crisis during the 19th century, and the creation of the WTO.\\r\\nWhen Alexander Hamilton was the United States Secretary of the Treasury he issued the Report on Manufactures, which reasoned that applying tariffs in moderation, in addition to raising revenue to fund the federal government, would also encourage domestic manufacturing and growth of the economy by applying the funds raised in part towards subsidies (called bounties in his time) to manufacturers. The main purposes sought by Hamilton through the tariff were to: (1) protect American infant industry for a short term until it could compete; (2) raise revenue to pay the expenses of government; (3) raise revenue to directly support manufacturing through bounties (subsidies).[5] This resulted in the passage of three tariffs by Congress, the Tariff of 1789, the Tariff of 1790, and the Tariff of 1792 which progressively increased tariffs.\\r\\nTariffs contributed to sectionalism between the North and the South. The Tariff of 1824 increased tariffs in order to protect American industry in the face of cheaper imported commodities such as iron products, wool and cotton textiles, and agricultural goods from England. This tariff was the first in which the sectional interests of the North and the South truly came into conflict because the South advocated lower tariffs in order to take advantage of tariff reciprocity from England and other countries that purchased raw agricultural materials from the South.[citation needed]\\r\\nThe Tariff of 1828, also known as the Tariff of Abominations, and the Tariff of 1832 accelerated sectionalism between the North and the South. For a brief moment in 1832, South Carolina made vague threats to leave the Union over the tariff issue.[6] In 1833, to ease North-South relations, Congress lowered the tariffs.[6] In the 1850s, the South gained greater influence over tariff policy and made subsequent reductions.[7]\\r\\nIn 1861, just prior to the Civil War, Congress enacted the Morrill Tariff, which applied high rates and inaugurated a period of relatively continuous trade protection in the United States that lasted until the Underwood Tariff of 1913. The schedule of the Morrill Tariff and its two successor bills were retained long after the end of the Civil War.[8]\\r\\nIn 1921, Congress sought to protect local agriculture as opposed to industry by passing the Emergency Tariff, which increased rates on wheat, sugar, meat, wool and other agricultural products brought into the United States from foreign nations, which provided protection for domestic producers of those items.\\r\\nHowever, one year later Congress passed another tariff, the Fordney-McCumber Tariff, which applied the scientific tariff and the American Selling Price. The purpose of the scientific tariff was to equalize production costs among countries so that no country could undercut the prices charged by American companies.[9] The difference of production costs was calculated by the Tariff Commission. A second novelty was the American Selling Price. This allowed the president to calculate the duty based on the price of the American price of a good, not the imported good.[9]\\r\\nDuring the outbreak of the Great Depression in 1930, Congress raised tariffs via the Smoot-Hawley Tariff Act on over 20,000 imported goods to record levels, and, in the opinion of most economists, worsened the Great Depression by causing other countries to reciprocate thereby plunging American imports and exports by more than half.[citation needed]\\r\\nIn 1948, the US signed the General Agreement on Tariffs and Trade (GATT), which reduced tariff barriers and other quantitative restrictions and subsidies on trade through a series of agreements.\\r\\nIn 1993, the GATT was updated (GATT 1994) to include new obligations upon its signatories. One of the most significant changes was the creation of the World Trade Organization (WTO). Whereas GATT was a set of rules agreed upon by nations, the WTO is an institutional body. The WTO expanded its scope from traded goods to trade within the service sector and intellectual property rights. Although it was designed to serve multilateral agreements, during several rounds of GATT negotiations (particularly the Tokyo Round) plurilateral agreements created selective trading and caused fragmentation among members. WTO arrangements are generally a multilateral agreement settlement mechanism of GATT.[10]\\r\\nFederal excise taxes are applied to specific items such as motor fuels, tires, telephone usage, tobacco products, and alcoholic beverages. Excise taxes are often, but not always, allocated to special funds related to the object or activity taxed.\\r\\nDuring the presidency of George Washington, Alexander Hamilton proposed a tax on distilled spirits to fund his policy of assuming the war debt of the American Revolution for those states which had failed to pay. After a vigorous debate, the House decided by a vote of 35-21 to approve legislation imposing a seven cent per-gallon excise tax on whiskey. This marks the first time in American history that congress voted to tax an American product, which led to the Whiskey Rebellion.\\r\\nThe history of income taxation in the United States began in the 19th century with the imposition of income taxes to fund war efforts. However, the constitutionality of income taxation was widely held in doubt [Pollock v. Farmers' Loan & Trust Company, 157 U.S. 429 (1895)] \\"[11] until 1913 with the ratification of the 16th Amendment.\\r\\nArticle I, Section 8, Clause 1 of the United States Constitution assigns Congress the power to impose \\"Taxes, Duties, Imposts and Excises,\\" but Article I, Section 8 requires that, \\"Duties, Imposts and Excises shall be uniform throughout the United States.\\"[12]\\r\\nIn addition, the Constitution specifically limited Congress' ability to impose direct taxes, by requiring it to distribute direct taxes in proportion to each state's census population. It was thought that head taxes and property taxes (slaves could be taxed as either or both) were likely to be abused, and that they bore no relation to the activities in which the federal government had a legitimate interest. The fourth clause of section 9 therefore specifies that, \\"No Capitation, or other direct, Tax shall be laid, unless in Proportion to the Census or enumeration herein before directed to be taken.\\"\\r\\nTaxation was also the subject of Federalist No. 33 penned secretly by the Federalist Alexander Hamilton under the pseudonym Publius. In it, he explains that the wording of the \\"Necessary and Proper\\" clause should serve as guidelines for the legislation of laws regarding taxation. The legislative branch is to be the judge, but any abuse of those powers of judging can be overturned by the people, whether as states or as a larger group.\\r\\nWhat seemed to be a straightforward limitation on the power of the legislature based on the subject of the tax proved inexact and unclear when applied to an income tax, which can be arguably viewed either as a direct or an indirect tax. The courts have generally held that direct taxes are limited to taxes on people (variously called \\"capitation\\", \\"poll tax\\" or \\"head tax\\") and property.[13] All other taxes are commonly referred to as \\"indirect taxes\\".[14]\\r\\nIn order to help pay for its war effort in the American Civil War, Congress imposed its first personal income tax in 1861.[15] It was part of the Revenue Act of 1861 (3% of all incomes over US $800; rescinded in 1872). Congress also enacted the Revenue Act of 1862, which levied a 3% tax on incomes above $600, rising to 5% for incomes above $10,000. Rates were raised in 1864. This income tax was repealed in 1872.\\r\\nA new income tax statute was enacted as part of the 1894 Tariff Act.[16][17] At that time, the United States Constitution specified that Congress could impose a \\"direct\\" tax only if the law apportioned that tax among the states according to each state's census population.[18]\\r\\nIn 1895, the United States Supreme Court ruled, in Pollock v. Farmers' Loan & Trust Co., that taxes on rents from real estate, on interest income from personal property and other income from personal property (which includes dividend income) were direct taxes on property and therefore had to be apportioned. Since apportionment of income taxes is impractical, the Pollock rulings had the effect of prohibiting a federal tax on income from property. Due to the political difficulties of taxing individual wages without taxing income from property, a federal income tax was impractical from the time of the Pollock decision until the time of ratification of the Sixteenth Amendment (below).\\r\\nIn response to the Supreme Court decision in the Pollock case, Congress proposed the Sixteenth Amendment, which was ratified in 1913,[19] and which states:\\r\\nThe Congress shall have power to lay and collect taxes on incomes, from whatever source derived, without apportionment among the several States, and without regard to any census or enumeration.\\r\\nThe Supreme Court in Brushaber v. Union Pacific Railroad, 240 U.S. 1 (1916), indicated that the Sixteenth Amendment did not expand the federal government's existing power to tax income (meaning profit or gain from any source) but rather removed the possibility of classifying an income tax as a direct tax on the basis of the source of the income. The Amendment removed the need for the income tax on interest, dividends and rents to be apportioned among the states on the basis of population. Income taxes are required, however, to abide by the law of geographical uniformity.\\r\\nCongress enacted an income tax in October 1913 as part of the Revenue Act of 1913, levying a 1% tax on net personal incomes above $3,000, with a 6% surtax on incomes above $500,000. By 1918, the top rate of the income tax was increased to 77% (on income over $1,000,000, equivalent of 15,300,000 in 2012 dollars[20]) to finance World War I. The average rate for the rich however, was only 15%.[21] The top marginal tax rate was reduced to 58% in 1922, to 25% in 1925 and finally to 24% in 1929. In 1932 the top marginal tax rate was increased to 63% during the Great Depression and steadily increased, reaching 94% (on all income over $200,000, equivalent of 2,500,000 in 2012 dollars[22])in 1945. During World War II, Congress introduced payroll withholding and quarterly tax payments.[23]\\r\\nFollowing World War II tax increases, top marginal individual tax rates stayed near or above 90%, and the effective tax rate at 70% for the highest incomes (few paid the top rate), until 1964 when the top marginal tax rate was lowered to 70%. Kennedy explicitly called for a top rate of 65 percent, but added that it should be set at 70 percent if certain deductions weren't phased out at the top of the income scale.[24][25][26] The top marginal tax rate was lowered to 50% in 1982 and eventually to 28% in 1988. It slowly increased to 39.6% in 2000, then was reduced to 35% for the period 2003 through 2012.[23] Corporate tax rates were lowered from 48% to 46% in 1981 (PL 97-34), then to 34% in 1986 (PL 99-514), and increased to 35% in 1993.\\r\\nTimothy Noah, senior editor of the New Republic, argues that while Ronald Reagan made massive reductions in the nominal marginal income tax rates with his Tax Reform Act of 1986, this reform did not make a similarly massive reduction in the effective tax rate on the higher marginal incomes. Noah writes in his ten part series entitled \\"The Great Divergence,\\" that in 1979, the effective tax rate on the top 0.01 percent of taxpayers was 42.9 percent, according to the Congressional Budget Office, but that by Reagan's last year in office it was 32.2%. This effective rate on high incomes held steadily until the first few years of the Clinton presidency when it increased to a peak high of 41%. However, it fell back down to the low 30s by his second term in the White House. This percentage reduction in the effective marginal income tax rate for the wealthiest Americans, 9%, is not a very large decrease in their tax burden, according to Noah, especially in comparison to the 20% drop in nominal rates from 1980 to 1981 and the 15% drop in nominal rates from 1986 to 1987. In addition to this small reduction on the income taxes of the wealthiest taxpayers in America, Noah discovered that the effective income tax burden for the bottom 20% of wage earners was 8% in 1979 and dropped to 6.4% under the Clinton Administration. This effective rate further dropped under the George W. Bush Administration. Under Bush, the rate decreased from 6.4% to 4.3%. Looking at the simple math, reductions in the effective income tax burden on the poor coinciding with modest reductions in the effective income tax rate on the wealthiest 0.01% of tax payers could not alone have been the direct cause of increased income inequality that began in the 1980s.[27] These figures also correspond to an analysis of effective tax rates from 1979ÿ2005 by the Congressional Budget Office.[28]\\r\\nCongress re-adopted the income tax in 1913, levying a 1% tax on net personal incomes above $3,000, with a 6% surtax on incomes above $500,000. By 1918, the top rate of the income tax was increased to 77% (on income over $1,000,000) to finance World War I. The top marginal tax rate was reduced to 58% in 1922, to 25% in 1925, and finally to 24% in 1929. In 1932 the top marginal tax rate was increased to 63% during the Great Depression and steadily increased.\\r\\nDuring World War II, Congress introduced payroll withholding and quarterly tax payments. In pursuit of equality (rather than revenue) President Franklin D. Roosevelt proposed a 100% tax on all incomes over $25,000.[30][31] When Congress did not enact that proposal, Roosevelt issued an executive order attempting to achieve a similar result through a salary cap on certain salaries in connection with contracts between the private sector and the federal government.[32][33][34] For tax years 1944 through 1951, the highest marginal tax rate for individuals was 91%, increasing to 92% for 1952 and 1953, and reverting to 91% for tax years 1954 through 1963.[35]\\r\\nFor the 1964 tax year, the top marginal tax rate for individuals was lowered to 77%, and then to 70% for tax years 1965 through 1981. In 1978 income brackets were adjusted for inflation, so fewer people were taxed at high rates.[36] The top marginal tax rate was lowered to 50% for tax years 1982 through 1986.[37] Reagan undid 40% of his 1981 tax cut, in 1983 he hiked gas and payroll taxes, and in 1984 he raised tax revenue by closing loopholes for businesses.[38] According to historian and domestic policy adviser Bruce Bartlett, Reagan's 12 tax increases over the course of his presidency took back half of the 1981 tax cut.[39]\\r\\nFor tax year 1987, the highest marginal tax rate was 38.5% for individuals.[40] It was lowered to 28% in revenue neutral fashion, eliminating many loopholes and shelters, along with in corporate taxes, (with a 33% \\"bubble rate\\") for tax years 1988 through 1990.[41][42] Ultimately, the combination of base broadening and rate reduction raised revenue equal to about 4% of existing tax revenue[43]\\r\\nFor the 1991 and 1992 tax years, the top marginal rate was increased to 31% in a budget deal President George H. W. Bush made with the Congress.[44]\\r\\nIn 1993 the Clinton administration proposed and the Congress accepted (with no Republican support) an increase in the top marginal rate to 39.6% for the 1993 tax year, where it remained through tax year 2000.[45]\\r\\nIn 2001, President George W. Bush proposed and the Congress accepted an eventual lowering of the top marginal rate to 35%. However, this was done in stages: with a highest marginal rate of 39.1% for 2001, then 38.6% for 2002 and finally 35% for years 2003 through 2010.[46] This measure had a sunset provision and was scheduled to expire for the 2011 tax year, when rates would have returned to those adopted during the Clinton years unless Congress changed the law;[47] Congress did so by passing the Tax Relief, Unemployment Insurance Reauthorization and Job Creation Act of 2010, signed by President Barack Obama on December 17, 2010.\\r\\nAt first the income tax was incrementally expanded by the Congress of the United States, and then inflation automatically raised most persons into tax brackets formerly reserved for the wealthy until income tax brackets were adjusted for inflation. Income tax now applies to almost two-thirds of the population.[48] The lowest earning workers, especially those with dependents, pay no income taxes as a group and actually get a small subsidy from the federal government because of child credits and the Earned Income Tax Credit.[citation needed]\\r\\nWhile the government was originally funded via tariffs upon imported goods, tariffs now represent only a minor portion of federal revenues. Non-tax fees are generated to recompense agencies for services or to fill specific trust funds such as the fee placed upon airline tickets for airport expansion and air traffic control. Often the receipts intended to be placed in \\"trust\\" funds are used for other purposes, with the government posting an IOU ('I owe you') in the form of a federal bond or other accounting instrument, then spending the money on unrelated current expenditures.\\r\\nNet long-term capital gains as well as certain types of qualified dividend income are taxed preferentially. The federal government collects several specific taxes in addition to the general income tax. Social Security and Medicare are large social support programs which are funded by taxes on personal earned income (see below).\\r\\nTax statutes passed after the ratification of the Sixteenth Amendment in 1913 are sometimes referred to as the \\"modern\\" tax statutes. Hundreds of Congressional acts have been passed since 1913, as well as several codifications (i.e., topical reorganizations) of the statutes (see Codification).\\r\\nThe modern interpretation of the Sixteenth Amendment taxation power can be found in Commissioner v. Glenshaw Glass Co. 348 U.S. 426 (1955). In that case, a taxpayer had received an award of punitive damages from a competitor, and sought to avoid paying taxes on that award. The U.S. Supreme Court observed that Congress, in imposing the income tax, had defined income to include:\\r\\ngains, profits, and income derived from salaries, wages, or compensation for personal service . . . of whatever kind and in whatever form paid, or from professions, vocations, trades, businesses, commerce, or sales, or dealings in property, whether real or personal, growing out of the ownership or use of or interest in such property; also from interest, rent, dividends, securities, or the transaction of any business carried on for gain or profit, or gains or profits and income derived from any source whatever.[49]\\r\\nThe Court held that \\"this language was used by Congress to exert in this field the full measure of its taxing power\\", id., and that \\"the Court has given a liberal construction to this broad phraseology in recognition of the intention of Congress to tax all gains except those specifically exempted.\\"[50]\\r\\nThe Court then enunciated what is now understood by Congress and the Courts to be the definition of taxable income, \\"instances of undeniable accessions to wealth, clearly realized, and over which the taxpayers have complete dominion.\\" Id. at 431. The defendant in that case suggested that a 1954 rewording of the tax code had limited the income that could be taxed, a position which the Court rejected, stating:\\r\\nThe definition of gross income has been simplified, but no effect upon its present broad scope was intended. Certainly punitive damages cannot reasonably be classified as gifts, nor do they come under any other exemption provision in the Code. We would do violence to the plain meaning of the statute and restrict a clear legislative attempt to bring the taxing power to bear upon all receipts constitutionally taxable were we to say that the payments in question here are not gross income.[51]\\r\\nIn Conner v. United States,[52] a couple had lost their home to a fire, and had received compensation for their loss from the insurance company, partly in the form of hotel costs reimbursed. The U.S. District Court acknowledged the authority of the IRS to assess taxes on all forms of payment, but did not permit taxation on the compensation provided by the insurance company, because unlike a wage or a sale of goods at a profit, this was not a gain. As the court noted, \\"Congress has taxed income, not compensation\\".[53] By contrast, at least two Federal courts of appeals have indicated that Congress may constitutionally tax an item as \\"income,\\" regardless of whether that item is in fact income. See Penn Mutual Indemnity Co. v. Commissioner[54] and Murphy v. Internal Revenue Serv.[55]\\r\\nThe origins of the estate and gift tax occurred during the rise of the state inheritance tax in the late 19th century and the progressive era.\\r\\nIn the 1880s and 1890s many states passed inheritance taxes, which taxed the donees on the receipt of their inheritance. While many objected to the application of an inheritance tax, some including Andrew Carnegie and John D. Rockefeller supported increases in the taxation of inheritance.[56]\\r\\nAt the beginning of the 20th century President Theodore Roosevelt advocated the application of a progressive inheritance tax on the federal level.[57]\\r\\nIn 1916, Congress adopted the present federal estate tax, which instead of taxing the wealth that a donee inherited as occurred in the state inheritance taxes it taxed the wealth of a donor's estate upon transfer.\\r\\nLater, Congress passed the Revenue Act of 1924, which imposed the gift tax, a tax on gifts given by the donor.\\r\\nIn 1948 Congress allowed marital deductions for the estate and the gift tax. In 1981, Congress expanded this deduction to an unlimited amount for gifts between spouses.[58]\\r\\nToday, the estate tax is a tax imposed on the transfer of the \\"taxable estate\\" of a deceased person, whether such property is transferred via a will or according to the state laws of intestacy. The estate tax is one part of the Unified Gift and Estate Tax system in the United States. The other part of the system, the gift tax, imposes a tax on transfers of property during a person's life; the gift tax prevents avoidance of the estate tax should a person want to give away his/her estate just before dying.\\r\\nIn addition to the federal government, many states also impose an estate tax, with the state version called either an estate tax or an inheritance tax. Since the 1990s, the term \\"death tax\\" has been widely used by those who want to eliminate the estate tax, because the terminology used in discussing a political issue affects popular opinion.[59]\\r\\nIf an asset is left to a spouse or a charitable organization, the tax usually does not apply. The tax is imposed on other transfers of property made as an incident of the death of the owner, such as a transfer of property from an intestate estate or trust, or the payment of certain life insurance benefits or financial account sums to beneficiaries.\\r\\nPrior to the Great Depression, the following economic problems were considered great hazards to working-class Americans:\\r\\nIn the 1930s, the New Deal introduced Social Security to rectify the first three problems (retirement, injury-induced disability, or congenital disability). It introduced the FICA tax as the means to pay for Social Security.\\r\\nIn the 1960s, Medicare was introduced to rectify the fourth problem (health care for the elderly). The FICA tax was increased in order to pay for this expense.\\r\\nPresident Franklin D. Roosevelt introduced the Social Security (FICA) Program. FICA began with voluntary participation, participants would have to pay 1% of the first $1,400 of their annual incomes into the Program, the money the participants elected to put into the Program would be deductible from their income for tax purposes each year, the money the participants put into the independent \\"Trust Fund\\" rather than into the General operating fund, and therefore, would only be used to fund the Social Security Retirement Program, and no other Government program, and, the annuity payments to the retirees would never be taxed as income.[citation needed]\\r\\nDuring the Lyndon B. Johnson administration Social Security moved from the trust fund to the general fund.[citation needed] Participants may not have an income tax deduction for Social Security withholding.[citation needed] Immigrants became eligible for Social Security benefits during the Carter administration.[citation needed] During the Reagan administration Social Security annuities became taxable.[60]\\r\\nThe alternative minimum tax (AMT) was introduced by the Tax Reform Act of 1969,[61] and became operative in 1970. It was intended to target 155 high-income households that had been eligible for so many tax benefits that they owed little or no income tax under the tax code of the time.[62]\\r\\nIn recent years, the AMT has been under increased attention. With the Tax Reform Act of 1986, the AMT was broadened and refocused on home owners in high tax states. Because the AMT is not indexed to inflation and recent tax cuts,[62][63] an increasing number of middle-income taxpayers have been finding themselves subject to this tax.\\r\\nIn 2006, the IRS's National Taxpayer Advocate's report highlighted the AMT as the single most serious problem with the tax code. The advocate noted that the AMT punishes taxpayers for having children or living in a high-tax state, and that the complexity of the AMT leads to most taxpayers who owe AMT not realizing it until preparing their returns or being notified by the IRS. [2]\\r\\nThe origins of the income tax on gains from capital assets did not distinguish capital gains from ordinary income. From 1913 to 1921, income from capital gains were taxed at ordinary rates, initially up to a maximum rate of 7 percent.[64]\\r\\nCongress began to distinguish the taxation of capital gains from the taxation of ordinary income according to the holding period of the asset with the Revenue Act of 1921, allowed a tax rate of 12.5 percent gain for assets held at least two years.[64]\\r\\nIn addition to different tax rates depending on holding period, Congress began excluding certain percentages of capital gains depending on holding period. From 1934 to 1941, taxpayers could exclude percentages of gains that varied with the holding period: 20, 40, 60, and 70 percent of gains were excluded on assets held 1, 2, 5, and 10 years, respectively.[64] Beginning in 1942, taxpayers could exclude 50 percent of capital gains from income on assets held at least six months or elect a 25 percent alternative tax rate if their ordinary tax rate exceeded 50 percent.[64]\\r\\nCapital gains tax rates were significantly increased in the 1969 and 1976 Tax Reform Acts.[64]\\r\\nThe 1970s and 1980s saw a period of oscillating capital gains tax rates. In 1978, Congress reduced capital gains tax rates by eliminating the minimum tax on excluded gains and increasing the exclusion to 60 percent, thereby reducing the maximum rate to 28 percent.[64] The 1981 tax rate reductions further reduced capital gains rates to a maximum of 20 percent.\\r\\nLater in the 1980s Congress began increasing the capital gains tax rate and repealing the exclusion of capital gains. The Tax Reform Act of 1986 repealed the exclusion from income that provided for tax-exemption of long term capital gains, raising the maximum rate to 28 percent (33 percent for taxpayers subject to phaseouts).[64] When the top ordinary tax rates were increased by the 1990 and 1993 budget acts, an alternative tax rate of 28 percent was provided.[64] Effective tax rates exceeded 28 percent for many high-income taxpayers, however, because of interactions with other tax provisions.[64]\\r\\nThe end of the 1990s and the beginning of the present century heralded major reductions in taxing the income from gains on capital assets. Lower rates for 18-month and five-year assets were adopted in 1997 with the Taxpayer Relief Act of 1997.[64] In 2001, President George W. Bush signed the Economic Growth and Tax Relief Reconciliation Act of 2001, into law as part of a $1.35 trillion tax cut program.\\r\\nThe United States' corporate tax rate was at its highest, 52.8 percent, in 1968 and 1969. The top rate was hiked for the last time in 1993 to its current rate of 35 percent.[65]","input":"When did the federal government first adopt an income tax?"},{"output":"June 29, 2007","context":"The history of iPhone began with a request from inventor Steve Jobs to Apple Inc.'s engineers, asking them to investigate the use of touchscreen devices and tablet computers (which later came to fruition with the iPad).[1][2][3][4] Many have noted the device's similarities to Apple's previous touch-screen portable device, the Newton MessagePad.[5][6][7][8] Like the Newton, the iPhone is nearly all screen. Its form factor is credited to Apple's Chief Design Officer, Jonathan Ive.[3][9]\\r\\nIn April 2003, at the \\"All Things Digital\\" executive conference, Jobs expressed his belief that tablet PCs and traditional PDAs were not good choices as high-demand markets for Apple to enter, despite receiving many requests for Apple to create another PDA. He believed that cell phones were going to become important devices for portable information access, and that mobile phones needed to have excellent synchronization software. At that time, instead of focusing on a follow-up to their Newton PDA, Jobs had Apple focus on the iPod. Jobs also had Apple develop the iTunes software, which can be used to synchronize content with iPod devices. iTunes was released in January 2001.[10][11][12][13] On September 7, 2005, Apple and Motorola released the ROKR E1, the first mobile phone to use iTunes. Jobs was unhappy with the ROKR, feeling that having to compromise with a non-Apple designer (Motorola) prevented Apple from designing the phone they wanted to make.[14] In September 2006, Apple discontinued support for the ROKR, and released a version of iTunes that included references to an as-yet unknown mobile phone that could display pictures and video.[15] Ed Zander (the CEO of Motorola at the time) \\"inspired\\"[clarify] Steve Jobs with Moto's[clarify] multimedia (e.g., iTunes) + smartphone product concept.[clarify] As a result, Apple gained a new product concept, called \\"iPhone\\", while Motorola walked away[clarify] with a limited version of iTunes for Rokr/Slvr.\\r\\nOn January 9, 2007, Steve Jobs announced iPhone at the Macworld convention, receiving substantial media attention.[16] Jobs announced that the first iPhone would be released later that year. On June 29, 2007, the first iPhone[17] was released.\\r\\nOn June 11, 2007, Apple announced at the Apple's Worldwide Developers Conference that the iPhone would support third-party applications using the Safari engine. Third parties would be able to create Web 2.0 applications, which users could access via the internet.[18] Such applications appeared even before the release of the iPhone; the first of these, called OneTrip, was a program meant to keep track of users' shopping lists.[19] On June 29, 2007, Apple released version 7.3 of iTunes to coincide with the release of iPhone.[20] This release contains support for iPhone service activation and syncing.\\r\\nAccording to The Wall Street Journal, the iPhone is manufactured on contract[clarify] in the Shenzhen factory of the Taiwanese company Hon Hai (also known as Foxconn).[21] Also, according to recent news, Apple will shortly begin outsourcing the manufacturing of iPhones.[22]\\r\\n\\r\\n\\r\\nWhen Apple released the iPhone on January 9, 2007,[23] it was sold only with AT&T (formerly Cingular) contracts in the United States.[14] After 18 months of negotiations, Steve Jobs reached an agreement with the wireless division of AT&T to be the iPhone's exclusive carrier. Consumers were unable to use any other carrier without unlocking their device.\\r\\nApple retained control of the design, manufacturing and marketing of the iPhone.[24] Since some customers were jailbreaking their iPhones to leave their network, AT&T began charging them a $175 early-termination fee for leaving before the end of their contract.[25]\\r\\nQuestions arose about the legality of Apple's arrangement after the iPhone was released.[26] Two class-action lawsuits were filed against the company in October 2007: one in Federal court and the other in state court.[27] According to the suits, Apple's exclusive agreement with AT&T violated antitrust law.[28]\\r\\nThe state-court suit, filed by the law office of Damian R. Fernandez on behalf of California resident Timothy P. Smith,[28] sought an injunction barring Apple from selling iPhones with a software lock and $200 million in damages.[29] In Smith v. Apple Inc., the plaintiffs said that Apple failed to disclose to purchasers its five-year agreement with AT&T when they bought iPhones with a two-year contract and cited the Sherman Act's prohibition of monopolies.[30]\\r\\nThe second case was filed in the United States District Court for the Northern District of California. The plaintiff, Paul Holman, filed a complaint against Apple and AT&T Mobility that he could not switch carriers or change SIM cards without losing iPhone improvements to which he was entitled. Holman also cited a Sherman Act violation by the defendants.[31] On July?8, 2010, the case was affirmed for class certification.[32] On December 9 the court ordered a stay on the case, awaiting the Supreme Court's decision in AT&T v. Concepcion (disputed whether the state's basic standards of fairness were met by a clause in AT&T's contract limiting complaint resolution to arbitration).[33] On April 27, 2011, the Supreme Court ruled that AT&T met the state's fairness standards.[34]\\r\\nThe first advertisement for iPhone, titled \\"Hello\\", aired during the 79th Academy Awards on February 25, 2007, on American Broadcasting Company (ABC).[35] On June 4, 2007, Apple released four advertisements announcing that iPhone would be released on June 29, 2007.\\r\\nOn July 1, 2007, it was reported that Apple paid at least US$1 million to Michael Kovatch for the iPhone.com domain name, previously owned by Kovatch since 1995.[36] The URL now redirects to Apple's iPhone page.\\r\\nOn June 28, 2007, during an address to Apple employees, Steve Jobs announced that all full-time Apple employees and those part-time employees who had been with the company for at least one year would receive a free iPhone. Employees received their phones in July after the initial demand for iPhones subsided.[37]\\r\\nInitially priced at US $499 and US $599 for the 4GB models and 8GB models respectively, the iPhone went on sale on June 29, 2007. Apple closed its stores at 2:00pm local time to prepare for the 6:00pm iPhone launch, while hundreds of customers lined up at stores nationwide.[38]\\r\\nIn the US and some other countries, iPhones could only be acquired with a credit card, preventing completely anonymous purchases of iPhones.[39][40][41] There was no way to opt out of the data plan.[clarify] At first, iPhones could not be added to an AT&T Business account, and any existing business account discounts could not be applied to an iPhone AT&T account. AT&T changed these restrictions in late January 2008.[42]\\r\\nThe Associated Press also reported in 2007 that some users were unable to activate their phones because, according to AT&T, \\"[a] high volume of activation requests [was] taxing the company's computer servers.\\"[43][44] On Oct 29, 2007, the Usenet newsgroup misc.phone.mobile.iphone was created.[relevant? ÿ discuss]\\r\\nEarly estimates by technology analysts estimated sales of between 250,000 and 700,000 iPhones in the first weekend alone, with strong sales continuing after the initial weekend.[45][46] As part of their quarterly earnings announcement, AT&T reported that 146,000 iPhones were activated in the first weekend. Though this figure does not include units that were purchased for resale on eBay or otherwise not activated until after the opening weekend, it is still less than most initial estimates.[47] It is also estimated that 95% of the units sold are the 8GB model.[48]\\r\\nOn January 11, 2011, Verizon announced during a media event that it had reached an agreement with Apple and would begin selling a CDMA iPhone 4. The Verizon iPhone went on sale on February 10, 2011.[49][50][51]\\r\\nDuring Apple's official unveiling of iPhone 4S on October 4, 2011, it was announced that Sprint would begin carrying the reconfigured CDMA iPhone 4 and iPhone 4S in the US on October 14.[52][53] Cricket Wireless announced on May 31, 2012 that it would become the first prepaid carrier in the US to offer iPhone 4 and iPhone 4S, beginning June 22, 2012.[54] A week later, Virgin Mobile USA became the second American prepaid carrier to offer iPhone 4 and 4S, announcing plans to release the phones on June 29, 2012.[55] Due to T-Mobile USA's inability to provide iPhone to customers raised its subscription churn rate, put the unit in an \\"unsustainable position\\", and contributed to parent Deutsche Telekom's decision to sell it to AT&T in March 2011;[clarify] T-Mobile began offering iPhone on April 12, 2013.[56]\\r\\nMedia reports emerged in early August 2013 that announced that Apple would be launching its next iPhone model on September 10, 2013, but further details were not available. Brian Barrett, Managing Editor of the Gizmodo publication, speculated that either an upgraded version of iPhone 5 or a budget version would be released.[57]\\r\\nStories of unexpected billing issues began to circulate in blogs and the technical press a little more than a month after iPhone's heavily advertised and anticipated release.[58] The 300-page iPhone bill in a box received by iJustine on Saturday, August 11, 2007[59][60] became the subject of a viral video, posted by the following Monday, which quickly became an Internet meme.[61][62] This video clip brought the voluminous bills to the attention of the mass media. Ten days later, after the video had been viewed more than 3 million times on the Internet,[63] and had received international news coverage, AT&T sent iPhone users a text message outlining changes in its billing practices.[64]\\r\\nOn September 5, 2007, the 4GB model was discontinued, and the 8GB model price was cut by a third, from US $599 to US $399.[65] Those who had purchased an iPhone in the 14-day period before the September 5, 2007 announcement were eligible for a US $200 \\"price protection\\" rebate from Apple or AT&T. However, it was widely reported that some who bought between the June 29, 2007 launch and the August 22, 2007 price protection kick-in date complained that this was a larger-than-normal price drop for such a relatively short period and accused Apple of unfair pricing.[66][67]\\r\\nIn response to customer complaints, on September 6, 2007, Apple CEO Steve Jobs wrote in an open letter to iPhone customers that everyone who purchased an iPhone at the higher price \\"and who is not receiving a rebate or other consideration\\", would receive a US$100 credit to be redeemed towards the purchase of any product sold in Apple's retail or online stores.[68]\\r\\nWith the July 11, 2008 release of the iPhone 3G, Apple and AT&T changed the US pricing model from the previous generation. Following the de facto model for mobile phone service in the United States, AT&T would subsidize a sizable portion of the upfront cost for the iPhone 3G, followed by charging moderately higher monthly fees over a minimum two-year contract.[69]\\r\\nOn November 9, 2007, the iPhone was officially launched in Europe, in the United Kingdom and Germany.[clarify] In the UK, sales go through the UK O2 unit of Telef܇nica, while in Germany, it is offered through Deutsche Telekom's T-Mobile division.[clarify] As in the case of the previous launch in the US, customers lined up as much as a day in advance to obtain the much-anticipated phone.[citation needed]\\r\\nApple occasionally produced a limited number of 4GB iPhones for German and UK markets, but they never reached end customers and were used as in-store demo units. Later[when?] most of the units were disposed of.[70]\\r\\nThe initial operating model of locking iPhone owners to one selected carrier has been controversial in Europe. In Germany, Vodafone, an operator competing with the operator that Apple had locked German iPhone sales to (Deutsche Telekom's T-Mobile division), brought a legal case[clarify] claiming that the arrangement was against German law. On November 20, 2007, an interim court order resulted in sales of locked iPhones in Germany being temporarily stopped. The iPhone launch in France a few weeks later through the operator Orange faced the same legal issues. Other countries that will pose[clarify] the same problems for the business model revolving around the sale of locked iPhones include Belgium, Italy, Finland, and Brazil.\\r\\nOn December 1, 2007, Tu?mobil, the Slovenian mobile operator,[clarify] started selling \\"unlocked\\" iPhones without an official contract with Apple. The offer caused confusion between Apple Europe, local media, and local Apple representatives.[71]\\r\\nOn May 6, 2008, Telecom Italia announced that it had signed a deal with Apple to sell iPhones in Italy by the end of 2008.[72] It was estimated that it would probably be the second generation iPhone with 3G-UMTS capability.\\r\\nOn May 27, 2008, TeliaSonera released a press release stating that it would start selling iPhones in Sweden, Norway, Denmark, Finland, Estonia, Lithuania, and Latvia during 2008.[73]\\r\\nOn June 4, 2008, Movistar announced that it had signed a deal with Apple to sell iPhones in Spain beginning on July 11, 2008.[74]\\r\\nOn August 22, 2008, Estonian mobile operator EMT started selling iPhones.[75]\\r\\nOn August 22, 2008, Vodafone Greece released iPhones in the Greek market.[76]\\r\\nOn September 26, 2008, Omnitel released iPhones in Lithuania.[77]\\r\\nOn November 7, 2008, T-Mobile released iPhones in Croatia.[78]\\r\\nOn September 29, 2010, Elisa released the iPhone 4 in Finland.[79]\\r\\nSingTel (in Singapore) and Globe Telecom (in the Philippines) were the first two carriers to launch the iPhone in Southeast Asia. Both carriers launched the iPhone 3G in August 2008.\\r\\nOn March 20, 2009, Telkomsel became the first telecommunications company in Indonesia to offer the iPhone 3G with customizable plans for all Telkomsel customers.[clarify][80] In the same month, Maxis of Malaysia and DiGi both launched the iPhone 3G.[where?]\\r\\nOn October 2011, StarHub launched the iPhone in Singapore. Smart Communications followed suit in December 2011 by launching the iPhone 4S in the Philippines. Smart Communications was the last telecommunications company to carry Apple's iPhone in Southeast Asia.[clarify][81]\\r\\nThe iPhone 3G was released in Australia on July 11, 2008.[82]\\r\\nThe very first iPhone 3G model released on July 11, 2008[clarify] was sold in Auckland, New Zealand to 22-year-old student Jonny Gladwell at 12:01 am NZST.[83] The iPhone 3G was only available to customers on the Vodafone network.[clarify][84] There was criticism from some New Zealand customers when Vodafone announced pricing for the iPhone 3G, as Vodafone was the only network to offer this generation of iPhone.[where?]\\r\\nThe first-generation iPhone was only available for sale in New Zealand through parallel import stores soon after it went on sale in the US. The original models available for sale in New Zealand were unlocked for use on the Vodafone network and could be used with any plan, including pre-paid plans.[85]\\r\\nSubsequent launches of iPhone models in New Zealand have typically been a few weeks after the worldwide release.\\r\\nOn November 8, 2011, Telecom announced that they would offer the iPhone 4S on their network, along with earlier models (the iPhone 3GS and the iPhone 4).[86]\\r\\nAfter months of high anticipation, the first iPhone to be released in Canada was the iPhone 3G. Rogers Wireless began offering 8 GB and 16 GB models on July 11, 2008. Facing a public backlash,[87] Rogers dropped the price of its service plan from CA$100 to CA$30 per month.[88]\\r\\nThe iPhone 3GS, with the new iOS 3.0 operating system, was released in Canada by Rogers Wireless on June 19, 2009. Users who signed up for a 3-year agreement with a data option[clarify] could choose between a 16 GB device for CA$199 and a 32 GB device for CA$299.[89]\\r\\nBell and Telus Mobility announced that they would release iPhone on November 4 and 5, 2009, respectively.[clarify][90]\\r\\nOn May 6, 2008, Vodafone announced that they had signed a deal with Apple to sell iPhone in Australia, the Czech Republic, Egypt, Greece, Italy, India, Portugal, New Zealand, South Africa, and Turkey.[91]\\r\\nSubsequent announcements confirmed that Apple is moving away from exclusive one-carrier deals.[needs update?] Soon after Vodafone's announcement, TIM announced that it would also be selling iPhone in Italy, on May 12, 2008, Optus[92] confirmed that it would sell iPhone in Australia and SingTel confirmed that it would be selling iPhone in India through its Indian Joint Venture, Airtel.[clarify]\\r\\nOn June 4, 2008, SoftBank Mobile released a press release stating that it would start selling iPhone in Japan during 2008.[93]\\r\\nRussia's second largest mobile operator, Beeline, announced on August 28, 2008 that they signed a contract with Apple to sell iPhone on the Russian market by late 2008. The deal was rumoured to be non-exclusive, according to unofficial statements made by MTS and MegaFon. MTS and MegaFon belong to the \\"Russian Big Three\\",[relevant? ÿ discuss] and were expected to release the iPhone 3G at the same time as Beeline. As predicted, MegaFon issued a press release regarding the iPhone 3G release on September 2, 2008.[94]\\r\\nOn November 14, 2008, Vodafone Egypt and Mobinil started selling the iPhone 3G in Egypt. iPhone 3G is priced at EGS3,800 and EGS4,600 for the 8 GB and 16 GB models respectively. Customers must also sign up for one of 3 service plans[clarify] to use the phone.\\r\\nOn September 28, 2009, Orange announced that they were going to become the second operator of the iPhone in the UK, indicating that an exclusive deal that O2 had established with Apple in 2007 had ended. Orange later announced that the iPhone would be released on November 10, with pricing plans starting from S29.36 on contract and S440 for the 3GS 16GB on pay as you go.[clarify][95][96] On the following day, Vodafone UK announced that they would be selling the iPhone by early 2010, becoming the third UK network and Vodafone's 11th country to offer the iPhone.[97]\\r\\nThere had been ongoing speculation in the United States that Apple might offer a CDMA-compatible iPhone for Verizon Wireless.[98] This speculation increased on October 6, 2010, when The Wall Street Journal reported that Apple would begin producing a CDMA-compatible iPhone, with such a model going on sale in early 2011.[99]\\r\\nOn January 8, 2011, the Wall Street Journal confirmed that Verizon Wireless would, on January 11, 2011, officially announce the launch of a CDMA-based iPhone for use on their network.[100] The date in which the Verizon iPhone would go on sale was unknown, though the two most recent[needs update?] iPhone releases were made available within weeks of their launch announcement. Verizon confirmed the announcement on January 11, with an on-sale date of February 10.[101]\\r\\nOn January 11, 2011, Verizon announced that they would start carrying a CDMA version of Apple's iPhone 4 during February 2011. Existing Verizon Wireless customers could pre-order iPhone on February 3. Pricing for the iPhone 4 was $199 for 16GB and $299 for 32GB.[102] The Verizon iPhone 5 released on Friday, September 19, in the United States; it was the first GSM unlocked iPhone,[103] which worked on AT&T and other GSM networks.[clarify]\\r\\nThe international release of iPhone has been staggered over several months. Today, the iPhone is available in most countries.[104]\\r\\n? iPhone offered by multiple carriers under contract from Apple (country not carrier-exclusive)\\r\\n? iPhone offered without contract and without carrier lock\\r\\n MVNO with O2\\r\\nEach iPhone normally prevents access to its media player and web features unless it has been activated as a phone through AT&T or O2. On July 3, 2007, Jon Lech Johansen reported on his blog that he had successfully bypassed this requirement and unlocked iPhone's other features with jailbreaking. He published the software and offsets for others to use.[116]\\r\\nOn August 14, 2007, Gizmodo reported verification of a method to bypass iPhone's SIM lock, allowing the phone to work freely with carriers other than AT&T. This method requires usage of a Turbo SIM card, costing approximately US$80; the method essentially tricks iPhone into believing that it is operating on the AT&T network, even when it is connected natively (not in roaming mode) to another carrier.[117] Australian Personal Computer later published a ten-step guide to unlocking iPhone, using the Turbo SIM method.[118]\\r\\nIn mid-August, UniquePhones announced an unlocking service for iPhone, only to retract the service the following week after receiving a phone call from a lawyer representing AT&T.\\r\\nOn August 24, 2007, George Hotz, a 17-year-old hacker from Glen Rock, New Jersey, broke the lock that ties Apple's iPhone to AT&T's wireless network. He confirmed that he unlocked the phone and was using it on T-Mobile's network. The hack opened up a realm of possibilities for overseas customers because iPhone was only sold in the US at the time. By unlocking it, Hotz opened up the phone to all kinds of phone networks across the world. Hotz posted the hack on his blog. The process is complicated and requires both disassembling iPhone and executing software commands on a personal computer. Hotz, along with four others across the world, reportedly spent about 500 hours unlocking the phone.[119][120]\\r\\nAlso on August 24, 2007, Engadget reported, by way of photos and a video clip, that they were called by the \\"iPhoneSimFree\\" team, who offered to show Engadget a demonstration of unlocking iPhone using a software-only method.[121] Unlike Hotz's hardware hack, the code in this hack was not made available to the general public. Sales of the unlock started on September 10. These sales occurred through several resellers who were able to order \\"keys\\" from iPhoneSimFree, then pass the \\"keys\\" to customers, allowing the customers to use the software.\\r\\nOn September 11, after one day of sales, the iPhone Dev Team announced that they had created a working \\"software unlock\\", and released it to the public for free.[122] Utilizing the existing unlock[clarify] requires some technical knowledge, although a simpler, GUI-based version was under construction. Two free, GUI-based unlocking programs that have been made available are AnySim and iUnlock Reloaded.\\r\\nOn September 24, 2007 Apple issued a warning that future updates could render unlocked iPhones unusable.[123] On September 27, 2007, owners of unlocked iPhones who took advantage of the version 1.1.1 update through iTunes reported that the update rendered the device virtually inoperable.[124] There were also reports that the update even affected some iPhones that were not unlocked,[125] and Engadget found that the firmware update had \\"bricked\\" unhacked iPhones as well. The firmware update relocks iPhones, but on October 11 iPhoneSIMFree announced that they had hacked the 1.1.1 iPhone update, not only unlocking them but also unbricking those iPhones which were bricked by the update.[126]\\r\\nOn October 16, 2007, the iPhone Dev Team released AnySIM 1.1, the free utility that unlocks iPhones. The updated version works on firmware version 1.1.1, but doesn't fix baseband problems caused by updating an unlocked 1.0.2 phone up to 1.1.1.[127]\\r\\nOn October 23, 2007, the iPhone Elite Dev-Team released Revirginizing Tool to rebuild the lock table in the seczone area to repair the damage done by the original anySIM 1.0x unlockers so unlocked 1.0.2 iPhones can upgrade to 1.1.1 without bricking iPhone. The tool is unbricking the previously bricked iPhones.[128]\\r\\nOn November 21, 2007, T-Mobile announced that due to litigation commenced against them by their competitor Vodafone, which resulted in a preliminary injunction preventing T-Mobile from locking the SIM card to T-Mobile in Germany, it will sell the phone \\"unlocked\\" and will offer iPhone without a T-Mobile contract for ?999 (US$1,478) at its shops to customers in Germany until the court renders a decision.[129]\\r\\nBy the end of November, Apple released another version of iPhone firmware, 1.1.2. This version does not have many new features but breaks unlocks.[citation needed]\\r\\nDuring Macworld '08, on January 15, Apple released the fifth version of iPhone firmware, 1.1.3; this version repairs loopholes used by \\"iPhone Hackers.\\" The firmware, however, had been compromised prior to release and new security measures were quickly bypassed.[citation needed]\\r\\nOn February 8, 2008, Geohot released the first full software unlock for the 1.1.2 & 1.1.3 OTB iPhones.\\r\\nFor recent information see IPhone SIM unlocking.","input":"When was the first iphone released to the public?"},{"output":"August 1966","context":"The United Farm Workers of America, or more commonly just United Farm Workers (UFW), is a labor union for farmworkers in the United States. It originated from the merger of two workers' rights organizations, the Agricultural Workers Organizing Committee (AWOC) led by organizer Larry Itliong, and the National Farm Workers Association (NFWA) led by Csar Chvez and Dolores Huerta. They became allied and transformed from workers' rights organizations into a union as a result of a series of strikes in 1965, when the mostly Filipino farmworkers of the AWOC in Delano, California initiated a grape strike, and the NFWA went on strike in support. As a result of the commonality in goals and methods, the NFWA and the AWOC formed the United Farm Workers Organizing Committee on August 22, 1966.[2] This organization was accepted into the AFL-CIO in 1972 and changed its name to the United Farmworkers Union.[3]\\r\\n\\r\\n\\r\\nDolores Huerta grew up in Stockton, California, which is in the San Joaquin Valley, an area filled with farms. In the early 1950s, she completed a degree at Delta Community College, part of the University of the Pacific. She briefly worked as an elementary school teacher. Huerta saw that her students, many of them children of farm workers, were living in poverty without enough food to eat or other basic necessities. To help, she became one of the founders of the Stockton chapter of the Community Service Organization (CSO). The CSO worked to improve social and economic conditions for farm workers and to fight discrimination.[4]\\r\\nBy 1959, Csar Chvez had already established professional relationships with local community organizations that aimed to empower the working class population by encouraging them to become more politically active. In 1952, Chvez met Fred Ross who was a community organizer working on behalf of the Community Service Organization. This was a group which was affiliated with the Industrial Areas Foundation which was headed by Saul Alinsky.[5]\\r\\nTo further her cause, Huerta created the Agricultural Workers Association (AWA) in 1960. Through the AWA, she lobbied politicians on many issues, including allowing migrant workers without U.S. citizenship to receive public assistance and pensions and creating Spanish-language voting ballots and driver's tests. In 1962, she co-founded a workers' union with Csar Chvez, which was later known as the United Farm Workers (UFW). The two made a great team. Chvez was the dynamic leader and speaker and Huerta was a skilled organizer and tough negotiator. Huerta was instrumental in the union's many successes, including the strikes against California grape growers in the 1960s and 1970s.[4]\\r\\nDuring Chvezs participation in the Community Service Organization, Fred Ross trained Csar Chvez in the grassroots, door-to-door, house meeting tactic of organization, a tactic which was crucial to the UFWs recruiting methods. The house meeting tactic successfully established a broad base of local Community Service Organization chapters during Ross's era, and Chvez used this technique to extend the UFW's reach as well as to find up and coming organizers. During the 1950s, Csar Chvez and Fred Ross developed twenty-two new Community Service Organization chapters in the Mexican American neighborhoods of San Jose. In 1959, Chvez would claim the rank of executive director in the Community Service Organization. During this time, Chvez observed and adopted the notion of having the community become more politically involved in order to bring about the social changes that the community sought. This would be a vital tactic in Chvezs future struggles in fighting for immigrant rights.[5][6]\\r\\nCsar Chvezs ultimate goal in his participation with the Community Service Organization and the Industrial Areas Foundation was to eventually organize a union for the farm workers. Saul Alinsky did not share Chvezs sympathy for the farm workers struggle, claiming that organizing farm workers, \\"was like fighting on a constantly disintegrating bed of sand.\\" (Alinsky, 1967) [5]\\r\\nIn March 1962 at the Community Service Organization convention, Chvez proposed a pilot project for organizing farm workers which was rejected by the organizations members. Chvezs reaction to this led him to resign from the organization in order to pursue his goal of creating a farm workers union which would later come to be known as the National Farm Workers Association.[5]\\r\\nBy 1965 the National Farm Workers Association had acquired twelve hundred members through Chvezs person-to-person recruitment efforts which he learned from Fred Ross just a decade earlier. Out of those twelve hundred, only about two hundred paid dues.[5] Also in 1962, Richard Chavez, the brother of Csar Chvez, designed the black Aztec eagle insignia that would become the symbol of the NFW and the UFW.[7] Csar Chvez chose the red and black colors used by the organization.[8]\\r\\nAlthough still in its infant stages, the organization lent its support to a strike by workers in the rose industry in 1965. This initial protest by the young organization resulted in a failed attempt to strike against the rose industry. That same year the farm workers who worked in the Delano fields of California wanted to strike against the growers in response to the growers refusal to raise wages from $1.20 to $1.40 an hour, and they sought out Chvez and the National Farm Workers Association for support. The Delano agricultural workers were mostly Filipino workers affiliated with the Agricultural Workers Organizing Committee, a charter of the American Federation of Labor and Congress of Industrial Organizations. The unification of these two organizations, in an attempt to boycott table grapes which were grown in the Delano fields, resulted in the creation of the United Farm Workers of America.[5] The AFL-CIO chartered the United Farm Workers, officially combining the AWOC and the NFWA, in August 1966.[9]\\r\\nIn the early history of American agriculture, farm workers experienced many failed attempts to organize agricultural laborers. In 1903, Japanese and Mexican farm workers attempted to come together to fight for better wages and better working conditions. This attempt to organize agricultural laborers was ignored and disbanded when organizations, such as the American Federation of Labor, neglected to support their efforts, often withholding assistance on the basis of race.[5]\\r\\nIn 1913, the Industrial Workers of the World organized a rally at a large ranch in the rural area of Northern California which involved two thousand farm workers. This resulted in an attack against the participants of the rally by national guardsmen. As a result of the violence the two lead organizers for the Industrial Workers of the World were arrested, convicted of murder, and were sentenced to life imprisonment. It is believed that the two people arrested were wrongly convicted of the murder charges.[5]\\r\\nIn the later teens and 1920s in the United States, further attempts to organize farm laborers were undertaken by spontaneous local efforts, and some which were led by communist unions. These attempts also resulted in failure because during that time employers were not required by law to involve themselves with negotiations with their workers. During this time period, Employers could also legally fire their employees if they chose to join a union.[3]\\r\\nIn 1936, the National Labor Relations Act was put into effect. This legislation provided most American workers the right to join unions and bargain collectively. Agricultural workers were exempt from the protection of this law. Some believe that this labor category was excluded as a result of a political tactic to gain the support of Southern politicians in the passing of this law.[3]\\r\\nIn 1941, the United States Government and the Mexican Government enacted the Bracero Program. Initially, this joint project between the United States and Mexico was established during the Second World War in order to address labor shortages by allowing \\"guest workers\\" from Mexico to work in the American agricultural industry until the end of the crop harvest. Thousands of Mexican Nationals were brought north to work in the fields in the United States and growers used this opportunity to undercut domestic wages, and the Braceros were also utilized in breaking strikes from resident farm workers. This program was extended until 1964.[3]\\r\\nMany Mexican women in California who joined the UFW in the 1960s were already previously involved in community-based activism in the 1950s through the Community Service Organization for Latino civil rights. The racial discrimination and economic disadvantages they faced from a young age made it necessary to form networks of support like the CSO to empower Latinos in America with voter registration drives, citizenship classes, lawsuits and legislative campaigns, and political protests against police brutality and immigration policies.[10]\\r\\nWhile male activists held leadership roles and more authority, the women activists participated in volunteering and teaching valuable skills to individuals of the Latino community. By the 1960s, Huerta and others began to shift their attention to the labor exploitation of Latino farm workers in California and began to strike, demonstrate, and organize to fight for a myriad of issues that Mexican laborers faced. While many of the male leaders of the movement had the role of being dynamic, powerful speakers that would inspire others to join the movement, the women devoted their efforts to negotiating better working contracts with companies, organizing boycotts, rallying for changes in immigration policies, registering Latinos to vote with Spanish language ballots, and increasing pressure on legislation to improve labor relations.[11]\\r\\nAmong the women who engaged in activism for labor rights, traditional and non traditional patterns of activism existed. Mexican-American women like Dolores Huerta used their education and resources arrange programs at the grassroots level, sustaining and leading members it into the labor movement. As the sister-in-law of Csar Chvez, Huerta co-founded the National Farmworkers Association which would become the United Farm Workers and she had immense influence over the direction that it took, breaking stereotypes of the Mexican woman in the 1960s. However, it was most common for Chicana activists and female labor union members to be involved in administrative tasks for the early stages of UFW; women like Helen Chvez were essential in these responsibilities, such as credit union bookkeeping, behind the scenes and advising her husband. Still, both women along with other Chicana activists participated in picketing with their families in the face of police intimidation and racial abuse.[12] Keeping track of union services and membership were traditionally responsibilities given to female organizers and it was integral to the institutional survival of the UFW, but it has gone much less recognized throughout history due to the male led strikes receiving majority public attention.[13]\\r\\nIn May 1966, California farm worker activist Eugene Nelson traveled to Texas to rally support for the Schenley Farms boycott. While in Houston, AFL-CIO state representatives suggested that he visit Rio Grande City on the Texas-Mexico border in the lower Rio Grande Valley. Seeing the possibilities for organizing workers in the impoverished region, he quickly set about recruiting volunteers for the United Farm Workers Organizing Committee (UFWOC) as both strikers and assistants. Other UFWOC activists joined Nelson in Rio Grande City, including Gilbert Padilla, Antonio Orendain, and Bill Chandler.\\r\\nOn June 1, Nelson led workers to strike demanding $1.25 as a minimum hourly wage, protesting La Casita Farms and others packing sheds. The activists also protested the hiring of \\"scab\\" labor, mostly those with green card visas from Mexico, who were allowed to cross the border as day workers. In the dispute, reports and allegations of vandalism to equipment, produce, and public property caused Starr County officials, along with the support of the growers, to call for additional law enforcement, which arrived in the form of the Texas Rangers. Both county officials and rangers arrested protestors for secondary picketing, standing within 50 feet of one another, a practice illegal at the time. Allegations of brutality and questions of jurisdictional limits created national headlines in what came to be known as \\"La Huelga.\\"\\r\\nOn July 4, members of UFWOC, strikers, and members of the clergy set out on a march to Austin to demand the $1.25 minimum wage and other improvements for farm workers. Press coverage intensified as the marchers made their way north in the summer heat. Politicians, members of the AFL-CIO, and the Texas Council of Churches accompanied the protestors. Gov. John Connally, who had refused to meet them in Austin, traveled to New Braunfels with then House Speaker Ben Barnes, and Attorney General Waggoner Carr to intercept the march and inform strikers that their efforts would have no effect.\\r\\nProtestors arrived in Austin in time for a Labor Day rally, but no changes in law resulted. Strikes and arrests continued in Rio Grande City through 1966 into 1967. Violence increased as the spring melon crop ripened and time neared for the May harvest. In June, when beatings of two UFWOC supporters by Texas rangers surfaced, tempers flared.\\r\\nAt the end of June as the harvest was ending, members of the Senate Subcommittee on Migratory Labor, including Senators Harrison Williams and Edward Kennedy, arrived in the lower Rio Grande Valley to hold hearings in Rio Grande City and Edinburg, Texas. The senators took their findings back to Washington as a report on pending legislation. Subsequently, the rangers left the area and the picketing ended. On September 20, Hurricane Beulah's devastations ruined the farming industry in the Valley for the following year. One major outcome of the strikes came in the form of a 1974 Supreme Court victory in Medrano v. Allee, limiting jurisdiction of Texas Rangers in labor disputes. Farm workers continued to organize through the 1970s on a smaller scale, under new leadership in San Juan, Texas, independent of Csar Chvez.\\r\\nBy mid-1971 the Texas campaign was well underway. In Sept. 1971, Thomas John Wakely, recent discharge from the United States Air Force joined the San Antonio office of the Texas campaign. His pay was room and board, $5.00 a week plus all of the menudo he could eat. The menudo was provided to the UFOC staff by the families of migrant workers working the Texas fields.\\r\\nTJ worked for UFOC for about 2 years and his responsibilities included organizing the Grape Boycott in San Antonio. His primary target was the H.E.B grocery store chain. In addition, he attempted to organize Hispanic farm workers working the farmers market in San Antonio  an institution at that time controlled by the corporate farms. Among his many organizing activities included an early 1972 episode where he and several other UFOC staff members who were attempting to organize warehouse workers in San Antonio were fired upon by security agents of the corporate farm owners.\\r\\nIn mid-1973 the San Antonio office of the UFOC was taken over by the Brown Berets. This radicalization of the San Antonio UFOC office led to the eventual collapse of the San Antonio UFOC organizing campaign.\\r\\nIn 1970, Chavez decided to move the union's headquarters from Delano to La Paz, California into a former sanatorium in the Tehachapi Mountains. Whereas Chavez thought this change would aid the creation of \\"a national union of the poor ... serving the needs of all who suffer,\\" other union members objected to this distancing of the leadership away from the farmworkers.[15]\\r\\nThe union was poised to launch its next major campaign in the lettuce fields in 1970 when a deal between the International Brotherhood of Teamsters and the growers nearly destroyed it. Initially the Teamsters signed contracts with lettuce growers in the Salinas Valley, who wanted to avoid recognizing the UFW. Then in 1973, when the three-year UFW grape contracts expired, the grape growers signed contracts giving the Teamsters the right to represent the workers who had been members of the UFW.\\r\\nThe UFW responded with strikes, lawsuits and boycotts, including secondary boycotts in the retail grocery industry. The union struggled to regain the members it had lost in the lettuce fields; it never fully recovered its strength in grapes, due in some part to incompetent management of the hiring halls it had established that seemed to favor some workers over others.\\r\\nThe battles in the fields became violent, with a number of UFW members killed on the picket line. The violence led the state in 1975 to enact the California Agricultural Labor Relations Act, creating an administrative agency, the ALRB, that oversaw secret ballot elections and resolved charges of unfair labor practices, like failing to bargain in good faith, or discrimination against activists. The UFW won the majority of secret ballot elections in which it participated.[1]\\r\\nIn the late 1970s, the leadership of the UFW was wracked by a series of conflicts, as differences emerged between Chavez and some of his former colleagues.[16] In 1977, the Teamsters signed an agreement with the UFW promising to end their efforts to represent farm workers. [2]\\r\\nIn the 1980s, the membership of the UFW shrank, as did its national prominence.[3] After taking office in the 1980s, California Governor George Deukmejian stopped enforcement of the state's farm labor laws, resulting in farm workers losing their UFW contracts, being fired, and blacklisted.[17] Due to internal squabbles, most of the union's original leadership left or were forced out, except for Chavez and Huerta.[3][16] By 1986, the union had been reduced to 75 contracts and had stopped organizing.[15]\\r\\nIn the 1980s, the UFW joined with the AFL-CIO and other organizations for the national Wrath of Grapes campaign, re-instituting the grape boycott.\\r\\nIn July 2008 the farm worker Ramiro Carrillo Rodriguez, 48, died of a heat stroke. According to United Farm Workers, he was the \\"13th farm worker heat death since CA Governor Schwarzenegger took office\\"[18] in 2003. In 2006 California's first permanent heat regulations were enacted[19] but these regulations were not strictly enforced, the union contended.\\r\\nCsar Chvez is a film released in March, 2014, directed by Diego Luna about the life of the Mexican-American labor leader who co-founded the United Farm Workers. The film stars Michael Pe?a as Chvez. Co-producer John Malkovich also co-stars in the role of an owner of a large industrial grape farm who leads the sometimes violent opposition to Chvez's organizing efforts.\\r\\nThe grape strike officially began in Delano in September 1965. In December, union representatives traveled from California to New York, Washington, D.C., Pittsburg, Detroit, and other large cities to encourage a boycott of grapes grown at ranches without UFW contracts.\\r\\nIn the summer of 1966, unions and religious groups from Seattle and Portland endorsed the boycott. Supporters formed a boycott committee in Vancouver, prompting an outpouring of support from Canadians that would continue throughout the following years.\\r\\nIn 1967, UFW supporters in Oregon began picketing stores in Eugene, Salem, and Portland. After melon workers went on strike in Texas, growers held the first union representation elections in the region, and the UFW became the first union to ever sign a contract with a grower in Texas.\\r\\nNational support for the UFW continued to grow in 1968, and hundreds of UFW members and supporters were arrested. Picketing continued throughout the country, including in Massachusetts, New Jersey, Ohio, Oklahoma, and Florida. The mayors of New York, Baltimore, Philadelphia, Buffalo, Detroit, and other cities pledged their support, and many of them altered their cities grape purchases to support the boycott.\\r\\nIn 1969, support for farm workers increased throughout North America. The grape boycott spread into the South as civil rights groups pressured grocery stores in Atlanta, Miami, New Orleans, Nashville, and Louisville to remove non-union grapes. Student groups in New York protested the Department of Defense and accused them of deliberately purchasing boycotted grapes. On May 10, UFW supporters picketed Safeway stores throughout the U.S. and Canada in celebration of International Grape Boycott Day. Cesar Chavez also went on a speaking tour along the East Coast to ask for support from labor groups, religious groups, and universities.[9]\\r\\nMapping UFW Strikes, Boycotts, and Farm Worker Actions 1965-1975 shows over 1,000 farm worker strikes, boycotts, and other actions.\\r\\nThe UFW during Chavez's tenure was committed to restricting immigration. Chavez and Dolores Huerta, cofounder and president of the UFW, fought the Bracero Program that existed from 1942 to 1964. Their opposition stemmed from their belief that the program undermined U.S. workers and exploited the migrant workers. Since the Bracero Program ensured a constant supply of cheap immigrant labor for growers, immigrants could not protest any infringement of their rights, lest they be fired and replaced. Their efforts contributed to Congress ending the Bracero Program in 1964. In 1973, the UFW was one of the first labor unions to oppose proposed employer sanctions that would have prohibited hiring illegal immigrants.\\r\\nOn a few occasions, concerns that illegal immigrant labor would undermine UFW strike campaigns led to a number of controversial events, which the UFW describes as anti-strikebreaking events, but which have also been interpreted as being anti-immigrant. In 1969, Chavez and members of the UFW marched through the Imperial and Coachella Valleys to the border of Mexico to protest growers' use of illegal immigrants as strikebreakers. In its early years, the UFW and Chavez went so far as to report illegal immigrants who served as strikebreaking replacement workers (as well as those who refused to unionize) to the Immigration and Naturalization Service.[20][21][22][23][24]\\r\\nIn 1973, the United Farm Workers set up a \\"wet line\\" along the United States-Mexico border to prevent Mexican immigrants from entering the United States illegally and potentially undermining the UFW's unionization efforts.[25] During one such event, in which Chavez was not involved, some UFW members, under the guidance of Chavez's cousin Manuel, physically attacked the strikebreakers after peaceful attempts to persuade them not to cross the border failed.[26][27][28]\\r\\nThe United Farm Workers, a working class movement, had received substantial support from the middle class, causing problems of power and control within the union. The UFW gave no structural power to farm workers, as there were no locals elected as staff. The survival of the staff wasn't linked directly to membership, since they made more money from outside sources than union dues. Today, the UFW only consists of five thousand members who work in very similar low conditions as they did 40 years ago.[29] UFW includes undocumented farmworkers as well.\\r\\nThe role of Cesar Chavez, the founder of UFW, was to frame his campaigns in terms of consumer safety and involving social justice, bringing benefits to the farmworker unions. One of UFWs, along with Cesar Chavezs, important aspects that has been overlooked is building coalitions.[30]\\r\\nThe United Farm Workers allows farmworkers to help improve their working conditions and wages. The UFW embraces nonviolence in its attempt to cultivate members on political and social issues.[31]\\r\\nThe union publicly adopted the principles of non-violence championed by Mahatma Gandhi and Dr. Martin Luther King, Jr.\\r\\nOn July 22, 2005, the UFW announced that it was joining the Change to Win Federation, a coalition of labor unions functioning as an alternative to the AFL-CIO. On January 13, 2006, the union officially disaffiliated from the AFL-CIO. In contrast to other Change to Win-affiliated unions, the AFL-CIO neglected to offer the right of affiliation to regional bodies to the UFW.[32]","input":"When did the united farm workers union start?"},{"output":"In the late 9th and 10th centuries","context":"","input":"When did the vikings first invade europes mainland?"},{"output":"nitrogen","context":"The atmosphere of Earth is the layer of gases, commonly known as air, that surrounds the planet Earth and is retained by Earth's gravity. The atmosphere of Earth protects life on Earth by creating pressure allowing for liquid water to exist on the Earth's surface, absorbing ultraviolet solar radiation, warming the surface through heat retention (greenhouse effect), and reducing temperature extremes between day and night (the diurnal temperature variation).\\r\\nBy volume, dry air contains 78.09% nitrogen, 20.95% oxygen,[2] 0.93% argon, 0.04% carbon dioxide, and small amounts of other gases. Air also contains a variable amount of water vapor, on average around 1% at sea level, and 0.4% over the entire atmosphere. Air content and atmospheric pressure vary at different layers, and air suitable for use in photosynthesis by terrestrial plants and breathing of terrestrial animals is found only in Earth's troposphere and in artificial atmospheres.\\r\\nThe atmosphere has a mass of about 5.15G1018?kg,[3] three quarters of which is within about 11?km (6.8?mi; 36,000?ft) of the surface. The atmosphere becomes thinner and thinner with increasing altitude, with no definite boundary between the atmosphere and outer space. The Krmn line, at 100?km (62?mi), or 1.57% of Earth's radius, is often used as the border between the atmosphere and outer space. Atmospheric effects become noticeable during atmospheric reentry of spacecraft at an altitude of around 120?km (75?mi). Several layers can be distinguished in the atmosphere, based on characteristics such as temperature and composition.\\r\\nThe study of Earth's atmosphere and its processes is called atmospheric science (aerology). Early pioneers in the field include Lon Teisserenc de Bort and Richard Assmann.[4]\\r\\n\\r\\n\\r\\nThe three major constituents of Earth's atmosphere, are nitrogen, oxygen, and argon. Water vapor accounts for roughly 0.25% of the atmosphere by mass. The concentration of water vapor (a greenhouse gas) varies significantly from around 10 ppm by volume in the coldest portions of the atmosphere to as much as 5% by volume in hot, humid air masses, and concentrations of other atmospheric gases are typically quoted in terms of dry air (without water vapor).[5] The remaining gases are often referred to as trace gases,[6] among which are the greenhouse gases, principally carbon dioxide, methane, nitrous oxide, and ozone. Filtered air includes trace amounts of many other chemical compounds. Many substances of natural origin may be present in locally and seasonally variable small amounts as aerosols in an unfiltered air sample, including dust of mineral and organic composition, pollen and spores, sea spray, and volcanic ash. Various industrial pollutants also may be present as gases or aerosols, such as chlorine (elemental or in compounds), fluorine compounds and elemental mercury vapor. Sulfur compounds such as hydrogen sulfide and sulfur dioxide (SO2) may be derived from natural sources or from industrial air pollution.\\r\\n(A) volume fraction is equal to mole fraction for ideal gas only,\\r\\n????also see volume (thermodynamics)\\r\\n(B) ppmv: parts per million by volume\\r\\n(C) Water vapor is about 0.25% by mass over full atmosphere\\r\\n(D) Water vapor strongly varies locally[5]\\r\\nThe relative concentration of gasses remains constant until about 10,000?m (33,000?ft).[9]\\r\\nIn general, air pressure and density decrease with altitude in the atmosphere. However, temperature has a more complicated profile with altitude, and may remain relatively constant or even increase with altitude in some regions (see the temperature section, below). Because the general pattern of the temperature/altitude profile is constant and measurable by means of instrumented balloon soundings, the temperature behavior provides a useful metric to distinguish atmospheric layers. In this way, Earth's atmosphere can be divided (called atmospheric stratification) into five main layers. Excluding the exosphere, the atmosphere has four primary layers, which are the troposphere, stratosphere, mesosphere, and thermosphere.[10] From highest to lowest, the five main layers are:\\r\\nThe exosphere is the outermost layer of Earth's atmosphere (i.e. the upper limit of the atmosphere). It extends from the exobase, which is located at the top of the thermosphere at an altitude of about 700?km above sea level, to about 10,000?km (6,200?mi; 33,000,000?ft) where it merges into the solar wind.\\r\\nThis layer is mainly composed of extremely low densities of hydrogen, helium and several heavier molecules including nitrogen, oxygen and carbon dioxide closer to the exobase. The atoms and molecules are so far apart that they can travel hundreds of kilometers without colliding with one another. Thus, the exosphere no longer behaves like a gas, and the particles constantly escape into space. These free-moving particles follow ballistic trajectories and may migrate in and out of the magnetosphere or the solar wind.\\r\\nThe exosphere is located too far above Earth for any meteorological phenomena to be possible. However, the aurora borealis and aurora australis sometimes occur in the lower part of the exosphere, where they overlap into the thermosphere. The exosphere contains most of the satellites orbiting Earth.\\r\\nThe thermosphere is the second-highest layer of Earth's atmosphere. It extends from the mesopause (which separates it from the mesosphere) at an altitude of about 80?km (50?mi; 260,000?ft) up to the thermopause at an altitude range of 500ÿ1000?km (310ÿ620?mi; 1,600,000ÿ3,300,000?ft). The height of the thermopause varies considerably due to changes in solar activity.[11] Because the thermopause lies at the lower boundary of the exosphere, it is also referred to as the exobase. The lower part of the thermosphere, from 80 to 550 kilometres (50 to 342?mi) above Earth's surface, contains the ionosphere.\\r\\nThe temperature of the thermosphere gradually increases with height. Unlike the stratosphere beneath it, wherein a temperature inversion is due to the absorption of radiation by ozone, the inversion in the thermosphere occurs due to the extremely low density of its molecules. The temperature of this layer can rise as high as 1500?C (2700?F), though the gas molecules are so far apart that its temperature in the usual sense is not very meaningful. The air is so rarefied that an individual molecule (of oxygen, for example) travels an average of 1 kilometre (0.62?mi; 3300?ft) between collisions with other molecules.[13] Although the thermosphere has a high proportion of molecules with high energy, it would not feel hot to a human in direct contact, because its density is too low to conduct a significant amount of energy to or from the skin.\\r\\nThis layer is completely cloudless and free of water vapor. However, non-hydrometeorological phenomena such as the aurora borealis and aurora australis are occasionally seen in the thermosphere. The International Space Station orbits in this layer, between 350 and 420?km (220 and 260?mi).\\r\\nThe mesosphere is the third highest layer of Earth's atmosphere, occupying the region above the stratosphere and below the thermosphere. It extends from the stratopause at an altitude of about 50?km (31?mi; 160,000?ft) to the mesopause at 80ÿ85?km (50ÿ53?mi; 260,000ÿ280,000?ft) above sea level.\\r\\nTemperatures drop with increasing altitude to the mesopause that marks the top of this middle layer of the atmosphere. It is the coldest place on Earth and has an average temperature around ?85?C (?120?F; 190?K).[14][15]\\r\\nJust below the mesopause, the air is so cold that even the very scarce water vapor at this altitude can be sublimated into polar-mesospheric noctilucent clouds. These are the highest clouds in the atmosphere and may be visible to the naked eye if sunlight reflects off them about an hour or two after sunset or a similar length of time before sunrise. They are most readily visible when the Sun is around 4 to 16 degrees below the horizon. Lightning-induced discharges known as transient luminous events (TLEs) occasionally form in the mesosphere above tropospheric thunderclouds. The mesosphere is also the layer where most meteors burn up upon atmospheric entrance. It is too high above Earth to be accessible to jet-powered aircraft and balloons, and too low to permit orbital spacecraft. The mesosphere is mainly accessed by sounding rockets and rocket-powered aircraft.\\r\\nThe stratosphere is the second-lowest layer of Earth's atmosphere. It lies above the troposphere and is separated from it by the tropopause. This layer extends from the top of the troposphere at roughly 12?km (7.5?mi; 39,000?ft) above Earth's surface to the stratopause at an altitude of about 50 to 55?km (31 to 34?mi; 164,000 to 180,000?ft).\\r\\nThe atmospheric pressure at the top of the stratosphere is roughly 1/1000 the pressure at sea level. It contains the ozone layer, which is the part of Earth's atmosphere that contains relatively high concentrations of that gas. The stratosphere defines a layer in which temperatures rise with increasing altitude. This rise in temperature is caused by the absorption of ultraviolet radiation (UV) radiation from the Sun by the ozone layer, which restricts turbulence and mixing. Although the temperature may be ?60?C (?76?F; 210?K) at the tropopause, the top of the stratosphere is much warmer, and may be near 0?C.[16]\\r\\nThe stratospheric temperature profile creates very stable atmospheric conditions, so the stratosphere lacks the weather-producing air turbulence that is so prevalent in the troposphere. Consequently, the stratosphere is almost completely free of clouds and other forms of weather. However, polar stratospheric or nacreous clouds are occasionally seen in the lower part of this layer of the atmosphere where the air is coldest. The stratosphere is the highest layer that can be accessed by jet-powered aircraft.\\r\\nThe troposphere is the lowest layer of Earth's atmosphere. It extends from Earth's surface to an average height of about 12?km, although this altitude varies from about 9?km (30,000?ft) at the poles to 17?km (56,000?ft) at the equator,[12] with some variation due to weather. The troposphere is bounded above by the tropopause, a boundary marked in most places by a temperature inversion (i.e. a layer of relatively warm air above a colder one), and in others by a zone which is isothermal with height.[17][18]\\r\\nAlthough variations do occur, the temperature usually declines with increasing altitude in the troposphere because the troposphere is mostly heated through energy transfer from the surface. Thus, the lowest part of the troposphere (i.e. Earth's surface) is typically the warmest section of the troposphere. This promotes vertical mixing (hence the origin of its name in the Greek word ??, tropos, meaning \\"turn\\"). The troposphere contains roughly 80% of the mass of Earth's atmosphere.[19] The troposphere is denser than all its overlying atmospheric layers because a larger atmospheric weight sits on top of the troposphere and causes it to be most severely compressed. Fifty percent of the total mass of the atmosphere is located in the lower 5.6?km (18,000?ft) of the troposphere.\\r\\nNearly all atmospheric water vapor or moisture is found in the troposphere, so it is the layer where most of Earth's weather takes place. It has basically all the weather-associated cloud genus types generated by active wind circulation, although very tall cumulonimbus thunder clouds can penetrate the tropopause from below and rise into the lower part of the stratosphere. Most conventional aviation activity takes place in the troposphere, and it is the only layer that can be accessed by propeller-driven aircraft.\\r\\nWithin the five principal layers that are largely determined by temperature, several secondary layers may be distinguished by other properties:\\r\\nThe average temperature of the atmosphere at Earth's surface is 14?C (57?F; 287?K)[22] or 15?C (59?F; 288?K),[23] depending on the reference.[24][25][26]\\r\\nThe average atmospheric pressure at sea level is defined by the International Standard Atmosphere as 101325 pascals (760.00?Torr; 14.6959?psi; 760.00?mmHg). This is sometimes referred to as a unit of standard atmospheres (atm). Total atmospheric mass is 5.1480G1018 kg (1.135G1019 lb),[28] about 2.5% less than would be inferred from the average sea level pressure and Earth's area of 51007.2 megahectares, this portion being displaced by Earth's mountainous terrain. Atmospheric pressure is the total weight of the air above unit area at the point where the pressure is measured. Thus air pressure varies with location and weather.\\r\\nIf the entire mass of the atmosphere had a uniform density from sea level, it would terminate abruptly at an altitude of 8.50?km (27,900?ft). It actually decreases exponentially with altitude, dropping by half every 5.6?km (18,000?ft) or by a factor of 1/e every 7.64?km (25,100?ft), the average scale height of the atmosphere below 70?km (43?mi; 230,000?ft). However, the atmosphere is more accurately modeled with a customized equation for each layer that takes gradients of temperature, molecular composition, solar radiation and gravity into account.\\r\\nIn summary, the mass of Earth's atmosphere is distributed approximately as follows:[29]\\r\\nBy comparison, the summit of Mt. Everest is at 8,848?m (29,029?ft); commercial airliners typically cruise between 10?km (33,000?ft) and 13?km (43,000?ft) where the thinner air improves fuel economy; weather balloons reach 30.4?km (100,000?ft) and above; and the highest X-15 flight in 1963 reached 108.0?km (354,300?ft).\\r\\nEven above the Krmn line, significant atmospheric effects such as auroras still occur. Meteors begin to glow in this region, though the larger ones may not burn up until they penetrate more deeply. The various layers of Earth's ionosphere, important to HF radio propagation, begin below 100?km and extend beyond 500?km. By comparison, the International Space Station and Space Shuttle typically orbit at 350ÿ400?km, within the F-layer of the ionosphere where they encounter enough atmospheric drag to require reboosts every few months. Depending on solar activity, satellites can experience noticeable atmospheric drag at altitudes as high as 700ÿ800?km.\\r\\nThe division of the atmosphere into layers mostly by reference to temperature is discussed above. Temperature decreases with altitude starting at sea level, but variations in this trend begin above 11?km, where the temperature stabilizes through a large vertical distance through the rest of the troposphere. In the stratosphere, starting above about 20?km, the temperature increases with height, due to heating within the ozone layer caused by capture of significant ultraviolet radiation from the Sun by the dioxygen and ozone gas in this region. Still another region of increasing temperature with altitude occurs at very high altitudes, in the aptly-named thermosphere above 90?km.\\r\\nBecause in an ideal gas of constant composition the speed of sound depends only on temperature and not on the gas pressure or density, the speed of sound in the atmosphere with altitude takes on the form of the complicated temperature profile (see illustration to the right), and does not mirror altitudinal changes in density or pressure.\\r\\nThe density of air at sea level is about 1.2?kg/m3 (1.2?g/L, 0.0012 g/cm3). Density is not measured directly but is calculated from measurements of temperature, pressure and humidity using the equation of state for air (a form of the ideal gas law). Atmospheric density decreases as the altitude increases. This variation can be approximately modeled using the barometric formula. More sophisticated models are used to predict orbital decay of satellites.\\r\\nThe average mass of the atmosphere is about 5 quadrillion (5G1015) tonnes or 1/1,200,000 the mass of Earth. According to the American National Center for Atmospheric Research, \\"The total mean mass of the atmosphere is 5.1480G1018?kg with an annual range due to water vapor of 1.2 or 1.5G1015?kg, depending on whether surface pressure or water vapor data are used; somewhat smaller than the previous estimate. The mean mass of water vapor is estimated as 1.27G1016?kg and the dry air mass as 5.1352 I0.0003G1018?kg.\\"\\r\\nSolar radiation (or sunlight) is the energy Earth receives from the Sun. Earth also emits radiation back into space, but at longer wavelengths that we cannot see. Part of the incoming and emitted radiation is absorbed or reflected by the atmosphere. In May 2017, glints of light, seen as twinkling from an orbiting satellite a million miles away, were found to be reflected light from ice crystals in the atmosphere.[31][32]\\r\\nWhen light passes through Earth's atmosphere, photons interact with it through scattering. If the light does not interact with the atmosphere, it is called direct radiation and is what you see if you were to look directly at the Sun. Indirect radiation is light that has been scattered in the atmosphere. For example, on an overcast day when you cannot see your shadow there is no direct radiation reaching you, it has all been scattered. As another example, due to a phenomenon called Rayleigh scattering, shorter (blue) wavelengths scatter more easily than longer (red) wavelengths. This is why the sky looks blue; you are seeing scattered blue light. This is also why sunsets are red. Because the Sun is close to the horizon, the Sun's rays pass through more atmosphere than normal to reach your eye. Much of the blue light has been scattered out, leaving the red light in a sunset.\\r\\nDifferent molecules absorb different wavelengths of radiation. For example, O2 and O3 absorb almost all wavelengths shorter than 300 nanometers. Water (H2O) absorbs many wavelengths above 700?nm. When a molecule absorbs a photon, it increases the energy of the molecule. This heats the atmosphere, but the atmosphere also cools by emitting radiation, as discussed below.\\r\\nThe combined absorption spectra of the gases in the atmosphere leave \\"windows\\" of low opacity, allowing the transmission of only certain bands of light. The optical window runs from around 300?nm (ultraviolet-C) up into the range humans can see, the visible spectrum (commonly called light), at roughly 400ÿ700?nm and continues to the infrared to around 1100?nm. There are also infrared and radio windows that transmit some infrared and radio waves at longer wavelengths. For example, the radio window runs from about one centimeter to about eleven-meter waves.\\r\\nEmission is the opposite of absorption, it is when an object emits radiation. Objects tend to emit amounts and wavelengths of radiation depending on their \\"black body\\" emission curves, therefore hotter objects tend to emit more radiation, with shorter wavelengths. Colder objects emit less radiation, with longer wavelengths. For example, the Sun is approximately 6,000?K (5,730?C; 10,340?F), its radiation peaks near 500?nm, and is visible to the human eye. Earth is approximately 290?K (17?C; 62?F), so its radiation peaks near 10,000?nm, and is much too long to be visible to humans.\\r\\nBecause of its temperature, the atmosphere emits infrared radiation. For example, on clear nights Earth's surface cools down faster than on cloudy nights. This is because clouds (H2O) are strong absorbers and emitters of infrared radiation. This is also why it becomes colder at night at higher elevations.\\r\\nThe greenhouse effect is directly related to this absorption and emission effect. Some gases in the atmosphere absorb and emit infrared radiation, but do not interact with sunlight in the visible spectrum. Common examples of these are CO2 and H2O.\\r\\nThe refractive index of air is close to, but just greater than 1. Systematic variations in refractive index can lead to the bending of light rays over long optical paths. One example is that, under some circumstances, observers onboard ships can see other vessels just over the horizon because light is refracted in the same direction as the curvature of Earth's surface.\\r\\nThe refractive index of air depends on temperature,[33] giving rise to refraction effects when the temperature gradient is large. An example of such effects is the mirage.\\r\\nAtmospheric circulation is the large-scale movement of air through the troposphere, and the means (with ocean circulation) by which heat is distributed around Earth. The large-scale structure of the atmospheric circulation varies from year to year, but the basic structure remains fairly constant because it is determined by Earth's rotation rate and the difference in solar radiation between the equator and poles.\\r\\nThe first atmosphere consisted of gases in the solar nebula, primarily hydrogen. There were probably simple hydrides such as those now found in the gas giants (Jupiter and Saturn), notably water vapor, methane and ammonia.[34]\\r\\nOutgassing from volcanism, supplemented by gases produced during the late heavy bombardment of Earth by huge asteroids, produced the next atmosphere, consisting largely of nitrogen plus carbon dioxide and inert gases.[34] A major part of carbon-dioxide emissions dissolved in water and reacted with metals such as calcium and magnesium during weathering of crustal rocks to form carbonates that were deposited as sediments. Water-related sediments have been found that date from as early as 3.8 billion years ago.[35]\\r\\nAbout 3.4 billion years ago, nitrogen formed the major part of the then stable \\"second atmosphere\\". The influence of life has to be taken into account rather soon in the history of the atmosphere, because hints of early life-forms appear as early as 3.5 billion years ago.[36] How Earth at that time maintained a climate warm enough for liquid water and life, if the early Sun put out 30% lower solar radiance than today, is a puzzle known as the \\"faint young Sun paradox\\".\\r\\nThe geological record however shows a continuous relatively warm surface during the complete early temperature record of Earth ÿ with the exception of one cold glacial phase about 2.4 billion years ago. In the late Archean Eon an oxygen-containing atmosphere began to develop, apparently produced by photosynthesizing cyanobacteria (see Great Oxygenation Event), which have been found as stromatolite fossils from 2.7 billion years ago. The early basic carbon isotopy (isotope ratio proportions) strongly suggests conditions similar to the current, and that the fundamental features of the carbon cycle became established as early as 4 billion years ago.\\r\\nAncient sediments in the Gabon dating from between about 2,150 and 2,080 million years ago provide a record of Earth's dynamic oxygenation evolution. These fluctuations in oxygenation were likely driven by the Lomagundi carbon isotope excursion.[37]\\r\\nThe constant re-arrangement of continents by plate tectonics influences the long-term evolution of the atmosphere by transferring carbon dioxide to and from large continental carbonate stores. Free oxygen did not exist in the atmosphere until about 2.4 billion years ago during the Great Oxygenation Event and its appearance is indicated by the end of the banded iron formations.\\r\\nBefore this time, any oxygen produced by photosynthesis was consumed by oxidation of reduced materials, notably iron. Molecules of free oxygen did not start to accumulate in the atmosphere until the rate of production of oxygen began to exceed the availability of reducing materials that removed oxygen. This point signifies a shift from a reducing atmosphere to an oxidizing atmosphere. O2 showed major variations until reaching a steady state of more than 15% by the end of the Precambrian.[40] The following time span from 541 million years ago to the present day is the Phanerozoic Eon, during the earliest period of which, the Cambrian, oxygen-requiring metazoan life forms began to appear.\\r\\nThe amount of oxygen in the atmosphere has fluctuated over the last 600 million years, reaching a peak of about 30% around 280 million years ago, significantly higher than today's 21%. Two main processes govern changes in the atmosphere: Plants use carbon dioxide from the atmosphere, releasing oxygen. Breakdown of pyrite and volcanic eruptions release sulfur into the atmosphere, which oxidizes and hence reduces the amount of oxygen in the atmosphere. However, volcanic eruptions also release carbon dioxide, which plants can convert to oxygen. The exact cause of the variation of the amount of oxygen in the atmosphere is not known. Periods with much oxygen in the atmosphere are associated with rapid development of animals. Today's atmosphere contains 21% oxygen, which is great enough for this rapid development of animals.[41]\\r\\nAir pollution is the introduction into the atmosphere of chemicals, particulate matter or biological materials that cause harm or discomfort to organisms.[42] Stratospheric ozone depletion is caused by air pollution, chiefly from chlorofluorocarbons and other ozone-depleting substances.\\r\\nThe scientific consensus is that the anthropogenic greenhouse gases currently accumulating in the atmosphere are the main cause of global warming.[43]\\r\\nOn October 19, 2015 NASA started a website containing daily images of the full sunlit side of Earth on http://epic.gsfc.nasa.gov/. The images are taken from the Deep Space Climate Observatory (DSCOVR) and show Earth as it rotates during a day.[44]","input":"What are the 3 most common gasses in earth's atmosphere?"},{"output":"probably around 8,000 HP","context":"Funny Car is a type of drag racing vehicle and a specific racing class in organized drag racing.  Funny cars are characterized by having tilt-up fiberglass or carbon fiber automotive bodies over a custom-fabricated chassis, giving them an appearance vaguely approximating manufacturers' showroom models.  They also have the engine placed in front of the driver, as opposed to dragsters, which place it behind the driver.[1]\\r\\n\\r\\nFunny car bodies typically reflect the models of newly available cars in the time period that the funny car was built.  For example, in the 1970s, then current models such as the Chevrolet Vega or Plymouth Barracuda were often represented as funny cars, and the bodies represented the Big Three of General Motors, Ford, and Chrysler.[2]  Currently, four manufacturers are represented in National Hot Rod Association (NHRA) Funny Car  Chevrolet with the Camaro,[3] Dodge with the Charger,[4] Ford with the Mustang,[5] and Toyota with the Camry.[6] Worldwide, however, many different body styles are used. These \\"fake\\" body shells are not just cosmetic; they serve an important aerodynamic purpose.[7]\\r\\n\\r\\nToday, fielding a Funny Car team can cost between US$2.6 and US$3 million.[8]  A single carbon fiber body can cost US$70,000.[9]\\r\\n\\r\\nNitro Funny Car racing has never been more competitive than since 2006.[10] The dominance of John Force Racing ended in 2006 and between 2007 and 2015 was equaled by Don Schumacher Racing (DSR), with three TF/FC titles each.[11] Funny Car is dominated by multi-car teams, with only Cruz Pedregon, Jim Dunn, and Tim Wilkerson maintaining the traditional one-car operation.[12]\\r\\n\\r\\nThe NHRA has strict guidelines for funny cars. Most of the rules relate to the engine. In short, the engines can only be V-8s displacing no more than 500 cubic inches (8.19 L). The most popular design is loosely based on the second generation Chrysler 426 Hemi \\"Elephant Engine\\" made from 1964 to 1971.\\r\\n\\r\\nThere can only be two valves per cylinder. The heads are machined from aluminum billet and have no water jackets, as the high latent heat of the methanol in the fuel coupled with the brevity of the run precludes the need for water cooling of the cylinder heads. Superchargers are restricted to a basic Roots type19-inch (480?mm) rotor case width with a breadth of 11.25 inches (286?mm). The rotors are not allowed to have more than a certain amount of helical twist in them so the blower does not become a screw-type supercharger in function. Only single camshafts are allowed. There are two common bore-stroke combinations: 4.1875 by 4.50 inches (106.36?mm G?114.30?mm) (called a 3/4 stroker) and 4.25 by 4.375 inches (108.0?mm G?111.1?mm) (called a 5/8 stroker). The 3/4 stroker is the most common combination used today and equals 496 CID (8.1 L).\\r\\n\\r\\nCrankshafts are CNC machine carved from steel billet then nitrided in an oven to increase surface hardness. Intake valves are titanium and of 2.40-inch (61?mm) width, while exhaust valves are 1.90-inch (48?mm) width of Inconel. Every funny car has ballistic blankets covering the supercharger because this part of the engine is prone to explosion.\\r\\n\\r\\nFunny car fuel systems are key to their immense power. During a single run (starting, burnout, backing up, staging, 1/4 mile) cars can burn as much as 15 US gallons (12?imp?gal; 57?L) of fuel. The fuel mixture is usually 85ÿ90% nitromethane with 10ÿ15% methanol. The ratio of fuel to air can be as high as 1:1. Compression ratios vary from 6:1 to 7:1. The engines in funny cars commonly exhibit varying piston heights and ratios that are determined by the piston's proximity to the air intake. Funny cars have a fixed gear ratio of 3.20:1 and have a reversing gear; power is transmitted from engine to final drive through a multiple staged clutch which provides progressive incremental lockup as the run proceeds. The rate/degree of lockup is mechanically/pneumatically controlled and preset before each run according to various conditions, in particular track surface. Wheelbase is between 100 and 125 inches (2.5 and 3.2?m). The car must maintain a 3-inch (76?mm) ground clearance.\\r\\n\\r\\nHorsepower claims vary widelyfrom 6,978 to 8,897but are probably around 8,000 HP. Supercharged, nitromethane-fueled motors of this type also have a very high torque, which is estimated at about 7,000?ft?lbf (9,500?N?m). They routinely achieve a 6G acceleration from a standing start.\\r\\n\\r\\nMany safety rules are in place to protect the driver and fans. The more visible safety devices are the twin parachutes to help stabilize and decelerate the car after crossing the finish line. Less visible precautions include roll cages and fire extinguishers.\\r\\n\\r\\nDuring safety evaluations in the wake of the fatal crash of Scott Kalitta on June 21, 2008, in Englishtown, N.J., the NHRA reduced the distance of Top Fuel and Funny Car races to 1,000 feet effective July 2, 2008. Pro Stock and sportsman classes still race to 1,320 feet.\\r\\n\\r\\nIn drag racing in the mid-1960s, Top Fuel horsepower began to be combined with bodied cars with altered wheelbases to produce the first \\"funny cars\\" (originally a derisive term).[13] The first funny cars were built in the early to mid-1960s. Funny Car as a class traces its roots to Super Stock, through \\"the intriguingly named Optional Super Stock class\\", to A/Factory Experimental (A/FX), which NHRA introduced in 1962, and ultimately XS (experimental stock).[14]\\r\\n\\r\\nAt the start, the rear tires (\\"slicks\\") were made with a bias-ply construction (\\"wrinklewall\\" slicks had not been invented yet), which meant that grip upon launching was poor. Racers who performed these altered wheelbase modifications found it shifted the center of gravity rearward, which placed more weight on the rear wheels, enhancing traction from these bias-ply slicks. Because of these many obvious modifications they did not look stock, hence the name \\"funny\\".[15] The wheelbases were changed to assist traction for the narrow (7?in (180?mm)-wide) slicks (required by NHRA rules), while keeping the mandatory factory distance between axle centers.[16]\\r\\n\\r\\nThe first of the \\"funny-looking cars\\" were a trio of 1964 Dodge 330 Max Wedges which were named the \\"Dodge Chargers\\". They debuted in March 1964 at San Diego Raceway.[17]  Funny Cars started as stockers, and were, at first, pure exhibition cars, in the Super/Factory Experimental (S/FX) class; NHRA treated them like a passing fad,[18] and tried to \\"legislate them out of existence\\" by placing them in first gas and then fuel dragster classes, with cars of half the weight and twice the horsepower.[19]\\r\\n\\r\\nFunny car success followed the popularity of gassers, the previous favorite doorslammer class.[20]  The precursor of the funny car, appearing almost a decade earlier, was John Bandimere's blown '55 Chevy.[21]  Funny cars were also preceded by the Modified Sport cars, which had fiberglass bodies, tube frames, and supercharged set-back engines even before Super Stock was conceived.[22]  Among the Modified Sport racers to challenge early funny cars was Roger Hardcastle, in an Astra J-5.[23]\\r\\n\\r\\nThe first funny cars were Super Stock 1964 Dodge 330 Max Wedges, named the \\"Dodge Chargers\\", prepared, at the behest of Don Beebe, by Dragmaster's Jim Nelson and Dode Martin.[24] Raced in the Supercharged Experimental Stock (S/XS) class, their original 426 Max Wedges were replaced by stroked 480?cu?in (8?l) Top Gas engines (virtual clones of the Top Gas Dodge Dart engines also built by Dragmaster).[25] (Thus, they were technically \\"funny gassers\\", not fuel cars, unlike the later examples.[26]) Despite their fuel limitations, however, they weree turning in E.T.s in the high 10s, with speeds around 130?mph (210?km/h), when Super Stock and FX cars were only running 11s at about 120?mph (190?km/h), clearly a winning edge.[27] They would also be the first factory cars fitted with parachutes, and the first to see the drivers wear firesuits.[28]\\r\\n\\r\\nThe first major altered-wheelbase car was Dick Landy's class-legal SS/A 1964 Dodge Coronet, which had front and rear axles moved radically forward, a high gasser-style front end and axle, and a 426 hemi.  It moved the rear wheels forward 15?in (380?mm), the front 10?in (250?mm), and 80?lb (36?kg) worth of fiberglass parts (including hood, instrument panel, doors, front fenders, front deck lid, front bumpers)  replaced steel.[29] First appearing at the AHRA Winternationals at Phoenix, Arizona, 29ÿ31 January 1964, the combination improved E.T.s from low 11s with speeds in the 120?mph (190?km/h) range to 10.60s at almost 130?mph (210?km/h).[30]  Only twelve were built.[31]\\r\\n\\r\\nThe three Chargers, wearing a color scheme of red body sides and white roof, hood, and trunk, with two blue longitudinal stripes,[32]  were driven by Jimmy Nix, who previously ran a Top Gas dragster; Jim Johnson, who ran a Dodge Polara stocker, and who had won the B/SA title in 1963; Jim Nelson; and Dode Martin.[33] \\r\\n(Nix tried to persuade Chrisman to get Mercury Racing Director Fran Hernandez to allow him to run his Comet's 427 on nitro, as a way to gain leverage on NHRA, so Nix could use nitro himself).[34]\\r\\n\\r\\nTheir debut was at San Diego Raceway in March 1964, for a three-race exhibition. While in theory all were identical, Nix would change slicks or add lead shot in the trunk of his Dodge 330 to improve traction.[35]\\r\\n\\r\\nThey were shortly turning in E.T.s in the low 11s and trap speeds of over 140?mph (230?km/h); at Long Beach on 21 March, an 11.49 pass at 141.66?mph (227.98?km/h) was recorded.[36]  These cars ran in NHRA's S/FX class, variously defined as \\"Super Factory Experimental\\" or \\"Supercharged Factory Experimental\\".[37]  For their part, the Dodge factory spent only US$250,000 on the inaugural season, insufficient for a single car, let alone three,[38] an amount arranged by promoter Don Beebe, who persuaded Wally Parks safety would not be compromised, promising the cars would be built to Super Stock standard.[39]\\r\\n\\r\\nThree months after the Chargers' debut, the factory-backed Sachs and Sons 1964 Mercury Comet, powered by a supercharged SOHC 427 \\"cammer\\", made its debut, at the 1964 Nationals in Indianapolis.[40]  Driven by Jack Chrisman, and entered in B/FD, the Comet created a sensation.[41]\\r\\n\\r\\nWhen Chrismans Comet first ran in Indy, the Charger program had been waylaid by financial issues and parts shortages. Their final race appearance was at a Greer, South Carolina, dragstrip, in July 1964. Nix, disappointed, went back to TG/D.[42]  Chrismans Comet was placed in the B/Fuel Dragster class at Indianapolis; he was defeated in eliminations, but not before recording a pass of 10.25 seconds at 156.31?mph (251.56?km/h) mph.[43]\\r\\n\\r\\nThe success of these cars inspired other racers to give up class racing for supercharged exhibition cars, led by \\"Arnie Farmer\\" Beswick  and his Pontiac GTO, Gary Dyer's hemi Dodge A/FX (financed by Norm Krause, \\"Mister Norm\\"[44]), and Bob Sullivan's Pandemonium (a '65 Plymouth Barracuda).  Pandemonium joined about six other nitro-fuelled early funny cars facing fuel dragsters in the 1965 season.[45] Dyer's A/FX was the first to have all four of the trademark early funny car features:  altered wheelbase, supercharging, nitromethane fuel, and (then long-since out of production) 392 hemi (rather than the Max Wedges of other Chrysler racers).[46]\\r\\n\\r\\nFunny cars proved enormously popular, with cars driven by Chrisman and Beswick setting track records all over the U.S.[47]  The first wave of funny car development ended around 1965, when bracket racer Jim Liberman and crew chief Lew Arrington made a deal with Pontiac to supply rare hemis (remnants of Mickey Thompson's gas dragster program).  (The duo later switched to Chrysler powerplants.)[48] Two of the Dodge trio would return in 1965 as the Guzler Chargers team, powered by supercharged, nitro-fuelled hemis, with direct drive; both crashed the same year.[49] The popularity of funny car grew that year, with January's AHRA Winternationals seeing seven entrants:  the Ramchargers, Dandy Dick Landy, and Bud Faubel, in Dodges; and Butch Leal, Sox & Martin, the Golden Commandos, and Lee Smith in Plymouths.[50]  By June, the number was over a dozen, including factory Mustangs and Cyclones with 427 cammers.[51]\\r\\n\\r\\nA dedicated funny car class was tried by NHRA at one 1966 national event, and at two in 1968, before Funny Car Eliminator was created in 1969.[52] The trend to flip-top fiberglass bodies (\\"floppers\\") began with Jim Lytle's US$2000 Allison V-1710-powered chopped '34 Tudor Big Al II.[53] It would inspire \\"every flopper body ever formed\\".[54] Chrysler's dominance led Hernandez and Al Turner to try and turn things in Mercury's favor; Don Nichsolson's flip-top, tube-chassis Comet, arriving in 1966, changed everything.[55]  The flopper-bodied Comets were highly successful, in the hands of Chrisman, Kenz and Leslie, and Eddie Schartman; at the 1966 World Final, Schartman would become NHRA's first official Funny Car title winner.[56]\\r\\n\\r\\nTom McEwen, better known for his dragster racing, flirted with funny cars in 1965, as did Lou Barney, a veteran slingshot racer; Barney's hemi-powered, mid-engined Barracuda proved unsafe, before being replaced by another, which turned out to be \\"one of the quickest early match racers\\".[57]  So did Gary Gabelich,[58] probably better known for land speed racing, in the Beach City Chevrolet-sponsored Sting Ray.[59]\\r\\n\\r\\nBefore TF/FC became an official class, funny cars were run as B/FDs and C/FDs (B and C/Fuel Dragster),[60] an odd classification, since they were bodied cars, not dragsters.\\r\\n\\r\\nIn 1965, Ford produced Holman and Moody-built fiberglass-bodied Mustangs for (among others) \\"Gas\\" Ronda, who was the most successful Ford racer.  In 1966, Mercury offered a revolutionary flopper-bodied Comet, as exemplified by Don Nicholson's Eliminator I, which clocked a 7.98 at Detroit Dragway in its debut season, the quickest of the fuel injected cars.[61] The car was built by Logghe Bros. (based in Detroit[62]) (with bodies by Fiberglass Trends), weighing in around 1,700?lb (770?kg), making it heavier than most contemporary top fuel dragsters.[63] (It would be the first Funny Car on the cover of Hot Rod, in April 1966.[64])  Similar cars went to Chrisman, \\"Fast Eddie\\" Schartman, and Kenz and Leslie.[65]  These cars had the first coilover suspension in funny car, and were powered by Hilborn-injected 427 SOHCs producing 1,000?hp (750?kW) on 80% nitro.[66]  (Chrisman's was the oddity, a roadster running a 6-71 GMC supercharger.[67]) They were capable of mid-seven second e.t.s at around 185?mph (298?km/h).[68] Schartman (working with Roy Steffey, on the \\"Flip-Top Fueller\\") would beat Chrisman for Top Funny Car at the NHRA World Finals in 1966 at Tulsa, Oklahoma, with a pass of 8.28 at 174.41?mph (280.69?km/h).[69]  Nicholson would fit a Pete Robinson-built Top Fuel 427 SOHC early in the 1967 season and turn 7.90s at around 180?mph (290?km/h), earning an eighty-six percent winning record.[70]  (The success of the Top Fuel-engined Comets would eventually prompt both Ford and Chrysler to drop funny car sponsorship.)[71]  In 1967, Doug Thorley would record the first (unofficial) 200?mph (320?km/h) funny car pass in his Corvair at Lions.[72]\\r\\n\\r\\nEven in 1965, Ford factory support wavered, since the manufacturer did not build street versions of the radically altered cars; by 1968, pioneering Chrysler was also considering withdrawal.[73]  Of the privateers in this era, Bruce Larson's USA-1 (a '66 Chevelle with a Hilborn-injected 427 and four-speed) was the most successful.[74]  Among other early funny car competitors were Hayden Proffitt, who faced Chrisman at Lions Dragway in 1966 and won in a Hicks and Sublet-chassised Corvair.[75]  Butch Leal would body one of Logghe's first customer chassis with a fiberglass Plymouth Barracuda and run an inected 426 Hemi on 100% nitro; this car's best pass would be a 7.82 at 182.16?mph (293.16?km/h),[76] with a career win ratio of ninety percent.[77] In 1967, Proffitt would take over the failed Grant Rebel SST AMC Rambler, aided by Les Shockley, \\"Famous\\" Amos Satterlee, and Dwight Guild.[78] Gene Conway built the hemi Jeep Destroyer (sponsored by the U.S. Navy), and scored so much success, NHRA banned Jeep funny cars in 1967.[79]\\r\\n\\r\\nLogghe proved unable to keep up with demand for chassis, leading to the creation of a funny car chassis-building industry, which was soon joined by Dick Fletcher, Don Hardy, Ronnie Scrima, and a number of others.[80] Late in 1969, Pat Foster and John Buttera would devise a Top Fuel dragster-style chassis to replace the \\"dune buggy\\" design common at the time. This would go under the Mustang Mach Is of Danny Ongais and Mickey Thompson. Similar chassis would be built by Logghe, Scrima, Buttera, Woody Gilmore, Don Long, and Steve Plueger, among others; this design remains the standard in TF/FC.[81]\\r\\n\\r\\nIn 1968, Thorley would drive a rear-engined Javelin, built by Woody Gilmore, powered by an AMC 401.[82] (This engine would later be replaced by a 392 hemi prepared by John Hoven and Glenn Okazaki.) That same year, Leal would sell his 'cuda to Don Schumacher.[83]\\r\\n\\r\\nNHRA created the new Funny Car (TF/FC) class at the NHRA Winternationals in 1969; Funny Car Eliminator (FCE) would be won by Clare Sanders, teammate of \\"Jungle Jim\\" Liberman.[84] Tragedy struck the same year, with the death of Jerry Schwartz in the ex-Foster Mach I.[85] In a virtually identical car (except the color), Ongais won a number of rounds, with passes frequently in the low sevens at over 182.16?mph (293.16?km/h), including taking Funny Car Eliminator at the USnats.[86] Gene Snow would record the first official 200?mph (320?km/h) pass in the Keith Black-engined, Logghe-chassised 1969 Dodge Charger, Rambunctious.[87] One of the most famous (and popular) funny cars in NHRA history would appear in 1969:  Chi-Town Hustler, a Charger prepared by Fakonas and Coil (driven by Pat Minnick).[88]\\r\\n\\r\\nAnother Funny Car record was set in 1970 by Leroy Goldstein, then testing Firestone tires, with a 6.99 pass at Capitol Raceway, Funny Car's first under seven seconds.[89] By November, Jake Johnson in the hemi-powered Blue Max (driving for Harry Schmidt) turned in a 6.72 at 218?mph (351?km/h), at OCIR.[90] The big news that year was the creation of Mattel Hot Wheels-sponsored team of Don Prudhomme and Tom McEwen.[91]\\r\\n\\r\\nDon Garlits' 1971 accident in Top Fuel Dragster, which led to the creation of the revolutionary Swamp Rat XIV, did not produce the same kind of change in Funny Car, though there had been a number of rear-engined examples, including Thorley's Javelin and Dave Bowmans California Stud, which was the most successful of the rear-engined funny cars.[92]\\r\\n\\r\\nThe Funny Car Eliminator title at the 1971 Winternats would go to Roland Leong's Charger, Hawaiian.[93]\\r\\n\\r\\nAt the 1972 Supernationals, Jim Dunn recorded a historic win in his Barracuda, the first, and only, one by a mid-engined funny car.[94]\\r\\n\\r\\nIn 1973, Shirley Muldowney teamed up with Connie Kalitta as the Bounty Hunter and Bounty Huntress, in a pair of Ford Mustangs, hers a Buttera chassis, his a Logghe.[95]\\r\\n\\r\\nBetween 1973 and 1975, Ed McCullough would score eighteen wins at NHRA national events in the Revell-sponsored Dodge Dart, Revelloution.[96]\\r\\n\\r\\nShirl Greer would defeat Prudhomme in the final in 1974 to take the first NHRA Funny Car World Championship.[97] He would suffer severe burns in the final after an engine exploded.[98]\\r\\n\\r\\nIn 1975, Raymond Beadle and Harry Schmidt resurrected the Blue Max; built by Tony Casarez Race Cars, the Mustang II would win at Indianapolis.  Beadle later bought out Schmidt and went on to seven funny car national titles, four with NHRA, three with IHRA.[99]\\r\\n\\r\\nMark Oswald, driving for Candies and Hughes (with Old Milwaukee sponsorship[100]), in 1984 did something no other driver has:  he won both the NHRA and IHRA world championships.[101] The team took four IHRA titles between 1983 and 1987, including two in a row, 1986 and 1987, as well as beating John Force in the 1986 Big Bud Shootout (losing to him the next year).[102]\\r\\n\\r\\nForce between 1987 and 1996 won sixty-seven of 203 NHRA national events, four of nine Big Bud Shootouts, and six World Championships.[103] In 1996, with Austin Coil tuning, Force went to the final round in sixteen of nineteen national events, taking thirteen wins, one of the best records ever in Funny Car history.[104] Force's domination in 1989 would only really be challenged by Bruce Larson, a long-time East Coast match racer, with Outlaw sprint car driver Maynard Yingst as his tuner, winning six events and taking the runner-up spot five times, in an Oldsmobile sponsored by Sentry.[105]  In 1992, the honor of putting Force on the trailer would go to Cruz Pedregon, driving the Larry Minor McDonald's-sponsored Olds to the championship.[106]  Pedregon was also one of the first Funny Car drivers to clock a five-second e.t.[107]\\r\\n\\r\\nEd McCulloch in 1988 would claim the US$100,000 prize for winning both IHRA TF/FC events at Texas Motorplex; Eddie Hill would do the same in TFD that year. (Billy Meyer, who owned IRHA and offered the prize, would sell at season's end.)[108]\\r\\n\\r\\nKenny Bernstein and tuner Dale Armstrong would turn to land speed racers the Arivett brothers to design Bernstein's car in 1989.[109]  This car would be dubbed the \\"Batmobile\\".[110] It would profoundly change Funny Car aerodynamics.[111]\\r\\n\\r\\nIn 1991, Jim White, driving for Leong, turned in two of the fastest Funny Car passes to date, at over 290?mph (470?km/h), and placed second to Force in the championship.[112]\\r\\n\\r\\nAl and Helen Hoffman, with tuner Tom Anderson, \\"were the antithesis of the corporate button-down shirt racers\\".[113] Sponsored by BDS,[114] between 1991 and 1995, Hoffman earned eleven national event wins, as well as the 1991 Winston Invitational and the Big Bud Shootout in 1991, 1994, and 1995.[115]\\r\\n\\r\\nTom McEwen would build his \\"gorgeous\\" replica '57 Funny Car, running it as an NHRA exhibition vehicle and creating Nostalgia Funny Car, even though the car would not (now) be legal in that class.[116]\\r\\n\\r\\nMajor corporate sponsorship money came to Funny Car starting in 1997, leading to significant changes in the sport.  Multi-car teams, with several tuners each, became commonplace, and single car teams \\"had a very slim chance of winning an NHRA World Championship\\".[117] Force's domination would continue, with ten NHRA FC World Championship wins from 1993 to 2002, including six straight 1997-2002; his success was so amazing, he was accused of cheating (and was willing to strip off his firesuit to prove he was not).[118] Between 1997 and 2006, Force went to the final in 105 of 228 events and took sixty-one tour wins, as well as qualifying for all ten Big Bud Shootouts, winning in 2000 and 2006. Between 1997 and 2006, Force went to the final in 105 of 228 events and took sixty-one tour wins.[119]   On top of that, he had ten of the quickest or fastest passes in Funny Car.[120]\\r\\n\\r\\nIn recent years, a resurgence of interest in vintage drag cars has created many new \\"nostalgia\\" funny cars, which are newly made vintage-style funny car bodies mounted on modern funny car frames or, in certain cases, newly built frames that look close to the originals and are made NHRA legal. These \\"Nostalgia Funny Cars\\" often compete in various nostalgia drag racing events, such as the NHRA Heritage Hot Rod Racing Series, which includes the National Hot Rod Reunion and the California Hot Rod Reunion.\\r\\n\\r\\nIn 2007, NHRA limited technical innovation in Funny Car, as well as introducing a 1,000?ft (300?m) track length and restrictions on maximum engine revs.[121]\\r\\n\\r\\nNitro Funny Car racing has never been more competitive than since 2006.[122] The dominance of John Force Racing ended in 2006 and between 2007 and 2015 was equalled by DSR, with three TF/FC titles each.[123] Funny Car is dominated by multi-car teams, with only Cruz Pedregon, Jim Dunn, and Tim Wilkerson maintaining the traditional one-car operation.[124]\\r\\n\\r\\nCurrently, John Force is the driver in the Funny Car class with the most wins, having 16 championships, over 1,000 round wins and over 145 National Event wins. He is also the owner with the most funny car championships with 19, since Tony Pedregon (2003) and Robert Hight (2009&2017) have won three titles while on his team. Force's former crew chief, Austin Coil, also has logged the highest number of wins in that position.","input":"How much hp does a nitro funny car have?"},{"output":"the 16th century","context":"\\r\\n\\r\\nHorses in the United States have significant popularity and status that is acknowledged by a number of observers and researchers. There are about 9.2 million horses in the country[1] and 4.6 million citizens are involved in the horse business.[2][3] In addition, there are about 82,000[4] wild horses that roam freely in a wild state in certain parts of the country.\\r\\n\\r\\nThe horse evolved in the Americas, but became extinct between 8,000 and 12,000 years ago.  When the Spanish arrived on the American mainland in the 16th century, they brought horses with them and re-established the animals on the continent.\\r\\n\\r\\nFossils of the earliest direct ancestor to the modern horse, Eohippus have been found in the Eocene layers of North American strata, mainly in the Wind River basin in Wyoming.[5] Fossils found at the Hagerman Fossil Beds in Idaho, called the Hagerman horse or Equus simplicidens are from the Pliocene, dating to about 3.5 million years ago (mya). Paleontologists determined the fossils represented the oldest remains of the genus Equus.[6] The genus Equus, which includes all extant equines, was plentiful in North America and spread into the Old World by about 2.5 mya.[7]\\r\\n\\r\\nA 2005 genetic study of fossils found evidence for three genetically divergent equid lineages in Pleistocene North and South America.[8][9] Recent studies suggest all North American fossils of caballine-type horses, including both the domesticated horse and Przewalski's horse,[9] belong to the same species: E. ferus. Remains attributed to a variety of species and lumped as New World stilt-legged horses probably all belong to a second closely related species that was endemic to North America.[8] Digs in western Canada have unearthed clear evidence horses existed in North America as recently as 12,000 years ago.[10] Other studies produced evidence that horses in the Americas existed until 8,000ÿ10,000 years ago.[7]\\r\\n\\r\\nAlthough one somewhat obscure hypothesis posits that horses survived the ice age in North America, [11] all Equidae in North America ultimately became extinct, along with several other megafauna. The causes of this extinction have been debated. Given the suddenness of the event and because these mammals had been flourishing for millions of years previously, something quite unusual must have happened. The first main hypothesis attributes extinction to climate change. For example, in Alaska, beginning approximately 12,500 years ago, the grasses characteristic of a steppe ecosystem gave way to shrub tundra, which was covered with unpalatable plants.[12][13] However, it has been proposed that the steppe-tundra vegetation transition in Beringia may have been a consequence, rather than a cause, of the extinction of megafaunal grazers.[14]\\r\\n\\r\\nThe other hypothesis suggests extinction was linked to overexploitation of native prey by newly arrived humans. The extinctions were roughly simultaneous with the end of the most recent glacial advance and the appearance of the big game-hunting Clovis culture.[15][16] Several studies have indicated humans probably arrived in Alaska at the same time or shortly before the local extinction of horses.[16][17][18]\\r\\n\\r\\nHorses returned to the Americas thousands of years later, well after domestication of the horse, beginning with Christopher Columbus in 1493. These were Iberian horses first brought to Hispaniola and later to Panama, Mexico, Brazil, Peru, Argentina, and, in 1538, Florida.[19] The first horses to return to the main continent were 16 specifically identified horses brought by Hernn Corts in 1519. Subsequent explorers, such as Coronado and De Soto brought ever-larger numbers, some from Spain and others from breeding establishments set up by the Spanish in the Caribbean.[20]\\r\\n\\r\\nThese domesticated horses were the ancestral stock of the group of breeds or strains known today as the Colonial Spanish Horse.  They predominated through the southeast and western United States from 16th century until about 1850, when crossbreeding with larger horse breeds changed the phenotype and diluted the Spanish bloodlines.[21] Later, some horses became strayed, lost or stolen, and proliferated into large herds of feral horses that became known as mustangs.[20]  Modern domesticated horses that retain Colonial Spanish type include the Spanish Mustang, Choctaw horse,  Florida Cracker horse, and the Marsh Tacky.[22]\\r\\n\\r\\nEuropean settlers brought a variety of horses to the Americas.  The first imports were smaller animals suited to the size restrictions imposed by ships.  Starting in the mid-19th century, larger draft horses began to be imported, and by the 1880s, thousands had arrived.[23] Formal horse racing in the United States dates back to 1665, when a racecourse was opened on the Hempstead Plains near Salisbury in what is now  Nassau County, New York[24]\\r\\n\\r\\nThere are multiple theories for how Native American people obtained horses from the Spanish, but early capture of stray horses during the 16th century was unlikely due to the need to simultaneously acquire the skills to ride and manage them.  It is unlikely that Native people obtained horses in significant numbers to become a horse culture any earlier than 1630ÿ1650.  From a trade center in the Santa Fe, New Mexico area, the horse spread slowly north.[25] The Comanche people were thought to be among the first tribes to obtain horses and use them successfully.[26]  By 1742, there were reports that the Crow and Blackfoot people had horses.[25]  The horse became an integral part of the lives and culture of Native Americans, especially the Plains Indians, who viewed them as a source of wealth and used them for hunting, travel, and warfare.[27]\\r\\n\\r\\nIn the 19th century, horses were used for many jobs.  In the west, they were ridden by cowboys for handling cattle on the large ranches of the region and on cattle drives.[28]  In cities, including transporting people via carriage and horse-drawn public transport. They were used for hauling freight and for farming.   In some cases, their labor was deemed more efficient than using steam-powered equipment to power certain types of mechanized equipment.  At the same time, the maltreatment of horses in cities such as New York, where over 130,000 horses were used, led to the creation of the first ASPCA in 1866.[29] In the 19th century, the Standardbred breed of harness racing horse developed in the United States,[30] and many Thoroughbred horse races were established.\\r\\n\\r\\nAt the start of the 20th century, the United States Department of Agriculture began to establish breeding farms for research, to preserve American horse breeds,  and to develop horses for military and agricultural purposes.[23]  However, after the end of World War I, the increased use of mechanized transportation resulted in a decline in the horse populations, with a 1926 report noting horse prices were the lowest they had been in 60 years.[31]  Horse numbers rebounded in the 1960s, as horses came to be used for recreational purposes.[32]\\r\\n\\r\\nIn 1912, the United States and Russia held the most horses in the world, with the U.S. having the second-highest number.[33] There were an estimated of 20 million horses in March 1915 in the United States.[34] A USDA census in 1959 showed the horse population had dropped to 4.5 million.  Numbers began to rebound somewhat, and by 1968 there were about 7 million horses, mostly used for riding.[32] In 2005, there were about 9 million horses.[35]\\r\\n\\r\\nThere are about 82,000 feral horses in the western United States under the supervision of the Bureau of Land Management.[36]  Additional feral horse populations exist elsewhere in the United States, especially on several islands off the Atlantic coast, where the National Park Service oversees populations of the Banker horse in North Carolina,[37] the Cumberland Island horse in Georgia,[38] and the horses on the Maryland side of Assateague Island, home to the Chincoteague pony.[39] In Canada, a similar Atlantic population is the Sable Island horse of Nova Scotia.[40]","input":"When were horses first introduced to north america?"},{"output":"July 2010","context":"The Glock pistol, sometimes referred to by the manufacturer as a Glock \\"Safe Action\\" pistol and colloquially as a Glock, is a series of polymer-framed, short recoil-operated, locked-breech semi-automatic pistols designed and produced by Glock Ges.m.b.H., located in Deutsch-Wagram, Austria. It entered Austrian military and police service by 1982 after it was the top performer on an exhaustive series of reliability and safety tests.[5]\\r\\nDespite initial resistance from the market to accept a perceived \\"plastic gun\\" due to unfounded durability and reliability concerns and fears that it might circumvent metal detectors in airports, Glock pistols have become the company's most profitable line of products, commanding 65% of the market share of handguns for United States law enforcement agencies, as well as supplying numerous national armed forces, security agencies, and police forces in at least 48 countries.[6] Glocks are also popular firearms among civilians for recreational and competition shooting, home and self-defense, and concealed carry or open carry.[7]\\r\\nThe company's founder, engineer Gaston Glock, had no experience with firearms design or manufacture at the time their first pistol, the Glock 17, was being prototyped. Glock did, however, have extensive experience in advanced synthetic polymers, knowledge of which was instrumental in the company's design of the first commercially successful line of pistols with a polymer frame.[8] Glock introduced ferritic nitrocarburizing into the firearms industry as an anticorrosion surface treatment for metal gun parts.[9]\\r\\nIn 1980, the Austrian military announced that it would seek tenders for a new, modern duty pistol to replace their World War II-era Walther P38 handguns.[10] The Austrian Ministry of Defence formulated a list of 17 criteria for the new generation service pistol:[5]\\r\\nGlock became aware of the Austrian Army's planned procurement, and in 1982 assembled a team of Europe's leading handgun experts from military, police, and civilian sport-shooting circles to define the most desirable characteristics in a combat pistol.[5] Within three months, Glock developed a working prototype that combined proven mechanisms and traits from previous pistol designs.[12] In addition the plan was to make extensive use of synthetic materials and modern manufacturing technologies, to make it a very cost-effective candidate.\\r\\nSeveral samples of the 9G19mm Glock 17 (so named because it was the 17th patent procured by the company[13]) were submitted for assessment trials in early 1982, and after passing all of the exhaustive endurance and abuse tests, the Glock emerged as the winner.[14][15][16]\\r\\nThe handgun was adopted into service with the Austrian military and police forces in 1982 as the P80 (Pistole 80),[17] with an initial order for 25,000 guns.[12] The Glock 17 outperformed eight different pistols from five other established manufacturers (Heckler & Koch of Germany offered their P7M8, P7M13, and P9S, SIG Sauer of Switzerland bid with their P220 and P226 models, Beretta of Italy submitted their model 92SB-F, FN Herstal proposed an updated variant of the Browning Hi-Power, and the home-grown Steyr Mannlicher entered the competition with the GB).[18]\\r\\nThe results of the Austrian trials sparked a wave of interest in Western Europe and overseas, particularly in the United States, where a similar effort to select a service-wide replacement for the M1911 had been going on since the late 1970s (known as the Joint Service Small Arms Program). In late 1983, the United States Department of Defense inquired about the Glock pistol and received four samples of the Glock 17 for unofficial evaluation.[19] Glock was then invited to participate in the XM9 Personal Defense Pistol Trials, but declined because the DOD specifications would require extensive retooling of production equipment and providing 35 test samples in an unrealistic time frame.[19]\\r\\nShortly thereafter, the Glock 17 was accepted into service with the Norwegian and Swedish armed forces, surpassing all prior NATO durability standards.[19] As a result, the Glock 17 became a standard NATO-classified sidearm and was granted a NATO stock number (1005-25-133-6775).[19]\\r\\nBy 1992, some 350,000 pistols had been sold in more than 45 countries, including 250,000 in the United States alone.[17]\\r\\nStarting in 2013 the British Army is replacing the Browning Hi-Power pistol with the Glock 17 Gen 4, due to concerns about weight and the external safety of the Hi-Power.[20]\\r\\nGlock has updated its basic design several times throughout its production history. Commentators had long separated the large changes into generations. Glock eventually accepted this nomenclature with their \\"Gen4\\" models.\\r\\nA mid-life upgrade to the Glock pistols involved the addition of checkering on the front strap and serrations to the back strap. These versions, introduced in 1988, were informally referred to as \\"second-generation\\" models. To meet American ATF regulations, a steel plate with a stamped serial number was embedded into the receiver in front of the trigger guard.\\r\\nIn 1991, an integrated recoil spring assembly replaced the original two-piece recoil spring and tube design. The magazine was slightly modified, changing the floorplate and fitting the follower spring with a resistance insert at its base.\\r\\nIn 1998, the frame was further modified with an accessory rail (called the \\"Universal Glock rail\\") to allow the mounting of laser sights, tactical lights, and other accessories. Thumb rests on both sides of the frame and finger grooves on the front strap were added. Glock pistols with these upgrades are informally referred to as (early) \\"third-generation\\" models. Later third-generation models additionally featured a modified extractor that serves as a loaded chamber indicator, and the locking block was enlarged, along with the addition of an extra cross pin to aid the distribution of bolt thrust forces exerted by the locking block. This cross pin is known as the locking block pin and is located above the trigger pin.[21]\\r\\nThe polymer frames of third-generation models can be black, flat dark earth, or olive drab. Besides that, non-firing dummy pistols (\\"P\\" models) and non-firing dummy pistols with resetting triggers (\\"R\\" models) have a bright red frame and Simunition-adapted practice pistols (\\"T\\" models) ÿ a bright blue frame for easy identification.[22]\\r\\nIn 2009, the Glock 22 RTF2 (Rough Textured Frame 2) (chambered in .40 S&W) was introduced. This pistol featured a new checkering texture around the grip and new scalloped (fish gill-shaped) serrations at the rear of the sides of the slide.[23][24] Many of the existing models became available in the RTF2 version, including the 31, 32, 23, 21, 19. Some of those did not have the fish gills.\\r\\nAt the 2010 SHOT Show, Glock presented the \\"fourth generation\\", now dubbed \\"Gen4\\" by Glock itself. Updates centered on ergonomics and the recoil spring assembly. Some parts of fourth-generation Glock pistols cannot be interchanged with those of the previous generations. The initial two fourth-generation models announced were the full-sized Glock 17 and Glock 22, chambered for the 9G19?mm Parabellum and .40 S&W cartridges, respectively. The pistols were displayed with a modified rough-textured frame, grip checkering, and interchangeable backstraps of different sizes. \\"Gen4\\" is rollmarked on the slide next to the model number to identify the fourth-generation pistols.\\r\\nThe basic grip size of the fourth-generation Glock pistols is slightly smaller compared to the previous design. A punch is provided to remove the standard trigger housing pin and replace it with the longer cross pin needed to mount the medium or large backstrap that will increase the trigger distance by 2?mm (0.079?in) or 4?mm (0.16?in). With the medium backstrap installed, the grip size is identical to the third-generation pistols. The magazine release catches are enlarged and reversible for left-handed use. To use the exchangeable magazine release feature, fourth-generation Glock magazines have a notch cut on both sides of the magazine body. Earlier versions of the magazines will not lock into the Gen4 pistols if the user has moved the magazine release button to be operated by a left-handed user. Gen4 magazines will work in older models.[25][26][non-primary source needed]\\r\\nMechanically, fourth-generation Glock pistols are fitted with a dual recoil spring assembly to help reduce perceived recoil and increase service life expectancy. Earlier subcompact Glock models such as the Glock 26 and Glock 30 have already used a dual recoil spring assembly which was carried over to the fourth-generation versions of those models. The slide and barrel shelf have been resized, and the front portion of the polymer frame has been widened and internally enlarged, to accommodate the dual recoil spring assembly. The trigger mechanism housing has also been modified to fit into the smaller-sized grip space.[27][28][29][30][31]\\r\\nThe introduction of fourth-generation Glock pistols continued in July 2010 when the Glock 19 and Glock 23, the reduced size \\"compact\\" versions of the Glock 17 and Glock 22, became available for retail.[32] In late 2010, Glock continued the introduction of fourth-generation models with the Glock 26 and Glock 27 \\"subcompact\\" variants.\\r\\nIn January 2013, more fourth-generation Glock pistols were introduced commercially during the annual SHOT Show, including the Glock 20 Generation 4 along with other fourth-generation Glock models.\\r\\nIn September 2011, Glock announced a recoil spring exchange program in which the manufacturer voluntarily offers to exchange the recoil spring assemblies of its fourth-generation pistols (with the exception of the \\"subcompact\\" Glock 26 and Glock 27 models) sold before 22 July 2011 at no cost \\"to ensure our products perform up to GLOCKs stringent standards\\", according to the company.[33]\\r\\nOn 29 June 2016 the United States Federal Bureau of Investigation (FBI) awarded a contract to Glock to provide new 9G19mm Parabellum chambered duty pistols.[34] The solicitation specifications deviated from the specifications of Glock fourth-generation models.[35]\\r\\nIn August 2016 the Indianapolis Metro Police Department (IMPD) started training with a batch of Glock 17M pistols. The most obvious difference with the Glock third and fourth-generation models on published images is the omission of finger grooves on the grip.[36] The IMPD issued a Glock 17M voluntary recall following failures encountered while dry firing the pistols during training. According to Major Riddle with the IMPD; \\"Glock is working to correct the problem and we hope to begin issuing the new [17Ms] as soon as December\\".[37][38]\\r\\nIn August 2017, Glock presented the \\"fifth generation\\" or \\"Gen5\\". The revisions centered on ergonomics and improving reliability. Many parts of fifth-generation Glock pistols cannot be interchanged with those of the previous generations. The two fifth-generation models announced were the Glock 17 and Glock 19, chambered for the 9G19?mm Parabellum. Some conspicuous changes on the fifth-generation models are: nDLC (Diamond-Like Carbon) surface finish for barrel and slide, new barrel rifling and a deeper rtecessed barrle crown, omission of the finger grooves on the grip, a reintroduction of a cutout on the bottom front of the grip, ambidextrous slide stop lever, and a flared magazine well. The locking block pin located above the trigger pin that was introduced in the third-generation is omitted. Many internal parts were less conspicuous revised.[39][40][41][42][43] \\"Gen 5\\" is rollmarked on the slide next to the model number to identify the fifth-generation pistols. The magazines were also revised for the fifth-generation models. The redesigned magazine floor plates feature a frontward protruding lip to offer grip for manual assisted extraction and the magazine follower became orange colored for easier visual identification.\\r\\nThe Glock 17 is a 9 mm short recoilÿoperated, locked-breech semi-automatic pistol that uses a modified Browning cam-lock system adapted from the Hi-Power pistol.[44] The firearm's locking mechanism uses a linkless, vertically tilting barrel with a rectangular breech that locks into the ejection port cut-out in the slide. During the recoil stroke, the barrel moves rearward initially locked together with the slide about 3?mm (0.12?in) until the bullet leaves the barrel and chamber pressure drops to a safe level. A ramped lug extension at the base of the barrel then interacts with a tapered locking block integrated into the frame, forcing the barrel down and unlocking it from the slide. This camming action terminates the barrel's movement while the slide continues back under recoil, extracting and ejecting the spent cartridge casing. The slide's uninterrupted rearward movement and counter-recoil cycle are characteristic of the Browning system.[45]\\r\\nThe slide features a spring-loaded claw extractor, and the stamped sheet metal ejector is pinned to the trigger mechanism housing.[46] Pistols after 2002 have a reshaped extractor that serves as a loaded chamber indicator. When a cartridge is present in the chamber, a tactile metal edge protrudes slightly out immediately behind the ejection port on the right side of the slide.[47] The striker firing mechanism has a spring-loaded firing pin that is cocked in two stages that the firing pin spring powers. The factory-standard firing pin spring is rated at 24?N (5.4?lbf), but by using a modified firing pin spring, it can be increased to 28?N (6.3?lbf) or to 31?N (7.0?lbf).[26] When the pistol is charged, the firing pin is in the half-cock position. As the trigger is pulled, the firing pin is then fully cocked. At the end of its travel, the trigger bar is tilted downward by the connector, releasing the firing pin to fire the cartridge. The connector resets the trigger bar so that the firing pin will be captured in half-cock at the end of the firing cycle. This is known as a preset trigger mechanism, referred to as the \\"Safe Action\\" trigger by the manufacturer. The connector ensures the pistol can only fire semiautomatically.\\r\\nThe factory-standard, two-stage trigger has a trigger travel of 12.5?mm (0.49?in) and is rated at 25?N (5.6?lbf), but by using a modified connector, it can be increased to 35?N (7.9?lbf) or lowered to 20?N (4.5?lbf). In response to a request made by American law enforcement agencies for a two-stage trigger with increased trigger pull, Glock introduced the NY1 (New York) trigger module, which features a flat spring in a plastic housing that replaces the trigger bar's standard coil spring. This trigger modification is available in two versions: NY1 and NY2 that are rated at 25?N (5.6?lbf) to 40?N (9.0?lbf) and 32?N (7.2?lbf) to 50?N (11.2?lbf), respectively, which require about 20?N (4.5?lbf) to 30?N (6.7?lbf) of force to disengage the safeties and another 10?N (2.2?lbf) to 20?N (4.5?lbf) in the second stage to fire a shot.\\r\\nThe Glock's frame, magazine body, and several other components are made from a high-strength nylon-based polymer invented by Gaston Glock, called Polymer 2.[48] This plastic was specially formulated to provide increased durability and is more resilient than carbon steel and most steel alloys. Polymer 2 is resistant to shock, caustic liquids, and temperature extremes where traditional steel/alloy frames would warp and become brittle.[48] The injection-molded frame contains four hardened steel guide rails for the slide: two at the rear of the frame, and the remaining pair above and in front of the trigger guard. The trigger guard itself is squared off at the front and checkered. The grip has an angle of 109 and a nonslip, stippled surface on the sides and both the front and rear straps.[49] The frame houses the locking block, which is an investment casting that engages a 45 camming surface on the barrel's lower camming lug. It is retained in the frame by a steel axis pin that holds the trigger and slide catch. The trigger housing is held to the frame by means of a polymer pin. A spring-loaded sheet-metal pressing serves as the slide catch, which is secured from unintentional manipulation by a raised guard molded into the frame.\\r\\nThe Glock pistol has a relatively low slide profile, which holds the barrel axis close to the shooter's hand and makes the pistol more comfortable to fire by reducing muzzle rise and allows for faster aim recovery in rapid firing sequences. The rectangular slide is milled from a single block of ordnance-grade steel using CNC machinery.[50] The barrel and slide undergo two hardening processes prior to treatment with a proprietary nitriding process called Tenifer. The Tenifer treatment is applied in a 500?C (932?F) nitrate bath.[48] The Tenifer finish is between 0.04 and 0.05?mm (0.0016 and 0.0020?in) in thickness, and is characterized by extreme resistance to wear and corrosion; it penetrates the metal, and treated parts have similar properties even below the surface to a certain depth.[51]\\r\\nThe Tenifer process produces a matte gray-colored, nonglare surface with a 64 Rockwell C hardness rating and a 99% resistance to salt water corrosion (which meets or exceeds stainless steel specifications),[50] making the Glock particularly suitable for individuals carrying the pistol concealed as the highly chloride-resistant finish allows the pistol to better endure the effects of perspiration.[51] Glock steel parts using the Tenifer treatment are more corrosion resistant than analogous gun parts having other finishes or treatments, including Teflon, bluing, hard chrome plating, or phosphates.[51] During 2010 Glock switched from the salt bath nitriding Tenifer process to a not exactly disclosed gas nitriding process. After applying the nitriding process, a black Parkerized decorative surface finish is applied. The underlying nitriding treatment will remain, protecting these parts even if the decorative surface finish were to wear off.[9]\\r\\nA current production Glock 17 consists of 34 parts.[26] For maintenance, the pistol disassembles into five main groups: the barrel, slide, frame, magazine, and recoil-spring assembly. The firearm is designed for the NATO-standard 9G19mm Parabellum pistol cartridge, but can use high-power (increased pressure) +P and +P+ ammunition with either full-metal-jacket or jacketed hollow-point projectiles.\\r\\nThe hammer-forged barrel has a female type polygonal rifling with a right-hand twist. The stabilization of the round is not by conventional rifling, using lands and grooves, but rather through a polygonal profile consisting of a series of six or eight interconnected noncircular segments (only the .45 ACP and .45 GAP have octagonal polygonal rifling). Each depressed segment within the interior of the barrel is the equivalent of a groove in a conventional barrel. Thus, the interior of the barrel consists of smooth arcs of steel rather than sharply defined slots.\\r\\nThe method by which Glock barrels are rifled is somewhat unusual; instead of using a traditional broaching machine to cut the rifling into the bore, the Glock process involves beating a slowly rotating mandrel through the bore to obtain the hexagonal or octagonal shape.[52] As a result, the barrel's thickness in the area of each groove is not compromised as with conventional square-cut barrels. This has the advantage of providing a better gas seal behind the projectile as the bore has a slightly smaller diameter, which translates into more efficient use of the combustion gases trapped behind the bullet,[52] slightly greater (consistency in) muzzle velocities, and increased accuracy and ease of maintenance.[53]\\r\\nGlock pistols are designed with three independent safety mechanisms to prevent accidental discharge. The system, designated \\"Safe Action\\" by Glock, consists of an external integrated trigger safety and two automatic internal safeties: a firing pin safety, and a drop safety.[54] The external safety is a small inner lever contained in the trigger. Pressing the lever activates the trigger bar and sheet metal connector. The firing pin safety is a solid hardened steel pin that, in the secured state, blocks the firing pin channel (disabling the firing pin in its longitudinal axis). It is pushed upward to release the firing pin for firing only when the trigger is actuated and the safety is pushed up through the backward movement of the trigger bar. The drop safety guides the trigger bar in a ramp that is released only when direct rearward pressure is applied to the trigger. The three safety mechanisms are automatically disengaged one after the other when the trigger is squeezed, and are automatically reactivated when the trigger is released.[17][55] This passive safety system omits the manipulation of traditional on-off levers, hammers, or other external safeties as found in many other handgun designs. The ability to fire immediately, without worrying about an external safety, is one feature Glock has stressed as an advantage when selling its guns, especially to police departments.[56]\\r\\nIn 2003, Glock announced the Internal Locking System (ILS) safety feature. The ILS is a manually activated lock located in the back of the pistol's grip. It is cylindrical in design and, according to Glock, each key is unique. When activated, the lock causes a tab to protrude from the rear of the grip, giving both a visual and tactile indication as to whether the lock is engaged or not. When activated, the ILS renders the Glock unfireable, as well as making it impossible to disassemble. When disengaged, the ILS adds no further safety mechanisms to the Glock pistol. The ILS is available as an option on most Glock pistols. Glock pistols cannot be retrofitted to accommodate the ILS. The lock must be factory built in Austria and shipped as a special order.\\r\\nThe Glock 17 feeds from staggered-column or double stack magazines that have a 17-round capacity (which can be extended to 19 with an optional floor plate) or optional 33-round high-capacity magazines.[57] For jurisdictions which restrict magazine capacity to 10 rounds, Glock offers single-stack, 10-round magazines. The magazines are made of steel and are overmolded with plastic. A steel spring drives a plastic follower. After the last cartridge has been fired, the slide remains open on the slide stop. The slide stop release lever is located on the left side of the frame directly beneath the slide and can be manipulated by the thumb of the right-handed shooter.\\r\\nGlock magazines are interchangeable between models of the same caliber, meaning that a compact or subcompact pistol will accept magazines designed for the larger pistols chambered for the same round. However, magazines designed for compact and subcompact models will not function in larger pistols because they are not tall enough to reach the slide and magazine release. For example, the subcompact Glock 26 will accept magazines from both the full-size Glock 17 and the compact Glock 19, but the Glock 17 will not accept magazines from the smaller Glock 19 or the Glock 26. The magazines for the Glock 36, the Glock 42, and the Glock 43 are all unique; they cannot use magazines intended for another model, nor can their magazines be used in other models.\\r\\nThe Glock 17 has a fixed polymer combat-type sighting arrangement that consists of a ramped front sight and a notched rear sight with white contrast elements painted on for increased acquisition speed ÿ a white dot on the front post and a rectangular border on the rear notch. The rear sight can be adjusted for windage (on certain models due to the windage sights not coming as factory default), as it has a degree of lateral movement in the dovetail it is mounted in. Three other factory rear sight configurations are available in addition to the standard 6.5?mm (0.26?in) height sight: a lower impact 6.1?mm (0.24?in) sight, and two higher impact versions ÿ 6.9?mm (0.27?in) and 7.3?mm (0.29?in).[58]\\r\\nThe Glock pistol accessories available from the factory include several devices for tactical illumination, such as a series of front rail-mounted \\"Glock tactical lights\\" featuring a white tactical light and an optional visible laser sight. An alternate version of the tactical light using an invisible infrared light and laser sight is available, designed to be used with an infrared night vision device. Another lighting accessory is an adapter to mount a flashlight onto the bottom of a magazine.\\r\\nPolymer holsters in various configurations and matching magazine pouches are available. In addition, Glock produces optional triggers, recoil springs, slide stops, magazine release levers, and maritime spring cups. Maritime spring cups are designed to allow the pistol to be fired immediately after being submerged in water. They feature additional openings that allow liquids to flow and escape around them, offering enhanced reliability when water has penetrated into the firing pin assembly channel.\\r\\nMagazine floor plates (or +2 baseplates), which expand the capacity of the standard magazines by two rounds are available for models chambered for the 9G19mm Parabellum, .45 ACP, .40 S&W, .357 SIG, and .380 ACP cartridges. In addition to the standard nonadjustable polymer sight line, three alternative sight lines are offered by Glock. These consist of steel, adjustable, and self-illuminating tritium night rear sights and factory steel and self-illuminating tritium contrast pointer steel front sights.\\r\\nFollowing the introduction of the Glock 17, numerous variants and versions have been offered. Variants that differ in caliber, frame, and slide length are identified by different model numbers with the exception of the Glock 17L. Other changes not dealing with frame and slide length are identified with suffixes, such as \\"C\\", which denotes compensated models.[59][non-primary source needed][60] Minor options such as frame color, sights, and included accessories are identified by a separate model code on the box and do not appear anywhere on the firearm.\\r\\nGlock pistols are made in five form factors, all modeled after the original full-sized Glock 17. \\"Standard\\" models are designed as full-sized duty firearms with a large magazine capacity. \\"Compact\\" models are slightly smaller with reduced magazine capacity and lighter weight, while maintaining a usable grip length. \\"Subcompact\\" models are designed for easier carry, and being lighter and shorter, are intended to be used with two fingers on the grip below the trigger guard, and lack an accessory rail like the larger, after generation two, Glock models. The .45 ACP and 10mm Auto models have bigger, wider slides and are slightly larger than the smaller-chambered pistols and are available in the subcompact models Glock 29 (10mm) and Glock 30 (.45 ACP). Glock produces three models of single-stack \\"Slimline\\" subcompact pistols, the Glock 36 in .45 ACP, the Glock 42 in .380 ACP, and the Glock 43 in 9 x19 mm. \\"Competition\\" versions have longer barrels and slides, adjustable sights, an extended slide and magazine release.\\r\\nBeginning in 2007, Glock introduced several \\"Short Frame\\" models designated by the suffix \\"SF\\". The short frame was originally designed to compete in the now cancelled U.S. military Joint Combat Pistol trials for a new .45 ACP pistol to replace the M9 pistol. Glock's entry featured an optional ambidextrous magazine release and MIL-STD-1913 rail along with a reduction in the size of the backstrap. The Glock 21SF is currently available in three versions: one with a Picatinny rail and ambidextrous magazine release and two with a Universal Glock rail available with or without the ambidextrous magazine release. Current 10?mm and .45 ACP Glock magazines are manufactured with ambidextrous magazine release cutouts. As of January 2009, the Glock 20, 21, 29, and 30 were offered in short-framed variations. These models incorporate a 2.5?mm (0.098?in) reduction in trigger reach, and full-sized models feature a 4?mm (0.16?in) reduction in heel depth, which corresponds to an overall reduction in length for those models.[61][62][63]\\r\\nGlock pistols chambered for the .45 ACP (and the .45 GAP) feature octagonal polygonal rifling rather than the hexagonal shaped bores used for models in most other chamberings.[75] Octagonal rifling provides a better gas seal in relatively large diameter rifled bores, since an octagon resembles a circle more closely than a hexagon.[53]\\r\\nAs is typical of pistols chambered in .40 S&W, each of the standard Glock models (22, 23, and 27) may be easily converted to the corresponding .357 SIG chambering (Glock 31, 32, and 33, respectively) simply by replacing the barrel. No other parts need to be replaced, as the .40 S&W magazines will feed the .357 SIG rounds.\\r\\nThe first two .380 ACP models are primarily intended for markets which prohibit civilian ownership of firearms chambered in military calibers such as 9G19mm Parabellum.[82]\\r\\nDue to the relatively low bolt thrust of the .380 ACP cartridge, the locked-breech design of the Glock 19 and Glock 26 was minimally modified for the Glock 25 and Glock 28 to implement unlocked breech operation. It operates via straight blowback of the slide. This required modification of the locking surfaces on the barrel, as well as a redesign of the former locking block. Unusual for a blowback design, the barrel is not fixed to the frame. It moves rearward in recoil until it is tilted below the slide, similar to the standard locked-breech system. The reduced size and mass of the Glock 42 required return to the Glock-standard locked-breech design.\\r\\nAs is typical of pistols chambered in .357 SIG, each of the standard Glock models (31, 32, and 33) may be easily converted to the corresponding .40 S&W chambering (Glock 22, 23, and 27, respectively) simply by replacing the barrel. No other parts need to be replaced, as the .357 SIG magazines will feed the .40 S&W round.\\r\\nGlock pistols chambered for the .45 GAP (and the .45 ACP) feature octagonal polygonal rifling rather than the hexagonal shaped bores used for models in most other chamberings.[75] Octagonal rifling provides a better gas seal in relatively large diameter rifled bores, since an octagon resembles a circle more closely than a hexagon.[53]\\r\\nAside from the original Austrian company, Glock pistols are manufactured by the Glock Inc. subsidiary division located in the United States. Those batches are nearly the same or identical compared to the Austrian-made ones, but they are marked as \\"USA\\", instead of \\"AUSTRIA\\", on the slide; and they have seven-digit serial numbers, instead of the Austrians' six. Glock 17 pistols are being assembled locally at army workshops of Uruguay to fulfill the needs of the national military services and law enforcement organizations.[92][93] These pistols are assembled initially with original Glock parts and later with locally manufactured parts.[92]\\r\\nThe 205th Armory in Taiwan produces a copy of the Glock 19, named as the T97. The Taiwan-made Glocks were made to replace the Smith & Wesson Model 5906 used by the Taiwan police, but it ultimately did not enter service. Turkish company Akdal Arms produces a pistol named the Ghost TR01, which is heavily influenced by Glock pistols in its design.[94] Russian firms such as Skat,[95] ORSIS[96] and Izhmash [97] assembles three models of Glock pistols locally: the Glock 17, 34, and 35. There are three sidearms made by Iranian DIO's Shahid Kaveh Industry Complex which they call Ra'ad (has a safety selector, possibly an unlicensed copy of Glock 17), Glock 19 and Kaveh-17 (probably an improved Ra'ad, a variant of Glock 17S), which all of them are unlicensed clones of Glock pistols.[98] It is not known if they could make their way to Iranian Military and replace the Browning Hi-Power, 1911 and SIG P226 pistols and they were possibly some prototypes and have never gone on mass production.[99]","input":"When was the glock 19 gen 4 released?"},{"output":"Oil Creek Pennsylvania","context":"The first successful oil well in North America was established in Oil Springs, Ontario, Canada in 1858. The field is still in production although quantities are low.\\r\\nThe history of the petroleum industry in the United States goes back to the early 19th century, although the indigenous peoples, like many ancient societies, have used petroleum seeps since prehistoric times; where found, these seeps signaled the growth of the industry from the earliest discoveries to the more recent.\\r\\nPetroleum became a major industry following the oil discovery at Oil Creek Pennsylvania in 1859. For much of the 19th and 20th centuries, the US was the largest oil producing country in the world. As of October 2015, the US was the world's third-largest producer of crude oil.[1]\\r\\n\\r\\n\\r\\nIndians had known of the oil in western Pennsylvania, and had made some use of it for many years before the mid-19th century. Early European explorers noted seeps of oil and natural gas in western Pennsylvania and New York. Interest grew substantially in the mid-1850s as scientists reported on the potential to manufacture kerosene from crude oil, if a sufficiently large oil supply could be found.\\r\\nThe Jesuit Relations of 1657 states:\\r\\nAs one approaches nearer to the country of the Cats, one finds heavy and thick water, which ignites like brandy, and boils up in bubbles of flame when fire is applied to it. It is, moreover, so oily, that all our Savages use it to anoint and grease their heads and their bodies.[2]\\r\\nSalt was a valuable commodity, and an industry developed near salt springs in the Ohio River Valley, producing salt by evaporating brine from the springs. Salt wells were sunk at the salt springs to increase the supply of brine for evaporation. Some of the wells were hand-dug, but salt producers also learned to drill wells by percussion (cable tool) methods. In a number of locations in western Virginia, Ohio, and Kentucky, oil and natural gas came up the wells along with the brine. The oil was mostly a nuisance, but some salt producers saved it and sold it as illuminating oil or medicine. In some locations, enough natural gas was produced to be used as fuel for the salt evaporating pans.[3] Early salt brine wells that produced byproduct oil included the Thorla-McKee Well of Ohio in 1814, a well near Burkesville, Kentucky, in 1828,[4] and wells at Burning Springs, West Virginia, by 1836.\\r\\nThe US natural gas industry started in 1821 at Fredonia, Chautauqua County, New York, when William Hart dug a well to a depth of 27 feet (8.2?m) into gas-bearing shale, then drilled a borehole 43 feet (13?m) further, and piped the natural gas to a nearby inn where it was burned for illumination. Soon many gas wells were drilled in the area, and the gas-lit streets of Fredonia became a tourist attraction.\\r\\nOn August 28, 1859, George Bissell and Edwin L. Drake made the first successful use of a drilling rig on a well drilled especially to produce oil, at a site on Oil Creek near Titusville, Pennsylvania. The Drake partners were encouraged by Benjamin Silliman (1779-1864), a chemistry professor at Yale, who tested a sample of the oil, and assured them that it could be distilled into useful products such as illuminating oil.\\r\\nThe Drake well is often referred to as the \\"first\\" commercial oil well, although that title is also claimed for wells in Azerbaijan, Ontario, West Virginia, and Poland, among others. However, before the Drake well, oil-producing wells in the United States were wells that were drilled for salt brine, and produced oil and gas only as accidental byproducts. An intended drinking water well at Oil Springs, Ontario found oil in 1858, a year before the Drake well, but it had not been drilled for oil. Historians have noted that the importance of the Drake well was not in being the first well to produce oil, but in attracting the first great wave of investment in oil drilling, refining, and marketing:\\r\\nThe success of the Drake well quickly led to oil drilling in other locations in the western Appalachian mountains, where oil was seeping to the surface, or where salt drillers had previously found oil fouling their salt wells. During the American Civil War, the oil-producing region spread over much of western Pennsylvania, up into western New York state, and down the Ohio River valley into the states of Ohio, Kentucky, and the western part of Virginia (now West Virginia). The Appalachian Basin continued to be the leading oil-producing region in the United States through 1904.[6]\\r\\nThe first commercial oil well in New York was drilled in 1865. New York's (and Northwestern Pennsylvania) crude oil is very high in paraffin.[7]\\r\\nThe principal product of the oil in the 19th century was kerosene, which quickly replaced whale oil for illuminating purposes in the United States. Originally dealing in whale oil which was widely used for illumination, Charles Pratt (1830ÿ1891) of Massachusetts was an early pioneer of the natural oil industry in the United States. He was founder of Astral Oil Works in the Greenpoint section of Brooklyn, New York. Pratt's product later gave rise to the slogan, \\"The holy lamps of Tibet are primed with Astral Oil.\\" He joined with his protg Henry H. Rogers to form Charles Pratt and Company in 1867. Both companies became part of John D. Rockefeller's Standard Oil in 1874.\\r\\nThe Mid-continent area is an area generally including Kansas, Oklahoma, Arkansas, North Louisiana and the part of Texas away from the Gulf Coast. The first commercially successful oil well drilled in Kansas was the Norman No. 1 near Neodesha, Kansas, on November 28, 1892.\\r\\nOil was discovered at Bartlesville and Burbank in 1897. But the initial discoveries created no great excitement until the discovery gusher of the Glenn Pool in 1905. The Glenn discovery came when Gulf Coast production was declining rapidly, and the operators were eager for new areas to drill. The increased drilling resulted in major discoveries at Cushing in 1912 and Healdton in 1913.[8]\\r\\nThe largest oil field in the lower 48 states, the East Texas oil field, was not discovered until 1930, when wildcatter Columbus Marion Joiner (more commonly known as \\"Dad\\" Joiner) drilled the Daisy Bradford No. 3 well, in Rusk County, Texas.[9]\\r\\nIn 1906, the Caddo-Pine Island Field in northern Caddo Parish, Louisiana was discovered, and a rush of leasing and drilling activity ensued. In 1908, the first natural gas pipeline was constructed to transport gas from Caddo-Pine Island to Shreveport, Louisiana. This was one of the earliest commercial uses of natural gas, which was commonly viewed as an undesirable by-product of oil production and often \\"flared\\" or burnt off at the well site.\\r\\nOther innovations in the Caddo-Pine Island Field included the first over-water oil platform, which was constructed in the field on Caddo Lake in 1910. In that same year, a major oil pipeline was constructed from Caddo-Pine Island Field to a refinery built and operated by Standard Oil Company of Louisiana in Baton Rouge, Louisiana. The refinery continues to operate today.\\r\\nOther early petroleum discoveries in North Louisiana included the Bull Bayou Field, Red River Parish, Louisiana (1913), Monroe Gas Field, Ouachita Parish, Louisiana (1916), Homer Field, Claiborne Parish, Louisiana (1919) and Haynesville Field, Claiborne Parish, Louisiana (1921).[10]\\r\\nNative Americans had known of the tar seeps in southern California for thousands of years, and used the tar to waterproof their canoes. Spanish settlers also knew of the seeps, such as at Rancho La Brea (Spanish for Tar Ranch) in present-day Los Angeles, from which the priests obtained tar to waterproof the roofs of the Los Angeles and San Gabriel missions.[11]\\r\\nDespite the abundance of well-known seeps in southern California, the first commercial oil well in California was drilled in Humboldt County, northern California in 1865.[12]\\r\\nSome attempts were made in the 1860s to exploit oil deposits under tar seeps in the Ventura Basin of Ventura County and northeastern Los Angeles county. The early efforts failed because of complex geology, and, more importantly, because the refining techniques then available could not manufacture high-quality kerosene from California crude oil, which differed chemically from Pennsylvania crude oil.[13] Most California crude oil in the early years was turned into the less lucrative products of fuel oil and asphalt.\\r\\nOil production in the Los Angeles Basin started with the discovery of the Brea-Olinda Oil Field in 1880, and continued with the development of the Los Angeles City Oil Field in 1893, the Beverly Hills Oil Field in 1900, the Salt Lake Oil Field in 1902, and many others. The discovery of the Long Beach Oil Field in 1921, which proved to be the world's richest in production per-acre of the time, increased the importance of the Los Angeles Basin as a worldwide oil producer. This increased again with the discovery of the Wilmington Oil Field in 1932, and the development of the Port of Los Angeles as a means of shipping crude oil overseas.[14]\\r\\nProduction in Santa Barbara County began in the 1890s with the development of the Summerland Oil Field, which included the world's first offshore oil wells. With the discovery of the Orcutt and Lompoc fields, northern Santa Barbara County became a regional center of production; towns such as Orcutt owe their existence to the quickly growing industry.[14]\\r\\nOil in the San Joaquin Basin was first discovered at the Coalinga field in 1890. By 1901, the San Joaquin Basin was the main oil-producing region of California, and it remains so in the 21st century, with huge oil fields including the Midway-Sunset, Kern River, and Belridge fields producing much of California's onshore oil.\\r\\nThe first commercial oil well in the Rocky Mountains was drilled near Canon City, Colorado in 1862. The wells in the Canyon City-Florence field, drilled near surface oil seeps, produced from fractures in the Pierre Shale.\\r\\nA Russian sea captain noted oil seeps along the shore of the Cook Inlet as early as 1853, and oil drilling began in 1898 in a number of locations along the southern coast of Alaska.[15] Production was relatively small, however, until huge discoveries were made on Alaska's remote North Slope.\\r\\nPetroleum seeps on the North Slope have been known for many years, and in 1923, the federal government created US Naval Petroleum Reserve No. 4 to cover the presumed oil fields beneath the seeps. Some exploration drilling was done in the reserve during World War II and the 1950s, but the remote location deterred intensive exploration until the 1960s. The Prudhoe Bay Oil Field, the largest oil field in the United States in terms of total oil produced, was discovered in 1968. Production began in 1977, following completion of the Trans-Alaska Pipeline. Through 2005, the field has produced 13 billion barrels (2.1G10^9?m3) of oil (an average of 1.5 million barrels/day), and is estimated to contain another 2 billion barrels (320G10^6?m3) of economically recoverable oil.\\r\\nCapt. Anthony Francis Lucas, an experienced mining engineer and salt driller, drilled a well to find oil at Spindletop Hill. On the morning of January 10, 1901, the little hill south of Beaumont, Texas began to tremble and mud bubbled up over the rotary table. A low rumbling sound came from underground, and then, with a force that shot 6 tons of 4-inch (100?mm) diameter pipe out over the top of the derrick, knocking off the crown block, the Lucas Gusher roared in and the Spindletop oil field was born. Spindletop became the focus of frenzied drilling; oil production from the field peaked in 1902 at 17,400,000 barrels (2,770,000?m3), but by 1905 production had declined 90% from the peak.[16]\\r\\nSpindletop Hill turned out to be the surface expression of an underground salt dome, around which the oil accumulated. The Spindletop gusher started serious oil exploration of the Gulf Coast in Texas and Louisiana, an area that had previously been dismissed by oil men. Other salt dome mounds were quickly drilled, resulting in discoveries at Sour Lake (1902), Batson (1904) and Humble (1905).[17]\\r\\nThe Standard Oil Company was slow to appreciate the economic potential of the Spindletop oil field, and the Gulf Coast generally, which gave greater opportunity to others; Spindletop became the birthplace of oil giants Texaco and Gulf Oil. Although in 1899 Standard Oil controlled more than 85% of the oil production in the older oil regions in the Appalachian Basin and the Lima-Indiana trend, it never controlled more than 10% of the oil production in the new Gulf Coast province.[18]\\r\\nBy the Natural Gas Act of 1938, the federal government imposed price controls on natural gas in interstate commerce. The Federal Power Commission was mandated to set interstate gas prices at \\"just and reasonable\\" rates.[19] The FPC at first only regulated the price at which pipelines sold gas to utilities and industry, but later put limits on the wellhead price of gas sold to an interstate pipeline. Gas producers challenged the controls, but lost in the Supreme Court in Phillips Petroleum Co. v. Wisconsin (1954).\\r\\nThe federal government had controlled the price of natural gas that crossed state lines, but not of gas produced and sold within a state. In the 1970s, the low interstate price set by the federal government caused supply shortages of gas in consuming states, because gas producers sold as much as they could of their product for higher prices in the local markets within gas-producing states. In the Natural Gas Policy Act of 1978, the federal government extended price controls to all natural gas in the country. At the same time, the government created a complex price system in which the price paid to the producer depended on the date the well was drilled, the depth of the well, the geological formation, the distance to other gas wells, and several other factors. The price system was an attempt to keep the average price low while encouraging new production.[20]\\r\\nThe last federal price controls on natural gas were removed by the Natural Gas Decontrol Act of 1989, which phased out the last remaining price control as of 1 January 1993.[21]\\r\\nAs of December, 2012, North Dakota was producing oil at the rate of 750,000 barrels/day.[22]","input":"Where was the world's first commercial natural gas well drilled?"},{"output":"Global System for Mobile Communications","context":"GSM (Global System for Mobile Communications, originally Groupe Spcial Mobile) is a standard developed by the European Telecommunications Standards Institute (ETSI) to describe the protocols for second-generation digital cellular networks used by mobile devices such as mobile phones, first deployed in Finland in December 1991.[2] As of 2014[update], it has become the global standard for mobile communications ÿ with over 90% market share, operating in over 219 countries and territories.[3]\\r\\n2G networks developed as a replacement for first generation (1G) analog cellular networks, and the GSM standard originally described as a digital, circuit-switched network optimized for full duplex voice telephony. This expanded over time to include data communications, first by circuit-switched transport, then by packet data transport via GPRS (General Packet Radio Services) and EDGE (Enhanced Data rates for GSM Evolution, or EGPRS).\\r\\nSubsequently, the 3GPP developed third-generation (3G) UMTS standards, followed by fourth-generation (4G) LTE Advanced standards, which do not form part of the ETSI GSM standard.\\r\\n\\"GSM\\" is a trademark owned by the GSM Association. It may also refer to the (initially) most common voice codec used, Full Rate.\\r\\n\\r\\n\\r\\nIn 1983, work began to develop a European standard for digital cellular voice telecommunications when the European Conference of Postal and Telecommunications Administrations (CEPT) set up the Groupe Spcial Mobile committee and later provided a permanent technical-support group based in Paris. Five years later, in 1987, 15 representatives from 13 European countries signed a memorandum of understanding in Copenhagen to develop and deploy a common cellular telephone system across Europe, and EU rules were passed to make GSM a mandatory standard.[4] The decision to develop a continental standard eventually resulted in a unified, open, standard-based network which was larger than that in the United States.[5][6][7][8]\\r\\nIn February 1987, Europe produced the very first agreed GSM Technical Specification. Ministers from the four big EU countries cemented their political support for GSM with the Bonn Declaration on Global Information Networks in May and the GSM MoU was tabled for signature in September. The MoU drew in mobile operators from across Europe to pledge to invest in new GSM networks to an ambitious common date.\\r\\nIn this short 38-week period, the whole of Europe (countries and industries) had been brought behind GSM in a rare unity and speed guided by four public officials: Armin Silberhorn (Germany), Stephen Temple (UK), Philippe Dupuis (France), and Renzo Failli (Italy).[9] In 1989, the Groupe Spcial Mobile committee was transferred from CEPT to the European Telecommunications Standards Institute (ETSI).[6][7][7][8]\\r\\nIn parallel, France and Germany signed a joint development agreement in 1984 and were joined by Italy and the UK in 1986. In 1986, the European Commission proposed reserving the 900?MHz spectrum band for GSM. The former Finnish prime minister Harri Holkeri made the world's first GSM call on July 1, 1991, calling Kaarina Suonio (mayor of the city of Tampere) using a network built by Telenokia and Siemens and operated by Radiolinja.[10] In the following year, 1992, saw the sending of the first short messaging service (SMS or \\"text message\\") message, and Vodafone UK and Telecom Finland signed the first international roaming agreement.\\r\\nWork began in 1991 to expand the GSM standard to the 1800?MHz frequency band and the first 1800?MHz network became operational in the UK by 1993, called and DCS 1800. Also that year, Telecom Australia became the first network operator to deploy a GSM network outside Europe and the first practical hand-held GSM mobile phone became available.\\r\\nIn 1995, fax, data and SMS messaging services were launched commercially, the first 1900?MHz GSM network became operational in the United States and GSM subscribers worldwide exceeded 10 million. In the same year, the GSM Association formed. Pre-paid GSM SIM cards were launched in 1996 and worldwide GSM subscribers passed 100 million in 1998.[7]\\r\\nIn 2000, the first commercial GPRS services were launched and the first GPRS-compatible handsets became available for sale. In 2001, the first UMTS (W-CDMA) network was launched, a 3G technology that is not part of GSM. Worldwide GSM subscribers exceeded 500 million. In 2002, the first Multimedia Messaging Service (MMS) were introduced and the first GSM network in the 800?MHz frequency band became operational. EDGE services first became operational in a network in 2003, and the number of worldwide GSM subscribers exceeded 1 billion in 2004.[7]\\r\\nBy 2005, GSM networks accounted for more than 75% of the worldwide cellular network market, serving 1.5 billion subscribers. In 2005, the first HSDPA-capable network also became operational. The first HSUPA network launched in 2007. (High-Speed Packet Access (HSPA) and its uplink and downlink versions are 3G technologies, not part of GSM.) Worldwide GSM subscribers exceeded three billion in 2008.[7]\\r\\nThe GSM Association estimated in 2010 that technologies defined in the GSM standard served 80% of the mobile market, encompassing more than 5 billion people across more than 212 countries and territories, making GSM the most ubiquitous of the many standards for cellular networks.[11]\\r\\nGSM is a second-generation (2G) standard employing time-division multiple-Access (TDMA) spectrum-sharing, issued by the European Telecommunications Standards Institute (ETSI). The GSM standard does not include the 3G Universal Mobile Telecommunications System (UMTS) code division multiple access (CDMA) technology nor the 4G LTE orthogonal frequency-division multiple access (OFDMA) technology standards issued by the 3GPP.[12]\\r\\nGSM, for the first time, set a common standard for Europe for wireless networks. It was also adopted by many countries outside Europe. This allowed subscribers to use other GSM networks that have roaming agreements with each other. The common standard reduced research and development costs, since hardware and software could be sold with only minor adaptations for the local market.[13]\\r\\nTelstra in Australia shut down its 2G GSM network on December 1, 2016, the first mobile network operator to decommission a GSM network.[14] The second mobile provider to shut down its GSM network (on January 1, 2017) was AT&T Mobility from the United States.[15] Optus in Australia completed the shut down its 2G GSM network on August 1, 2017, part of the Optus GSM network covering Western Australia and the Northern Territory had earlier in the year been shut down in April 2017.[16] Singapore will phase out 2G services by April 2017.\\r\\nThe network is structured into a number of discrete sections:\\r\\nGSM is a cellular network, which means that cell phones connect to it by searching for cells in the immediate vicinity. There are five different cell sizes in a GSM networkmacro, micro, pico, femto, and umbrella cells. The coverage area of each cell varies according to the implementation environment. Macro cells can be regarded as cells where the base station antenna is installed on a mast or a building above average rooftop level. Micro cells are cells whose antenna height is under average rooftop level; they are typically used in urban areas. Picocells are small cells whose coverage diameter is a few dozen meters; they are mainly used indoors. Femtocells are cells designed for use in residential or small business environments and connect to the service providers network via a broadband internet connection. Umbrella cells are used to cover shadowed regions of smaller cells and fill in gaps in coverage between those cells.\\r\\nCell horizontal radius varies depending on antenna height, antenna gain, and propagation conditions from a couple of hundred meters to several tens of kilometres. The longest distance the GSM specification supports in practical use is 35 kilometres (22?mi). There are also several implementations of the concept of an extended cell,[17] where the cell radius could be double or even more, depending on the antenna system, the type of terrain, and the timing advance.\\r\\nIndoor coverage is also supported by GSM and may be achieved by using an indoor picocell base station, or an indoor repeater with distributed indoor antennas fed through power splitters, to deliver the radio signals from an antenna outdoors to the separate indoor distributed antenna system. These are typically deployed when significant call capacity is needed indoors, like in shopping centers or airports. However, this is not a prerequisite, since indoor coverage is also provided by in-building penetration of the radio signals from any nearby cell.\\r\\nGSM networks operate in a number of different carrier frequency ranges (separated into GSM frequency ranges for 2G and UMTS frequency bands for 3G), with most 2G GSM networks operating in the 900?MHz or 1800?MHz bands. Where these bands were already allocated, the 850?MHz and 1900?MHz bands were used instead (for example in Canada and the United States). In rare cases the 400 and 450?MHz frequency bands are assigned in some countries because they were previously used for first-generation systems.\\r\\nFor comparison, most 3G networks in Europe operate in the 2100?MHz frequency band. For more information on worldwide GSM frequency usage, see GSM frequency bands.\\r\\nRegardless of the frequency selected by an operator, it is divided into timeslots for individual phones. This allows eight full-rate or sixteen half-rate speech channels per radio frequency. These eight radio timeslots (or burst periods) are grouped into a TDMA frame. Half-rate channels use alternate frames in the same timeslot. The channel data rate for all 8 channels is 270.833 kbit/s, and the frame duration is 4.615 ms.\\r\\nThe transmission power in the handset is limited to a maximum of 2 watts in GSM 850/900 and 1 watt in GSM 1800/1900.\\r\\nGSM has used a variety of voice codecs to squeeze 3.1?kHz audio into between 6.5 and 13?kbit/s. Originally, two codecs, named after the types of data channel they were allocated, were used, called Half Rate (6.5?kbit/s) and Full Rate (13?kbit/s). These used a system based on linear predictive coding (LPC). In addition to being efficient with bitrates, these codecs also made it easier to identify more important parts of the audio, allowing the air interface layer to prioritize and better protect these parts of the signal. GSM was further enhanced in 1997[18] with the Enhanced Full Rate (EFR) codec, a 12.2?kbit/s codec that uses a full-rate channel. Finally, with the development of UMTS, EFR was refactored into a variable-rate codec called AMR-Narrowband, which is high quality and robust against interference when used on full-rate channels, or less robust but still relatively high quality when used in good radio conditions on half-rate channel.\\r\\nOne of the key features of GSM is the Subscriber Identity Module, commonly known as a SIM card. The SIM is a detachable smart card containing the user's subscription information and phone book. This allows the user to retain his or her information after switching handsets. Alternatively, the user can also change operators while retaining the handset simply by changing the SIM. Some operators will block this by allowing the phone to use only a single SIM, or only a SIM issued by them; this practice is known as SIM locking.\\r\\nSometimes mobile network operators restrict handsets that they sell for use with their own network. This is called locking and is implemented by a software feature of the phone. A subscriber may usually contact the provider to remove the lock for a fee, utilize private services to remove the lock, or use software and websites to unlock the handset themselves. It is possible to hack past a phone locked by a network operator.\\r\\nIn some countries (e.g., Bangladesh, Belgium, Brazil, Chile, Germany, Hong Kong, India, Iran, Lebanon, Malaysia, Nepal, Pakistan, Poland, Singapore, South Africa, Thailand) all phones are sold unlocked.[19]\\r\\nGSM was intended to be a secure wireless system. It has considered the user authentication using a pre-shared key and challenge-response, and over-the-air encryption. However, GSM is vulnerable to different types of attack, each of them aimed at a different part of the network.[20]\\r\\nThe development of UMTS introduced an optional Universal Subscriber Identity Module (USIM), that uses a longer authentication key to give greater security, as well as mutually authenticating the network and the user, whereas GSM only authenticates the user to the network (and not vice versa). The security model therefore offers confidentiality and authentication, but limited authorization capabilities, and no non-repudiation.\\r\\nGSM uses several cryptographic algorithms for security. The A5/1, A5/2, and A5/3 stream ciphers are used for ensuring over-the-air voice privacy. A5/1 was developed first and is a stronger algorithm used within Europe and the United States; A5/2 is weaker and used in other countries. Serious weaknesses have been found in both algorithms: it is possible to break A5/2 in real-time with a ciphertext-only attack, and in January 2007, The Hacker's Choice started the A5/1 cracking project with plans to use FPGAs that allow A5/1 to be broken with a rainbow table attack.[21] The system supports multiple algorithms so operators may replace that cipher with a stronger one.\\r\\nSince 2000, different efforts have been made in order to crack the A5 encryption algorithms. Both A5/1 and A5/2 algorithms have been broken, and their cryptanalysis has been revealed in the literature. As an example, Karsten Nohl?(de) developed a number of rainbow tables (static values which reduce the time needed to carry out an attack) and have found new sources for known plaintext attacks.[22] He said that it is possible to build \\"a full GSM interceptor...from open-source components\\" but that they had not done so because of legal concerns.[23] Nohl claimed that he was able to intercept voice and text conversations by impersonating another user to listen to voicemail, make calls, or send text messages using a seven-year-old Motorola cellphone and decryption software available for free online.[24]\\r\\nGSM uses General Packet Radio Service (GPRS) for data transmissions like browsing the web. The most commonly deployed GPRS ciphers were publicly broken in 2011.[25]\\r\\nThe researchers revealed flaws in the commonly used GEA/1 and GEA/2 ciphers and published the open-source \\"gprsdecode\\" software for sniffing GPRS networks. They also noted that some carriers do not encrypt the data (i.e., using GEA/0) in order to detect the use of traffic or protocols they do not like (e.g., Skype), leaving customers unprotected. GEA/3 seems to remain relatively hard to break and is said to be in use on some more modern networks. If used with USIM to prevent connections to fake base stations and downgrade attacks, users will be protected in the medium term, though migration to 128-bit GEA/4 is still recommended.\\r\\nThe GSM systems and services are described in a set of standards governed by ETSI, where a full list is maintained.[26]\\r\\nSeveral open-source software projects exist that provide certain GSM features:\\r\\nPatents remain a problem for any open-source GSM implementation, because it is not possible for GNU or any other free software distributor to guarantee immunity from all lawsuits by the patent holders against the users. Furthermore, new features are being added to the standard all the time which means they have patent protection for a number of years.[citation needed]\\r\\nThe original GSM implementations from 1991 may now be entirely free of patent encumbrances, however patent freedom is not certain due to the United States' \\"first to invent\\" system that was in place until 2012. The \\"first to invent\\" system, coupled with \\"patent term adjustment\\" can extend the life of a U.S. patent far beyond 20 years from its priority date. It is unclear at this time whether OpenBTS will be able to implement features of that initial specification without limit. As patents subsequently expire, however, those features can be added into the open-source version. As of 2011, there have been no lawsuits against users of OpenBTS over GSM use.[citation needed]","input":"What is the meaning of g s m?"},{"output":"an art museum located in the Henry Clay Frick House on the Upper East Side in Manhattan, New York City at 1 East 70th Street, at the northeast corner with Fifth Avenue.","context":"The Frick Collection is an art museum located in the Henry Clay Frick House on the Upper East Side in Manhattan, New York City at 1 East 70th Street, at the northeast corner with Fifth Avenue. It houses the collection of industrialist Henry Clay Frick (1849ÿ1919).\\r\\n\\r\\n\\r\\nHenry Frick started his substantial art collection as soon as he started amassing his fortunes. A considerable amount of his art collection is located in his former residence \\"Clayton\\" in Pittsburgh, which is today a part of the Frick Art & Historical Center. Another part was given by his daughter and heiress Helen to the Frick Fine Arts Building, which is on the campus of the University of Pittsburgh.\\r\\nThe family did not permanently move from Pittsburgh to New York until 1905. Henry Frick initially leased the Vanderbilt house at 640 Fifth Avenue, to which he moved a substantial amount of his collection. He had his permanent residence built between 1912 and 1914 by Thomas Hastings of Carrre and Hastings. He stayed in the house until his death in 1919. He willed the house and all of its contents, including art, furniture, and decorative objects, as a public museum. His widow Adelaide Howard Childs Frick, however, retained the right of residence and continued living in the mansion with her daughter Helen. After Adelaide Frick died in 1931, the conversion of the house into a public museum started.\\r\\nJohn Russell Pope altered and enlarged the building in the early 1930s to adapt it to use as a public institution. It opened to the public on December 16, 1935. Various additions to the architecture and landscape architecture of the museum site have been considered over the years including the placement of a prominent magnolia garden from the 1930s. As stated by the museum announcements: \\"As a result of a decision of the Board of Trustees in 1939, three magnolias were selected for the Fifth Avenue garden. The two trees on the lower tier are Saucer Magnolias (Magnolia soulangeana) and the species on the upper tier by the flagpole is a Star Magnolia (Magnolia stellata).\\"[2]\\r\\nFurther expansions of the museum took place in 1977 and in 2011. In 2014, the museum announced further expansion plans, but came up against community opposition because it would result in the loss of a garden. The Frick ultimately dropped those plans and is said to be considering other options.[3][4][5]\\r\\nThe Frick is one of the pre-eminent small art museums in the United States, with a high-quality collection of old master paintings and fine furniture housed in nineteen galleries of varying size within the former residence. Frick had intended the mansion to become a museum eventually, and a few of the paintings are still arranged according to Frick's design. Besides its permanent collection, the Frick has always organized small, focused temporary exhibitions.[6]\\r\\nThe collection features some of the best-known paintings by major European artists as well as numerous works of sculpture and porcelain. It also has 18th-century French furniture, Limoges enamel, and Oriental rugs.[1] After Frick's death, his daughter, Helen Clay Frick, and the Board of Trustees expanded the collection: nearly half of the collection's artworks have been acquired since 1919. Although the museum cannot lend the works of art that belonged to Frick, as stipulated in his will, The Frick Collection does lend artworks and objects acquired since his death.[6]\\r\\nIncluded in the collection are Jean-Honor Fragonard's masterpiece The Progress of Love, three paintings by Johannes Vermeer including Mistress and Maid, two paintings by Jacob van Ruisdael including Quay at Amsterdam,[7] and Piero della Francesca's St. John the Evangelist.\\r\\nThe Frick is known to have extraordinary temporary exhibits. When the Mauritshuis was under reconstruction, key and rare works like Vermeer's Girl with a Pearl Earring and Fabritiuss The Goldfinch toured the United States, and was exhibited at the Frick in 2013 as opposed to other venues available in New York City.[8]\\r\\nThe Frick Collection oversees the nearby Frick Art Reference Library. The collections held at the library focus on art of the Western tradition from the fourth century to the mid-twentieth century, and chiefly include information about paintings, drawings, sculpture, prints, and illuminated manuscripts. Archival materials augment its research collections. Opened in 1920, the library quickly became a prime resource for students.[9]\\r\\nAccording to The Art Newspaper, the Frick Collection has a typical annual attendance of 275,000 to 300,000.[10][6]\\r\\nIn 2011, Ian Wardropper succeeded Anne Poulet, who had run the Frick Collection as director since 2003.[11] Poulet took the position after Samuel Sachs II stepped down after running the institution for six years. Poulet was the first female director of the Frick.[12] During her time at the Frick Collection, Poulet increased the museums small board of trustees, adding 10 new members. She also introduced the Directors Circle, a group of 44 members who each give a minimum of $25,000 a year to the Frick Collection, although many have made significantly larger contributions.[12]\\r\\nBy 1997, the Frick Collection had an operating budget of $10 million and an endowment of $170 million.[13] Despite its large endowment, the institution still needs money to preserve the building.[6]\\r\\nFeatured artists include:\\r\\nGiovanni Bellini, St. Francis in Ecstasy, 1478\\r\\nTitian, Portrait of a Man in a Red Cap, c. 1516\\r\\nHans Holbein the Younger, Portrait of Thomas More, 1527\\r\\nHans Holbein the Younger, Thomas Cromwell, 1532 or 1533\\r\\nAgnolo di Cosimo, Portrait of Ludovico Cappon, 1551\\r\\nPieter Bruegel the Elder, Three Soldiers, 1568\\r\\nEl Greco, Saint Jerome, c. 1590ÿ1600\\r\\nDiego Velzquez, King Philip IV of Spain, 1644\\r\\nRembrandt, The Polish Rider, 1655\\r\\nRembrandt, Self-Portrait, 1658\\r\\nJan Vermeer, Officer and Laughing Girl, 1657\\r\\nJan Vermeer, Girl Interrupted at Her Music, 1658ÿ1661\\r\\nJan Vermeer, Mistress and Maid, 1667\\r\\nFran?ois Boucher, The Four Seasons (Spring), 1755\\r\\nFran?ois Boucher, The Four Seasons (Summer), 1755\\r\\nFran?ois Boucher, The Four Seasons (Autumn), 1755\\r\\nFran?ois Boucher, The Four Seasons (Winter), 1755\\r\\nJean-Honor Fragonard, The Secret Meeting, 1771\\r\\nJean-Honor Fragonard, The Progress of Love - Love Letters, 1771-1772\\r\\nFrancisco Goya, The Forge, 1817\\r\\nJ.M.W. Turner, The Harbor of Dieppe, 1826\\r\\nJean Auguste Dominique Ingres, Louise de Broglie, Countess d'Haussonville, 1845\\r\\nPierre-Auguste Renoir, Mother and Children (La Promenade), 1875ÿ76\\r\\nJames McNeill Whistler, Harmony in Pink and Grey (Portrait of Lady Meux), 1881\\r\\nNotes\\r\\nFurther reading","input":"What is the frick in new york city?"},{"output":"Avatar","context":"Films generate income from several revenue streams, including theatrical exhibition, home video, television broadcast rights and merchandising. However, theatrical box office earnings are the primary metric for trade publications in assessing the success of a film, mostly because of the availability of the data compared to sales figures for home video and broadcast rights, but also because of historical practice. Included on the list are charts of the top box office earners (ranked by both the nominal and real value of their revenue), a chart of high-grossing films by calendar year, a timeline showing the transition of the highest-grossing film record, and a chart of the highest-grossing film franchises and series. All charts are ranked by international theatrical box office performance where possible, excluding income derived from home video, broadcasting rights and merchandise.\\r\\nTraditionally, war films, musicals and historical dramas have been the most popular genres, but franchise films have been among the best performers in the 21st century. Six Harry Potter films and five films from Peter Jackson's Middle-earth series are included in the nominal earnings chart, while the Star Wars and Pirates of the Caribbean franchises feature prominently. There is also continued interest in the superhero genre: Batman and Superman from DC Comics and films based on the Marvel Comics brand, such as Spider-Man, X-Men and films in the Marvel Cinematic Universe, have generally done well. Although the nominal earnings chart is dominated by films adapted from pre-existing properties and sequels, it is headed by Avatar and Titanic (both directed by James Cameron), which are original works. Animated family films have performed consistently well, with Disney films enjoying lucrative re-releases prior to the home-video era. Disney also enjoyed later success with films such as Frozen (the highest-grossing animated film), Zootopia and The Lion King, as well as with its Pixar brand, of which the Toy Story and Finding Nemo films have been the best performers. Beyond Disney and Pixar animation, the Shrek, Ice Age and Despicable Me series have met with the most success.\\r\\nWhile inflation has eroded away the achievements of most films from the 1960s and 1970s, there are franchises originating from that period that are still active. Besides the Star Wars and Superman franchises, James Bond and Star Trek films are still being released periodically; all four are among the highest-grossing franchises. Some of the older films that held the record of highest-grossing film still have respectable grosses by today's standards, but no longer compete numerically against today's top-earners in an era of much higher individual ticket prices. When properly adjusted for inflation, however, on that comparative scale Gone with the Windwhich was the highest-grossing film outright for twenty-five yearsis still the highest-grossing film of all time. All grosses on the list are expressed in U.S. dollars at their nominal value, except where stated otherwise.\\r\\nWith a worldwide box-office gross of over $2.7?billion, Avatar is often proclaimed to be the \\"highest-grossing\\" film, but such claims usually refer to theatrical revenues only and do not take into account home video and television income, which can form a significant portion of a film's earnings. Once revenue from home entertainment is factored in it is not immediately clear which film is the most successful. Titanic earned $1.2?billion from video and DVD sales and rentals,[1] in addition to the $2.2?billion it grossed in theaters. While complete sales data are not available for Avatar, it earned $345?million from the sale of sixteen million DVD and Blu-ray units in North America,[2] and ultimately sold a total of thirty million DVD and Blu-ray units worldwide.[3] After home video income is accounted for, both films have earned over $3?billion. Television broadcast rights will also substantially add to a film's earnings, with a film often earning as much as 20ÿ25% of its theatrical box-office for a couple of television runs on top of pay-per-view revenues;[4] Titanic earned a further $55?million from the NBC and HBO broadcast rights,[1] equating to about 9% of its North American gross.\\r\\nWhen a film is highly exploitable as a commercial property, its ancillary revenues can dwarf its income from direct film sales.[5] The Lion King earned over $2?billion in box-office and home video sales,[6] but this pales in comparison to the $6?billion earned at box offices around the world by the stage adaptation.[7] Merchandising can be extremely lucrative too: The Lion King also sold $3?billion of merchandise,[8] while Pixar's Carswhich earned $462?million in theatrical revenues and was only a modest hit by comparison to other Pixar films[9]generated global merchandise sales of over $8?billion in the five years after its 2006 release.[10][11] Pixar also had another huge hit with Toy Story 3, which generated almost $10?billion in merchandise retail sales in addition to the $1?billion it earned at the box office.[12]\\r\\nOn this chart, films are ranked by the revenues from theatrical exhibition at their nominal value, along with the highest positions they attained. Thirty-four films in total have grossed in excess of $1?billion worldwide, of which three have grossed over $2?billion, with Avatar ranked in the top position. All of the films have had a theatrical run (including re-releases) in the 21st century, and films that have not played during this period do not appear on the chart because of ticket-price inflation, population size and ticket purchasing trends not being considered.\\r\\nFBox Office Mojo stopped updating its main total for Frozen in August 2014, while it was still in release. The total listed here incorporates subsequent earnings in Japan, Nigeria, Spain, the United Kingdom and Germany up to the end of 2015 but omits earnings in Turkey, Iceland, Brazil, and Australia (2016) which amount to a few hundred thousand dollars. It was re-released in the United Kingdom in December 2017 with Olaf's Frozen Adventure earning an additional $1,655,398. The total is rounded to $1 million to compensate for the numerical inaccuracy.\\r\\nF8In the case of The Fate of the Furious the gross is sourced from BoxOffice rather than the chart's regular source, Box Office Mojo, after irregularities were discovered in the latter's figure. Ongoing weekly drops in the totals for several countriesArgentina being the worst affectedled to a drop in the overall worldwide total.[14] In view of what appears to be an aberration in the source an alternative figure is provided.\\r\\nTS3Box Office Mojo revised the grosses for Pixar films in August 2016, resulting in the gross for Toy Story 3 being corrected from $1.063 billion to $1.067 billion.[15][16] This means that it peaked at #4 rather than #5 at the end of its release, as indicated by the source.\\r\\nDM2Disney issued an erratum to the gross for The Lion King, correcting its gross from $987.5 million to $968.5 million.[17] This means that Despicable Me 2 finished its run ahead of it and would have ranked one place higher at the end of its release.\\r\\nFNFinding Nemo finished one place higher at the end of its original release, after taking corrections into account. Its total now stands at $940.3 million, which would put the first run at $871.0 million after deducting the 3D reissue gross of $69.3 million, and slightly higher than the $864.6 million Box Office Mojo originally had listed. Meanwhile, Box Office Mojo originally had the gross for The Lord of the Rings: The Fellowship of the Ring listed at $871.4 million prior to its 2011 re-release, but this was dropped to $870.8 million by 2009.[18] The slightly higher gross of $871.0 million for Finding Nemo would rank above the slightly lower gross of $870.8 million for The Fellowship of the Ring.\\r\\nBecause of the long-term effects of inflation, notably the significant increase of movie theater ticket prices, the list unadjusted for inflation gives far more weight to later films.[19] The unadjusted list, while commonly found in the press, is therefore largely meaningless for comparing films widely separated in time, as many films from earlier eras will never appear on a modern unadjusted list, despite achieving higher commercial success when adjusted for price increases.[20] To compensate for the devaluation of the currency, some charts make adjustments for inflation, but not even this practice fully addresses the issue since ticket prices and inflation do not necessarily parallel one another. For example, in 1970, tickets cost $1.55 or about $6.68 in inflation-adjusted 2004 dollars; by 1980, prices had risen to about $2.69, a drop to $5.50 in inflation-adjusted 2004 dollars.[21] Ticket prices have also risen at different rates of inflation around the world, further complicating the process of adjusting worldwide grosses.[19]\\r\\nAnother complication is release in multiple formats for which different ticket prices are charged. One notable example of this phenomenon is Avatar, which was also released in 3D and IMAX: almost two-thirds of tickets for that film were for 3D showings with an average price of $10, and about one-sixth were for IMAX showings with an average price over $14.50, compared to a 2010 average price of $7.61 for 2D films.[22] Social and economic factors such as population change[23] and the growth of international markets[24][25][26] also impact on the number of people purchasing theater tickets, along with audience demographics where some films sell a much higher proportion of discounted children's tickets, or perform better in big cities where tickets cost more.[20]\\r\\nThe measuring system for gauging a film's success is based on unadjusted grosses, mainly because historically this is the way it has always been done because of the practices of the film industry: the box office receipts are compiled by theaters and relayed to the distributor, which in turn releases them to the media.[27] Converting to a more representative system that counts ticket sales rather than gross is also fraught with problems because the only data available for older films are the sale totals.[23] As the motion picture industry is highly oriented towards marketing currently released films, unadjusted figures are always used in marketing campaigns so that new blockbuster films can much more easily achieve a high sales ranking, and thus be promoted as a \\"top film of all time\\",[21][28] so there is little incentive to switch to a more robust analysis from a marketing or even newsworthy point of view.[27]\\r\\nDespite the inherent difficulties in accounting for inflation, several attempts have been made. Estimates depend on the price index used to adjust the grosses,[28] and the exchange rates used to convert between currencies can also impact upon the calculations, both of which can have an effect on the ultimate rankings of an inflation adjusted list. Gone with the Windfirst released in 1939is generally considered to be the most successful film, with Guinness World Records in 2014 estimating its adjusted global gross at $3.4 billion. Estimates for Gone with the Wind's adjusted gross have varied substantially: its owner, Turner Entertainment, estimated its adjusted earnings at $3.3 billion in 2007, a few years earlier than the Guinness estimate;[29] other estimates fall either side of this amount, with one putting its gross just under $3 billion in 2010,[30] while another provided an alternative figure of $3.8 billion in 2006.[31] Which film is Gone with the Wind's nearest rival depends on the set of figures used: Guinness had Avatar in second place with $3 billion, while other estimates saw Titanic in the runner-up spot with first-run worldwide earnings of almost $2.9 billion at 2010 prices. The only other film that all sources agreed grossed in excess of $2 billion at recent prices is Star Wars; according to Guinness it has earned $2.8 billion at 2014 price levels, while other sources from 2010/2011 put its adjusted earnings at $2.2ÿ2.6 billion.[30][32]\\r\\nInfInflation adjustment is carried out using the International Monetary Fund's global Consumer price index.[34] The index is uniformly applied to the grosses in the chart published by Guinness World Records in 2014, beginning with the 2014 index. The figures in the above chart take into account inflation that occurred in 2014, and in every available year since then, with 2016 the most recent year available.\\r\\nTThe figure for Titanic is most likely based on the gross from its 1997 theatrical release, and does not incorporate earnings from the 2012 reissue. According to the 2012 edition of Guinness World Records, the adjusted total for Titanic as of 2011 stood at $2,413,800,000,[35] and a re-release in 2012 added a further $343,550,770 to the total.[36] However, the 2015 edition put the adjusted total at $2,516,000,000an increase of just $102,000,000; this is a rise of 4.2% since 2011, an increase shared by the other adjusted totals in the chart.\\r\\nTFASince Star Wars: The Force Awakens was released in 2015, inflation is only applied to its gross from 2016 onwards.\\r\\nAudience tastes were fairly eclectic during the 20th century, but several trends did emerge. During the silent era, films with war themes were popular with audiences, with The Birth of a Nation (American Civil War), The Four Horsemen of the Apocalypse, The Big Parade and Wings (all World War I) becoming the most successful films in their respective years of release, with the trend coming to an end with All Quiet on the Western Front in 1930. With the advent of sound in 1927, the musicalthe genre best placed to showcase the new technologytook over as the most popular type of film with audiences, with 1928 and 1929 both being topped by musical films. The genre continued to perform strongly in the 1930s, but the outbreak of World War II saw war themed films dominate again during this period, starting with Gone with the Wind (American Civil War) in 1939, and finishing with The Best Years of Our Lives (World War II) in 1946. Samson and Delilah (1949) saw the beginning of a trend of increasingly expensive historical dramas set during Ancient Rome/biblical times throughout the 1950s as cinema competed with television for audiences,[40] with Quo Vadis, The Robe, The Ten Commandments, Ben-Hur and Spartacus all becoming the highest-grossing film of the year during initial release, before the genre started to wane after several high-profile failures.[41] The success of White Christmas and South Pacific in the 1950s foreshadowed the comeback of the musical in the 1960s with West Side Story, Mary Poppins, My Fair Lady, The Sound of Music and Funny Girl all among the top films of the decade. The 1970s saw a shift in audience tastes to high concept films, with six such films made by either George Lucas or Steven Spielberg topping the chart during the 1980s. The 21st century has seen an increasing dependence on franchises and adaptations, with the box office dominance of films based on pre-existing intellectual property at record levels.[42]\\r\\nSteven Spielberg is the most represented director on the chart with six films to his credit, occupying the top spot in 1975, 1981, 1982, 1984, 1989 and 1993. Cecil B. DeMille (1932, 1947, 1949, 1952 and 1956) and William Wyler (1942, 1946, 1959 and 1968) are in second and third place with five and four films respectively, while D. W. Griffith (1915, 1916 and 1920), George Roy Hill (1966, 1969 and 1973) and James Cameron (1991, 1997 and 2009) all feature heavily with three films apiece. George Lucas directed two chart-toppers in 1977 and 1999, but also served in a strong creative capacity as a producer and writer in 1980, 1981, 1983, 1984 and 1989 as well. The following directors have also all directed two films on the chart: Frank Lloyd, King Vidor, Frank Capra, Michael Curtiz, Leo McCarey, Alfred Hitchcock, David Lean, Stanley Kubrick, Guy Hamilton, Mike Nichols, William Friedkin, Peter Jackson, Gore Verbinski and Michael Bay; Mervyn LeRoy, Ken Annakin and Robert Wise are each represented by one solo credit and one shared credit, and John Ford co-directed two films. Disney films are usually co-directed and some directors have served on several winning teams: Wilfred Jackson, Hamilton Luske, Clyde Geronimi, David Hand, Ben Sharpsteen, Wolfgang Reitherman and Bill Roberts have all co-directed at least two films on the list. Only five directors have topped the chart in consecutive years: McCarey (1944 and 1945), Nichols (1966 and 1967), Spielberg (1981 and 1982), Jackson (2002 and 2003) and Verbinski (2006 and 2007).\\r\\nBecause of release schedulesespecially in the case of films released towards the end of the yearand different release patterns across the world, many films can do business in two or more calendar years; therefore the grosses documented here are not confined to just the year of release. Grosses are not limited to original theatrical runs either, with many older films often being re-released periodically so the figures represent all the business a film has done since its original release; a film's first-run gross is included in brackets after the total if known. Because of incomplete data it cannot be known for sure how much money some films have made and when they made it, but generally the chart chronicles the films from each year that went on to earn the most. In the cases where estimates conflict both films are recorded, and in cases where a film has moved into first place because of being re-released the previous record-holder is also retained. At least one film every year has generated $100 million in gross revenue at the box office since 1967,[clarification needed] and from 2008 each year has succeeded in producing a billion dollar grossing film.\\r\\n( ... ) Since grosses are not limited to original theatrical runs, a film's first-run gross is included in brackets after the total if known.\\r\\n*Canada and U.S. gross only.\\r\\nRDistributor rental.\\r\\nTBATo be ascertained.\\r\\nINNo contemporary sources provide figures for 20,000 Leagues Under the Sea, although The Numbers provides a figure of $8,000,000 for the North American box office gross.[47] However, it is possible this figure has been mistaken for the gross of the 1954 remake which also earned $8,000,000 in North American rentals.[48]\\r\\nFHSome sources such as The Numbers state that Aloma of the South Seas is the highest grossing film of the year, earning $3 million.[49] However, no contemporary sources provide figures for Aloma of the South Seas, so it is unclear what the $3 million figure relates to. If it were the rental gross then that would have made it not only the highest-grossing film of the year, but one of the highest-grossing films of the silent era, and if that is the case it would be unusual for both International Motion Picture Almanac and Variety to omit it from their lists.\\r\\nSSIt is not clear if the figure for Sunny Side Up is for North America or worldwide. Other sources put its earnings at $2 million,[50] which may suggest the higher figure is the worldwide rental, given the confusion over international figures during this period.[51]\\r\\nONThe figure for It Happened One Night is not truly representative of its success: it was distributed as a package deal along with more than two dozen other Columbia films, and the total earnings were averaged out; the true gross would have been much higher.\\r\\nS7Snow White's $418 million global cume omits earnings outside of North America from 1987 onwards.\\r\\nGWIt is not absolutely clear how much Gone with the Wind earned from its initial release. Contemporary accounts often list it as earning $32 million in North American rentals and retrospective charts have often duplicated this claim; however, it is likely this was the worldwide rental figure. Trade journals would collate the data by either obtaining it from the distributors themselves, who were keen to promote a successful film, or by surveying theaters and constructing an estimate. Distributors would often report the worldwide rental since the higher figure made the film appear more successful, while estimates were limited to performance in North America; therefore it was not unusual for worldwide and North American rentals to be mixed up. Following the outbreak of World War II, many of the foreign markets were unavailable to Hollywood so it became standard practice to just report on North American box-office performance.[51] In keeping with this new approach, the North American rental for Gone with the Wind was revised to $21 million in 1947 ($11 million lower than the previous figure),[52] and as of 1953following the 1947 re-releaseVariety was reporting earnings of $26 million.[53] Through 1956, MGM reported cumulative North American earnings of $30,015,000 and foreign earnings of $18,964,000, from three releases.[54] Worldwide rentals of $32 million from the initial release is consistent with the revised figures and later reported worldwide figures: they indicate that the film earned $21 million in North America and $11 million overseas from the initial release, and added a further $9 million in North America and $8 million overseas from subsequent re-releases up to 1956.\\r\\nMDMom and Dad does not generally feature in 'high-gross' lists such as those published by Variety due to its independent distribution. Essentially belonging to the exploitation genre, it was marketed as an educational sex hygiene film in an effort to circumvent censorship laws. Falling foul of the Motion Picture Production Code, Mom and Dad was prevented from obtaining mainstream distribution and restricted to independent and drive-in theaters. It was the biggest hit of its kind, and remained in continual distribution until the 1970s when hardcore pornography eventually took over. At the end of 1947 it had earned $2 million, and by 1949, $8 million; by 1956 it had earned $22 million in rentals, representing a gross of $80 million, and would have easily placed in the top ten films in the late 1940s and early 1950s. Estimates of its total earnings are as high as $100 million.\\r\\nUNChopra-Gant stipulates that the figure given for Unconquered is for North American box-office, but as was common at the time, the chart confuses worldwide and North American grosses. Other sources state that the takings for Forever Amber ($8 million) and Life with Father ($6.5 million)[55] were in fact worldwide rental grosses, so it is possible this is also true of Unconquered.\\r\\nCIThe Cinerama figures represent gross amounts. Since the Cinerama corporation owned the theaters there were no rental fees for the films, meaning the studio received 100% of the box-office gross, unlike the case with most other films where the distributor typically receives less than half the gross. Since Variety at the time ranked films by their US rental, they constructed a hypothetical rental figure for the Cinerama films to provide a basis for comparison to other films in their chart: in the case of This Is Cinerama, the $50 million worldwide gross was reconfigured as a $12.5 million US rental gross; this is exactly 25% of the amount reported by Cinerama, so Variety's formula seemingly halved the gross to obtain an estimate for the US share, and halved it again to simulate a rental fee. Variety's 'rental' amounts are often repeated, but have no basis in the reality of what the films actually earnedthey are hypothetical figures conceived for comparative analysis.[56] All five Cinerama features collectively generated $120 million in worldwide box office receipts.[57]\\r\\nGSVariety put the worldwide rental for The Greatest Show on Earth at around $18.35 million (with $12.8 million coming from the United States[48]) a year after its release; however, Birchard puts its earnings at just over $15 million up to 1962. It is likely that Birchard's figure is just the North American gross rental, and includes revenue from the 1954 and 1960 reissues.\\r\\nSWThe \\"first run\\" Star Wars grosses do not include revenue from the 1997 special-edition releases; however, the figure does include revenue from the re-releases prior to the special editions.\\r\\nHPProduction costs were shared with Harry Potter and the Deathly Hallows?ÿ Part 1.\\r\\nAt least ten films have held the record of 'highest-grossing film' since The Birth of a Nation assumed the top spot in 1915. Both The Birth of a Nation and Gone with the Wind spent twenty-five consecutive years apiece as the highest-grosser, with films directed by Steven Spielberg holding the record on three occasions and James Cameronthe current holdertwice. Spielberg became the first director to break his own record when Jurassic Park overtook E.T., and Cameron emulated the feat when Avatar broke the record set by Titanic.\\r\\nSome sources claim that The Big Parade superseded The Birth of a Nation as highest-grossing film, eventually being replaced by Snow White and the Seven Dwarfs, which in turn was quickly usurped by Gone with the Wind.[58] Exact figures are not known for The Birth of a Nation, but contemporary records put its worldwide earnings at $5.2 million as of 1919.[59] Its international release was delayed by World War I, and it was not released in many foreign territories until the 1920s; coupled with further re-releases in the United States, its $10 million earnings as reported by Variety in 1932 are consistent with the earlier figure.[60] At this time, Variety still had The Birth of a Nation ahead of The Big Parade ($6,400,000) on distributor rentals andif its estimate is correctSnow White and the Seven Dwarfs ($8,500,000)[61] would not have earned enough on its first theatrical run to take the record;[62] although it would have been the highest-grossing 'talkie',[63] displacing The Singing Fool ($5,900,000).[64] Although received wisdom holds that it is unlikely The Birth of a Nation was ever overtaken by a silent-era film,[65] the record would fall to 1925's Ben-Hur ($9,386,000) if The Birth of a Nation earned significantly less than its estimated gross.[66] In addition to its gross rental earnings through public exhibition, The Birth of a Nation played at a large number of private, club and organizational engagements which figures are unavailable for.[67] It was hugely popular with the Ku Klux Klan who used it to drive recruitment,[68] and at one point Variety estimated its total earnings to stand at around $50 million.[69] Despite later retracting the claim, the sum has been widely reported even though it has never been substantiated.[59] While it is generally accepted that Gone with the Wind took over the record of highest-grossing film on its initial releasewhich is true in terms of public exhibitionit is likely it did not overtake The Birth of a Nation in total revenue until a much later date, with it still being reported as the highest earner up until the 1960s.[67] Gone with the Wind itself may have been briefly overtaken by The Ten Commandments (1956), which closed at the end of 1960 with worldwide rentals of $58ÿ60 million[70][71] compared to Gone with the Wind's $59 million;[72] if it did claim the top spot its tenure there was short-lived, since Gone with the Wind was re-released the following year and increased its earnings to $67 million. Depending on how accurate the estimates are, the 1959 remake of Ben-Hur may also have captured the record from Gone with the Wind: as of the end of 1961 it had earned $47 million worldwide,[73] and by 1963 it was trailing Gone with the Wind by just $2 million with international takings of $65 million,[74] ultimately earning $66 million from its initial release.[75]\\r\\nAnother film purported to have been the highest-grosser is the 1972 pornographic film, Deep Throat. In 1984, Linda Lovelace testified to a United States Senate Judiciary Subcommittee on juvenile justice that the film had earned $600 million;[76] this figure has been the subject of much speculation, since if it is accurate then the film would have made more money than Star Wars, and finished the 1970s as the highest-grossing film. The main argument against this figure is that it simply did not have a wide enough release to sustain the sort of sums that would be required for it to ultimately gross this amount.[77] Exact figures are not known, but testimony in a federal trial in 1976about four years into the film's releaseshowed the film had grossed over $25 million.[78] Roger Ebert has reasoned it possibly did earn as much as $600 million on paper, since mobsters owned most of the adult movie theaters during this period and would launder income from drugs and prostitution through them, so probably inflated the box office receipts for the film.[79]\\r\\nThe Birth of a Nation, Gone with the Wind, The Godfather, Jaws, Star Wars, E.T. and Avatar all increased their record grosses with re-releases. The grosses from their original theatrical runs are included here along with totals from re-releases up to the point that they lost the record; therefore the total for The Birth of a Nation includes income from its reissues up to 1940; the total for Star Wars includes revenue from the late 1970s and early 1980s reissues but not from the 1997 Special Edition; the total for E.T. incorporates its gross from the 1985 reissue but not from 2002; the total for Avataras the current record-holderincludes all its earnings at the present time. Gone with the Wind is represented twice on the chart: the 1940 entry includes earnings from its staggered 1939ÿ1942 release (roadshow/general release/second-run)[80] along with all of its revenue up to the 1961 reissue prior to losing the record to The Sound of Music in 1966; its 1971 entryafter it took back the recordincludes income from the 1967 and 1971 reissues but omitting later releases. The Godfather was re-released in 1973 after its success at the 45th Academy Awards, and Jaws was released again in 1976, and their grosses here most likely include earnings from those releases. The Sound of Music, The Godfather, Jaws, Jurassic Park and Titanic increased their earnings with further releases in 1973, 1997, 1979, 2013 and 2012 respectively, but they are not included in the totals here since they had already conceded the record prior to being re-released.\\r\\nRDistributor rental.\\r\\nIncludes revenue from re-releases. If a film increased its gross through re-releases while holding the record, the year in which it recorded its highest gross is also noted in italics.\\r\\nPrior to 2000, only seven film series had grossed over $1 billion at the box office: James Bond,[90] Star Wars,[91] Indiana Jones,[92] Rocky,[93][94][95] Batman,[96] Jurassic Park[97] and Star Trek.[98] Since the turn of the century that number has increased to over fifty (not including one-off hits such as Avatar, Titanic and Frozen).[99] This is partly due to inflation and market growth, but also to Hollywood's adoption of the franchise model: films that have built-in brand recognition, such as being based on a well known literary source or an established character. The methodology is based on the concept that films associated with things audiences are already familiar with can be more effectively marketed to them, and as such are known as \\"pre-sold\\" films within the industry.[32]\\r\\nThe films in the cross-franchise Marvel Cinematic Universe have collectively grossed the most, amassing over $16 billion at the box office. The Harry Potter films are the highest-grossing series based on a single property, earning nearly $8 billion at the box office (although the Eon James Bond films have earned over $14 billion in total when adjusted to current prices[100]); Harry Potter has also generated at least $3.5 billion in home video revenue,[101] taking total consumer spending on the films to over $11 billion. If ancillary income from merchandise is included, then Star Wars is the most lucrative property;[102] it holds the Guinness world record for the \\"most successful film merchandising franchise\\" and was valued at S19.51 billion in 2012 (approximately $30 billion).[103][104] Only two franchises have had more than two films gross over $1 billion: the Marvel Cinematic Universe with six, and Star Wars with four. The three Avengers films comprise the only franchise where each installment has grossed over $1 billion. Avengers is also the only franchise to have a series average of over $1 billion per film, although the Star Wars, Pirates of the Caribbean, Jurassic Park and Finding Nemo franchises, Harry Potter films, and Peter Jackson's Middle-earth adaptation all average over $1 billion adjusted for inflation.[32][105]\\r\\nThe following list includes the shared universes Marvel Cinematic Universe and DC Extended Universe. Some films in these franchises are grouped both with the MCU or DCEU and with other films featuring the same character(s).[clarification needed]\\r\\n*Canada and U.S. gross only.\\r\\nRDistributor rental.","input":"What is the highest grossing movie in theaters?"},{"output":"to prevent the escape and the officer has probable cause to believe that the suspect poses a significant threat of death or serious bodily harm to the officer or others","context":"Deadly force, also known as lethal force, is use of force that is likely to cause serious bodily injury or death to another person. In most jurisdictions, the use of deadly force is justified only under conditions of extreme necessity as a last resort, when all lesser means have failed or cannot reasonably be employed.\\r\\n\\r\\nFirearms, bladed weapons, explosives, and vehicles are among those weapons the use of which is considered deadly force. The use of non-traditional weapons in an offensive manner, such as a baseball bat, sharp pencil, tire iron or other, may also be considered deadly force.[1]\\r\\n\\r\\nThe United States Armed Forces defines deadly force as \\"force that a person uses causing, or that a person knows or should know would create a substantial risk of causing, death or serious bodily harm or injury\\".[2][1]\\r\\nIn the United States, the use of deadly force by sworn law enforcement officers is lawful  when the officer reasonably believes the subject poses a significant threat of serious bodily injury or death to themselves or others.  The use of deadly force by law enforcement is also lawful when used to prevent the escape of a fleeing felon when the officer believes escape would pose a significant threat of serious bodily injury or death to members of the public. Common law allowed officers to use any force necessary to effect a felony arrest but this was narrowed in the Tennessee v. Garner ruling in 1985 when the U.S. Supreme Court said that \\"deadly force...may not be used unless necessary to prevent the escape and the officer has probable cause to believe that the suspect poses a significant threat of death or serious bodily harm to the officer or others.\\" [1]\\r\\n\\r\\nIn the 1989 Graham v. Connor ruling, the Supreme Court expanded its definition to include \\"objective reasonableness\\" standardnot subjective as to what the officer's intent might have beenand it must be judged from the perspective of a reasonable officer at the sceneand its calculus must embody the fact that police officers are often forced to make split-second decisions about the amount of force necessary in a particular situation.[1]\\r\\n\\r\\nMost law enforcement agencies establish a use of force continuum starting with simple presence through deadly force. With this model, officers attempt to control subjects and situations with the minimum force necessary. Agencies often have policies limiting the force used to be equal or one step higher on the continuum to the force they are opposing.\\r\\n\\r\\nA civilian's use of deadly force is generally justified if he or she reasonably believe that he or she is or other innocent lives are in imminent danger of death or serious injury.[1]  Justification and affirmative defenses vary by state and may include certain property crimes, specific crimes against children or prevention of sexual assaults. \\r\\n\\r\\nU.S. law requires an investigation whenever a person causes another person's death, but the mechanism for such investigations can vary by state. The investigation develops evidence regarding the use of deadly physical force for the particular state or jurisdiction. An investigation may performed by a local or state police agency and also a civilian agency, such as a county prosecutor or State Attorney General.[1] A report of the findings of such an investigation may be submitted for prosecution and made public.[3]\\r\\n\\r\\nIn Scott v. Harris,  No. 05-1631 (April 30, 2007). , the (U.S. Supreme Court 2007) held that a police officer's attempt to terminate a dangerous high-speed car chase that threatened the lives of innocent bystanders did not violate the Fourth Amendment, even when it places the fleeing motorist at risk of serious bodily injury or death. In the Harris case, Officer Scott applied his police car's push bumper to the rear of the suspect's vehicle, causing the suspect vehicle to lose control and crash, resulting in the fleeing suspect being paralyzed from the waist down.[1]\\r\\n\\r\\nTraditionally, intentional contact between vehicles has been characterized as unlawful deadly force, though some U.S. federal appellate cases have mitigated this precedent. In\\r\\nAdams v. St. Lucie County Sheriff's Department, 998 F.2d 923 (11th Cir. 1993). ,\\r\\nthe Seventh Circuit Court of Appeals ruled that although fatalities may result from intentional collisions between automobiles such fatalities are infrequent, and therefore unlawful deadly force should not be presumed to be the level of force applied in such incidents; the Adams case was subsequently called into question by\\r\\nHarris v Coweta County, 406 F.3d 1307 (11th Cir. 2005). , which in turn was reversed by the U.S. Supreme Court in the Scott v. Harris case discussed above; the extent to which Adams can continue to be relied on is uncertain. In the Adams case, the officer rammed the suspect's vehicle.\\r\\n\\r\\nIn\\r\\nDonovan v. City of Milwaukee, 17 F.3d 944 (7th Cir. 1994). , the Seventh Circuit Court of Appeals recognized this principle but added that collisions between automobiles and motorcycles frequently lead to the death of the motorcyclist, and therefore a presumption that unlawful deadly force was used in such intentional collisions is more appropriate. In the Donovan case, the suspect lost control of his motorcycle and became airborne, crashing into the officer's vehicle, which was parked as part of an intercepting roadblock.","input":"When are police allowed to use deadly force?"},{"output":"Alaska pollock","context":"The Filet-O-Fish, otherwise known as the Fish-O-Filet, is a fish sandwich sold by the international fast food restaurant chain McDonald's. It was invented in 1962 by Lou Groen, a McDonald's franchise owner in Cincinnati, Ohio,[1][2] in response to falling hamburger sales on Fridays resulting from the Roman Catholic practice of abstaining from meat on Fridays.[3] While the fish composition of the sandwich has changed through the years to satisfy taste and supply shortcomings, the framework of its ingredients have remained constant; a fried breaded fish fillet, a steamed bun, tartar sauce and pasteurized processed American cheese.\\r\\n\\r\\nAs of  December?2014[update], the US Filet-O-Fish contains a battered, fried fish fillet made from Alaska pollock.[4] In the Republic of Ireland either hoki or Alaska pollock may be served.[5] In New Zealand and the United Kingdom Filet-O-Fish contains hoki instead of Alaska pollock.[6] McDonald's Canada, United States, United Kingdom, Australia, New Zealand, Portugal, Czech Republic, The Netherlands and Hong Kong use a half slice of cheese in each Filet-O-Fish sandwich.[7][8][9][10]\\r\\n\\r\\nThe sandwich was invented in 1962 by Lou Groen, a McDonald's franchise owner in Cincinnati;[1][2] his store was in a predominantly Roman Catholic neighborhood, which led to falling hamburger sales on Fridays resulting from the Roman Catholic practice of abstaining from meat on Fridays. [3]\\r\\n\\r\\nThe product was named by Cye Landy of Cye Landy Advertising Agency, which was the advertising firm for that particular McDonald's franchise.\\r\\n\\r\\nIt has become popular with people with dietary restrictions concerning meat-based products.\\r\\n\\r\\nThe sandwich was the first non-hamburger menu item brought in by new McDonald's company owner Ray Kroc.[11] Kroc made a deal with Groen: they would sell two non-meat sandwiches on a Friday, Kroc's own Hula Burger (grilled pineapple with cheese on a cold bun) and the Filet-O-Fish, and whichever sold the most would be added to the permanent menu. The Filet-O-Fish \\"won hands down\\"[12] and was added to menus throughout 1963 until reaching nationwide status in 1965.[13]\\r\\n\\r\\nThe use of farmed fish in the Filet-O-Fish first came about in 1981, when an owner of a New Zealand fisheries company was dissatisfied with the pollock Filet-O-Fish he purchased at the Courtenay Place, Wellington restaurant. Saying to the manager that he could make a better-tasting fish fillet, he was handed a box of fillets and told to come back with identical, better-tasting fillets. He substituted red cod for the pollock, and after the manager was satisfied with the better-tasting red cod fillets, ended up in agreement to supply the Courtenay Place restaurant (and eventually several other New Zealand restaurants) with the red cod fillets. The similar-tasting hoki was substituted several years later, due to its competitive market value and its boneless fillets, and eventually was introduced widely in the early 1990s when global pollock stocks were facing low numbers.[14] McDonald's removed the Filet-O-Fish from its menus in the United States on September 26, 1996,[15] and replaced it with the Fish Filet Deluxe sandwich, which was part of McDonald's ill-fated Deluxe line of sandwiches. However, the Filet-O-Fish was brought back to its menus on a gradual basis starting in the middle of 1997, due to overwhelming letters and petitions, receiving the larger fish patty from the Fish Filet Deluxe. The Fish Filet Deluxe itself was discontinued at most restaurants early the next year, while others kept it a little longer until the Fish Filet Deluxe was finally removed in the year 2000.[16]\\r\\n\\r\\nIn November 2007, McDonald's lowered the use of New Zealand hoki and increased the use of Alaskan pollock,[17] due to declining New Zealand hoki fishery sustainability and large cutbacks in the total allowable commercial catch of hoki by the New Zealand Ministry of Fisheries - from 250,000?tonnes in 1997 to 90,000?tonnes in 2007.[18] McDonald's originally used Atlantic cod, before declining cod catches forced McDonald's to find sustainable fish elsewhere. McDonald's is trying to maintain fish only from areas certified as sustainable by the Marine Stewardship Council, but that is becoming more difficult each year. Hoki is still a major ingredient.[19]\\r\\n\\r\\nAs of March 2009, the Marine Stewardship Council[20] placed the Alaskan pollock fisheries in a re-assessment program[21] due to catch numbers declining by over 30% between 2005 and 2008, and by-catch problems with salmon.\\r\\n\\r\\nAs of January 2013 the Marine Stewardship Council stated that the pollock comes from suppliers with sustainable fishing practices, and McDonald's packaging and promotion will reflect that change.[22]\\r\\n\\r\\nIn February 2015, for a limited time, McDonald's began offering a special Filet-O-Fish with Old Bay Seasoning in 700 stores within the United States[23]","input":"What fish is in filet o fish australia?"},{"output":"Dilophosaurus","context":"","input":"What is the spitting dinosaur in jurassic park?"},{"output":"107.6 billion as of 2011","context":"This article lists estimates of world population, as well as projections of future developments.\\r\\nIn summary, estimates for the progression of world population since the late medieval period are in the following ranges:\\r\\n\\r\\nEstimates for pre-modern times are necessarily fraught with great uncertainties, and few of the published estimates have confidence intervals; in the absence of a straightforward means to assess the error of such estimates, a rough idea of expert consensus can be gained by comparing the values given in independent publications. Population estimates cannot be considered accurate to more than two decimal digits;\\r\\nfor example, world population for the year 2012 was estimated at\\r\\n7.02,  7.06 and 7.08 billion by the  United States Census Bureau, the Population Reference Bureau  and the United Nations Department of Economic and Social Affairs, respectively, corresponding to \\r\\na spread of estimates of the order of 0.8%.\\r\\n\\r\\nAs a general rule, the confidence of estimates on historical world population decreases for the more distant past. \\r\\nRobust population data only exists for the last two or three centuries. Until the late 18th century, few governments had ever performed an accurate census. In many early attempts, such as in Ancient Egypt and the Persian Empire, the focus was on counting merely a subset of the population for purposes of taxation or military service.[3]  \\r\\nPublished estimates for the 1st century (\\"AD 1\\") suggest an uncertainty of the order of 50% (estimates range between 150 and 330 million).\\r\\nSome estimates extend their timeline into deep prehistory, to \\"10,000 BC\\", i.e. the  early Holocene,  when world population estimates range roughly between one and ten million (with an uncertainty of up to an order of magnitude).[4][5]\\r\\n\\r\\nEstimates for yet deeper prehistory, into the Paleolithic, are of a different nature. At this time human populations consisted entirely of non-sedentary hunter-gatherer populations, with anatomically modern humans existing alongside archaic human varieties, some of which are still ancestral to the modern human population due to  interbreeding with modern humans during the Upper Paleolithic. \\r\\nEstimates of the size of these populations are a topic of paleoanthropology. A late human population bottleneck is postulated by some scholars at approximately 70,000 years ago, during the Toba catastrophe, when Homo sapiens population may have dropped to as low as between 1,000 and 10,000 individuals.[6][7]\\r\\nFor the time of speciation of Homo sapiens, some 200,000 years ago,  an effective population size of the order of 10,000  to 30,000 individuals has been estimated, with an actual \\"census population\\" of early Homo sapiens of roughly 100,000 to 300,000 individuals.[8]\\r\\n\\r\\n\\r\\nThe question of \\"how many people have ever lived?\\" or \\"what percentage of people who have ever lived are alive today\\" can be traced to the 1970s.[9]\\r\\nThe more dramatic phrasing of \\"the living outnumber the dead\\" also dates to the 1970s, a time of population explosion and growing fears of human overpopulation in the wake of decolonization and before the adoption of China's One-child policy.\\r\\nThe claim that \\"the living outnumber the dead\\" was never accurate (although it may be roughly accurate if only ancestral population is considered). Arthur C. Clarke in 2001: A Space Odyssey (1968) has the claim that \\"Behind every man now alive stand 30 ghosts, for that is the ratio by which the dead outnumber the living\\", which was roughly accurate at the time of writing.[10]\\r\\n\\r\\nEstimates of the \\"total number of people who have ever lived\\" is 107.6 billion as of 2011.[11] \\r\\nThe answer naturally depends on the definition of \\"people\\", i.e. is only Homo sapiens to be counted, or all of genus Homo, but due to the small population sizes in the Lower Paleolithic, the order of magnitude of the estimate is not affected by the choice of cut-off date substantially more than by the uncertainty of estimates throughout the Neolithic to Iron Age.[12]\\r\\nThe estimate is more crucially affected by the estimate of infant mortalitys vs. stillborn infants, due to the very high infant mortality throughout the pre-modern period. An estimate on the \\"total number of people who have ever lived\\" as of 1995 was calculated by Haub (1995) at \\"about 105 billion births since the dawn of the human race\\" with a cut-off date at 50,000 BC (beginning of the Upper Paleolithic), and an inclusion of a high infant mortality rate throughout pre-modern history.[13]\\r\\n\\r\\nThe following table uses astronomical year numbering for dates, negative numbers corresponding roughly to the corresponding year BC (i.e. -10000 = 10,001 BC, etc.). The table starts counting around the Late Glacial Maximum period, in which ice retreated and humans started to spread into the northern hemisphere.\\r\\n\\r\\nFrom the beginning of the early modern period until the 20th century, world population has been characterized by a faster-than-exponential growth.\\r\\nFor the period of Classical Antiquity to the Middle Ages, roughly 500 BC to AD 1500, there has also been a general tendency of growth (estimated at roughly a factor 4 to 5 over the  2,000 year period), but not strictly monotonic: A noticeable dip in world population is assumed due to the Black Death in the mid-14th century.[14]\\r\\n\\r\\n(1973ÿ2016)[15]\\r\\n\\r\\n(2015)[16]\\r\\n\\r\\n(2008)[17]\\r\\n\\r\\n(2010)[citation needed]\\r\\n\\r\\n(1994)[18]\\r\\n\\r\\n(1980)[19]\\r\\n\\r\\nJones (1978)[20]\\r\\n\\r\\n(1975)[21]\\r\\n\\r\\n(1974)[22]\\r\\n\\r\\n(1967)[23]\\r\\n\\r\\nFor times after World War II, demographic data of some accuracy becomes available for a significant number of countries, and population estimates are often given as grand totals of numbers (typically given by country) of widely diverging accuracies. Some sources give these numbers rounded to the nearest million or the nearest thousand, while others give them without any rounding. \\r\\n\\r\\nTaking these numbers at face value would \\r\\nbe false precision; in spite of being stated to four, seven or even ten digits, they should not be interpreted as accurate to more than three digits at best (estimates by the United States Census Bureau and by the United Nations differ by about 0.5%ÿ1.5%).\\r\\n\\r\\n(2017)[28]\\r\\n\\r\\n(1973ÿ2016)[15]\\r\\n\\r\\n(2015)[16]\\r\\n\\r\\n(2008)[17]\\r\\n\\r\\n(2007)[24]\\r\\n\\r\\n(1994)[18]\\r\\n\\r\\n(1980)[19]\\r\\n\\r\\nJones (1978)[20]\\r\\n\\r\\n(1975)[21]\\r\\n\\r\\n(1974)[22]\\r\\n\\r\\n(1967)[23]\\r\\n\\r\\n\\r\\n\\r\\nAs of  2015[update], the population of the world is projected to reach 8 billion in 2025, and 9 billion by about 2040/42. Kapitza (1996) estimated an asymptotic limit of population growth of 14 billion,  90% of which (12.6 billion) expected to be reached by 2135.[29]\\r\\n\\r\\nReasonable predictions of population development are possible for the next 30 years or so, representing the period of fertility of the children alive today. Projections of population reaching more than one generation into the future are highly speculative: Thus, the United Nations Department of Economic and Social Affairs report of 2004 projected the world population to peak at 9.22 billion in 2075 and then stabilise at a value close to 9 billion;[30] \\r\\nBy contrast, a 2014 projection by the United Nations Population Division predicts a population close to 11 billion by 2100 without any declining trend in the foreseeable future.[31] On the other hand, a conservative scenario published in 2012 assumes that a maximum of 8 billion will be reached before 2040.[32]\\r\\n\\r\\nThe following table shows projections of world population for the 21st century.\\r\\n\\r\\n(2015)[28]\\r\\n\\r\\n(1973-2015)[15]\\r\\n\\r\\n(2015)[16]\\r\\n\\r\\nOther, historical projections include\\r\\n\\r\\nPopulation estimates for world regions based on Maddison (2007),[33]  in millions.\\r\\nThe row showing total world population includes the average growth rate per year over the period separating each column from the preceding one.\\r\\n\\r\\nWhen considering population estimates by world region, it is worth noting that population history of the indigenous peoples of the Americas before the 1492 voyage of Christopher Columbus has proven difficult to establish, with many historians arguing for an estimate of 50 million people throughout the Americas, and some estimating that populations may have reached 100 million people or more.[35] It is therefore estimated by some that populations in Mexico, Central, and South America could have reached 37 million by 1492.[36] Additionally, the population estimate of 2 million for North America for the same time period represents the low end of modern estimates, and some estimate the population to have been as high as 18 million.[37]","input":"What is the total population of the world since creation?"},{"output":"Earls Colne Airfield","context":"\\r\\nEssex & Herts Air Ambulance Trust (EHAAT) is a Charity Air Ambulance service providing a free, life-saving Helicopter Emergency Medical Service (HEMS) for the critically ill and injured of Essex, Hertfordshire and surrounding areas. It is not funded by the NHS ÿ only by charitable donations.\\r\\n\\r\\nThe charity aims to save lives, reduce or prevent disability or suffering from critical illness and injury, by delivering a first class pre-hospital emergency medical service.\\r\\n\\r\\nSince fundraising began in 1997, Essex & Herts Air Ambulance has flown over 20,000 missions[1] ÿ being deployed, on average, four to five times per day. The helicopters and Rapid Response Vehicles (RRVs) are based at Earls Colne Airfield and North Weald Airfield.[2]\\r\\n\\r\\nIt costs S6 million every year to cover all charitable costs and aircraft operations.[3]\\r\\n\\r\\nEssex & Herts Air Ambulance provides Helicopter Emergency Medical Service (HEMS) 7 days a week, between 7am and 9pm. At sunset, the helicopters cease to operate, when rapid response vehicles (RRVs) come into operation to provide cover until 9pm. RRVs are also operational for the hours where the aircraft is unable to fly in bad weather or maintenance.\\r\\n\\r\\nOn Friday and Saturday, between 9pm and 2am, the Critical Care Team extends its operating hours, again using RRVs. The overall goal of the charity is to become a 24/7 helicopter service.\\r\\n\\r\\nEach HEMS Team consists of a Pilot, Co-Pilot, a Pre-hospital Care Doctor and a Critical Care Paramedic, who can be rushed to the scene of an incident with life-saving support equipment to deliver advanced clinical care that is normally only found in the hospital emergency department. The dual pilot scheme was introduced in 2016 to enhance patient care[4] - as previously the paramedic would act as navigator, aiding the pilot.\\r\\n\\r\\nEHAAT works in partnership with the East of England Ambulance Service NHS Trust who monitor incoming 999 calls and, according to clinical need, dispatch the Critical Care Team from the Critical Care Desk based in the Emergency Operation Centre at Broomfield Hospital. The desk is manned by a Critical Care Paramedic and a Dispatcher to ensure appropriate tasking.[5]\\r\\n\\r\\nThe helicopters take off within two minutes of the emergency call being received at the Airbase. The helicopter based at Earls Colne can reach the farthest point in Essex in less than 20 minutes and the helicopter based at North Weald can reach the farthest point in Hertfordshire in less than 15 minutes. Once a patient is stabilised the HEMS Team will triage patients to the most appropriate hospital if they require specialist care, such as a Major Trauma Centre. This saves vital minutes between onset of illness or time of accident to the patient receiving specialist medical care in hospital. The helicopters and RRVs can also carry cutting edge life-saving medical equipment and drugs, much of which will not be found on standard land ambulances - along with the specially trained Doctor in Pre-Hospital Emergency Medicine, who can perform life-saving open heart surgery and general anaesthesia at the roadside.[6]\\r\\n\\r\\nEssex & Herts Air Ambulance utilises two helicopters and six rapid response cars to transport their pre-hospital care teams.\\r\\nBoth current helicopters entered service in August 2017. The helicopters have the ability to access remote parts of Essex and Hertfordshire quickly. They are not affected by the ever-increasing traffic congestion on our roads and country lanes. The helicopters can also reach areas inaccessible to land vehicles including woods, beaches, docks and golf courses.\\r\\n\\r\\nIn March 2016, EHAAT signed a contract with aircraft operator, Specialist Aviation Services (SAS) to secure the purchase and operation of an Agusta Westland 169 (AW169) ÿ the leading edge helicopter for emergency medical service operations.[7] This is the first time in the Charity's history that they have been able to purchase an aircraft. It was delivered in August 2017, along with G-EHEM.\\r\\n\\r\\nBased at North Weald, Hertfordshire.\\r\\n\\r\\nCallsign: Helimed 55\\r\\n\\r\\nFinancial status: Wholly owned by charity\\r\\n\\r\\nG-EHEM, previously G-LNCT at Lincs & Notts Air Ambulance, continues to be leased from Specialist Aviation Services (SAS).[8]\\r\\n\\r\\nBased at Earls Colne, Essex.\\r\\n\\r\\nCallsign: Helimed 07\\r\\n\\r\\nFinancial status: Leased from Specialist Aviation Services (Medical Aviation Services)\\r\\n\\r\\nEach base has two RRVs for the medical crew to operate from when helicopters are offline in darkness and bad weather. Each base operates a Vauxhall Insignia VXR and Skoda Octavia Scout, both with four-wheel-drive capability to allow the team to reach the patient in any weather conditions in any location.\\r\\n\\r\\nWhen RRVs are operated, the callsign is changed from 'Helimed' to 'Medic' to signify they are a ground-based resource.\\r\\n\\r\\nAs of January 2018, new two new Volvo XC90s have been delivered and are being branded to work alongside the current fleet.[9][10]\\r\\n\\r\\nG-ESAM was a B?lkow 105, operated between 1998 and 2003.\\r\\n\\r\\nFinancial status: Leased from Bond\\r\\n\\r\\nEurocopter EC135 operated from May 2003 until 2010.[11]\\r\\n\\r\\nFinancial status: Leased from Bond\\r\\n\\r\\nIn 2008, the first Hertfordshire aircraft launched, an MD902 Explorer.\\r\\n\\r\\nFinancial status: Leased from Specialist Aviation Services\\r\\n\\r\\nIn 2010, in line with the new aircraft for Hertfordshire, Essex's aircraft was upgraded to an MD902 Explorer.\\r\\n\\r\\nFinancial status: Leased from Specialist Aviation Services\\r\\n\\r\\nPreviously the Trust operated a single Rapid Response Vehicle. This was a BMW X3, which has now been re-livered into a charity advertisement vehicle, advertising the work the charity does.\\r\\n\\r\\nThe Essex Air Ambulance Charity was established and began fundraising in 1997, launching as a dual paramedic and single pilot service from New Hall School in Boreham, Essex in July 1998.[12] In 1999, the service began operating 7 days a week, during daylight hours - as opposed to the previous 5-day service.\\r\\n\\r\\nIn 2003, the Essex Air Ambulance was upgraded to a Eurocopter EC135 T2.[13]\\r\\n\\r\\nIn April 2007 the Essex Air Ambulance charity became known as the Essex & Herts Air Ambulance Trust (EHAAT), responsible for both the Essex and the new Hertfordshire Air Ambulance services. The Hertfordshire Air Ambulance was introduced on 5 November 2008.[14] With the launch of the Hertfordshire aircraft, Essex's operational colour stayed as yellow and Hertfordshire gained red ÿ both of which featured on the helicopters G-EHAA and G-HAAT.\\r\\n\\r\\nDoctors were introduced to the Essex Air Ambulance Air Crew in July 2008[15] ÿ this new Doctor/Critical Care Paramedic model is used on both aircraft at all times. Pre-hospital Care Doctors could then work alongside specially trained Critical Care Paramedics from the East of England Ambulance Service NHS Trustt to optimise patient outcome. Doctors are employed by Mid Essex Hospital NHS Trust, on behalf of EHAAT - except for a team of consultants, who are seconded from some of their hospital work. Paramedics are provided by EEAST. All paramedics are trained to Critical Care qualification, while doctors have a sub-speciality in Pre-hospital emergency medicine. The team of doctors also included a small number of Consultants.[16]\\r\\n\\r\\nIn 2011, The Essex Air Ambulance's operational base moved from Boreham to Earls Colne Airfield and the Charity Head Office and Essex Fundraising Team move to Earls Colne Business Park in March 2015.[17]\\r\\n\\r\\nIn March 2017, to coincide with the Charity's 20 year anniversary, a new brand was launched which unified Essex Air Ambulance and Herts Air Ambulance, bringing them together for the first time to signify the united future of the Charity.[18] Before this, both helicopters would interchange between Essex and Hertfordshire area on almost a daily bases - despite the names.\\r\\n\\r\\nThis charity is one of many Pre-hospital care providers in the East, which has an established trauma network ÿ the first to be fully operational in the UK.\\r\\n\\r\\nOther Pre-hospital care providers that they work and train alongside are:\\r\\n\\r\\nThe East of England teams commonly end up working alongside crews from Lincolnshire & Nottinghamshire Air Ambulance, London's Air Ambulance and The Air Ambulance Service, along with other BASICS charities.","input":"Where is essex and herts air ambulance based?"},{"output":"Hip hop/pop combination","context":"","input":"What is the most popular music in the usa?"},{"output":"July 12, 1975","context":"The islands of S?o Tom and Prncipe were uninhabited at the time of the arrival of the Portuguese sometime between 1469 and 1471. After the islands were discovered by the explorers Jo?o de Santarm and Pro Escobar,[1] Portuguese navigators explored the islands and decided they would be a good location for bases to trade with the mainland.\\r\\n\\r\\n\\r\\nThe first successful settlement of S?o Tom was established in 1493 by lvaro Caminha, who received the land as a grant from the crown. Prncipe was settled in 1500 under a similar arrangement. Attracting settlers proved difficult, however, and most of the earliest inhabitants were \\"undesirables\\" sent from Portugal, mostly Jews. In time, these settlers found the excellent volcanic soil of the region suitable for agriculture, especially the growing of sugar.\\r\\nThe cultivation of sugar was a labor-intensive process, and the Portuguese began to import large numbers of slaves from the African mainland. By the mid-16th century, the Portuguese settlers had turned the islands into Africa's foremost exporter of sugar. S?o Tom and Prncipe were taken over and administered by the Portuguese crown in 1522 and 1573, respectively.\\r\\nHowever, superior sugar colonies in the western hemisphere began to hurt the islands. The large slave population also proved difficult to control with Portugal unable to invest many resources in the effort. As well, the Dutch captured and occupied S?o Tom for seven years in 1641, razing over 70 sugar mills.[2] Sugar cultivation thus declined over the next 100 years, and by the mid-17th century, the economy of S?o Tom had changed. It was now primarily a transit point for ships engaged in the slave trade between the West and continental Africa.\\r\\nIn the early 19th century, two new cash crops, coffee and cocoa, were introduced. The rich volcanic soils proved well suited to the new cash crop industry, and soon extensive plantations (ro?as), owned by Portuguese companies or absentee landlords, occupied almost all of the good farmland. By 1908, S?o Tom had become the world's largest producer of cocoa, which still is the country's most important crop.\\r\\nThe ro?as system, which gave the plantation managers a high degree of authority, led to abuses against the African farm workers. Although Portugal officially abolished slavery in 1876, the practice of forced paid labor continued. In the early 20th century, an internationally publicized controversy arose over charges that Angolan contract workers were being subjected to forced labor and unsatisfactory working conditions. Sporadic labor unrest and dissatisfaction continued well into the 20th century, culminating in an outbreak of riots in 1953 in which several hundred African laborers were killed in a clash with their Portuguese rulers. This \\"Batep Massacre\\" remains a major event in the colonial history of the islands, and its anniversary is officially observed by the government.\\r\\nDuring the 1967ÿ70 secession war from Nigeria (Nigerian Civil War), S?o Tom served as the major base of operations for the Biafran airlift. The airlift was an international humanitarian relief effort (the largest civilian airlift to date) that transported food and medicine to eastern Nigeria. It is estimated to have saved more than a million lives.[3]\\r\\nBy the late 1950s, when other emerging nations across the African Continent were demanding independence, a small group of S?o Tomans had formed the Movement for the Liberation of S?o Tom and Prncipe (MLSTP), which eventually established its base in nearby Gabon. Picking up momentum in the 1960s, events moved quickly after the overthrow of the Caetano dictatorship in Portugal in April 1974. The new Portuguese regime was committed to the dissolution of its overseas colonies; in November 1974, their representatives met with the MLSTP in Algiers and worked out an agreement for the transfer of sovereignty. After a period of transitional government, S?o Tom and Prncipe achieved independence on July 12, 1975, choosing as its first president the MLSTP Secretary General Manuel Pinto da Costa.\\r\\nIn 1990, S?o Tom became one of the first African countries to embrace democratic reform and changes to the constitutionthe legalization of opposition political partiesled to elections in 1991 that were nonviolent, free, and transparent. Miguel Trovoada, a former prime minister who had been in exile since 1986, returned as an independent candidate and was elected president. Trovoada was re-elected in S?o Tom's second multiparty presidential election in 1996. The Party of Democratic Convergence (PCD) toppled the MLSTP to take a majority of seats in the National Assembly, with the MLSTP becoming an important and vocal minority party. Municipal elections followed in late 1992, in which the MLSTP came back to win a majority of seats on five of seven regional councils. In early legislative elections in October 1994, the MLSTP won a plurality of seats in the Assembly. It regained an outright majority of seats in the November 1998 elections. The Government of S?o Tom fully functions under a multiparty system. Presidential elections were held in July 2001. The candidate backed by the Independent Democratic Action party, Fradique de Menezes, was elected in the first round and inaugurated on September 3. Parliamentary elections were held in March 2002. For the next four years, a series of short-lived, opposition-led governments were formed.\\r\\nThe army seized power for one week in July 2003, complaining of corruption and that forthcoming oil revenues would not be divided fairly. An accord was negotiated under which President de Menezes was returned to office.\\r\\nThe cohabitation period ended in March 2006, when a pro-presidential coalition won enough seats in National Assembly elections to form and head a new government.\\r\\nIn the 30 July 2006 presidential election, Fradique de Menezes easily won a second five-year term in office, defeating two other candidates Patrice Trovoada (son of former President Miguel Trovoada) and independent Nilo Guimar?es. Local elections, the first since 1992, took place on 27 August 2006 and were dominated by members of the ruling coalition.","input":"When did sao tome and principe gain independence?"},{"output":"St. Francis Preparatory School","context":"St. Francis Preparatory School, commonly known as St. Francis Prep, is a private, independent Catholic college preparatory school in the Fresh Meadows neighborhood of the New York City Borough of Queens, in the State of New York. It is the largest non-diocesan Catholic high school in the United States.[3] St. Francis is run by the Franciscan Brothers of Brooklyn, who maintain a residence on the top floor of the school. The school has a student body of about 2,750 students and graduates between 600 and 700 students annually.\\r\\n\\r\\n\\r\\nSt. Francis Preparatory originated as St. Francis Academy, a small all-boys high school on 300 Baltic Street in Brooklyn, New York, founded by the Franciscans Brothers of Brooklyn (O.S.F.).[3] The college section became St. Francis College, a private predominantly undergraduate college in Brooklyn Heights. It took its current name in 1935, then moved to a larger facility in Williamsburg, Brooklyn in 1952.[4] The school moved to its current location in Fresh Meadows, Queens in 1974 when it acquired the facility that formerly housed Bishop Reilly High School, a co-educational Catholic high school. The school began admitting female students that same year.[4] A fitness center was added recently and the science labs are being updated.[citation needed] There are currently plans to add a three-story addition to the rear of the existing building.[citation needed] The upgrades to the art rooms will support students in the studio, digital and the performing arts.[5]\\r\\nSt. Francis Prep has a rivalry with Holy Cross High School, fueled particularly by their football teams. Known as the \\"Battle of the Boulevard\\" due to the two schools being located only 2 miles apart on Francis Lewis Boulevard,[6] the rivalry between the Prep Terriers and the Holy Cross Knights has been called \\"arguably the greatest rivalry in New York City football.\\"[7]\\r\\nThe St. Francis Prep girls tennis team has been undefeated for 17 consecutive years, making them 17 time CHSAA champions.[citation needed] In 2015 the St. Francis Prep Varsity Handball team won their 13th consecutive CHSAA championship (with an undefeated season).[citation needed]","input":"What is the largest catholic high school in america?"},{"output":"General of the Air Force (five-star general)","context":"This is a complete list of four-star generals in the United States Air Force. The rank of general (or full general, or four-star general) is the highest rank normally achievable in the U.S. Air Force. It ranks above lieutenant general (three-star general) and below General of the Air Force (five-star general).\\r\\nThere have been 215 four-star generals in the history of the U.S. Air Force. Of these, 211 achieved that rank while on active duty, 3 were promoted after retirement, and one was promoted posthumously. Generals entered the Air Force via several paths: 60 were commissioned via the U.S. Military Academy (USMA), 49 via the aviation cadet program, 39 via the U.S. Air Force Academy (USAFA), 38 via Air Force Reserve Officer Training Corps (AFROTC) at a civilian university, 12 via AFROTC at a senior military college, 8 via Air Force Officer Training School (OTS), 4 via the U.S. Naval Academy (USNA), 2 via direct commission, one via Reserve Officer Training Corps (ROTC) at a civilian university, one via the Army National Guard (ARNG), and one via the Royal Canadian Air Force (RCAF).\\r\\n\\r\\n\\r\\nEntries in the following list of four-star generals are indexed by the numerical order in which each officer was promoted to that rank while on active duty, or by an asterisk (*) if the officer did not serve in that rank while on active duty. Each entry lists the general's name, date of rank,[1] active-duty positions held while serving at four-star rank,[2] number of years of active-duty service at four-star rank (Yrs),[3] year commissioned and source of commission,[4] number of years in commission when promoted to four-star rank (YC),[5] and other biographical notes.[6]\\r\\nThe list is sortable by last name, date of rank, number of years of active-duty service at four-star rank, year commissioned, and number of years in commission when promoted to four-star rank. The median number of years in commission to achieve four-star rank is 31 (as can be seen by sorting by 'YC' and scrolling halfway down this list) and the quickest rise to four-star is 22 years (LeMay and Norstad).\\r\\nThe modern rank of general was established by the Officer Personnel Act of 1947, which authorized the President to designate certain positions of importance to carry that rank. Officers appointed to such positions bear temporary four-star rank while so serving, and are allowed to retire at that rank if their performance is judged satisfactory.[21] The total number of active-duty four-star generals in the Air Force is limited to a fixed percentage of the number of Air Force general officers serving at all ranks.[22]\\r\\nWithin the Air Force, the chief of staff (CSAF) and vice chief of staff (VCSAF) are four-star generals by statute. Other four-star generals occupy positions of designated importance; historically, these have included the commanders responsible for strategic bombers and nuclear missiles (SAC/STRATCOM); tactical air combat (TAC/ACC); air transport (MAC/TRANSCOM); North American aerospace defense (NORAD); the Air Force formations in Europe and the Pacific; and other training, readiness, and materiel organizations.\\r\\nThe Air Force also competes with the other services for a number of joint four-star positions, such as the chairman (CJCS) and vice chairman (VCJCS) of the Joint Chiefs of Staff. Other joint four-star positions have included unified combatant commanders and certain NATO staff positions.","input":"What is the highest rank in the us air force?"},{"output":"the right-hand side, facing forward","context":"Port and starboard are nautical and aeronautical terms for left and right, respectively. Port is the left-hand side of a vessel or aircraft, facing forward. Starboard is the right-hand side, facing forward. Since port and starboard never change, they are unambiguous references that are not relative to the observer.[2][3]\\r\\nThe term starboard derives from the Old English steorbord, meaning the side on which the ship is steered. Before ships had rudders on their centrelines, they were steered with a steering oar at the stern of the ship and, because more people are right-handed, on the right-hand side of it.[citation needed] The term is cognate with the Old Norse styri (rudder) and bore (side of a ship).[citation needed] Since the steering oar was on the right side of the boat, it would tie up at wharf on the other side. Hence the left side was called port.[citation needed]\\r\\nFormerly, larboard was used instead of port. This is from Middle-English ladebord and the term lade is related to the modern load.[3] Larboard sounds similar to starboard and in 1844 the Royal Navy ordered that port be used instead.[4][non-primary source needed] The United States Navy followed suit in 1846.[5] Larboard continued to be used well into the 1850s by whalers.[citation needed] In Old English the word was b?cbord, of which cognates are used in other European languages, for example as the present Dutch bakboord, the German backbord and the French term babord (derived in turn from Middle Dutch).[citation needed]\\r\\nThe navigational treaty convention, the International Regulations for Preventing Collisions at Seafor instance, as appears in the Merchant Shipping (Distress Signals and Prevention of Collisions) Regulations of 1996 (and comparable US documents from the US Coast Guard),[6]sets forth the rights of way for maritime vessels, whether by sail or powered, and whether a vessel is overtaking, approaching head-on, or crossing.[6]:11-12 To set forth these navigational rules, the terms starboard and port are absolutely essential, and to aid in in situ decision-making, the two sides of each vessel are marked, dusk to dawn, by navigation lights, the vessel's starboard side by green and its port side by red.[6]:15 Aircraft are lit in the same way.","input":"What is the starboard side of a ship?"},{"output":"Holyoke, Massachusetts","context":"The International Volleyball Hall of Fame (IVHF) was founded to honor extraordinary players, coaches, officials, and leaders who have made significant contributions to the game of volleyball.   The Hall of Fame is located in Holyoke, Massachusetts, where volleyball was invented in 1895 by William G. Morgan at the local YMCA.[1]\\r\\n\\r\\nIn 1971 the Greater Holyoke Chamber of Commerce established a committee to campaign for the founding of the Volleyball Hall of Fame in Holyoke, Massachusetts.  \\r\\n\\r\\nIn 1978, the committee incorporated as Holyoke Volleyball Hall of Fame, Inc., a nonprofit corporation established for the purpose of planning, promoting, establishing and maintaining a living memorial to the sport of volleyball.  The name of the corporation was changed to the International Volleyball Hall of Fame by resolution of the Board of Directors on July 17, 2014.\\r\\n\\r\\nA small exhibit dedicated to the history of volleyball and the hall of fame's inductees opened in a 1,600 square feet (150?m2) section of the renovated Skinner Mill Warehouse on June 6, 1987 - a building built in 1949 to store silk fabric produced by the famous Skinner Mill in Holyoke.  The mill itself was destroyed by fire in 1980. \\r\\n\\r\\nIn 1998, the exhibit was expanded and moved to a permanent 5,000 square feet (460?m2) location in the Skinner Mill Warehouse in downtown Holyoke's Heritage State Park sharing the building with the Holyoke Children's Museum.  \\r\\n\\r\\nThe IVHF museum now features exhibits honoring each year's inductees, a replica of a full-size volleyball court, sport timelines, photos, and unique and meaningful memorabilia of the sport along with an interactive video kiosk, a special inductee display area, and a gift shop.[1]\\r\\n\\r\\nIn 1985, William G. Morgan (inventor of volleyball) was posthumously inducted into the hall as its first member. A total of 130 men and women from 22 countries around the world have since been inducted into the International Volleyball Hall of Fame. The international appeal of the sport explains a shift in the pool of inductees since 1998. Since that time, inductees have come from around the world and contribute to the honoring of the sport and its home in Holyoke. \\r\\n\\r\\nGeorge Mulry has served as Executive Director of the International Volleyball Hall of Fame since April 2011.\\r\\n\\r\\nThe following tables enumerate all of the inductees to the Volleyball Hall of Fame through 2017.[2][3]\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nCoordinates: 421220.6N 723621.5W? / ?42.205722N 72.605972W? / 42.205722; -72.605972","input":"Where is the volleyball hall of fame located?"},{"output":"Vedic","context":"","input":"What was the religion in india before hinduism?"},{"output":"27 April 1994","context":"The flag of South Africa was adopted on 27 April 1994, at the beginning of South Africa's 1994 general election, to replace the flag that had been used since 1928. The new national flag, designed by the then State Herald of South Africa Frederick Brownell, was chosen to represent the country's new democracy after the end of apartheid.\\r\\nThe flag has horizontal bands of red (on the top) and blue (on the bottom), of equal width, separated by a central green band which splits into a horizontal \\"Y\\" shape, the arms of which end at the corners of the hoist side (and follow the flag's diagonals). The \\"Y\\" embraces a black isosceles triangle from which the arms are separated by narrow yellow bands; the red and blue bands are separated from the green band and its arms by narrow white stripes. The stripes at the fly end are in the 5:1:3:1:5 ratio.\\r\\n\\r\\n\\r\\nAt the time of its adoption, the South African flag was the only national flag in the world to comprise six colours in its primary design and without a seal and brocade. The design and colours are a synopsis of principal elements of the country's flag history. Individual colours, or colour combinations have different meanings for different people and therefore no universal symbolism should be attached to any of the colours.\\r\\nThe central design of the flag, beginning at the flagpost in a \\"V\\" form and flowing into a single horizontal band to the outer edge of the fly, can be interpreted as the convergence of diverse elements within South African society, taking the road ahead in unity. The theme of convergence and unity ties in with the motto \\"Unity is Strength\\" of the previous South African Coat of Arms.\\r\\nThe design therefore represents a converging of paths, the merging of both the past and the present.\\r\\nAccording to the flag's designer, the red symbolizes the blood that was shed during the various wars and conflicts in the country. It is also suggested that the blue represents the sky and the two oceans that flank the country. The green symbolizes the farms and the rich, natural environment of the country, while the yellow represents the natural resources, particularly gold. Finally, it is said that the black represents black South Africans, while the white represents the white population of the country.\\r\\nThe Anglo-Boer War between 1899 and 1902 ended with the Treaty of Vereeniging on 31 May 1902 and resulted in what is now South Africa falling under the British Union Flag. The former Boer Republics of the Orange Free State and the Zuid-Afrikaanse Republiek (Transvaal) became British colonies along with the existing Cape and Natal colonies. Each was also entitled to a colonial flag following in the British tradition.\\r\\nOn 31 May 1910 these four colonies came together to form the Union of South Africa and the individual colonial flags were no longer used and new South African flags came into being. Once again, as a British dominion the British Union Flag was to continue as the national flag and the standard British ensign pattern was used as a basis for distinctive South African flags.\\r\\nAs was the case throughout the British Empire, the Red and Blue Ensigns were the official flags for merchant and government vessels at sea, and the British Admiralty authorised them to be defaced in the fly with the shield from the South African coat of arms.[1][2] These ensigns were not intended to be used as the Union's national flag, although they were used by some people as such. Although these ensigns were primarily intended for maritime use, they were also flown on land.\\r\\nThe South Africa Red Ensign was South Africa's de facto national flag between 1910 and 1928 and was flown at times from Government buildings.\\r\\nThe Blue Ensign was flown over the Unions offices abroad between 1910 and 1928.\\r\\nThe design of the Red Ensign was modified slightly in 1912 when the shield was placed on a white disc so as to make it more distinguishable. The Red Ensign continued to be used as the flag of the South African merchant marine until 1951.[3]\\r\\nThese flags never enjoyed much popular support due to the animosities lingering after the Anglo-Boer War. The Afrikaner descendants of the Dutch settlers from the former Boer Republics found the prominent position of the British Union Flag to be offensive while the English-speakers saw any move to remove it as an Afrikaner plot to deprive them of their imperial symbol.\\r\\nDue to the lack of popularity of these flags, there were intermittent discussions about the desirability of a more distinctive national flag for South Africa after 1910,[4] it was only after a coalition government took office in 1925 that a bill was introduced in Parliament to introduce a national flag for the Union. This provoked often violent controversy that lasted for three years based on whether the British Union Flag should be included in the new flag design or not. The Natal Province even threatened to secede from the Union should it be decided to remove it.\\r\\nFinally, a compromise was reached that resulted in the adoption of a separate flag for the Union in late 1927 and the design was first hoisted on 31 May 1928. The design was based on the so-called Van Riebeeck flag or Prinsenvlag (\\"Prince's Flag\\" in Afrikaans) that was originally the Dutch flag; it consisted of orange, white, and blue horizontal stripes. A version of this flag had been used as the flag of the Dutch East India Company (known as the VOC) at the Cape (with the VOC logo in the centre) from 1652 until 1795. The South African addition to the design was the inclusion of three smaller flags centred in the white stripe. The miniature flags were the British Union Flag (mirrored) towards the hoist, the flag of the Orange Free State hanging vertically in the middle and the Transvaal Vierkleur towards the fly. The position of each of the miniature flags is such that each has equal status. However, to ensure that the Dutch flag in the canton of the Orange Free State flag is placed nearest to the upper hoist of the main flag, the Free State flag must be reversed. The British Union Flag, which is nearest to the hoist and is thus in a more favoured position, is spread horizontally from the Free State flag towards the hoist and is thus also reversed. Although placed horizontally furthest from the hoist, to balance the British Union Flag, the Vierkleur is the only one of the miniature flags which is spread in the same direction as the main flag. This compensates for its otherwise less favourable position. In this arrangement, each of the miniature flags enjoy equal precedence.[5] Note that the miniature flag of the Orange Free State contains a miniature of the Dutch flag, making the South African flag the only flag in the world containing a flag in a flag in a flag.\\r\\nThe choice of the Prinsenvlag as the basis upon which to design the South African flag had more to do with compromise than Afrikaner political desires, as the Prinsenvlag was believed to be the first flag hoisted on South African soil by Jan van Riebeeck of the VOC and was politically neutral, as it was no longer the national flag of any nation. A further element of this compromise was that the British Union Flag would continue to fly alongside the new South African national flag over official buildings. This dual flag arrangement continued until 1957 when the British Union Flag lost its official status per an Act of Parliament.\\r\\nFollowing a referendum the country became a republic on 31 May 1961, but the design of the flag remained unchanged. However, there was intense pressure to change the flag, particularly from Afrikaners who still resented the fact that the British Union Flag was a part of the flag. In 1968, the then Prime Minister, John Vorster, proposed the adoption of a new flag from 1971, to commemorate the tenth anniversary of the declaration of a republic but this never materialised.[6]\\r\\nThe present South African national flag was first flown on 27 April 1994, the day of the 1994 election. However, the flag was first intended to be an interim flag only, and its design was decided upon only a week beforehand.\\r\\nThe choice of a new flag was part of the negotiation process set in motion when Nelson Mandela was released from prison in 1990. When a nationwide public competition was held in 1993, the National Symbols Commission received more than 7,000 designs. Six designs were shortlisted and presented to the public and the Negotiating Council, but none elicited enthusiastic support. A number of design studios were then contacted to submit further proposals, but these also did not find favour. Parliament went into recess at the end of 1993 without a suitable candidate for the new national flag.\\r\\nIn February 1994, Cyril Ramaphosa and Roelf Meyer, the chief negotiators of the African National Congress and the National Party government of the day respectively, were given the task of resolving the flag issue. A final design was adopted on 15 March 1994, derived from a design developed by the State Herald Fred Brownell,[7] who had also previously designed the Flag of Namibia. This interim flag was hoisted for the first time on the 27 April 1994, the day when the nations first fully inclusive elections commenced which resulted in Nelson Mandela being inaugurated as South Africas first democratically elected president on 10 May 1994.\\r\\nThe proclamation of the new national flag by South African President F. W. de Klerk was only published on 20 April 1994,[8] a mere seven days before the flag was to be inaugurated, sparking a frantic last-minute flurry for flag manufacturers. As stated in South Africa's post-apartheid interim constitution, the flag was to be introduced on an interim probationary period of five years, after which there would be discussion about whether or not to change the national flag in the final draft of the constitution. The Constitutional Assembly was charged with the responsibility of drafting the countrys new constitution and had called for submissions, inter alia, on the issues of its various national symbols. It received 118 submissions recommending the retention of the new flag and 35 suggesting changes to it. Thus on 28 September 1995 it decided that the flag should be retained unchanged and accordingly it was included as Section One of the Constitution of South Africa which came into force in February 1997.[9]\\r\\nThe South African government published guidelines for proper display of the flag at designated flag stations, in Government Notice 510 of 8 June 2001 (Gazette number 22356). These rules apply only to official flag stations and not to the general public.\\r\\nThe Southern African Vexillological Association (SAVA), a non-official association for the study of flags, published their own guide for proper display of the flag in 2002. This guide has no official authority but was drawn up with generally accepted vexillological etiquette and principles in mind.[10]\\r\\nAn addendum to the Transitional Executive Council agenda (April 1994) described the flag in heraldic terms as follows:\\r\\nThe National flag shall be rectangular in the proportion of two in the width to three to the length; per pall from the hoist, the upper band red (chilli) and lower band blue, with a black triangle at the hoist; over the partition lines a green pall one fifth the width of the flag, fimbriated white against the red and blue, and gold against the black triangle at the hoist, and the width of the pall and its fimbriations is one third the width of the flag.\\r\\nSchedule One of the Constitution of South Africa (1996) replaced the heraldic definition and described the flag in plain English as follows:[11]","input":"When was the new south african flag adopted?"},{"output":"Despacito","context":"YouTube is an American video-sharing website headquartered in San Bruno, California. Since its establishment in 2005, the website has featured a \\"most viewed\\" section, which lists the most viewed videos on the site. Although the most viewed videos were initially viral videos, such as Evolution of Dance and Charlie Bit My Finger, the most viewed videos were increasingly related to music videos. In fact, since Lady Gaga's Bad Romance, every single video that has reached the top of the \\"most viewed YouTube videos\\" list has been a music video. Although the most viewed videos are no longer listed on the site, reaching the top of the list is still considered a tremendous feat.\\r\\nIn June 2015, only two videos, \\"Gangnam Style\\" and \\"Baby\\", had reached over a billion views. Three months later, however, ten videos had done so.[1] As of September 2017, 78 videos on the list have exceeded one billion views, with 16 of them exceeding two billion views; two of which exceed three billion views. \\"Despacito\\" became the first video to reach three billion views on August 4, 2017, followed by \\"See You Again\\" on August 6, 2017.[2][3]\\r\\nAs of September 2017, the five fastest videos to reach the one billion view mark are \\"Hello\\" (87 days), \\"Despacito\\" (97 days), \\"Shape of You\\" (97 days), \\"Sorry\\" (137 days), and \\"Chantaje\\" (140 days).[4]\\r\\nThe five fastest videos to reach two billion views are \\"Despacito\\" (154 days), \\"Shape of You\\" (188 days), \\"Sorry\\" (394 days), \\"See You Again\\" (515 days) and \\"Hello\\" (620 days).[5]\\r\\nAs of September 2017, Justin Bieber and Katy Perry each have four videos exceeding one billion views, while Taylor Swift, Calvin Harris, Shakira and Ariana Grande each have three, and Fifth Harmony, Psy, Adele, Ellie Goulding, The Weeknd, Ed Sheeran, Nicky Jam and Eminem each have two. Swift and Perry are the only artists to have two videos exceeding two billion views.\\r\\n\\r\\n\\r\\nThe following table lists the top 100 most viewed videos on YouTube, with each total rounded to the nearest 10 million views, as well as the creator and date of publication to YouTube.[A]\\r\\nThe following table lists the current top 5 most viewed YouTube videos uploaded in each year, with each total rounded to the nearest million views, as well as the uploader and date of publication to YouTube.[J]\\r\\nAs of September 2017, only Linkin Park (2007), Gummib?r/icanrockyourworld (2007) and Taylor Swift (2014) have two videos in the top 5 of a single year, with both the English and French versions of Gummib?r's The Gummy Bear Song being in the top five videos of 2007.\\r\\nThe following table lists the last 15 videos to become YouTube's most viewed video, from October 2005 to the present.\\r\\n*The approximate number of views each video had when it became YouTube's most viewed video.\\r\\nTimeline of Most Viewed Videos (Oct 2005 - Sep 2017)\\r\\n 1 Most Viewed Video (Oct 2005 - Jun 2006)\\r\\n 1 Most Viewed Video (Apr 2006 - Jan 2010)\\r\\n 1 Most Viewed Video (Oct 2009 - Jan 2013)\\r\\n 1 Most Viewed Video (Jan 2012 - Sep 2017)","input":"What's the highest viewed video on youtube ever?"},{"output":"New International Version","context":"Partial Bible translations into languages of the English people can be traced back to the late 7th century, including translations into Old and Middle English. More than 450 translations into English have been written.\\r\\nThe New Revised Standard Version is the version most commonly preferred by biblical scholars.[1] In the United States, 55% of survey respondents who read the Bible reported using the King James Version in 2014, followed by 19% for the New International Version, with other versions used by fewer than 10%.[2]\\r\\n\\r\\n\\r\\nAlthough John Wycliffe is often credited with the first translation of the Bible into English, there were in fact many translations of large parts of the Bible centuries before Wycliffe's work. The English Bible was first translated from the Latin Vulgate into Old English by a few select monks and scholars. Such translations were generally in the form of prose or as interlinear glosses (literal translations above the Latin words).\\r\\nVery few complete translations existed during that time. Most of the books of the Bible existed separately and were read as individual texts. Thus the sense of the Bible as history that often exists today did not exist at that time. Instead, an allegorical rendering of the Bible was more common and translations of the Bible often included the writers own commentary on passages in addition to the literal translation.\\r\\nToward the end of the 7th century, the Venerable Bede began a translation of scripture into Old English (often incorrectly called Anglo-Saxon). Aldhelm (c. 639ÿ709) translated the complete Book of Psalms and large portions of other scriptures into Old English.\\r\\nIn the 10th century an Old English translation of the Gospels was made in the Lindisfarne Gospels: a word-for-word gloss inserted between the lines of the Latin text by Aldred, Provost of Chester-le-Street.[3] This is the oldest extant translation of the Gospels into the English language.[3]\\r\\nThe Wessex Gospels (also known as the West-Saxon Gospels) are a full translation of the four gospels into a West Saxon dialect of Old English. Produced in approximately 990, they are the first translation of all four gospels into English without the Latin text.\\r\\nIn the 11th century, Abbot ?lfric translated much of the Old Testament into Old English. The Old English Hexateuch is an illuminated manuscript of the first six books of the Old Testament without lavish illustrations and including a translation of the Book of Judges in addition to the 5 books of the Pentateuch.\\r\\nThe Ormulum is in Middle English of the 12th century. Like its Old English precursor from ?lfric, an Abbot of Eynsham, it includes very little Biblical text, and focuses more on personal commentary. This style was adopted by many of the original English translators. For example, the story of the Wedding at Cana is almost 800 lines long, but fewer than 40 lines are the actual translation of the text. An unusual characteristic is that the translation mimics Latin verse, and so is similar to the better known and appreciated 14th-century English poem, Cursor Mundi.\\r\\nRichard Rolle (1290ÿ1349) wrote an English Psalter. Many religious works are attributed to Rolle, but it has been questioned how many are genuinely from his hand. Many of his works were concerned with personal devotion, and some were used by the Lollards.[4]\\r\\nThe 14th century theologian John Wycliffe is credited with translating what is now known as Wycliffe's Bible, though it is not clear how much of the translation he himself did.[5] This translation came out in two different versions. The earlier text is characterised by a strong adherence to the word order of Latin, and might have been difficult for the layperson to comprehend. The later text made more concessions to the native grammar of English.\\r\\nEarly Modern English Bible translations are of between about 1500 and 1800, the period of Early Modern English. This, the first major period of Bible translation into the English language, began with the introduction of the Tyndale Bible. The first complete edition of his New Testament was in 1526. Tyndale used the Greek and Hebrew texts of the New Testament (NT) and Old Testament (OT) in addition to Jerome's Latin translation. He was the first translator to use the printing press ÿ this enabled the distribution of several thousand copies of his New Testament translation throughout England. Tyndale did not complete his Old Testament translation.\\r\\nThe first printed English translation of the whole bible was produced by Miles Coverdale in 1535, using Tyndale's work together with his own translations from the Latin Vulgate or German text. After much scholarly debate it is concluded that this was printed in Antwerp and the colophon gives the date as 4th October 1535. This first edition was adapted by Coverdale for his first \\"authorised version\\", known as the Great Bible, of 1539. Other early printed versions were the Geneva Bible (1560), notable for being the first Bible divided into verses; the Bishop's Bible (1568), which was an attempt by Elizabeth I to create a new authorised version; and the Authorized King James Version of 1611.\\r\\nThe first complete Roman Catholic Bible in English was the DouayÿRheims Bible, of which the New Testament portion was published in Rheims in 1582 and the Old Testament somewhat later in Douay in Gallicant Flanders. The Old Testament was completed by the time the New Testament was published, but due to extenuating circumstances and financial issues was not published until nearly three decades later, in two editions, the first released in 1609, and the rest of the OT in 1610. In this version, the seven deuterocanonical books are mingled with the other books, rather than kept separate in an appendix.\\r\\nWhile early English Bibles were generally based on a small number of Greek texts, or on Latin translations, modern English translations of the Bible are based on a wider variety of manuscripts in the original languages (Greek and Hebrew). The translators put much scholarly effort into cross-checking the various sources such as the Septuagint, Textus Receptus, and Masoretic Text. Relatively recent discoveries such as the Dead Sea scrolls provide additional reference information. There is some controversy over which texts should be used as a basis for translation, as some of the alternate sources do not include phrases (or sometimes entire verses) which are found only in the Textus Receptus.[6]\\r\\nSome[who?] say the alternate sources were poorly representative of the texts used in their time, whereas others[who?] claim the Textus Receptus includes passages that were added to the alternate texts improperly. These controversial passages are not the basis for disputed issues of doctrine, but tend to be additional stories or snippets of phrases. Many modern English translations, such as the New International Version, contain limited text notes indicating where differences occur in original sources.[7]\\r\\nA somewhat greater number of textual differences are noted in the New King James Bible, indicating hundreds of New Testament differences between the Nestle-Aland, the Textus Receptus, and the Hodges edition of the Majority Text. The differences in the Old Testament are less well documented, but do contain some references to differences between consonantal interpretations in the Masoretic Text, the Dead Sea Scrolls, and the Septuagint. Even with these hundreds of differences, however, a more complete listing is beyond the scope of most single volume Bibles (see Critical Translations below).\\r\\nModern translations take different approaches to the rendering of the original languages of approaches. The approaches can usually be considered to be somewhere on a scale between the two extremes:\\r\\nSome translations have been motivated by a strong theological distinctive, such as the conviction that God's name be preserved in a Semitic form, seen in Sacred Name Bibles. The Purified Translation of the Bible promotes the idea that Jesus and early Christians did not drink wine, but grape juice.[citation needed] The Jehovah's Witnesses' New World Translation of the Holy Scriptures renders the tetragrammaton as Jehovah throughout the Old Testament; it also uses the form Jehovah in the New Testament, including but not limited to passages quoting the Old Testament, even though it does not appear in the Greek text.\\r\\nOutline of Bible-related topics\\r\\nWhile most translations are made by committees of scholars in order to avoid bias or idiosyncrasy, translations are sometimes made by individuals. The translation of J.B. Phillips (1958), The Bible in Living English (1972) by Stephen T. Byington, J.N. Darby's Darby Bible (1890), Heinz Cassirer's translation (1989), R.A. Knox (1950), Gerrit Verkuyl's Berkeley Version (1959), The Complete Jewish Bible (1998) by Dr. David H. Stern, Robert Young's Literal Translation (1862), Jay P.Green's Literal Translation (1985), The Emphatic Diaglott by Benjamin Wilson (1864), Noah Webster's Bible Translation (1833), The Original Aramaic Bible in Plain English (2010) by David Bauscher, American King James Version (1999) by Michael Engelbrite, The Living Bible (1971) by Kenneth N. Taylor, The Modern Reader's Bible (1914) by Richard Moulton, The Five Pauline Epistles, A New Translation (1900) by William Gunion Rutherford, Joseph Bryant Rotherham's Emphasized Bible (1902), Professor S. H. Hooke's The Bible in Basic English (1949), The Holy Name Bible containing the Holy Name Version of the Old and New Testaments (1963) by Angelo Traina, and Eugene H. Peterson's The Message (2002) are largely the work of individual translators. Others, such as Robert Alter, N. T. Wright and Dele Ikeorha have translated portions of the Bible.\\r\\nMost translations make the translators' best attempt at a single rendering of the original, relying on footnotes where there might be alternative translations or textual variants. An alternative is taken by the Amplified Bible. In cases where a word or phrase admits of more than one meaning the Amplified Bible presents all the possible interpretations, allowing the reader to choose one. For example, the first two verses of the Amplified Bible read:\\r\\nIn the beginning God (Elohim) created [by forming from nothing] the heavens and the earth. The earth was formless and void or a waste and emptiness, and darkness was upon the face of the deep [primeval ocean that covered the unformed earth]. The Spirit of God was moving (hovering, brooding) over the face of the waters.[8]\\r\\nWhile most translations attempt to synthesize the various texts in the original languages, some translations also translate one specific textual source, generally for scholarly reasons. A single volume example for the Old Testament is The Dead Sea Scrolls Bible (ISBN?0-06-060064-0) by Martin Abegg, Peter Flint and Eugene Ulrich.\\r\\nThe Comprehensive New Testament (ISBN?978-0-9778737-1-5) by T. E. Clontz and J. Clontz presents a scholarly view of the New Testament text by conforming to the Nestle-Aland 27th edition and extensively annotating the translation to fully explain different textual sources and possible alternative translations.[9][10]\\r\\nA Comparative Psalter (ISBN?0-19-529760-1) edited by John Kohlenberger presents a comparative diglot translation of the Psalms of the Masoretic Text and the Septuagint, using the Revised Standard Version and the New English Translation of the Septuagint.\\r\\nR. A. Knox's Translation of the Vulgate into English is another example of a single source translation.\\r\\nJewish English Bible translations are modern English Bible translations that include the books of the Hebrew Bible (Tanakh) according to the masoretic text, and according to the traditional division and order of Torah, Nevi'im, and Ketuvim.\\r\\nJewish translations often also reflect traditional Jewish interpretations of the Bible, as opposed to the Christian understanding that is often reflected in non-Jewish translations. For example, Jewish translations translate ???? almah in Isaiah 7:14 as young woman, while many Christian translations render the word as virgin.\\r\\nWhile modern biblical scholarship is similar for both Christians and Jews, there are distinctive features of Jewish translations, even those created by academic scholars. These include the avoidance of Christological interpretations, adherence to the Masoretic Text (at least in the main body of the text, as in the new Jewish Publication Society (JPS) translation) and greater use of classical Jewish exegesis. Some translations prefer names transliterated from the Hebrew, though the majority of Jewish translations use the Anglicized forms of biblical names.\\r\\nThe first English Jewish translation of the Bible into English was by Isaac Leeser in the 19th century.\\r\\nThe JPS produced two of the most popular Jewish translations, namely the JPS The Holy Scriptures of 1917 and the NJPS Tanakh (first printed in a single volume in 1985, second edition in 1999).\\r\\nSince the 1980s there have been multiple efforts among Orthodox publishers to produce translations that are not only Jewish, but also adhere to Orthodox norms. Among these are The Living Torah and Nach by Aryeh Kaplan and others, the Torah and other portions in an ongoing project by Everett Fox, and the ArtScroll Tanakh.\\r\\nThe evangelical Christian Booksellers Association lists the most popular versions of the Bible sold by their members in the United States. Through 29 December 2012, the top 5 best selling translations (based on both dollar and unit sales) are as follows:[11]\\r\\nSales are affected by denomination and religious affiliation. For example, the most popular Jewish version would not compete with rankings of a larger audience. Sales data can be affected by the method of marketing. Some translations are directly marketed to particular denominations or local churches, and many Christian booksellers only offer Protestant Bibles, so Catholic and Orthodox Bibles may not appear as high on the CBA rank.\\r\\nA study published in 2014 by The Center for the Study of Religion and American Culture at Indiana University and Purdue University found that Americans read versions of the Bible as follows:[12][13]:12ÿ15","input":"What is the best selling bible translation of all time?"},{"output":"plutonium","context":"A period 7 element is one of the chemical elements in the seventh row (or period) of the periodic table of the chemical elements. The periodic table is laid out in rows to illustrate recurring (periodic) trends in the chemical behaviour of the elements as their atomic number increases: a new row is begun when chemical behaviour begins to repeat, meaning that elements with similar behaviour fall into the same vertical columns. The seventh period contains 32 elements, tied for the most with period 6, beginning with francium and ending with oganesson, the heaviest element currently discovered. As a rule, period 7 elements fill their 7s shells first, then their 5f, 6d, and 7p shells, in that order; however, there are exceptions, such as plutonium.\\r\\n\\r\\n\\r\\nAll elements of period 7 are radioactive. This period contains the actinides, which contains the heaviest naturally occurring element, plutonium; subsequent elements must be synthesized artificially. Whilst the first five of these are now available in macroscopic quantities, most are extremely rare, having only been prepared in microgram amounts or less. The later, transactinide elements have only been identified in laboratories in batches of a few atoms at a time.\\r\\nAlthough the rarity of many of these elements means that experimental results are not very extensive, their periodic and group trends are less well defined than other periods. Whilst francium and radium do show typical properties of their respective groups, actinides display a much greater variety of behaviour and oxidation states than the lanthanides. These peculiarities are due to a variety of factors, including a large degree of spin-orbit coupling and relativistic effects, ultimately caused by the very high positive electrical charge from their massive atomic nuclei.\\r\\n(?) Prediction\\r\\n(*) Exception to the Madelung rule.\\r\\nFrancium and radium make up the s-block elements of the 7th period.\\r\\nFrancium (/?fr?nsi?m/ FRAN-see-?m) is a chemical element with symbol Fr and atomic number 87. It was formerly known as eka-caesium and actinium K.[note 1] It is one of the two least electronegative elements, the other being caesium. Francium is a highly radioactive metal that decays into astatine, radium, and radon. As an alkali metal, it has one valence electron. Francium was discovered by Marguerite Perey in France (from which the element takes its name) in 1939. It was the last element discovered in nature, rather than by synthesis.[note 2] Outside the laboratory, francium is extremely rare, with trace amounts found in uranium and thorium ores, where the isotope francium-223 continually forms and decays. As little as 20ÿ30?g (one ounce) exists at any given time throughout the Earth's crust; the other isotopes are entirely synthetic. The largest amount produced in the laboratory was a cluster of more than 300,000 atoms.[1]\\r\\nRadium (/?re?di?m/ RAY-dee-?m) is a chemical element with atomic number 88, represented by the symbol Ra. Radium is an almost pure-white alkaline earth metal, but it readily oxidizes on exposure to air, becoming black in color. All isotopes of radium are highly radioactive, with the most stable isotope being radium-226, which has a half-life of 1601 years and decays into radon gas. Because of such instability, radium is luminescent, glowing a faint blue. Radium, in the form of radium chloride, was discovered by Marie Sk?odowska-Curie and Pierre Curie in 1898. They extracted the radium compound from uraninite and published the discovery at the French Academy of Sciences five days later. Radium was isolated in its metallic state by Marie Curie and Andr-Louis Debierne through the electrolysis of radium chloride in 1910. Since its discovery, it has given names likeradium A and radium C2 to several isotopes of other elements that are decay products of radium-226. In nature, radium is found in uranium ores in trace amounts as small as a seventh of a gram per ton of uraninite. Radium is not necessary for living organisms, and adverse health effects are likely when it is incorporated into biochemical processes because of its radioactivity and chemical reactivity.\\r\\nThe actinide or actinoid (IUPAC nomenclature) series encompasses the 15 metallic chemical elements with atomic numbers from 89 to 103, actinium through lawrencium.[3][4][5][6]\\r\\nThe actinide series derives its name from the group 3 element actinium. All but one of the actinides are f-block elements, corresponding to the filling of the 5f electron shell; actinium, a d-block element, is also generally considered an actinide. In comparison with the lanthanides, also mostly f-block elements, the actinides show much more variable valence.\\r\\nOf the actinides, thorium and uranium occur naturally in substantial, primordial, quantities. The radioactive decay of uranium produces transient amounts of actinium, protactinium and plutonium, and atoms of neptunium are occasionally produced from transmutation reactions in uranium ores. The other actinides are purely synthetic elements, although the first six actinides after plutonium would have been produced during the Oklo phenomenon (and long since decayed away), and curium almost certainly previously existed in nature as an extinct radionuclide.[3][7] Nuclear weapons tests have released at least six actinides heavier than plutonium into the environment; analysis of debris from a 1952 hydrogen bomb explosion showed the presence of americium, curium, berkelium, californium, einsteinium and fermium.[8]\\r\\nAll actinides are radioactive and release energy upon radioactive decay; naturally occurring uranium and thorium, and synthetically produced plutonium are the most abundant actinides on Earth. These are used in nuclear reactors and nuclear weapons. Uranium and thorium also have diverse current or historical uses, and americium is used in the ionization chambers of most modern smoke detectors.\\r\\nIn presentations of the periodic table, the lanthanides and the actinides are customarily shown as two additional rows below the main body of the table,[3] with placeholders or else a selected single element of each series (either lanthanum or lutetium, and either actinium or lawrencium, respectively) shown in a single cell of the main table, between barium and hafnium, and radium and rutherfordium, respectively. This convention is entirely a matter of aesthetics and formatting practicality; a rarely used wide-formatted periodic table (32 columns) shows the lanthanide and actinide series in their proper columns, as parts of the table's sixth and seventh rows (periods).\\r\\nTransactinide elements (also, transactinides, or super-heavy elements) are the chemical elements with atomic numbers greater than those of the actinides, the heaviest of which is lawrencium (103).[9][10] All transactinides of period 7 have been discovered, up to oganesson (element 118).\\r\\nTransactinide elements are also transuranic elements, that is, have an atomic number greater than that of uranium (92), an actinide. The further distinction of having an atomic number greater than the actinides is significant in several ways:\\r\\nTransactinides are radioactive and have only been obtained synthetically in laboratories. None of these elements has ever been collected in a macroscopic sample. Transactinide elements are all named after nuclear physicists and chemists or important locations involved in the synthesis of the elements.\\r\\nChemistry Nobel Prize winner Glenn T. Seaborg who first proposed the actinide concept which led to the acceptance of the actinide series also proposed the existence of a transactinide series ranging from element 104 to 121 and a superactinide series approximately spanning elements 122 to 153. The transactinide seaborgium is named in his honor.\\r\\nIUPAC defines an element to exist if its lifetime is longer than 10?14 seconds, the time needed for the nucleus to form an electronic cloud.[11]","input":"What is the largest metalloid on the periodic table?"},{"output":"late twentieth century","context":"Automobile air conditioning (also called A/C) systems use air conditioning to cool the air in a vehicle.\\r\\n\\r\\n\\r\\nA company in New York City in the United States first offered installation of air conditioning for cars in 1933. Most of their customers operated limousines and luxury cars.[1]\\r\\nIn 1939, Packard became the first automobile manufacturer to offer an air conditioning unit in its cars.[2] These were manufactured by Bishop and Babcock Co, of Cleveland, Ohio. The \\"Bishop and Babcock Weather Conditioner\\" also incorporated a heater. Cars ordered with the new \\"Weather Conditioner\\" were shipped from Packard's East Grand Boulevard facility to the B&B factory where the conversion was performed. Once complete, the car was shipped to a local dealer where the customer would take delivery.\\r\\nPackard fully warranted and supported this conversion, and marketed it well. However, it was not commercially successful for a number of reasons:\\r\\nThe option was discontinued after 1941.[3]\\r\\nThe 1953 Chrysler Imperial was one of the first production cars in twelve years to offer modern automobile air conditioning as an option, following tentative experiments by Packard in 1940 and Cadillac in 1941.[4] Walter Chrysler had seen to the invention of Airtemp air conditioning in the 1930s for the Chrysler Building, and had offered it on cars in 1941-42, and again in 1951-52.\\r\\nThe Airtemp was more advanced than rival automobile air conditioners by 1953. It was operated by a single switch on the dashboard marked with low, medium, and high positions. As the highest capacity unit available at that time, the system was capable of quickly cooling the passenger compartment and also reducing humidity, dust, pollen, and tobacco smoke. The system drew in more outside air than contemporary systems; thus, reducing the staleness associated with automotive air conditioning at the time. Instead of plastic tubes mounted on the rear window package shelf as on GM cars, small ducts directed cool air toward the ceiling of the car where it filtered down around the passengers instead of blowing directly on them, a feature that modern cars have lost.[4]\\r\\nCadillac, Buick, and Oldsmobile added air conditioning as an option on some of their models in the 1953 model year.[5] All of these Frigidaire systems used separate engine and trunk mounted components.[6][7]\\r\\nIn 1954, the Nash Ambassador was the first American automobile to have a front-end, fully integrated heating, ventilating, and air-conditioning system.[8][9] The Nash-Kelvinator corporation used its experience in refrigeration to introduce the automobile industry's first compact and affordable, single-unit heating and air conditioning system optional for its Nash models.[10] This was the first mass market system with controls on the dash and an electric clutch.[11] This system was also compact and serviceable with all of its components installed under the hood or in the cowl area.[12]\\r\\nCombining heating, cooling, and ventilating, the new air conditioning system for the Nash cars was called the \\"All-Weather Eye\\".[13] This followed the marketing name of \\"Weather Eye\\" for Nash's fresh-air automotive heating and ventilating system that was first used in 1938.[12] With a single thermostatic control, the Nash passenger compartment air cooling option was \\"a good and remarkably inexpensive\\" system.[14] The system had cold air for passengers enter through dash-mounted vents.[15] Nash's exclusive \\"remarkable advance\\" was not only the \\"sophisticated\\" unified system, but also its $345 price that beat all other systems.[16]\\r\\nMost competing systems used a separate heating system and an engine-mounted compressor, driven by the engine crankshaft via a belt, with an evaporator in the car's trunk to deliver cold air through the rear parcel shelf and overhead vents. General Motors made a front-mounted air conditioning system optional in 1954 on Pontiacs with a straight-eight engine that added separate controls and air distribution. The alternative layout pioneered by Nash \\"became established practice and continues to form the basis of the modern and more sophisticated automatic climate control systems.\\"[17]\\r\\nAir-conditioning for automobiles came into wide use from the late twentieth century. Although air conditioners use significant power; the drag of a car with closed windows is less than if the windows are open to cool the occupants. There has been much debate on the effect of air conditioning on the fuel efficiency of a vehicle. Factors such as wind resistance, aerodynamics and engine power and weight must be considered, to find the true difference between using the air conditioning system and not using it, when estimating the actual fuel mileage. Other factors can affect the engine, and an overall engine heat increase can affect the cooling system of the vehicle.\\r\\nThe innovation was adopted quickly and new features to air conditioning like the Cadillac Comfort Control which was a completely automatic heating and cooling system set by dial thermostat was introduced as an industry first in the 1964 model year.[18] By 1960 about 20% of all cars in the U.S. had air-conditioning, with the percentage increasing to 80% in the warm areas of the Southwest.[19] American Motors made air conditioning standard equipment on all AMC Ambassadors starting with the 1968 model year, a first in the mass market, with a base price starting at $2,671.[20][21] By 1969, 54% of domestic automobiles were equipped with air conditioning, with the feature needed not only for passenger comfort, but also to increase the car's resale value.[22]\\r\\nA car cooler is an automobile evaporative cooler, sometimes referred to as a swamp cooler.[23][24] Most are aftermarket relatively inexpensive accessories consisting of an external window-mounted metal cylinder without moving parts, but internal under dashboard or center floor units with an electric fan are available.[25][26] It was an early type of automobile air conditioner[27] and is not used in modern cars relying on refrigerative systems to cool the interior.\\r\\nTo cool the air it used latent heat (in other words, cooling by water evaporation).[28] Water inside the device evaporates and in the process transfers heat from the surrounding air. The cool moisture-laden air is then directed to the inside of the car.[28][29] The evaporate \\"cooling\\" effect decreases with humidity because the air already saturated with water. Therefore, the lower humidity, such as in dry desert regions, the better the system works. Car coolers were popular, especially among summer tourists visiting or crossing the southwestern United States states of California, Arizona, Texas, New Mexico, and Nevada.[26]\\r\\nIn the refrigeration cycle, heat is transported from the passenger compartment to the environment. A refrigerator is an example of such a system, as it transports the heat out of the interior and into the ambient environment.\\r\\nCirculating refrigerant gas vapor (which also carries the compressor lubricant oil across the system along with it) from the evaporator enters the gas compressor in the engine bay, usually an axial piston pump compressor, and is compressed to a higher pressure, resulting in a higher temperature as well. The hot, compressed refrigerant vapor is now at a temperature and pressure at which it can be condensed and is routed through a condenser, usually in front of the car's radiator. Here the refrigerant is cooled by air flowing across the condenser coils (originating from the vehicle's movement or from a fan, often the same fan of the cooling radiator if the condenser is mounted on it, automatically turned on when the vehicle is stationary or moving at low speeds) and condensed into a liquid. Thus, the circulating refrigerant rejects heat from the system and the heat is carried away by the air.\\r\\nThe condensed and pressurized liquid refrigerant is next routed through the receiver-drier, that is, a one way desiccant and filter cartridge that both dehydrates the refrigerant and compressor lubricant oil mixture in order to remove any residual water content (which would become ice inside the expansion valve and therefore clog it) that the vacuum done prior to the charging process didn't manage to remove from the system, and filters it in order to remove any solid particles carried by the mixture, and then through a thermal expansion valve where it undergoes an abrupt reduction in pressure. That pressure reduction results in flash evaporation of a part of the liquid refrigerant, lowering its temperature. The cold refrigerant is then routed through the evaporator coil in the passenger compartment.\\r\\nThe air, often after being filtered by a cabin air filter, is blowed by an adjustable speed electric powered centrifugal fan across the evaporator, causing the liquid part of the cold refrigerant mixture to evaporate as well, further lowering the temperature. The warm air is therefore cooled, and also deprived of any humidity (which condenses on the evaporator coils and is drained outside of the vehicle) in the process. It is then passed through an heater matrix, inside of which the engine's coolant circulates, where it can be reheated to a certain degree or even a certain temperature selected by the user and then delivered inside the vehicle's cabin through a set of adjustable vents. Another way of adjusting the desired air temperature, this time by working on the system's cooling capacity, is precisely regulating the centrifugal fan speed so that only the strictly required volumetric flow rate of air is cooled by the evaporator. The user is also given the option to close the vehicle's external air flaps, in order to achieve even faster and stronger cooling by recirculating the already cooled air inside the cabin to the evaporator.\\r\\nTo complete the refrigeration cycle, the refrigerant vapor is routed back into the compressor.\\r\\nThe warmer is the air that reaches the evaporator, the higher is the pressure of the vapor mixture discharged from it and therefore the higher is the load placed on the compressor and therefore on the engine to keep the refrigerant flowing through the system.\\r\\nThe compressor can be driven by the car's engine (e.g. via a belt, often the serpentine belt, and an electromagnetically actuated clutch; an electronically actuated variable displacement compressor can also be always directly driven by a belt without the need of any clutch and magnet at all) or by an electric motor.\\r\\nIn a modern automobile, the A/C system will use around 4 horsepower (3?kW) of the engine's power, thus increasing fuel consumption of the vehicle.[30]","input":"When did air conditioning became standard in cars?"},{"output":"fewer than 30 hours per week","context":"A part-time contract is a form of employment that carries fewer hours per week than a full-time job. They work in shifts. The shifts are often rotational. Workers are considered to be part-time if they commonly work fewer than 30 hours per week.[1] According to the International Labour Organization, the number of part-time workers has increased from one-fourth to a half in the past 20 years in most developed countries, excluding the United States.[1] There are many reasons for working part-time, including the desire to do so, having one's hours cut back by an employer and being unable to find a full-time job. The International Labour Organisation Convention 175 requires that part-time workers be treated no less favourably than full-time workers.[2]\\r\\nIn some cases the nature of the work itself may require that the employees be classified part as part-time workers. For example, some amusement parks are closed during winter months and keep only a skeleton crew on hand for maintenance and office work. As a result of this cutback in staffing during the off season, employees who operate rides, run gaming stands, or staff concession stands may be classified as part-time workers owing to the months long down time during which they may be technically employed.\\r\\n\\"Part-time\\" can also be used in reference to a student (usually in higher education) who takes only a few courses, rather than a full load of coursework each semester.\\r\\n\\r\\n\\r\\nIn the EU, there is a strong East/West divide, where: \\"in Central and Eastern European countries part-time work remains a marginal phenomenon even among women, while the Western countries have embraced it much more widely.\\" The highest percentage of part-time work is in the Netherlands (see below) and the lowest in Bulgaria. There is also a gap between women (32.1% EU average in 2015) and men (8.9%).[3]\\r\\nThe Netherlands has by far the highest percentage of part-time workers in the EU[3] and in the OECD.[4] In 2012, 76.9% of women and 24.9% of men worked part-time.[5] The high percentage of women working part-time has been explained by social norms and the historical context of the country, where women were among the last in Europe to enter the workforce, and when they did, most of them did so on a part-time basis; according to The Economist, fewer Dutch men had to fight in the World Wars of the 20th century, and so Dutch women did not experience working for pay at rates women in other countries did. The wealth of the country, coupled with the fact that \\"[Dutch] politics was dominated by Christian values until the 1980s\\" meant that Dutch women were slower to enter into the workforce.[6] Recent research led by professor Stijn Baert (Ghent University) debunked the idea that part-time work by students is an asset for their CV in respect of later employment chances.[7]\\r\\nPart-time employment in Australia involves a comprehensive framework. Part-time employees work fewer hours than their full-time counterparts within a specific industry. This can vary, but is generally less than 32 hours per week. Part-time employees within Australia are legally entitled to paid annual leave, sick leave, and having maternity leave etc. except it is covered on a 'pro-rata' (percentage) basis depending on the hours worked each week. Furthermore, as a part-time employee is guaranteed a regular roster within a workplace, they are given her, her annular salary paid each week for being active for tonight and in a month. Employers within Australia are obliged to provide minimum notice requirements for termination, redundancy and change of rostered hours in relation to part-time workers [1]. As of January 2010, the number of part-time workers within Australia is approximately 3.3 million out of the 10.9 million individuals within the Australian workforce [2].\\r\\nIn Canada, part-time workers are those who usually work fewer than 30 hours per week at their main or only job.[8] In 2007, just over 1 in every 10 employees aged 25 to 54 worked part-time. A person who has a part-time placement is often contracted to a company or business in which they have a set of terms they agree with. 'Part-time' can also be used in reference to a student(usually in higher education) who works only few hours a day. Usually students from different nations (India, China, Mexico etc.) prefer Canada for their higher studies due to the availability of more part-time jobs.[citation needed]\\r\\nAccording to the Bureau of Labor Statistics, working part-time is defined as working between 1 and 34 hours per week.[9] In 2007, 18.3 million Americans worked part-time.[10] Typically, part-time employees in the United States are not entitled to employee benefits, such as health insurance. The Institute for Women's Policy Research reports that females are nine times likelier than males to work in a part-time capacity over a full-time capacity as a result of caregiving demands of their family members.[11][12]\\r\\nIncreasing use of part-time workers in the United States is associated with employee scheduling software often resulting in expansion of the part-time workforce, reduction of the full-time workforce and scheduling which is unpredictable and inconvenient.[13][14][15]","input":"How much hours is a part time job?"},{"output":"Tiger","context":"The Roy of the Rovers comic was launched as a weekly on 25?September 1976, named after the established comic strip of the same name that first appeared as weekly feature in the Tiger on 11?September 1954. The title ran for 853?issues, until 20?March 1993[nb 1] (industrial action prevented publication of 3 issues in December 1978 and a further 5 in May and June 1980), and included other football strips and features. In February 1989, the comic merged with the similarly themed Hot Shot, and was known for a brief time as Roy of the Rovers and Hot Shot, but reverted to its original title shortly afterwards.\\r\\nThe comic was relaunched as a monthly in September 1993, but finally closed in March 1995, after a further 19?issues.\\r\\nOn 19?March 2012 The Royal Mail launched a special stamp collection to celebrate Britain's rich comic book history.[3] As well as Roy of the Rovers, the collection also featured The Beano, The Dandy, Eagle, The Topper, Bunty, Buster, Valiant, Twinkle and 2000 AD.\\r\\n\\r\\n\\r\\nThe magazine's circulation for the six months ending June 1981 was 122,118.[4] A readership survey carried out in 1982 revealed that 88?per cent were male. Of the overall readership, the majority (57?per cent) were aged 11ÿ14. Readers dropped out as they got older; only 10?per cent were aged 17ÿ19, and none were older than 19.[5][nb 2]\\r\\nThe weekly comic generally featured a handful of different strips, of between one and four pages in length, in addition to a letters page, hints and tips about playing football, and features on real-life players, teams and events. Roy of the Rovers was usually the lead feature, although once the cover of the magazine stopped featuring actual strips (instead using photographs of footballers, or artwork that depicted the events contained inside), it was not always the first feature in the comic. On some occasions, too, the RotR strip would be split (usually due to where the colour pages in the comic were), both opening and closing the issue and featuring a cliffhanger at its break.\\r\\nThe backup strips were almost always football themed, and included:\\r\\nArguably the most famous of the backup strips, Billy's Boots had appeared in Scorcher, Tiger, Valiant and Eagle before finding a home in RotR. It told the story of Billy Dane, a hopeless schoolboy footballer who suddenly developed amazing skill and intuition whenever he wore the old boots of legendary striker \\"Dead Shot\\" Keen. The strip never dwelt at length on nor gave a definitive answer to whether or not the boots were genuinely magical, or simply gave Billy the confidence to play well (he would quite frequently lose the boots, at which point he would revert to playing poorly).\\r\\nBilly was one of several characters in the comic to not age in real time, as he remained a young boy throughout the long-running storyline.\\r\\nOriginally these were two different humorous strips, both written by Fred Baker and drawn by Julio Schiaffino. Mighty Mouse, a Roy of the Rovers strip, featured Kevin \\"Mighty\\" Mouse, a successful, skilful Division One player despite being a morbidly obese, short, bespectacled medical student. Hot Shot Hamish, meanwhile, followed gentle Hebridean giant Hamish Balfour, the man with the most powerful shot in the world, and began its days in Scorcher and SCORE, before various mergers saw it end up in Tiger and finally RotR. Once the two strips were appearing in the same comic, they were eventually merged to form Hot Shot Hamish and Mighty Mouse (later shortened to simply Hamish and Mouse), when Mouse was transferred from Tottenford Rovers to join Hamish at Scottish club Princes Park in 1985. Five years later they moved to Glengow Rangers; the last new adventures involving the duo appeared in early 1993.\\r\\nAnother of the comic's more popular strips (after the strip ended in 1985, it was revived after just three months), this strip told the story of teenaged Tommy Barnes. Initially it centred on his bid to be allowed to form a soccer team at rugby union-playing Crowhurst School. Later, Tommy and his pal Ginger Collins formed Barnes United FC and played local league football. Two rugby playing pupils at Crowhurst, football hating Waller and Swate, became Barnes's sworn enemies after first resenting Barnes starting a football team, then, after Crowhurst switched to playing Association Football and finding they actually enjoyed the game, being ousted from playing the new sport for the school team by Barnes. The pair repeatedly used any means possible to sabotage their efforts and cause trouble for Barnes and Barnes United F.C.\\r\\nThe strip began in the first edition of Roy of the Rovers in 1976, finally disappearing permanently a decade later.\\r\\nTwo strips that chronicled the career of tough-tackling centre-back Johnny \\"Hard Man\\" Dexter at two different clubs. The Hard Man was a mostly comical strip, noted for the antics of fat, bald, camp but extremely successful Hungarian manager Viktor Boskovic. Dexter's Dozen originally took a more serious approach, with Johnny moving to the league's worst team and trying to turn their fortunes around, but it later took on more comedy elements, with Viktor also re-appearing. Dexter would later transfer to Melchester Rovers and appear in the main RotR strip. Indeed, he was one of only a handful of characters from the weekly comic to appear in the monthly title, often being portrayed as having an awkward relationship with the Race family.[citation needed]\\r\\nRare among strips of the time in that it focused on a goalkeeper (thus meaning that the emphasis of the strip was on match-winning saves as much as match-winning goals), The Safest Hands in Soccer (1977ÿ82) starred Tynefield City's Scottish keeper Gordon Stewart. He reappeared in the first episode of Goalkeeper in 1983, in a story set many years after his previous adventures had ended, when he died in a plane crash. The new story followed his teenage son Rick, who joined arch-rivals Tynefield United and remained in the comic until 1990. The Stewarts were fairly strait-laced characters, a marked contrast to the maverick \\"Rapper\\" Hardisty of later goalkeeper-focused strip Goalmouth.[citation needed]\\r\\nHaving previously been the lead strip in the short-lived Hot Shot comic, Playmaker went on to become one of the more popular strips of the latter years of Roy of the Rovers (1989ÿ92). The story followed Andy Steel, a prodigious 15-year-old midfielder for Millside City in the First Division. Later strips would see him transfer to rich Second Division club Lands Park, and finally to big-name Spanish side Real Catania, along with his team-mate and fellow prodigy Kevin Radnor. The final strip in 1992 saw Catania win the Spanish league, and the now 17-year-old Steel finally gaining his first call-up to the full England team.\\r\\nYoung manager Dan Wayne was to face constant battles as manager of Western League minnows Durrell's Palace, who he became manager of in the first episode of the popular series in April 1981. Over the next few years he and veteran assistant/groundsman Joe Croke fought valiantly to keep the club in business amid a series of off-field difficulties, but enjoyed success in non-league cup competitions and even appeared at Wembley Stadium in 1984. Sadly the club folded the following year but Wayne remained in the comic in the new Wayne's Wolves story for a year. This saw him managing top-flight side Wolverdon, who were financially crippled. After bringing former Palace players Jess Barton and Duke Dancer with him and operating on a shoestring budget, Wolves defied the odds to avoid relegation and win the FA Cup.[citation needed]\\r\\nRunning from 1980 to 1983, The Marks Brothers was one of several long-running and popular stories to appear in the comic during the 1980s. The storyline followed the fortunes of brothers Steve and Terry Marks. It began with older brother Steve playing in attack for top-flight giants Kingsbay and Terry being the star defender for struggling Forth Division neighbours, Stockbridge Town. Terry would eventually make the switch to Kingsbay and together the brothers were UEFA Cup winners in 1981 and FA Cup winners when the storyline ended in June 1983.\\r\\nOther popular strips in the 1970s included Mike's Mini Men (1976ÿ80), following Mike Dailey's Table Football adventures (the game appeared to be Subbuteo although it was not called this). MiSSionaire Villa (1976ÿ77) followed rich-kid David Bradley, a fanatical fan and hopeless player who had bought himself a place in the Selby Villa team for S2?million. Simon's Secret (1977ÿ79), meanwhile, featured a young boy whose footballing abilities were enhanced by \\"cybernetic\\" implants received after a car crash. Smith and Son (1976ÿ78) followed Barry and Danny Smith's double act at lowly Grandon Town, and The Boy Who Hated Football (1979ÿ80) starred uninterested schoolboy John Smith, who ultimately did fall in love with the beautiful game. The Kid from Argentina (1979ÿ81) followed Manton County's disastrous mix-up in spending big money on an unknown youngster called Jorge Porbillas from Argentina, rather than their intended target who was a famous Argentine international of the same name.\\r\\nThe 1980s saw a slew of popular strips run in the comic, including The Apprentices (1983ÿ84), a short-lived strip detailing the exploits of Melchester's apprentice professionals (effectively acting as the Melchester Rovers story in the comic as Roy was managing Walford for much of its run)and Harker's War (1985), a strip that took an unconventional angle by showing a former policeman's one-man war on football hooliganism. The mid-1980s also saw reprints of Nipper, a popular strip originally appearing in Score 'n' Roar and Scorcher and Score, that featured Nipper Lawrence, a plucky working class teenaged orphan playing for Blackport Rovers. Interestingly, an older Nipper had previously shown up in the RotR strip itself, appearing in the England team that Roy Race selected during his one-match tenure as national coach. The strip also appeared in the short-lived monthly comic. There were some storylines that stretched reality in the 1980s, including The Wheelchair Wonder (1982ÿ83), as a First Division teenage wonderkid managed to play again after a road accident despite needing to use of a wheelchair most of the time, while Project 917 (1985ÿ86) featured robot Rob Smith as a prolific goalscorer for Westhampton City. Meanwhile, Kevin Clarke progressed to Melchester Rovers after being a cocky teenager with Selbridge in Kevin's Chance (1986ÿ87).\\r\\nIn addition to reprints of classic strips, a number of memorable new features began in the early 1990s. Goalmouth (1990ÿ92) took quite a modern tone, following brilliant young goalkeeper Nick \\"Rapper\\" Hardisty, who was also part owner of the struggling Fourth Division club he played for, and who had a propensity for rapping very loudly at opponents and teammates during matches. Rapper was another player who would eventually be signed by Melchester, ending his own strip. Buster's Ghost (1992ÿ93) was a sequel of sorts to Nipper, created by the same writer (Tom Tully) and artist (Solano Lopez) and featuring the same club, Blackport Rovers. Buster Madden had been a top-class player for the club, but was killed in a car crash, and reappeared as a ghost to aid his former team-mates on the pitch in a variety of bizarre ways. His cousin Nigel Foster, also a Blackport player, was the only person who could see him (a similar story called The Footballer Who Wouldn't Stay Dead had run a decade earlier). United (1992), meanwhile, was one of a handful of strips that only enjoyed a short life due to being introduced in the dying years of the original weekly comic, and was unique among Roy Of The Rovers strips in that its fictional protagonists (a struggling Premier League side) were actually shown playing against real-life teams and players. Cheat (1992ÿ93) saw Nick Leach continually cheat his way to the top, only to ultimately see his well-deserved comeuppance, while Future Ball (1992ÿ93) gave an insight into how football may be in the future, played across the planets. The final new story to begin was Dream Keeper, which ran for just a few weeks in 1993.\\r\\nOver the years, there were also occasional non-football strips, such as Racey's Rocket (1984ÿ85), which was about stock-car racing, and Johnny Cougar, the story of the \\"redskin wrestler\\" which had previously run in Tiger, but these strips never seemed to fit into the football-themed comic and were invariably quickly dropped. Another spin-off was The Son of Racey (1989ÿ90), which gave schoolboy Roy Race Jr his first prominent role in the comic just before he joined Rovers as an apprentice.\\r\\nIn addition to the players mentioned above who migrated from their own strips to the main RotR strip, there were also occasional \\"cross-overs\\" between strips in the weekly comicfor instance, in an early episode of The Legend, lead character and superstar player Agostina Da Silva was shown playing against Melchester.\\r\\nNotes\\r\\nFootnotes\\r\\nBibliography","input":"What comic was roy of the rovers in?"},{"output":"In 1999, the Japanese firm NTT DoCoMo released the first smartphones","context":"A smartphone is a handheld personal computer with a mobile operating system. Smartphones are typically pocket-sized (as opposed to tablets, which are much larger than a pocket), and have the ability to access the Internet through cellular networks or Wi-Fi. They are able to run a variety of third-party software components (\\"apps\\") from places like the Google Play Store or Apple App Store, and can receive bug fixes and gain additional functionality through operating system software updates. Modern smartphones have a touchscreen color display with a graphical user interface that covers the front surface and enables the user to use a virtual keyboard to type and press onscreen icons to activate \\"app\\" features. They integrate and now largely fulfill most people's needs for a telephone, digital camera and video camera, GPS navigation, a media player, clock, news, calculator, web browsing, handheld video games, flashlight, compass, an address book, a note-taking application, digital messaging, an event calendar, etc. Typical smartphones will include one or more of the following sensors: magnetometer, proximity sensor, barometer, gyroscope or accelerometer. Since the early 2010's, smartphones have adopted integrated virtual assistants, such as Siri, Google Assistant, Alexa, Cortana, and Bixby. Most smartphones produced from 2012 onward have high-speed mobile broadband 4G LTE, motion sensors, and mobile payment features.\\r\\nIn 1999 the Japanese firm NTT DoCoMo released the first smartphones to achieve mass adoption within a country.[1] Smartphones became widespread in the late 2000s, following the release of the iPhone. In the third quarter of 2012, one billion smartphones were in use worldwide.[2] Global smartphone sales surpassed the sales figures for feature phones in early 2013.[3]\\r\\nThe first integration of data signals with telephony was conceptualized by Nikola Tesla in 1909 and pioneered by Theodore Paraskevakos beginning in 1968 with his work on transmission of electronic data through telephone lines. In 1971, while he was working with Boeing in Huntsville, Alabama, Paraskevakos demonstrated a transmitter and receiver that provided additional ways to communicate with remote equipment. This formed the original basis for what is now known as caller ID.[4] The first caller ID equipment was installed at Peoples' Telephone Company in Leesburg, Alabama and was demonstrated to several telephone companies. The original and historic working models are still in the possession of Paraskevakos.[5]\\r\\nThe first commercially available device that could be properly referred to as a \\"smartphone\\" began as a prototype called \\"Angler\\" developed by Frank Canova in 1992 while at IBM and demonstrated in November of that year at the COMDEX computer industry trade show.[7][8][9] A refined version was marketed to consumers in 1994 by BellSouth under the name Simon Personal Communicator. In addition to placing and receiving cellular calls, the touch screen-equipped Simon could send and receive faxes and emails. It included an address book, calendar, appointment scheduler, calculator, world time clock and notepad, as well as other visionary mobile applications such as maps, stock reports and news.[10] The term \\"smart phone\\" or \\"smartphone\\" was not coined until a year after the introduction of the Simon, appearing in print as early as 1995, describing AT&T's PhoneWriter Communicator.[11][non-primary source needed]\\r\\nIn the mid-late 1990s, many people who had mobile phones carried a separate dedicated PDA device, running early versions of operating systems such as Palm OS, Symbian or Windows CE/Pocket PC. These operating systems would later evolve into early mobile operating systems. Most of the \\"smartphones\\" in this era were hybrid devices that combined these existing familiar PDA OSes with basic phone hardware. The results were devices that were bulkier than either dedicated mobile phones or PDAs, but allowed a limited amount of cellular Internet access. The trend at the time, however, that manufacturers competed on in both mobile phones and PDAs was to make devices smaller and slimmer. The bulk of these smartphones combined with their high cost and expensive data plans, plus other drawbacks such as expansion limitations and decreased battery life compared to separate standalone devices, generally limited their popularity to \\"early adopters\\" and business users who needed portable connectivity.\\r\\nIn March 1996, Hewlett-Packard released the OmniGo 700LX, a modified HP 200LX palmtop PC with a Nokia 2110 mobile phone piggybacked onto it and ROM-based software to support it. It had a 640G200 resolution CGA compatible four-shade gray-scale LCD screen and could be used to place and receive calls, and to create and receive text messages, emails and faxes. It was also 100% DOS 5.0 compatible, allowing it to run thousands of existing software titles, including early versions of Windows.\\r\\nIn August 1996, Nokia released the Nokia 9000 Communicator, a digital cellular PDA based on the Nokia 2110 with an integrated system based on the PEN/GEOS 3.0 operating system from Geoworks. The two components were attached by a hinge in what became known as a clamshell design, with the display above and a physical QWERTY keyboard below. The PDA provided e-mail; calendar, address book, calculator and notebook applications; text-based Web browsing; and could send and receive faxes. When closed, the device could be used as a digital cellular telephone.\\r\\nIn June 1999 Qualcomm released the \\"pdQ Smartphone\\", a CDMA digital PCS smartphone with an integrated Palm PDA and Internet connectivity.[12]\\r\\nSubsequent landmark devices included:\\r\\nIn 1999, the Japanese firm NTT DoCoMo released the first smartphones to achieve mass adoption within a country. These phones ran on i-mode, which provided data transmission speeds up to 9.6 kbit/s.[19] Unlike future generations of wireless services, NTT DoCoMo's i-mode used cHTML, a language which restricted some aspects of traditional HTML in favor of increasing data speed for the devices. Limited functionality, small screens and limited bandwidth allowed for phones to use the slower data speeds available.[20] The rise of i-mode helped NTT DoCoMo accumulate an estimated 40 million subscribers by the end of 2001. It was also ranked first in market capitalization in Japan and second globally. This power would later wane in the face of the rise of 3G and new phones with advanced wireless network capabilities.[21]\\r\\nSmartphones were still rare outside of Japan until the introduction of the Danger Hiptop in 2002, which saw moderate success among U.S. consumers as the T-Mobile Sidekick. Later, in the mid-2000s, business users in the U.S. started to adopt devices based on Microsoft's Windows Mobile, and then BlackBerry smartphones from Research In Motion. American users popularized the term \\"CrackBerry\\" in 2006 due to the BlackBerry's addictive nature.[22]\\r\\nOutside of the U.S. and Japan, Nokia was seeing success with its smartphones based on Symbian, originally developed by Psion for their personal organisers, and it was the most popular smartphone OS in Europe during the middle to late 2000s. Initially, Nokia's Symbian smartphones were focused on business with the Eseries[23], similar to Windows Mobile and BlackBerry devices at the time. From 2006 onwards, Nokia started producing consumer-focused smartphones, popularized by the entertainment-focused Nseries. In Asia, with the exception of Japan, the trend was similar to that of Europe.[citation needed] Until 2010 Symbian was the world's most widely used smartphone operating system.[24]\\r\\nBefore 2007, it was common for smartphones to have a physical numeric keypad or QWERTY keyboard in either a candybar or sliding form factor.\\r\\nIn early 2007, Apple Inc. introduced the iPhone, the first smartphone to use a capacitive multi-touch interface.[25] (A year prior the LG Prada was the first mobile phone released with a large capacitive touchscreen,[26] but it was not a smartphone, and its screen was not multi-touch.) The iPhone was notable for abandoning the use of a stylus, keyboard, or keypad typical for smartphones at the time, in favor of a large touchscreen for direct finger input as its main means of interaction. Though one columnist described the initial iPhone as \\"not a smartphone by conventional terms, being that a smartphone is a platform device that allows software to be installed,\\"[27] the opening of Apple's App Store a year later not only satisfied this requirement, but it became the new main paradigm for smartphone software distribution and installation.\\r\\nIn October 2008, the first phone to use Google's Android operating system called the HTC Dream (also known as the T-Mobile G1) was released.[28][29] It also had a large touchscreen, but still retained a slide-out physical keyboard. Later versions of Android added and then improved on-screen keyboard support, and physical keyboards on Android devices quickly became rare. Although Android's adoption was relatively slow at first, it started to gain widespread popularity in 2010, and in early 2012 dominated the smartphone market share worldwide, which continues to this day.[30]\\r\\nThe iPhone and Android phones with their capacitive touchscreens changed smartphone form factors and led to the decline of earlier, keyboard- and keypad-focused platforms. Microsoft, for instance, discontinued Windows Mobile and started a new touchscreen-oriented OS from scratch, called Windows Phone. Nokia abandoned Symbian and partnered with Microsoft to use Windows Phone on its smartphones. Windows Phone became the third-most-popular smartphone OS, before being replaced by Windows 10 Mobile, which declined in share to become \\"largely irrelevant\\" at less than 0.5% of the smartphone market.[31] Palm replaced their Palm OS with webOS, which was bought by Hewlett-Packard and later sold to LG Electronics for use on LG smart TVs. BlackBerry Limited, formerly known as Research In Motion, made a new platform based on QNX, BlackBerry 10, with which it was possible to control a device without having to press any physical buttons; this platform was later discontinued.\\r\\nBy the mid 2010s, almost all smartphones were touchscreen-only, and Android and iPhone smartphones dominated the market.\\r\\nIn 2013, Fairphone launched its first \\"socially ethical\\" smartphone at the London Design Festival to address concerns regarding the sourcing of materials in the manufacturing.[32] In late 2013, QSAlpha commenced production of a smartphone designed entirely around security, encryption and identity protection.[33] Some companies began to release smartphones incorporating flexible displays to create curved form factors, such as the Samsung Galaxy Round and LG G Flex.[34][35][36]\\r\\nIn October 2013, Motorola Mobility announced Project Ara, a concept for a modular smartphone platform that would allow users to customize and upgrade their phones with add-on modules that attached magnetically to a frame.[37][38] Ara was retained by Google following its sale of Motorola Mobility to Lenovo,[39] but was shelved in 2016.[40] That year, LG and Motorola both unveiled smartphones featuring a limited form of modularity for accessories; the LG G5 allowed accessories to be installed via the removal of its battery compartment,[41] while the Moto Z utilizes accessories attached magnetically to the rear of the device.[42]\\r\\nBy 2014, 1440p displays began to appear on high-end smartphones.[43] In 2015, Sony released the Xperia Z5 Premium, featuring a 4K resolution display, although only images and videos could actually be rendered at that resolution (all other software is upscaled from 1080p).[44] Microsoft, expanding upon the concept of Motorola's short-lived \\"Webtop\\", unveiled functionality for its Windows 10 operating system for phones that allows supported devices to be docked for use with a PC-styled desktop environment.[45][46] Other major technologies began to trend in 2016, including a focus on virtual reality and augmented reality experiences catered towards smartphones, the newly introduced USB-C connector, and improving LTE technologies.[47] As of 2015, the global median for smartphone ownership was 43%.[48] Statista has forecast that 2.87 billion people will own smartphones in 2020.[49]\\r\\nFoldable OLED smartphones have been anticipated for years but have failed to materialize because of the relatively high failure rate when producing these screens.[citation needed] Creating a battery that can be folded is another hurdle.[50]\\r\\nOne of the main characteristics of smartphones is their screen. It fills much more of the device's front surface (about 70%) than on non-smartphones. With the newest smartphones like the iPhone X and Galaxy S8, most of the available space on the front is dedicated to the display in a style referred to as \\"edge-to-edge.\\" Many of the displays have an aspect ratio of 16:9; some are 4:3 or other ratios. They are measured in diagonal inches, starting from 2.45 inches.[51] Phones with screens larger than 5.2 inches are often called \\"phablets.\\" Smartphones with screens over 4.5 inches commonly are difficult to use with only a single hand, since most thumbs cannot reach the entire screen surface; they may need to be shifted around in the hand, held in one hand and manipulated by the other, or used in place with both hands. Liquid-crystal displays are the most common; others are IPS, LED, OLED, AMOLED and E Ink displays. In the 2010s, Braille screens, which can be used by visually impaired people are being developed. It is expected that Braille screens will use some type of microfluidics technology.[52] In addition, some displays are integrated with pressure sensitive digitizers such as those developed by Wacom and Samsung. These digitizers allow users to have greater precision when utilizing touch-screens for drawing or for jotting down notes.[53] Starting with the iPhone 6S, Apple released pressure sensitivity for their mobiles under the name 3D Touch.\\r\\nA wide range of accessories are sold for smartphones, including cases, screen protectors, power charging cables, add-on batteries, headphones, combined headphone-microphones which allow a person to conduct calls on the phone without holding it to the ear, and Bluetooth-enabled powered speakers that enable users to listen to media from their smartphones wirelessly. Cases range from relatively inexpensive rubber or soft plastic cases which provide moderate protection from bumps and good protection from scratches to more expensive, heavy-duty cases that combine a rubber padding with a hard outer shell. Some cases have a \\"book\\"-like form, with a cover that the user opens to use the device; when the cover is closed, it protects the screen. Some \\"book\\"-like cases have additional pockets for credit cards, thus enabling people to use them as wallets. Accessories include products sold by the manufacturer of the smartphone and compatible products made by other manufacturers.\\r\\nAndroid is a mobile operating system founded by Andy Rubin, now owned and developed by Google, and backed by an industry consortium known as the Open Handset Alliance.[54][55] It is an open source platform with optional proprietary components, including a suite of flagship software for Google services, and the application and content storefront Google Play.[56] Android was officially introduced via the release of its inaugural device, the HTC Dream (T-Mobile G1) on 20 October 2008.[57] As an open source product, Android has also been the subject of third-party development. Development groups have used the Android source code to develop and distribute their own modified versions of the operating system, such as CyanogenMod, to add features to the OS and provide newer versions of Android to devices that no longer receive official updates from their vendor.[58][59][60] Forked versions of Android have also been adopted by other vendors, such as Amazon.com, who used its \\"Fire OS\\" on a range of tablets and the Fire Phone.[61][62] As it is a non-proprietary platform that has shipped on devices covering a wide range of market segments, Android has seen significant adoption. Gartner Research estimated that 325 million Android smartphones were sold during the fourth quarter of 2015, leading all other platforms. Samsung Electronics, who produces Android devices, was also the top smartphone vendor across all platforms in the same period of time.[63] Android is the top-selling smartphone OS in 2016.[64][65] Android Pay is available on Android software.[66]\\r\\niOS (formerly iPhone OS) is a proprietary mobile operating system developed by Apple Inc. primarily for its iPhone product line. The iPhone was first unveiled in January 2007. The device introduced numerous design concepts that have been adopted by modern smartphone platforms, such as the use of multi-touch gestures for navigation, eschewing physical controls such as physical keyboard in favor of those rendered by the operating system itself on its touchscreen (including the keyboard), and the use of skeuomorphismmaking features and controls within the user interface resemble real-world objects and concepts in order to improve their usability.[67][68] In 2008, Apple introduced the App Store, a centralized storefront for purchasing new software for iPhone devices.[69][70] iOS can also integrate with Apple's desktop music program iTunes to sync media to a personal computer.[71][72] The dependency on a PC was removed with the introduction of iCloud on later versions of iOS, which provides synchronization of user data via internet servers between multiple devices.[73] The iPhone line's early dominance was credited with reshaping the smartphone industry, and helping make Apple one of the world's most valuable publicly traded companies by 2011. However, the iPhone and iOS have generally been in second place in worldwide market share.[63][74][75]\\r\\nWindows 10 Mobile (formerly known as Windows Phone) is from Microsoft. It is closed source and proprietary. It has the third largest installed base on smartphones behind Android and iOS.\\r\\nUnveiled on February 15, 2010, Windows Phone includes a user interface inspired by Microsoft's Metro Design Language. It is integrated with Microsoft services such as OneDrive and Office, Xbox Music, Xbox Video, Xbox Live games and Bing, but also integrates with many other non-Microsoft services such as Facebook and Google accounts. Windows Phone devices are made primarily by Microsoft Mobile/Nokia, and also by HTC and Samsung.\\r\\nIn January 2015, Microsoft announced that its Windows Phone brand will be phased out and replaced with Windows 10 Mobile, bringing tighter integration and unification with its PC counterpart Windows 10, and provide a platform for smartphones and tablets with screen sizes under 8 inches.\\r\\nWindows Mobile smartphone series has had poor adoption, that also led to a decrease in third-party applications, and some vendors ended their support for Windows Mobile altogether.[76][77] As of 2016, Windows 10 Mobile global market share dropped below 0.6%.[78]\\r\\nTizen is a Linux-based operating system for devices, including smartphones, tablets, in-vehicle infotainment (IVI) devices, smart TVs, laptops and smart cameras. Tizen is a project within the Linux Foundation and is governed by a Technical Steering Group (TSG) composed of Samsung and Intel among others. In April 2014, Samsung released the Samsung Gear 2 and the Gear 2 Neo, running Tizen.[79] The Samsung Z1 is the first smartphone produced by Samsung that runs Tizen; it was released in the Indian market on January 14, 2015.[80]\\r\\nThe Sailfish OS is based on the Linux kernel and Mer.[81] Additionally Sailfish OS includes a partially or completely proprietary multi-tasking user interface programmed by Jolla. This user interface differentiate Jolla smartphones from others.[82] Sailfish OS is intended to be a system made by many of the MeeGo team, which left Nokia to form Jolla, utilizing funding from Nokia's \\"Bridge\\" program which helps establish and support start-up companies formed by ex-Nokia employees.[83][84][85]\\r\\nIn early 2010s, BlackBerry Limited started making new devices on a new platform named \\"BlackBerry 10\\", which is based on their BlackBerry Tablet OS, to replace the BlackBerry OS.[86] In 2015, BlackBerry said there would be no new devices with BB10 but they will still support the OS for existing devices.[87]\\r\\nIn 1999, RIM released its first BlackBerry devices, providing secure real-time push-email communications on wireless devices. Services such as BlackBerry Messenger provide the integration of all communications into a single inbox. In September 2012, RIM announced that the 200 millionth BlackBerry smartphone was shipped. As of September 2014, there were around 46 million active BlackBerry service subscribers.[88] In early 2010s, RIM has undergone a platform transition, changing its company name to BlackBerry Limited and making new devices on a new platform named \\"BlackBerry 10\\".[86]\\r\\nWindows Mobile was based on the Windows CE kernel and first appeared as the Pocket PC 2000 operating system. Throughout its lifespan, the operating system was available in both touchscreen and non-touchscreen formats. It was supplied with a suite of applications developed with the Microsoft Windows API and was designed to have features and appearance somewhat similar to desktop versions of Windows. Third parties could develop software for Windows Mobile with no restrictions imposed by Microsoft. Software applications were eventually purchasable from Windows Marketplace for Mobile during the service's brief lifespan. Windows Mobile was eventually phased out in favor of Windows Phone OS.\\r\\nSymbian was originally developed by Psion as EPOC32. It was the world's most widely used smartphone operating system until Q4 2010, though the platform never gained popularity in the U.S., as it did in Europe and Asia. The first Symbian phone, the touchscreen Ericsson R380 Smartphone, was released in 2000,[89][90] and was the first device marketed as a \\"smartphone\\".[91] It combined a PDA with a mobile phone.[92] Variants of Symbian OS began to emerge, most notably Symbian UIQ, MOAP and S60, each supported by different manufacturers. With the creation of Symbian Foundation in 2008, Symbian OS was unified under one variant under the stewardship of Nokia. In February 2011, Nokia announced that it would replace Symbian with Windows Phone as the operating system on all of its future smartphones, with the platform being abandoned over the following few years.[93]\\r\\nFirefox OS was demonstrated by Mozilla in February 2012. It was designed to have a complete community-based alternative system for mobile devices, using open standards and HTML5 applications. The first commercially available Firefox OS phones were ZTE Open and Alcatel One Touch Fire. As of 2014, more companies had partnered with Mozilla including Panasonic (which was making a smart TV with Firefox OS) and Sony.[94] In December 2015, Mozilla announced that it would phase out development of Firefox OS for smartphones, and would reposition the project to focus on other forms of Internet-connected devices.[95]\\r\\nThe Bada operating system for smartphones was announced by Samsung in November 2009.[96][97] The first Bada-based phone was the Samsung Wave S8500, released in June 2010.[98][99] Samsung shipped 4.5 million phones running Bada in Q2 of 2011.[100] In 2013, Bada merged with a similar platform called Tizen.\\r\\nwebOS is a proprietary mobile operating system running on the Linux kernel, initially developed by Palm, which launched with the Palm Pre. After being acquired by HP, two phones (the Veer and the Pre 3) and a tablet (the TouchPad) running webOS were introduced in 2011. On August 18, 2011, HP announced that webOS hardware was to be discontinued[101] but would continue to support and update webOS software and develop the webOS ecosystem.[102] HP released webOS as open source under the name Open webOS, and plans to update it with additional features.[103] On February 25, 2013 HP announced the sale of WebOS to LG Electronics, who used the operating system for its current \\"smart\\" or Internet-connected TVs, but not smartphones. In January 2014, Qualcomm has announced that it has acquired technology patents from HP, which includes all the WebOS patents.[104]\\r\\nIn late 2001, Handspring launched the Springboard GSM phone module with limited success. In May 2002, Handspring released the Palm OS Treo 270 smartphone, which did not support Springboard, with both a touchscreen and a full keyboard. The Treo had wireless web browsing, email, calendar, a contact organizer and mobile third-party applications that could be downloaded or synced with a computer.[105] Handspring was purchased by Palm, Inc which released the Treo 600 and continued releasing Treo devices with a few Treo devices using Windows Mobile.\\r\\nMeeGo is an operating system created from the source code of Moblin (produced by Intel) and Maemo (produced by Nokia). Before that, Nokia used Maemo on some of its smartphones and internet tablets (such as Nokia N810 and N900). MeeGo was originally envisioned to power a variety of devices from netbooks, tablets to smartphones and smart TVs. However, the only smartphones which used MeeGo was the Nokia N9 and Nokia N950 (MeeGo v1.2 Harmattan). Following Nokia's decision to move to Windows Phone OS in 2011 and to cease MeeGo development, the Linux Foundation canceled MeeGo in September 2011 in favor of the development of Tizen.\\r\\nUbuntu Touch (also known as Ubuntu Phone) is a mobile version of the Ubuntu operating system developed by Canonical UK Ltd and Ubuntu Community.[106] It is designed primarily for touchscreen mobile devices such as smartphones and tablet computers.\\r\\nIn 2003, Motorola launched the first smartphone to use Linux, the A760 handset.[107] While the initial release was limited to a single high-end handset only available in the Asia-Pacific region, the maker's intention was to eventually use Linux on most of its handsets, including the lower-end models. Further models to use Linux such as the Motorola Ming A1200i in 2005 and several successors to the Ming line would be unveiled through 2010. In late 2009, Motorola released the Motorola Cliq,[108] the first of Motorola's smartphones to run the Linux-based Android operating system. Subsequently Motorola stopped developing phones based on other Linux variants.\\r\\nThe introduction of Apple's App Store for the iPhone and iPod Touch in July 2008 popularized manufacturer-hosted online distribution for third-party applications (software and computer programs) focused on a single platform. There are a huge variety of apps, including video games, music products and business tools. Up until that point, smartphone application distribution depended on third-party sources providing applications for multiple platforms, such as GetJar, Handango, Handmark, and PocketGear. Following the success of the App Store, other smartphone manufacturers launched application stores, such as Google's Android Market (now Google Play Store) and RIM's BlackBerry App World in April 2009. In February 2014, 93% of mobile developers were targeting smartphones first for mobile app development.[109]\\r\\nSince 1996, smartphone shipments have had positive growth. In November 2011, 27% of all photographs created were taken with camera-equipped smartphones.[110] In September 2012, a study concluded that 4 out of 5 smartphone owners use the device to shop online.[111] Global smartphone sales surpassed the sales figures for feature phones in early 2013.[3] Worldwide shipments of smartphones topped 1 billion units in 2013, up 38% from 2012's 725 million, while comprising a 55% share of the mobile phone market in 2013, up from 42% in 2012.[112] In Q1 2016 for the first time the shipments dropped by 3 percent year on year. The situation was caused by the maturing China market.[113]\\r\\nIn 2011, Samsung had the highest shipment market share worldwide, followed by Apple. In 2013, Samsung had 31.3% market share, a slight increase from 30.3% in 2012, while Apple was at 15.3%, a decrease from 18.7% in 2012. Huawei, LG and Lenovo were at about 5% each, significantly better than 2012 figures, while others had about 40%, the same as the previous years figure. Only Apple lost market share, although their shipment volume still increased by 12.9 percent; the rest had significant increases in shipment volumes of 36 to 92 percent.[116] In Q1 2014, Samsung had a 31% share and Apple had 16%.[117] In Q4 2014, Apple had a 20.4% share and Samsung had 19.9%.[118] In Q2 2016, Samsung had a 22.3% share and Apple had 12.9%.[114] In Q1 2017, IDC reported that Samsung was first placed, with 80 million units, followed by Apple with 50.8 million, Huawei with 34.6 million, Oppo with 25.5 million and Vivo with 22.7 million.[119]\\r\\nSamsung mobile business are half the size of Apples. Apple business has been increasing very quickly over the past 4 years. Noah Richardson [120]\\r\\nThe market has been dominated by the Android operating system since 2010. Android's market share (measured by units shipment) rose from 33.2% in Q4 2011 to 81.7% of the market in Q4 2016. Apple's market share oscillated between 18% and 12.5% during the same period. Windows Phone market share also oscillated between 1.5% and 0.3% during the same time frame. As of the end of Q4 2016, Android was the most popular operating system sold with new smartphones with an 81.7% market share, followed by iOS with 17.9%, Windows 10 Mobile with 0.3% and other OSes at 0.1%.[121]\\r\\nA 2012 University of Southern California study found that unprotected adolescent sexual activity was more common among owners of smartphones.[128] A study conducted by the Rensselaer Polytechnic Institute's (RPI) Lighting Research Center (LRC) concluded that smartphones, or any backlit devices, can seriously affect sleep cycles.[129] Some persons might become psychologically attached to cellphones resulting in anxiety when separated from the devices.[130] A \\"smombie\\" (a combination of \\"smartphone\\" and \\"zombie\\") is a walking person using a smartphone and not paying attention as they walk, possibly risking an accident in the process, an increasing social phenomenon.[131] The issue of slow-moving smartphone users led to the temporary creation of a \\"mobile lane\\" for walking in Chongqing, China.[132] The issue of distracted smartphone users led the city of Augsburg, Germany to embed pedestrian traffic lights in the pavement.[133]\\r\\nMobile phone use while driving - including talking on the phone, texting, playing media, web browsing, gaming, using mapping apps or operating other phone features - is common but controversial, since it is widely considered dangerous due to what's known as distracted driving. Being distracted while operating a motor vehicle has been shown to increase the risk of accidents. In September 2010, the US National Highway Traffic Safety Administration (NHTSA) reported that 995 people were killed by drivers distracted by phones. In March 2011 a US insurance company, State Farm Insurance, announced the results of a study which showed 19% of drivers surveyed accessed the Internet on a smartphone while driving.[134] Many jurisdictions prohibit the use of mobile phones while driving. In Egypt, Israel, Japan, Portugal and Singapore, both handheld and hands-free calling on a mobile phone (which uses a speakerphone) is banned. In other countries including the UK and France and in many US states, only the use of calling on handheld phones is banned, while hands-free use is permitted.\\r\\nA 2011 study reported that over 90% of college students surveyed text (initiate, reply or read) while driving.[135] The scientific literature on the danger of driving while sending a text message from a mobile phone, or texting while driving, is limited. A simulation study at the University of Utah found a sixfold increase in distraction-related accidents when texting.[136] Due to the complexity of smartphones, this has introduced additional difficulties for law enforcement officials when attempting to distinguish one usage from another in drivers using their devices. This is more apparent in countries which ban both handheld and hands-free usage, rather than those which ban handheld use only, as officials cannot easily tell which function of the phone is being used simply by looking at the driver. This can lead to drivers being stopped for using their device illegally for a call when, in fact, they were using the device legally, for example, when using the phone's incorporated controls for car stereo, GPS or satnav.\\r\\nA 2010 study reviewed the incidence of phone use while cycling and its effects on behavior and safety.[137] In 2013 a national survey in the US reported the number of drivers who reported using their phones to access the Internet while driving had risen to nearly one of four.[138] A study conducted by the University of Vienna examined approaches for reducing inappropriate and problematic use of mobile phones, such as using phones while driving.[139]\\r\\nAccidents involving a driver being distracted by being in a call on a phone have begun to be prosecuted as negligence similar to speeding. In the United Kingdom, from 27 February 2007, motorists who are caught using a hand-held phone while driving will have three penalty points added to their license in addition to the fine of S60.[140] This increase was introduced to try to stem the increase in drivers ignoring the law.[141] Japan prohibits all use of phones while driving, including use of hands-free devices. New Zealand has banned handheld phone use since 1 November 2009. Many states in the United States have banned text messaging on phones while driving. Illinois became the 17th American state to enforce this law.[142] As of July 2010, 30 states had banned texting while driving, with Kentucky becoming the most recent addition on July 15.[143]\\r\\nPublic Health Law Research maintains a list of distracted driving laws in the United States. This database of laws provides a comprehensive view of the provisions of laws that restrict the use of mobile devices while driving for all 50 states and the District of Columbia between 1992, when first law was passed through December 1, 2010. The dataset contains information on 22 dichotomous, continuous or categorical variables including, for example, activities regulated (e.g., texting versus talking, hands-free versus handheld calls, web browsing, gaming), targeted populations, and exemptions.[144]\\r\\nA \\"patent war\\" between Samsung and Apple started when the latter claimed that the original Galaxy S Android phone copied the interface??and possibly the hardware??of Apple's iOS for the iPhone 3GS. There was also smartphone patents licensing and litigation involving Sony Mobile, Google, Apple Inc., Samsung, Microsoft, Nokia, Motorola, HTC, Huawei and ZTE, among others. The conflict is part of the wider \\"patent wars\\" between multinational technology and software corporations. To secure and increase market share, companies granted a patent can sue to prevent competitors from using the methods the patent covers. Since 2010 the number of lawsuits, counter-suits, and trade complaints based on patents and designs in the market for smartphones, and devices based on smartphone OSes such as Android and iOS, has increased significantly. Initial suits, countersuits, rulings, license agreements, and other major events began in 2009 as the smartphone market grew more rapidly.\\r\\nWith the rise in number of mobile medical apps in the market place, government regulatory agencies raised concerns on the safety of the use of such applications. These concerns were transformed into regulation initiatives worldwide with the aim of safeguarding users from untrusted medical advice.[145]\\r\\nSmartphone malware is easily distributed through an insecure app store.[146][147] Often malware is hidden in pirated versions of legitimate apps, which are then distributed through third-party app stores.[148][149] Malware risk also comes from what's known as an \\"update attack\\", where a legitimate application is later changed to include a malware component, which users then install when they are notified that the app has been updated.[150] As well, one out of three robberies in 2012 in the United States involved the theft of a mobile phone. An online petition has urged smartphone makers to install kill switches in their devices.[151] In 2014, Apple's \\"Find my iPhone\\" and Google's \\"Android Device Manager\\" can disable phones that have been lost/stolen. With BlackBerry Protect in OS version 10.3.2, devices can be rendered unrecoverable to even BlackBerry's own Operating System recovery tools if incorrectly authenticated or dissociated from their account.[152]\\r\\nUsing smartphones late at night can disturb sleep, due to the brightly lit screen affecting melatonin levels and sleep cycles. In an effort to alleviate these issues, several apps that change the color temperature of a screen to a warmer hue based on the time of day to reduce the amount of blue light generated have been developed for Android, while iOS 9.3 integrated similar, system-level functionality known as \\"Night Shift\\". Amazon released a feature known as \\"blue shade\\" in their Fire OS \\"Bellini\\" 5.0 and later. It has also been theorized that for some users, addicted use of their phones, especially before they go to bed, can result in \\"ego depletion\\". Many people also use their phones as alarm clocks, which can also lead to loss of sleep.[153][154][155][156][157]\\r\\nSmartphones have presented issues similar to those affecting other devices. As well, there are some issues which are unique to smartphones.\\r\\nSmartphone battery life has generally been poor compared to earlier non-smartphone mobile phones, due to the significant power requirements of the smartphones' computer systems and color screens. Poor smartphone battery life has negatively affected customer satisfaction.[158][159][160] There is also a trend towards using batteries that the user cannot replace.[161] Smartphone users have addressed the challenge of limited battery life by purchasing additional chargers for use outside the home, at work, and in cars and by buying portable external \\"battery packs\\". External battery packs include generic models which are connected to the smartphone with a cable and custom-made models that \\"piggyback\\" onto a smartphone's case. Most recently, Samsung had to recall millions of the Galaxy Note 7 smartphones due to an explosive battery issue.[162] For consumer convenience, wireless charging stations have been introduced in some hotels, bars, and other public spaces.[163]\\r\\n\\"Phablet\\", a portmanteau of the words phone and tablet, describes smartphones with larger screens.[164][165]\\r\\n\\"Superphone\\" is also used by some companies to market phones with unusually large screens and other expensive features.[166][167]\\r\\n\\"Ultra Premium\\" is a term used to identify a smartphone which has top of the line materials.[168]","input":"When did cell phones first come on the market?"},{"output":"investigating crime and to protect the national security of the Commonwealth of Australia","context":"\\r\\n\\r\\nThe Australian Federal Police (AFP) is the principal federal law enforcement agency of the Australian Government with the unique role of investigating crime and to protect the national security of the Commonwealth of Australia. The AFP is an independent agency of the Department of Home Affairs and is responsible to the Minister for Home Affairs and accountable to the Parliament of Australia.[3] Since October 2014 the Commissioner of the Australian Federal Police has been Andrew Colvin.[4]\\r\\n\\r\\nThe AFP has a focus on preventing, investigating and disrupting transnational, serious, complex and organised crime including terrorism and violent extremism, cybercrime, child exploitation, drug smuggling, and human trafficking. The AFP is also responsible for delivering community policing in the Australian Capital Territory through ACT Policing and to other dependent territories, providing protective security in major airports and close protection for dignities including the Prime Minister of Australia and foreign diplomatic missions, delivering law enforcement training for Asia-Pacific partner agencies, acting as Australia's international law enforcement and policing representative, and contributing to United Nations peacekeeping around the world. The AFP is also a member of the National Intelligence Community and works closely with the Australian Security Intelligence Organisation, the Australian Border Force, and the Australian Criminal Intelligence Commission.\\r\\n\\r\\nThe AFP was formed on 19 October 1979 under the Australian Federal Police Act 1979[5] after the merging of the former Commonwealth Police and the Australian Capital Territory Police. This followed a review of Australia's anti-terrorism capacity by Sir Robert Mark, former Commissioner of the Metropolitan Police in the UK, which was commissioned by the Fraser Government following the 1978 Hilton bombing. In November 1979, the Federal Narcotics Bureau was transferred to the new agency.[6] In 1984 the protective service component of the AFP was separated forming the Australian Protective Service under the administrative service and later governed by Attorney-General's Department; that agency was transferred back to the AFP in 2004 and is now known as Australian Federal Police Uniform Protection. \\r\\n\\r\\nThe AFP is overseen by the Australian Commission for Law Enforcement Integrity and the Parliamentary Joint Committee on Law Enforcement.[citation needed]\\r\\n\\r\\nThe AFP's role is to enforce Australian criminal law, contribute to combating complex, transnational, serious and organised crime impacting Australia's national security and to protect Commonwealth interests from criminal activity in Australia and overseas.\\r\\n\\r\\nThe AFP is responsible to the Minister for Home Affairs, a ministerial position outside the federal cabinet and subordinate to the Attorney-General. Key priorities of the AFP are set by the Minister for Home Affairs, through a \\"ministerial direction\\" issued under the Australian Federal Police Act 1979.[7] Areas of operational emphasis include:\\r\\n\\r\\nContinued responsibilities include providing:\\r\\n\\r\\nFederal agents are based in each Australian state and territory capital city, internationally and form the largest component of the AFP staff, federal agents chiefly perform criminal investigative duties.\\r\\n\\r\\nCurrent areas of focus for the AFP:\\r\\n\\r\\nThe AFP hosts a National Missing Persons Coordination Unit, the Australian Interpol National Central Bureau, and the Australian Bomb Data Centre.\\r\\n\\r\\nMembers of the AFP outside the ACT and other federal territory do not exercise the powers, obligations and liabilities of a constable at common law. Consequently, they are identified by each state as federal agents; that is, a member of a law enforcement agency, not a police service.\\r\\n\\r\\nAssault rifle-armed AFP officers are situated in both chambers of the Australian Parliament as of 2015. It is the first time in Australian history that parliament has been guarded by armed personnel.[8]\\r\\n\\r\\nThe AFP provides community policing services to the ACT, under a contractual agreement between the Australian Government and the ACT government. This AFP portfolio, ACT Policing, is the successor of the ACT Police, one of the agencies that was merged to form the AFP in 1979. The mission of ACT Policing is to keep the peace and preserve public safety for the residents of the ACT. Key sections of ACT Policing include general duties, crime and safety management, criminal investigations, crime prevention, traffic operations and criminal intelligence. The head of ACT Policing is known as the chief police officer of the ACT.\\r\\n\\r\\nThe AFP provides community policing and counter terrorism first response duties at major Australian airports, and community policing in the Jervis Bay territory and in the external Australian territories of Norfolk Island, Christmas Island, and the Cocos Islands. The AFP provides a mix of United Nations peacekeeping, community policing and capacity development roles and services in a number of nations.[citation needed]\\r\\n\\r\\nAFP uniform protection provides physical protection for the Australian government at key locations throughout Australia and internationally. Uniform protection officers are firearms and defensive tactics trained, and perform duties which include armed escorts, bomb appraisals, bomb detection canines, visitor control, static guarding, alarm monitoring and response, mobile, foot and bicycle patrols, maintain civil order, security consultancy services, counter-terrorism first response at many Commonwealth establishments. Uniform protection officers have powers under Section 14 of the AFP Act 1979 to arrest, stop, search, and request identification in their jurisdiction. Uniform protection officers undertake an essential role in protecting Australia's critical infrastructure and assist in providing protection for Australian high office holders, diplomatic, consular personnel and other foreign nationals.\\r\\n\\r\\nUniform protection officers providing an armed uniform capability are located at federal establishments including Parliament House in Canberra; the residences of the prime minister and governor-general; foreign embassies and consulates in Canberra, Sydney, Melbourne and Perth; the Australian Nuclear Scientific Technology Organisation installation, Joint defence facilities such as the Australian Defence Force Headquarters in Canberra, Holsworthy Barracks, Garden Island Naval Base, Victoria Barracks, the Pine Gap US defence installation, and sensitive covert locations in Australia and internationally.\\r\\n\\r\\nSince its inception, the AFP has had a long tradition of involvement in international peacekeeping, policing and capacity development. International Deployment Group (IDG) is an AFP portfolio that has increased rapidly in a short time since its inception in 2004. Since 1964, Australia has contributed police officers to the United Nations Peacekeeping Force in Cyprus. AFP officers have also previously  served with the United Nations in East Timor (Timor Leste) and South Sudan.\\r\\n\\r\\nIn recent years, Australian government efforts to assist neighbouring and remote countries with institutional capacity building has led to AFP deployments to Papua New Guinea, the Solomon Islands (Under the Regional Assistance Mission to Solomon Islands), Timor-Leste (Under the Timor-Leste Police Development Program TLPDP), Nauru, Tonga, Vanuatu, Afghanistan, Samoa and Vanuatu. Previous peacekeeping missions have included Haiti, Mozambique, Thailand, Namibia, and Somalia.\\r\\n\\r\\nIDG uses the Specialist Response Group for particular medium and high risk planned operations or emergency incidents in addition to assisting with capacity building and force protection operations.\\r\\n\\r\\nThe AFP Ceremonial Team conducts and participates in a variety of police and community functions and ceremonies.\\r\\n\\r\\nCeremonial events include the annual National Police Remembrance Day Service at the National Police Memorial in Canberra on 29 September, medal presentations, parades, police funerals, memorial services, official opening of police stations and policing facilities, AFP pipes and drums concerts, inauguration events and public relations events\\r\\n\\r\\nThe Ceremonial Team coordinates the AFP Ceremonial and Protocol Officer (CAPO) Network, the AFP Ceremonial Mounted Cadre and the AFP Pipes and Drums to perform ceremonial duties at these functions and ceremonies.\\r\\n\\r\\nThe AFP Ceremonial Mounted Cadre was raised on 29 September 2006 at the dedication of the National Police Memorial. The ceremonial uniform comprises linkages to former mounted policing units of the AFP's predecessor organisations, namely the Commonwealth Police and the Peace Officer guard, as well as mounted policing units from the NSW Police Force which patrolled the geographic area of the ACT.\\r\\n\\r\\nThe AFP Ceremonial and Protocol team currently provide drill instructor accreditation for both the AFP and the NSW Police Force, and ceremonial and protocol officer accreditation for all of Australia's policing jurisdictions.\\r\\n\\r\\nThe AFP has an international network to assist with inquiries and liaison with police agencies around the world. The AFP represents Australian state/ territory police agencies internationally. AFP's International Liaison Officer Network has 85 AFP appointees in 30 countries around the world. AFP International Liaison Officers are the Australian Government's law enforcement representatives overseas.[9]\\r\\n\\r\\nThe Joint Counter Terrorism Teams (JCTTs) in each state and territory jurisdiction consisting of AFP, state and territory police, and Australian Security Intelligence Organisation officers. JCTTs conduct investigations to prevent and disrupt terrorism and violent extremism. The JCTT model can be seen as the Australian version of the United States' Joint Terrorism Task Force, Canada's Integrated National Security Enforcement Teams, and the United Kingdom's National Counter Terrorism Policing Network.[10]\\r\\n\\r\\nThe National Disruption Group (NDG) is an AFP-led interagency team which consolidates the capabilities of participating agencies to prevent, disrupt and prosecute Australian nationals who travel or intend to travel offshore to engage in hostilities and/or undertake terrorism training and support to terrorist entities. The NDG brings together the AFP and its partner agencies to coordinate operational disruption activities nationally and internationally with the aim of countering the enduring threat posed by foreign fighters.[11][12]\\r\\n\\r\\nThe Australian Bomb Data Centre (ABDC) is Australia's primary source of information and intelligence relating to the unlawful use of explosives. The ABDC officially began operations on 1 July 1978, and it is therefore one of the oldest bomb data centres in the world. The ABDC provides statistical reporting on all explosive incidents reported to the Centre by Australian policing and military agencies. This includes any minor incidents or acts of vandalism reported by the relevant agency. The ABDC is concerned both with criminals who use explosives for their own benefit and with those who use explosives and bombs for terrorism. It maintains records of all bomb-related incidents reported to it, regardless of design, target or motive. The ABDC is staffed by members of the AFP as well as members of the Australian Defence Force.[13][14]\\r\\n\\r\\nThe Australian High Tech Crime Centre (AHTCC) is a national cybercrime and cybersecurity initiative located within the AFP with staff also from the Australian Security Intelligence Organisation and Australian Signals Directorate. The primary role of the AHTCC is to coordinate the efforts of Australian law enforcement in combating serious, complex and multi-jurisdictional high tech crimes, especially those beyond the capability of single policing jurisdictions in Australia. Secondary roles include protecting the information infrastructure of Australia, and providing information to other law enforcement to help combat online crime.[citation needed]\\r\\n\\r\\nThe Australian Federal Police College is the training facility for the force. The college's residential area was home to then Prime Minister Tony Abbott when he was in Canberra as the Lodge was undergoing renovations.[15]\\r\\n\\r\\nThe senior AFP officer is the Commissioner of Police, appointed under Section 17 of the Australian Federal Police Act 1979.\\r\\n\\r\\n7003148900000000000?4?years, 28?days \\r\\n\\r\\nAFP members performing duties in ACT Policing, External Territories, Aviation, International Deployment Group (mission component) use uniform and community policing ranks.  All other members use the title Federal Agent.  Where applicable qualified members are also entitled to use Detective designation.\\r\\n\\r\\nAFP Commissioner's Order 1 (Administration) states that every AFP Member holds a rank (as detailed below), with the corresponding title and role adopted.\\r\\n\\r\\nFirst Class Constable is a reflection of four years of service as a Member. Detective Leading Senior Constable is a reflection of at least six years of service as a Member and detective superintendent is at least 15 to 20 years of service\\r\\n\\r\\nOn  2 July 2007 Muhamed Haneef was arrested and held by the AFP for terror-related incidents.  It was the longest detention without charge under recent anti-terror laws and was found to be unjustified.\\r\\n\\r\\nIn October 2006 a Cairns jury convicted pilot Frederic Arthur Martens under sex tourism laws of having intercourse with a 14-year-old girl in Port Moresby, Papua New Guinea.  However, Martins was not in Port Moresby at the time, and flight records could prove this.  The AFP refused to retrieve those records despite numerous requests, and Martins could not retrieve them as he was in jail.\\r\\nWhen the records were eventually retrieved by Martins' partner the convictions were quashed, with strong criticism of the AFP\\r\\nby Justice Chesterman. The AFP also froze all of Martin's funds while he was in custody, which prevented treatment for his daughter in Port Moresby who died as a result.[16]\\r\\n\\r\\nThe AFP were contacted by a member of the Bali Nine drug courier gang's father, and they said they would keep a watch on him. They could not stop them traveling to Indonesia to smuggle drugs.  Instead, they contacted the Indonesian Police which led to their arrest in Indonesia rather than when returning to Australia. The leaders of the gang Andrew Chan and Myuran Sukumaran were executed on 29 April 2015.\\r\\n[17]\\r\\n\\r\\nOver 200 heavily armed police conducted raids at 3am at various houses in Victoria on 19 April 2015, and then held Harun Causevic on a Preventative Detention Order (PDO), before charging him with terrorist offences.[18]\\r\\nVictorian premier Daniel Andrews said this was the first time a PDO had been used, and validated their importance.[19]\\r\\n\\r\\nHowever, after Causevic spent three months in jail awaiting trial the federal police decided to drop the terrorism charges.\\r\\n[20]\\r\\nCausevic's defense lawyer, Rob Stary, said there was never any real evidence against Causevic, and that this eroded confidence in the authorities.  He was also critical of the earlier \\"grandstanding\\" of Prime Minister Tony Abbott and Premier Daniel Andrews.\\r\\n[21]","input":"What is the role of the australian federal police?"},{"output":"May 5, 2018","context":"\\"This Is America\\" is a song by American rapper Childish Gambino. Written and produced by Gambino and Ludwig G?ransson, it was released on May 5, 2018, at the same time that Gambino was hosting that day's episode of Saturday Night Live. The song features background vocals by American rappers Young Thug, Slim Jxmmi, BlocBoy JB, 21 Savage and Quavo.[4][5] The song addresses the wider issue of gun violence in the United States, the high rate of mass shootings in the United States, along with longstanding racism and discrimination against African Americans.\\r\\n\\r\\nThe song's music video was directed by Japanese-American filmmaker Hiro Murai, a frequent Gambino collaborator.[6][7] According to RCA Records, the song is not the first single from Gambino's upcoming studio album.[8][9] \\"This Is America\\" became the 31st song to debut at number one on the US Billboard Hot 100, becoming both Gambino's first number one and top ten single in the country. It has also topped the charts in Australia, Canada, and New Zealand.\\r\\n\\r\\nThe song features a gospel-style choir and background contributions from various American rappers. Young Thug, Slim Jxmmi, BlocBoy JB, 21 Savage and Quavo each deliver an ad-lib.[7][10] Young Thug returns to supply the song's outro.[5] The lyrics primarily address being black in the United States and gun violence in the country.[11] It also touches on police brutality.[12][13] Pitchfork's Stephen Kearse described the song as a representation of the \\"tightrope of being black\\", with the song \\"built on the sharp contrast between jolly, syncretic melodies and menacing trap cadences\\".[14]\\r\\n\\r\\nMedia outlets reported that a number of listeners accused Gambino of plagiarism over \\"This Is America\\", pointing out the similarities between the song and \\"American Pharaoh\\" by Jase Harley.[15][16] CBS News stated, \\"The tracks have a similar sound, and share similar themes in the lyrics.\\" Harley stated that he felt \\"This Is America\\" was influenced by his song, but that he does not have an issue with it. Glover's manager, Fam Rothstein, denied any plagiarism.[17]\\r\\n\\r\\nDirected by Hiro Murai, the music video for the song was released on YouTube simultaneously with Gambino's performance of the song on Saturday Night Live.[18] The video follows Gambino dancing through a warehouse, interacting with a series of chaotic scenes.[19] According to Murai, the video was inspired by the films Mother! and City of God.[20] Choreographed by Sherrie Silver, Gambino and his entourage of young dancers perform several viral dance moves including the South African Gwara Gwara and \\"Shoot\\" popularized by BlocBoy JB, who is one of the ad-lib contributors on the song.[10][21] Gambino's dancing is contrasted against moments of violence. Only 53 seconds into the video,[22] Gambino shoots a man in the back of the head with a handgun, while assuming a comical stance similar to a Jim Crow caricature.[23] At a later point, he uses an automatic weapon to gun down a church choir, which viewers have interpreted as a reference to the 2015 Charleston church shooting.[24] In both instances, a child appears from offscreen holding a red cloth, on which Gambino gently lays the weapon used, while the bodies are simply dragged away, which viewers have interpreted \\"as a reference to Americans' willingness to protect gun rights over people\\".[25] The first shooting also marks a transition in the music, from an African \\"folk-inspired melody\\" to \\"dark, pulsing trap\\".[7]\\r\\n\\r\\nThroughout the video, numerous vehicles from several decades ago are featured, many of them with their hazard lights flashing and the driver's side door ajar,[25] which critics interpreted as representing fatal police shootings during traffic stops, particularly the shooting of Philando Castile, who was shot while in a 1997 Oldsmobile;[26] others have interpreted that the older model cars represent the relative lack of upward mobility of African-Americans.[25] American singer SZA makes a cameo appearance towards the end of the video, seated atop one of these vehicles.[13] The video ends with Gambino in a darkened portion of the warehouse, fearfully running towards the camera while being chased by several white people. Viewers have said this resembles scenes from the film Get Out.[24]\\r\\n\\r\\nThe video received 12.9?million views in 24 hours[27] and has over 360?million views as of  August?2018[update].[28] The first person depicted as being shot in the video, a guitarist who had been accompanying Gambino's singing up to that point, was musician Calvin the Second, but was initially mistaken by many viewers to be the father of teenager Trayvon Martin.[29]\\r\\n\\r\\nSpencer Kornhaber of The Atlantic described the initial reaction on Twitter as \\"a gushing river of well-deserved praise\\" and the video as \\"the most talked-about music video of recent memory.\\"[7] Daniel Kreps of Rolling Stone commented that the video \\"is a surreal, visceral statement about gun violence in America\\".[30] Pitchfork awarded the song the distinction of \\"Best New Track\\".[14] Billboard critics ranked it 10th among the \\"greatest music videos of the 21st century.\\"[31] Mahita Gajanan of Time quoted music history professor Guthrie Ramsey at the University of Pennsylvania,[32]\\r\\n\\r\\nHe's talking about the contradictions of trying to get money, the idea of being a black man in America. It comes out of two different sound worlds. Part of the brilliance of the presentation is that you go from this happy major mode of choral singing that we associate with South African choral singing, and then after the first gunshot it moves right into the trap sound.\\r\\n\\r\\nGlover hosted the May 5 episode of the 43rd season of Saturday Night Live, and performed two new songs as Childish Gambino on the same episode, the second of which was \\"This Is America\\". Daniel Kaluuya, best known as the star of the film Get Out which the music video reportedly references, introduced the song's performance.[33][34]\\r\\n\\r\\nSeveral artists attracted attention and millions of views for creating covers of the song and music video with altered lyrics and themes, retaining the song's instrumental and the general structure of its music video. On May 12, Canadian Internet personality Nicole Arbour released \\"This Is America: Women's Edit\\". Arbour intended for the cover to promote women's empowerment, but was accused of belittling the racial issues addressed by the original video.[35][36] Nigerian rapper Falz released \\"This Is Nigeria\\" on May 25, highlighting the nation's issues with corruption and organized crime among others.[37][38]\\r\\n\\r\\nThe music video also spawned popular Internet memes, particularly those in which the audio was replaced so that Childish Gambino appeared to be dancing in time to another song. Versions using Carly Rae Jepsen's \\"Call Me Maybe\\" and Earth, Wind & Fire's \\"September\\" were some of the most viewed.[39][40]\\r\\n\\r\\nThe UK comedian Lenny Henry parodied the song and music video as \\"This is the TV\\" (under the name Wildish Bambino) for The Lenny Henry Birthday Show on August 22, 2018 to celebrate Henry's 60th birthday.\\r\\n\\r\\n\\"This Is America\\" debuted at number one on the US Billboard Hot 100, becoming the 31st song to do so in the chart's history. It debuted with 78,000 downloads sold and 65.3?million US streams in the first week. Its music video accounted for 68% of the song's streaming total. \\"This Is America\\" is also Gambino's first top 10; he previously reached number 12 in August 2017 with \\"Redbone\\". \\"This Is America\\" overtook Drake's \\"Nice for What\\" from the top position for two weeks. Gambino is also the second Emmy Award-winning actor to reach number one on the Hot 100, the first being Justin Timberlake, who topped the chart with \\"Can't Stop the Feeling!\\" in 2016.[41] It topped the Hot 100 for two weeks, and left the top ten after five weeks.\\r\\n\\r\\nCredits are adapted from Tidal.[42]\\r\\n\\r\\n*sales figures based on certification alone^shipments figures based on certification alonesales+streaming figures based on certification alone","input":"When was childish gambino this is america released?"},{"output":"two terms (totaling eight years) or a maximum of ten years if the president acted as president for two years or less in a term where another was elected as president,","context":"A term of office is the length of time a person serves in a particular elected office. In many jurisdictions there is a defined limit on how long terms of office may be before the officeholder must be subject to re-election. Some jurisdictions exercise term limits, setting a maximum number of terms an individual may hold in a particular office.\\r\\n\\r\\nBeing the origin of the Westminster system, aspects of the United Kingdom's system of government are replicated in many other countries.\\r\\n\\r\\nThe monarch serves as head of state until his or her death or abdication.\\r\\n\\r\\nIn the United Kingdom Members of Parliament (MPs) in the House of Commons are elected for the duration of the parliament. Following dissolution of the Parliament, a general election is held which consists of simultaneous elections for all seats. For most MPs this means that their terms of office are identical to the duration of the Parliament, though an individual's term may be cut short by death or resignation. An MP elected in a by-election mid-way through a Parliament, regardless of how long they have occupied the seat, is not exempt from facing re-election at the next general election.\\r\\n\\r\\nThe Septennial Act 1715 provided that a Parliament expired seven years after it had been summoned; this maximum period was reduced to five years by the Parliament Act 1911. Prior to the Fixed-term Parliaments Act 2011 parliaments had no minimum duration. Parliaments could be dissolved early by the monarch at the Prime Minister's request. Early dissolutions occurred when the make-up of Parliament made forming government impossible (as occurred in 1974), or, more commonly, when the incumbent government reasoned an early general election would improve their re-election chances (e.g. 2001). The Fixed-term Parliaments Act 2011 mandated that Parliaments should last their full five years. Early dissolution is still possible, but under much more limited circumstances.\\r\\n\\r\\nBecause the government and Prime Minister are effectively indirectly elected through the Commons, the terms of Parliaments and MPs do not directly apply to offices of government, though in practice these are affected by changes in Parliament. While, strictly speaking, a Prime Minister whose incumbency spans multiple Parliaments only serves one, unbroken, term of office, some writers may refer to the different Parliaments as separate terms.[1]\\r\\n\\r\\nHereditary peers and life peers retain membership of the House of Lords for life, though members can resign or be expelled. Lords Spiritual hold membership of the House of Lords until the end of their time as bishops, though a senior bishop may be made a life peer upon the end of their bishopric (e.g. George Carey, made Baron Carey of Clifton the day after he ceased being Archbishop of Canterbury).\\r\\n\\r\\nThe devolved administrations in Scotland, Wales and Northern Ireland are variations on the system of government used at Westminster.\\r\\n\\r\\nThe office of the leader of the devolved administrations has no numeric term limit imposed upon it. However, in the case of the Scottish Government and the Welsh Assembly Government there are fixed terms for which the legislatures can sit. This is imposed at four years. Elections may be held before this time but only if no administration can be formed, which has not happened yet.\\r\\n\\r\\nOffices of local government other regional elected officials follow similar rules to the national offices discussed above, with persons elected to fixed terms of a few years.\\r\\n\\r\\nIn the United States, the president of the United States is elected indirectly through the United States Electoral College to a four-year term, with a term limit of two terms (totaling eight years) or a maximum of ten years if the president acted as president for two years or less in a term where another was elected as president, imposed by the Twenty-second Amendment to the United States Constitution, ratified in 1951.\\r\\n\\r\\nThe Vice President serves four-year terms. U.S. Representatives serve two-year terms. U.S. Senators serve six-year terms. \\r\\n\\r\\nFederal judges have different terms in office. Article I judges; such as those that sit on the United States bankruptcy courts, United States Tax Court, and United States Court of Appeals for the Armed Forces, and certain other federal courts and other forms of adjudicative bodies serve limited terms: The Court of Appeals for the Armed Forces for 15 years, bankruptcy courts for 14. However, the majority of the federal judiciary; Article III judges, such as those of the Supreme Court, courts of appeal, and federal district courts; serve for life.\\r\\n\\r\\nThe terms of office for officials in state governments varies according to the provisions of state constitutions and state law.\\r\\n\\r\\nThe term for state governors is four years in all states but Vermont and New Hampshire; the Vermont and New Hampshire governors serve for two years.\\r\\n\\r\\nThe National Conference of State Legislatures reported in January 2007 that among state legislatures [1]:\\r\\n\\r\\nAmong territories of the United States:\\r\\n\\r\\nMembers of Council of the District of Columbia serve a four-year term.\\r\\n\\r\\nAs a former British territory following the Westminster System, there are many similarities with the United Kingdom, although with some variations based on local customs, the federal system of government and the absentee monarch.\\r\\n\\r\\nBeing a Commonwealth realm, Canada shares a monarch with the United Kingdom and 14 other countries, who serves as head of state of all 16 realms until their death or abdication.\\r\\n\\r\\nThe Governor General is appointed by the monarch as his/her personal representative on the advice of the Prime Minister, and serves for an indefinite term, though the normal convention is 5 years. Similarly, the Lieutenant Governors, who represent the monarch at the provincial level, are appointed by the Governor General on the advice of the Prime Minister (usually also with consultation of the relevant provincial premier), and generally also serve 5 year terms by convention. The territories have Commissioners, who are not representatives of the monarch, but are instead appointed by and represent the Governor-in-Council (i.e. the federal cabinet), and conventionally serve for about 5 years.\\r\\n\\r\\nSimilar to the United Kingdom, MPs serve for the duration of the Parliament. They may resign before the end of a Parliament or be elected in by-elections during the middle of a Parliament.\\r\\n\\r\\nUnder the Constitution Act, 1867, a Parliament may last for a maximum of 5 years from the most recent election before expiring, although all Parliaments to date have been dissolved before they could expire. Bill C-16, introduced in the 39th Parliament, provided for fixed election dates every 4 years on the third Monday in October, beginning in 2009. However, the Prime Minister may still advise the Governor General to dissolve Parliament at any time. \\r\\n\\r\\nAs in the United Kingdom, the cabinet and head of government are indirectly elected based on the composition of the House of Commons, they are not technically affected by the terms of legislators or Parliaments. In practice however, the terms of government office holders are affected by changes in the House of Commons, and those who serve for multiple consecutive Parliaments are generally considered to have served a single term. The term of a government generally ends when it is defeated on a confidence matter or the governing party fails to gain enough seats in a general election.\\r\\n\\r\\nSenators are appointed to the Canadian Senate to represent a province by the Governor General of Canada on the advice of the Prime Minister, and serve until the mandatory retirement age of 75. Senators appointed before the passage of the British North America Act, 1965 served for life. Senators may also resign from office or be expelled from the Senate.\\r\\n\\r\\nProvincial legislatures and the legislature of the Yukon function very similarly to the federal House of Commons. MLAs (called MPPs in Ontario, MNAs in Quebec, and MHAs in Newfoundland and Labrador) serve for the duration of the legislature, though they may resign before the legislature is dissolved or be elected in by-elections between general elections. The legislatures of the Northwest Territories and Nunavut operate using a consensus model, but are similar otherwise. The premiers and their cabinets are selected in the same way as in the House of Commons, and like at the federal level, the term of a provincial government can be ended by defeat in a general election or the loss of the legislature's confidence.\\r\\n\\r\\nAll provincial legislatures except that of Nova Scotia have fixed-term election legislation in place, as does the legislature of the Northwest Territories. Premiers may also advise Lieutenant Governors to dissolve legislatures at any time before the prescribed election date.\\r\\n\\r\\nNumbers in years unless stated otherwise. Note that some countries where fixed-term elections are uncommon, the legislature is almost always dissolved earlier than its expiry date. \\"Until removed from office\\" refers to offices that don't have fixed terms; in these cases, the officeholder(s) may serve indefinitely until death, abdication, resignation, retirement, or forcible removal from office (such as impeachment).\\r\\n\\r\\nIn cases where the head of government is a different person from the head of state, its term of office is identical to the chamber that elected it (the legislature if it is unicameral, or most usually the lower house if it is bicameral), unless it doesn't survive a vote of no confidence.\\r\\n\\r\\n*Excludes senators for life.","input":"How long can the president stay in office?"},{"output":"St. Louis","context":"The Kansas City metropolitan area is a 15-county metropolitan area anchored by Kansas City, Missouri, that straddles the border between the U.S. states of Missouri and Kansas. With a population of 2,104,509, it ranks as the second largest metropolitan area with its core in Missouri (after Greater St. Louis). Alongside Kansas City, the area includes a number of other cities and suburbs, the largest being Overland Park, Kansas; Kansas City, Kansas; Olathe, Kansas; and Independence, Missouri; each over 100,000 in population. The Mid-America Regional Council (MARC) serves as the Council of Governments and the Metropolitan Planning Organization for the area.\\r\\n\\r\\nThe larger Kansas City Metropolitan Area as seen on a map can be visualized roughly as four quadrants:\\r\\n\\r\\nThe map's northeast quadrant is locally referred to as \\"north of the river\\" or \\"the Northland\\". It includes parts of Clay County, Missouri including North Kansas City, Missouri. North Kansas City is bounded by a bend in the Missouri River that defines a border between Wyandotte County, Kansas and Clay County, Missouri running approximately North-South and a border between North Kansas City, Missouri and Kansas City, Missouri running approximately East-West.\\r\\nThe river band's sharpest part forms a peninsula containing the Kansas City Downtown Airport.\\r\\n\\r\\nThe southeast quadrant includes Kansas City, Missouri and surrounding areas in Missouri. It includes the notorious Grandview Triangle.\\r\\n\\r\\nThe southwest quadrant includes all of Johnson County, Kansas, which includes the towns in the area known as Shawnee Mission, Kansas. Interstate 35 runs diagonally through Johnson County, Kansas from the southwest to downtown Kansas City, Missouri.\\r\\n\\r\\nThe northwest quadrant contains Wyandotte County, Kansas and parts of Platte County, Missouri. Wyandotte County, Kansas, sometimes referred to as just Wyandotte, which contains Kansas City, Kansas, Bonner Springs, Kansas and Edwardsville, Kansas is governed by a single unified government. Often the Wyandotte government is referred to simply as \\"The Unified Government\\". Another bend in the Missouri River forms the county line between\\r\\nWyandotte County, Kansas and Platte County, Missouri to the north and northeast.\\r\\n\\r\\nDowntown almost always refers to downtown Kansas City, Missouri. Downtown is the Kansas City's historic center, located entirely within Kansas City, Missouri, and containing the city's original town site, business districts, and residential neighborhoods. Downtown is bounded by the Missouri River on the north, the Missouri-Kansas state line on the west, 31st Street on the south and the Blue River on the east. The downtown area includes the Central Business District and its buildings, which form the city's skyline. The downtown loop is formed by Interstates 670, 70 and 35. Within the downtown loop are many of the tall buildings and skyscrapers that make up the city's skyline. Also within the downtown loop are small, distinct neighborhoods such as Quality Hill, the Garment District, the Financial District, the Convention Center District, and the Power and Light District.\\r\\n\\r\\nOther neighborhoods within downtown are the River Market and Columbus Park, both located between the downtown loop and the Missouri River. Between the downtown loop and the state line are the Westside neighborhood and the West Bottoms, located at the bottom of the bluff adjacent to Kaw Point. East of the loop are the 18th & Vine District, the North Bottoms, East Bottoms, Northeast, and Pendleton Heights. South of the loop is the Crossroads District, Union Hill, Crown Center, Hospital Hill, Longfellow, Wendell Phillips, and Washington Wheatley.\\r\\n\\r\\nThe Kansas City Convention Center, Municipal Auditorium, City Hall, Lyric Theater, Midland Theatre, Ilus Davis Park, and Barney Allis Plaza are within the Central Business District inside the downtown loop. The Sprint Center and the College Basketball Experience are within the Power & Light District, also within the downtown loop. The Kauffman Center for the Performing Arts is perched upon a high point immediately south of the downtown loop. South of the loop is the Crossroads District, Union Station, Crown Center, the National World War I Museum, Liberty Memorial, Penn Valley Park, Truman Medical Center, Children's Mercy Hospital, and the 18th & Vine District. North of the loop are City Market within the River Market and Richard L. Berkeley Riverfront Park. West of the loop within the West Bottoms are Kemper Arena and Hale Arena.\\r\\n\\r\\nMidtown is entirely within Kansas City, Missouri, just south of downtown, and bounded by 31st Street on the north, the state line on the west, West Gregory Boulevard (71st Street) on the south, and Troost Avenue on the east. Midtown is the core of the metropolitan area, as it contains numerous cultural attractions, shopping and entertainment areas, large hospitals, universities, and the metro area's most densely populated neighborhoods.\\r\\n\\r\\nMidtown consists of numerous distinct and historic neighborhoods such as Westport, Hyde Park, and Southmoreland. Shopping is centered on the Country Club Plaza, which contains numerous luxury retailers, hotels, and restaurants. Brookside and Westport also contain smaller-scale, neighborhood-oriented, and niche-market retailers. Midtown is home to Saint Luke's Hospital and Research Medical Center. Cultural attractions include the Nelson-Atkins Museum of Art, Kemper Museum of Contemporary Art, Uptown Theater, Starlight Theater, the Kansas City Zoo, Loose Park, and Swope Park. The last of these contains a soccer complex that is home to FC Kansas City of the National Women's Soccer League and the Swope Park Rangers, a United Soccer League team that is the official reserve side for the area's Major League Soccer club, Sporting Kansas City. Major educational institutions include the University of Missouri-Kansas City, Rockhurst University, Kansas City Art Institute, Stowers Institute for Medical Research, Midwest Research Institute, and Penn Valley Community College.\\r\\n\\r\\nAlso known as \\"South Kansas City\\", this area consists of the southern half of Kansas City, Missouri, as well as the suburbs of Grandview, Harrisonville, Belton, Loch Lloyd, Peculiar and Raymore.\\r\\n\\r\\nThe Northland is the area north of the Missouri River, bordered by the Kansas state line on the west and Missouri Highway 291 on the east. The southern half of Platte County, and much of Clay County make up the area. The economy of the Northland is dominated by Kansas City International Airport, Ford Kansas City Assembly Plant, the Zona Rosa shopping community and three riverboat casinos. The metro area's largest amusement park, Worlds of Fun and Oceans of Fun, is located in the Northland. Communities of the Northland outside the city limits include Parkville, Kearney, Liberty, Platte City, Gladstone, Riverside, Smithville, North Kansas City, and Weatherby Lake.\\r\\n\\r\\nEast Side of the Metro is primarily eastern Jackson County which is an area of the Kansas City Metro that contains the far-eastern urban side of Kansas City, Missouri and the following large suburbs of Blue Springs, Independence, and Lee's Summit. Also included in this area is western Lafayette County Missouri and the far northeast portion of Cass County Missouri.  The East Side of Metro includes the following Missouri suburbs of Independence, Blue Springs, Raytown, Lees Summit, Grain Valley, Oak Grove, Sugar Creek, River Bend, Lake Lotawana, Lone Jack, Greenwood, Unity Village, Buckner, Pleasant Hill, Bates City, Odessa, and Lake Tapawingo. Arrowhead Stadium, home of the NFL's Kansas City Chiefs and Kauffman Stadium, home of the MLB's Kansas City Royals are located on the eastern edge of Kansas City. The Silverstein Eye Centers Arena home of the ECHL's Kansas City Mavericks and the MASL's Missouri Comets is located in Independence.\\r\\n\\r\\nIn Wyandotte County lies Kansas City, Kansas, which is locally called \\"KCK\\" to distinguish it from the larger Kansas City, Missouri (KCMO). It contains many residential neighborhoods, the Fairfax Industrial District, and the Village West entertainment district. The General Motors Fairfax Assembly Plant is located in the Fairfax Industrial District. Village West contains many area attractions. This includes many sporting venues such as Children's Mercy Park, home of the area MLS soccer team Sporting Kansas City, the Kansas Speedway, which hosts many NASCAR races, and T-Bones Stadium, home of the independent baseball team, the Kansas City T-Bones. Other Village West attractions include the Legends shopping district, the Providence Medical Center Amphitheater, and Schlitterbahn Waterpark.\\r\\n\\r\\nJohnson County, Kansas contains many suburbs, both small and large. These suburbs include Overland Park, Olathe, Shawnee, Leawood, Lenexa, Prairie Village, Gardner, Merriam, Mission, Roeland Park, Fairway, Lake Quivira, Mission Hills, Mission Woods, Westwood, and Westwood Hills. Many local area attractions and shopping districts are located in Johnson County, such as Oak Park Mall, Town Center Plaza, and Prairie Fire.\\r\\n\\r\\nIn recent years, the Kansas City metropolitan area has been experiencing continued growth. Between July 2000 and July 2007, the population of the Kansas City MSA grew from 1,842,965 to an estimated 2,037,357, an increase of 10%.[1]\\r\\n\\r\\nThe MSA covers a total area of 7,952?sq?mi (20,600?km2) including 97?sq?mi (250?km2) of water.\\r\\n\\r\\nOften associated with Kansas City, the cities of Lawrence, Kansas, and St. Joseph, Missouri, are identified as separate Metropolitan Statistical Areas.[2]\\r\\n\\r\\nThe Kansas City-Overland Park-Kansas City, Missouri-Kansas Combined Statistical Area, which encompasses the Kansas City MO-KS MSA, the Warrensburg, Missouri Micropolitan Statistical Area (USA) (in Johnson County, Missouri), and the Atchison, Kansas SA (in Atchison County, Kansas), covers a total area of 9,220?sq?mi (23,900?km2) including 103?sq?mi (270?km2) of water.\\r\\n\\r\\nThe Kansas City metropolitan area has more freeway lane miles per capita than any other large metropolitan area in the United States (over 27% more than the second-place Dallas/Fort Worth Metroplex), over 50% more than the average American metro area, and nearly 75% more than the large metro area with the least: Las Vegas.[3]\\r\\n\\r\\nThe Kansas City area is a confluence of four major U.S. interstate highways:\\r\\n\\r\\nOther interstates that cross through the area include:\\r\\n\\r\\nU.S. Highways serving the Kansas City Metro Area include:\\r\\n\\r\\nKansas highways in the area include:\\r\\n\\r\\nMissouri highways in the area include:\\r\\n\\r\\nOther notable roads in the area are:\\r\\n\\r\\nThe Kansas City metropolitan area is served by several airports. It is primarily served by Kansas City International Airport, located 15 miles northwest of downtown Kansas City, Missouri, was built to serve as a world hub for the supersonic transport and Boeing 747. The airport's gates were positioned 100 feet (30?m) from the street; however, since the September 11, 2001 attacks, these have undergone expensive overhauls, retrofitting it to incorporate elements of conventional security systems.\\r\\n\\r\\nThe much smaller Charles B. Wheeler Downtown Airport, located to the immediate north of downtown near the Missouri River, was the original headquarters of Trans World Airlines (TWA) and houses the Airline History Museum. It served as the area's major airport until 1972, when Kansas City International (then known as Mid-Continent International Airport and was home to an Overhaul Base for TWA) became the primary airport for the metropolitan area after undergoing $150 million in upgrades that were approved by voters in a 1966 bond issue. Downtown Airport is still used to this day for general aviation and airshows.\\r\\n\\r\\nThere are two general aviation airports in Johnson County, Kansas.  New Century AirCenter borders southwest Olathe and northeast Gardner. The primary runway at New Century AirCenter is the second longest runway in the region next to those at Kansas City International Airport.   It is located 7 miles from the Logistics Park Kansas City Intermodal Facility. The other airport, Johnson County Executive Airport has one runway on 500 acres and is the fourth busiest towered airport in the state of Kansas.\\r\\n\\r\\nUnion Station serves as a hub for Amtrak, which maintains daily service by long-distance trains to and from Kansas City, Missouri.\\r\\n\\r\\nPublic transportation in the Kansas City area is only provided by city buses operated by the Kansas City Area Transportation Authority (KCATA). The Metro Area Express (MAX) went online as Kansas City, Missouri's first bus rapid transit line in July 2005, and operates and is marketed akin to a rail system as opposed to a local bus line; the MAX links the River Market, Downtown, Union Station, Crown Center and the Country Club Plaza.[4][5] Buses in Johnson County, Kansas, are operated by Johnson County Transit (known as \\"The JO\\").\\r\\n\\r\\nThe Kansas City Downtown Streetcar is a 2.2-mile modern streetcar line in downtown Kansas City opened to the public in May 2016, and is maintained and operated by the Kansas City Streetcar Authority, a non-profit corporation made up of private sector stakeholders and city appointees. A ballot initiative to fund construction of the $102 million line was approved by voters on December 12, 2012.[6] The system will run between River Market and Union Station, mostly on Main Street,[7] with extensions to the starter line planned for addition at a later date.\\r\\n\\r\\nSee related article: voy:Kansas City (Missouri) at Wikivoyage\\r\\n\\r\\nThe Missouri side of the metropolitan area shares a grid system with Johnson County on the Kansas side. Most east-west streets are numbered and most north-south streets named. Addresses on east-west streets are numbered from Main Street in Kansas City, Missouri, and on north-south streets from St. John Avenue (or the Missouri River, in the River Market area). The direction 'South' in street and address numbers is generally implied if 'North' is not specified, except for numbered 'avenues' in North Kansas City. In the northland, east-west streets use the prefix N.E. or N.W., depending on the side of N. Main on which they lie.\\r\\n\\r\\nThe Kansas City Star is the metropolitan area's major daily newspaper. The McClatchy Company, which owns The Star, is also the owner of two suburban weeklies, Lee's Summit Journal and Olathe Journal.\\r\\n\\r\\nThe Kansas City Kansan serves Wyandotte County, having moved from print to an online format in 2009. Additional weekly papers in the metropolitan area include the Liberty Tribune, Sun Newspapers of Johnson County, The Examiner in Independence and eastern Jackson County, The Pitch, and the Kansas-Missouri Sentinel. The area is also served by two newspapers focused the area's faith-based population: The Metro Voice Christian Newspaper and the Jewish Chronicle. The city's Hispanic and Latino American community is served by Dos Mundos, a bilingual newspaper with articles printed in Spanish and English, and Mi Raza magazine, the area's only weekly Hispanic publication printed in Spanish. The Kansas City Call serves the African American community publishing its paper weekly.\\r\\n\\r\\nAccording to Arbitron, about 1.5 million people over the age of 12 live within the Kansas City DMA, making it the 30th largest market for radio and 31st for television according to Nielsen. The Kansas City television and radio markets cover 32 counties encompassing northwestern Missouri and northeast Kansas.\\r\\n\\r\\nTelevision stations in the Kansas City metropolitan area, with all major network affiliates represented, include:\\r\\n\\r\\nThe Kansas City television market is in very close proximity to two other media markets, St. Joseph and Topeka. As such, most of the television stations in the Kansas City area are receivable over-the-air in portions of both markets, including their principal cities; likewise, stations from Topeka are receivable as far east as Kansas City, Kansas and stations from St. Joseph are viewable as far south as Kansas City, Missouri's immediate northern suburbs.\\r\\n\\r\\nOver 30 FM and 20 AM radio stations broadcast in the Kansas City area, with stations from Topeka, St. Joseph and Carrollton also reaching into the metropolitan area. The highest-rated radio stations, according to Arbitron are:\\r\\n\\r\\nHispanics, who account for 8% of the market's population, are specifically served by three AM radio stations who broadcast in Spanish:\\r\\n\\r\\nThe Kansas City metropolitan area's largest private employer is Cerner Corporation.[13] Cerner, a global healthcare IT company which is headquartered in North Kansas City, employs nearly 10,000 people in the area with a total workforce of nearly 20,000 people including global employees. In August 2014, the company announced its acquisition of competitor Siemens Healthcare, which, if approved, will further increase Cerner's total number of employees.[14] Cerner has several campuses across the area with its World Headquarters building in North Kansas City, Innovations Campus in South Kansas City, and Continuous Campus in the Kansas City, Kansas area.\\r\\n\\r\\nOther major employers and business enterprises are AT&T, BNSF Railway, Asurion, Sprint Corporation, Citigroup, EMBARQ, Farmers Insurance Group, Garmin, Hallmark Cards, Harley-Davidson, Husqvarna, H&R Block, General Motors, Honeywell, Ford Motor Company, MillerCoors, State Street Corporation, The Kansas City Star, and Waddell & Reed, some of which are headquartered in the metropolitan area. Kansas City also has a large pharmaceutical industry, with companies such as Bayer and Aventis having a large presence.\\r\\n\\r\\nThe following companies and organizations, excluding educational institutions, are among the larger ones that are currently headquartered in or have since relocated from the metropolitan area (headquarters of most companies are located in Kansas City, Missouri, unless otherwise noted):\\r\\n\\r\\nThe Kansas City Federal Reserve Bank is one of twelve such banks located in the United States.","input":"Which is bigger kansas city or st louis?"},{"output":"the world's first working railway suspension bridge","context":"The Niagara Falls Suspension Bridge, which stood from 1855 to 1897 across the Niagara River, was the world's first working railway suspension bridge. It spanned 825 feet (251?m) and stood 2.5 miles (4.0?km) downstream of Niagara Falls, where it connected Niagara Falls, Ontario, to Niagara Falls, New York. Trains used the upper of its two decks, pedestrians and carriages the lower. The brainchild of Canadian politicians, the bridge was built by one American and one Canadian company. It was most commonly called the Suspension Bridge; other names included Niagara Railway Suspension Bridge, Niagara Suspension Bridge, and its official American name, the International Suspension Bridge.\\r\\nThe bridge was part of Canadian politician William Hamilton Merritt's vision to promote trade within his country and with its neighbor the United States. Many, including bridge builders, argued that a suspension bridge could not allow the safe passage of trains. Nonetheless, the bridge companies hired Charles Ellet, Jr., who laid a line by a kite across the 800-foot (240?m) chasm and built a temporary suspension bridge in 1848. Ellet left the project after a financial dispute with the bridge companies, who hired John Augustus Roebling to complete the project. By 1854, his bridge was nearly complete, and the lower deck was opened for pedestrian and carriage travel. On March 18, 1855, a fully laden passenger train officially opened the completed bridge.\\r\\nA border crossing between Canada and the United States, the Suspension Bridge played significant roles in the histories of the Niagara region and the two countries. Three railway lines crossed over the bridge, connecting cities on both sides of the border. The Great Western Railway, New York Central Railroad, and New York and Erie Rail Road differed in the track gauge; the bridge used a triple gauge system to conserve space, overlapping two tracks on top of each other and using a rail of each to form the third track. The railroads brought a large influx of trade and tourists into the region around the Niagara Falls. In the time leading to the American Civil War, the Underground Railroad helped slaves in the United States escape across the Suspension Bridge to freedom in Canada. After the war, the bridge became a symbol of inspiration to Americans, encouraging them to rebuild their country and pushing them to quickly industrialize their nation.\\r\\nThe bridge's success proved that a railway suspension bridge could be safe and operational. Slowly decaying, the bridge's wooden structures were replaced with stronger steel and iron versions by 1886. Heavier trains required its replacement by the Steel Arch Bridge, later renamed the Whirlpool Rapids Bridge, on August 27, 1897.\\r\\n\\r\\n\\r\\nIn the mid-19th century, the hinterlands of the North American East Coast opened up rapidly.[1] In Canada, entrepreneur and politician William Hamilton Merritt helped establish several trade routes, especially in dredged waterways between the lake cities. He also envisioned a U.S. and Canadian rail network to connect the Atlantic coast with new territories in the West, and this led to a railway suspension bridge across the Niagara River below the falls.[2]\\r\\nMerritt's vision for the Niagara Suspension Bridge was conceived at the Niagara River itself.[nb 1] In summer 1844 while taking a picnic on the river shores, near what was then the town of Clifton, Merritt read a letter from his sons to his wife. The younger Merritts were touring Europe and visited the town of Fribourg, Switzerland. Amazed by the Freiburg Suspension Bridge,[4] they wrote to their parents, describing the wonders of the bridge in eloquent terms. Their writing had a profound effect on their parents, and the elder Merritts wondered if such a suspension bridge could be built across the Niagara.[5] Merritt was driven to realize that vision, and he approached the relevant authorities, including the Queen of England,[6] for permission to start the construction of the suspension bridge. His efforts were rewarded in 1846; the state of New York and the government of Canada approved the charters to form the Niagara Falls International Bridge Company and the Niagara Falls Suspension Bridge Company, respectively.[7]\\r\\nIn the years before the first bridge was built over the Niagara River, the river was crossed entirely by boats. Powered by steam engines, vessels ferried people and carriages across the raging river at calmer points of the water. One of these vessels was the Maid of the Mist, the first tourist boat to ply the waters of the Niagara River. Named after a local legend, the steamer began service in 1846.[8] Launching from a point 2 miles (3.2?km) below the Horseshoe Falls, it chugged up to the base of the falls, offering a close-up view of the natural wonder to its passengers, before moving to the opposite shore. The site for the Suspension Bridge was half a mile (0.8?km) from the Maid of the Mist's landings.[9] The selection of the bridge site was based more on aesthetics than technical ease; it was the narrowest point of the gorge800 feet (240?m) across and 230 feet (70?m) deepthat allowed a full view of the falls from the American side.[10][nb 2]\\r\\nAfter the bridge companies were founded, they invited engineers to submit plans and cost estimates for a suspension bridge that carried a railway. The invitation was met with skepticism among the engineering community. At that time, there was not a suspension bridge that could allow a train to pass over it safely.[12] While the Europeans were erecting suspension bridges by the hundreds,[13] the Americans mostly ignored them out of safety concerns; in 1831 Sir Samuel Brown's Broughton Suspension Bridge in Britain had collapsed under the marching feet of a troop of soldiers, sending those on its deck into the River Irwell.[14][nb 3] Furthermore, many American bridges had collapsed without experiencing weight and pressure equivalent to railroad traffic, and American engineers feared that any railway bridge would likely failespecially a suspension bridge.[16]\\r\\nFour engineers responded: Edward Serrell, Samuel Keefer, Charles Ellet, Jr., and John Augustus Roebling. All submitted designs for a suspension bridge. At the time of the bidding, Ellet and Roebling were acknowledged as masters of suspension bridge building in America. Roebling submitted two designs, a conservative single-deck suspension bridge and a double-decked version,[17] both with meticulous calculations and drawings. Instead of relying solely on submissions, Charles Ellet, Jr. took a proactive approach. When he got wind of the project in 1845, he wrote to Charles B. Stuart, chief engineer of the Great Western Railway,[nb 4] boldly proclaiming that he could build a bridge for any likely purpose across the Niagara. After the charters had been obtained, Ellet helped Stuart to sell the bridge companies' stock and offered to buy US$30,000[nb 5] worth of stock himself. His efforts earned him the $190,000 bridge contract on November 9, 1847.[19]\\r\\nWhile growing up on a farm in Pennsylvania, Charles Ellet, Jr. scraped through odd jobs, but saved enough money to finance an education at the cole nationale des Ponts et Chausses in France.[20] After attending four months of lectures, he toured Europe before returning to the United States as the only native-born American with European education in engineering. Ellet announced his ambitions to build suspension bridges in his country of birth by proposing to span the Potomac River with one. His proposal was ignored; few were willing to heed a young, inexperienced and impetuous engineer.[21] To gain experience, Ellet started to work on railroads and canals, and later became the chief engineer on the James River and Kanawha Canal project. He further improved his reputation by contributing articles about suspension bridges to respected engineering journals, such as American Railroad Journal; eventually, Ellet built his first suspension bridge over the Schuylkill River, Pennsylvania, in 1842.[22]\\r\\nEllet had the looks of an actor,[23] which were complemented by his entertaining oratorical skills.[16] He took advantage of these characteristics, and used showmanship and dramatics to market his proposals. These skills helped to win him attention and raise his profile both in the public and within the industry. However, his imperiousness also ruffled the feathers of people, which caused conflicts.[24] Nonetheless, his capability to promote himself had won him the contracts for the Suspension Bridge and the later Wheeling Suspension Bridge; the Wheeling contract was won in July 1847 while Ellet's plan for the Niagara Suspension Bridge was still in its initial stages of construction. Ellet's initial design for the bridge at Niagara placed all forms of transportation on a single deck. The railway track was in the middle of the deck, sandwiched between carriageways and footpaths on the outer sides.[25] Moreover, trains would not go over the bridge; their cars would be disconnected from the heavy locomotives and pulled across the bridge by horses, cables, or lighter 6-short-ton (5.4?t) engines.[26] Before the work could begin, Ellet faced the problem of all suspension bridge construction: getting a line across the gap.\\r\\nEllet's brainstorming sessions with his men raised several ideas that could enable a line to be suspended across the gorge; these included firing cannonballs with the line attached, towing it across the river with a steamer, and tying it to a rocket that would then be launched across the gorge. Ultimately the bridge engineer chose an idea inspired by Benjamin Franklin's experiment with a kite.[27] It was similar to 15th century inventor Leonardo da Vinci's plan to span a gap.[28] Ellet also took the opportunity to generate publicity for his project. Organizing a kite-flying contest, he offered $5[nb 6] to any boy who flew a kite across the gorge and secured the kite string to the other side.[23] Youths from nearby towns flocked in to participate. Unlike the other boys who flew their kites from the United States side of the gorge, 16-year-old Homan Walsh[nb 7] crossed the river by a ferry upstream and walked to the Canadian side of the bridge site to launch his kite. He almost succeeded on his first attempt; his kite flew across but crashed just short of the shore. After resting several days at a friend's house, Walsh finally got his kite across the gorge and secured its line to a tree.[30]\\r\\nCharles Ellet and his team tied a heavier line to the kite string and pulled the joined lines across. They pulled successive heavier and stronger lines across until the final bridge cable7?8 inch (2.2?cm) thickwas hanging across the gorge. The cable was suspended between two wooden towers 40 feet (12?m) tall, and it was attached to an iron basket. Ellet planned to use this system as a basket ferry to shuttle workers and materials across the gorge, saving time that would otherwise have been spent on land and ferry travel.[31] Through media coverage and word-of-mouth, many people knew of Ellet's efforts and flocked to the site to watch the construction. On March 13, 1848, the system was completed, and the team planned to test it by pulling the empty basket across. They hit a snag when the basket kept getting stuck halfway and could not move ahead. Pulling back the basket, Ellet decided to assure the watching crowd that the system was workable. He stepped into the basket, and it moved towards the opposite shore. When Ellet reached the problematic spot, he spotted the issue; the basket's rollers could not pass over a portion of the cable that had been accidentally flattened during the construction.[32] He fixed the problem and proceeded to cross to the Canadian side and back, becoming the first person to cross the gorge.[33] Although the bridge companies had prohibited Ellet from collecting tolls, he charged each person $1.00[nb 8] for the chance to \\"observe first hand the engineering wonder of bridging the Niagara\\".[30] On some days, the basket ferry conveyed up to 125 people across the gorge.[34]\\r\\nContinuing his construction, Ellet built two footbridges and joined them together to form an 8-foot (2.4?m) wide suspension bridge. He intended to use this temporary bridge as a scaffold for the construction of the permanent railway bridge.[36] On July 29, 1848, the bridge builder inaugurated the span in his typical manner; standing in his horse-buggy like a gladiator in his chariot, Ellet sped across the bridge, which had railings for only a third of its length at that time. His stunt garnered further publicity for the bridge, and the toll collected from the span proved lucrative; $5,000 was collected in less than a year since its official opening on August 1, 1848. Disputes arose between the bridge companies and Ellet over their shares of the money, and their relations turned bitter. The companies charged that Ellet was late in his schedule and withheld payment. Ellet retaliated by mounting cannons at the bridge to claim ownership over it. In the end the matter went to court. The bridge companies paid $10,000 to Charles Ellet, and he left the project to work full-time on the Wheeling Suspension Bridge.[37]\\r\\nThe Niagara Suspension Bridge project was in hiatus for three years before the bridge companies engaged another renowned civil engineer, John Augustus Roebling, to complete it. The delay caused Roebling to miss out on the honor of building the first permanent bridge to span the Niagara; Serrell completed the Lewiston Suspension Bridge in 1851.[38] Roebling would, however, achieve other honors in building his Niagara Railway Suspension Bridge.[39]\\r\\nBorn in Prussia (later a part of Germany), John Augustus Roebling obtained his first conditional engineering degree (Feldmesserprfung) at Erfurt in 1824. He attended two semesters of lessons at Berlin's Bauakademie and worked for the Prussian government, constructing military roads.[40] Tired of the bureaucracy, he resigned his position and left for the United States in 1830, arriving with his brother in Philadelphia on August 6, 1831. Instead of continuing an engineering profession, he took up farming for a living. After five years he married a tailor's daughter, and had eight children with her over the next decade. Agrarian work was unsatisfactory to John Roebling, and in 1837, after the death of his brother and the birth of his first child, he returned to engineering.[41]\\r\\nRoebling first signed on as a surveyor for the Beaver River canal system, launching his career with a string of canal and railroad projects.[42] Aside from writing articles in engineering journals, Roebling designed his own wire cables[43] and started his own company to manufacture them; the John A. Roebling Company was the first wire rope manufacturer in the United States.[44] Gradually gaining fame for his civil engineering,[45] Roebling finally got to build suspension bridges.[43] His first bridge was the Allegheny Suspension Aqueduct in Pittsburgh. The structure, completed in 1845, was the first suspension aqueduct in the world and the first large American suspension bridge that had multiple spans. Furthermore, it was the first suspension structure built with modern cable spinning techniquesRoebling's own invention.[46] Earlier bridge building techniques involved fabricating the main cables at a factory, transporting them to the bridge site, and then stretching the heavy cables over the gap to erect them over the bridge. Roebling, during his experiments with wire ropes, conceived and patented a new construction method for these main cables. A long linethe traveler ropeformed a loop around two horizontal wheels, one on each side of the gorge. A lightweight wheel, \\"the traveling wheel\\", was attached to this line, and a wire threaded around this wheel. Like a belt in a mechanical system, the traveler rope and its wheel moved across the gap as the horizontal wheels turned, pulling the wire along. The traveling wheel effectively hauled two lengths of the same wire (running above and under the traveling wheel) across the gap at a time. The lengths of wire were collected and bound at intervals to form thicker strands, which were later compressed together into the main cables.[47] which supported themselves and later the proportional weight of the bridge as they were formed.[48] The method became the standard for suspension bridge construction, and remained unchanged for many years. In the 20th century, suspension bridges were still built with this pulley winding system, albeit with more sophisticated equipment.[49]\\r\\nJohn Roebling was a contrasting character to Charles Ellet. Whereas Ellet embellished his proposals with fanciful words and deeds, Roebling presented papers filled with meticulous calculations and drawings.[33] The elder engineer was stern and driven to achieve, taking a scientific approach to all interests.[46] Rarely did he show emotions in his dealings, even to his closest associates.[50] The man, however, dared to confront his detractors and make bold exaltations about his work. He openly called European suspension bridgesincluding American suspension bridges built with European techniquesweak, and occasionally sniped at Ellet's and Stephenson's works.[51][52] He announced that his Brooklyn Bridge, when completed, \\"will not only be the greatest bridge in existence, but it will be the greatest engineering work of this continent, and of the age.\\"[39] Roebling's history with Ellet started before the bidding for the Niagara Suspension Bridge, early in their careers. During the bidding for the Schuylkill Suspension Bridge project, Ellet had written a proposal that was published in the American Railroad Journal. Mistakenly believing Ellet had won the contract, Roebling wrote to offer his congratulations and requested to be Ellet's assistant. He received a formal reply without any reference to his request, and his subsequent letter was ignored.[23] When Roebling learned that a contractor had won the bid, he successfully applied to be the contractor's chief engineer. Ellet, however, persisted with his tactics and snatched the project away from the contractor; he promoted himself to the bridge company and offered to accept land instead of cash as payment. From then on, Ellet and Roebling became rivals, vying with each other for suspension bridge projects in North America. Roebling learned from their rivalry. His losses to Ellet showed him that he needed to promote himself and gain backers to effectively secure the contracts he desired.[53]\\r\\nWhen Roebling was called to the Niagara Suspension Bridge project in 1851, he had six suspension structures to his name.[54] He found Ellet's final plan to be impractical; the bridge would have been too heavy and expensive.[55] Roebling had another design in mind: the double-deck bridge he had proposed earlier during the bidding.[nb 9] The lower deck, level with the edge of the chasm, would convey passengers and carriages, and the upper deck, 18 feet (5.5?m) above, would allow fully laden trains to continue their journeys non-stop,[57] albeit at a speed of 5 miles per hour (8.0?km/h). Roebling reasoned that the decks and sufficient trusses would form a rigid tube, making the bridge stiffer than a normal suspension bridge. The theory was similar to that of the tubular bridge but implemented at a lower cost.[58] The engineering community was critical of Roebling's project. Robert Stephenson, builder of the tubular Britannia Bridge, was among those short-listed to complete the Niagara Suspension Bridge before Roebling's selection. Stephenson had submitted a design for a tubular bridge, and in 1859 he built a large and expensive tubular bridge for the Grand Trunk Railway at Montreal, Quebec. The bridge builder then said in derision of Roebling's suspension railway, \\"If your bridge succeeds, mine is a magnificent blunder.\\"[59]\\r\\nIn the face of criticism, Roebling completed the project in four years, using Ellet's bridge as scaffolding. The railway deck was stress-tested by the crossing of the 23-short-ton (21?t) steam engine London at a speed of 8 miles per hour (13?km/h) on March 8, 1855.[30] Ten days later the upper deck of the bridge was officially opened;[60] the lower deck had been opened to the public a year earlier.[26] As the first commercial passenger train trundled over the bridge, the two countries were finally connected by railroad across the Niagara River. The successful crossings of these and later trains made Roebling's Suspension Bridge the first working suspension railway bridge in history.[39][nb 10]\\r\\nRoebling's bridge was supported by two limestone towers on each side of the gorge. These Egyptian-style towers[62] stood 88 feet (27?m) tall on the American shore and 78 feet (24?m) tall on the Canadian shore.[63] With their foundations 28 feet (8.5?m) in the earth, the limestone structures could support up to 12?million?pounds (5.4?million?kg).[56] Four 10.5-inch (27?cm) thick main cables held up the bridge; two cables ran through iron saddles at the top of each tower. Each cable comprised 3,059 wires that were spun with Roebling's patented technique used in his Allegheny Suspension Aqueduct. The ends of each cable were secured to 6-square-foot (0.56?m2) cast-iron plates sunk 20ÿ30 feet (6.1ÿ9.1?m) deep in the bedrock.[64] Support lines hung down from iron clamps that encircled the main cables, and held up the decks. Deep trussesnever before seen on a large suspension bridge[nb 11]lined the sides of the bridge, and joined the two decks so that the structure looked like a cage.[66] The trussed sides and the upper and lower decks, which spanned 825 feet (251?m),[nb 12] formed a \\"hollow straight beam\\", reinforcing the rigidity of the bridge.[55]\\r\\nThe Suspension Bridge was further stiffened by guy-wires which ran from its upper deck to the top of its towers. Criticism of suspension bridges was growing after the Wheeling Suspension Bridge collapsed under strong winds in 1854. To address these concerns, Roebling added more guy-wires to secure the lower deck to the shores below.[62] Roebling's efforts ensured that his Suspension Bridge remained standing while other suspension bridges across the Niagara River collapsed because of strong winds.[nb 13] Although he was not the first engineer to appreciate the need for a suspension bridge to be sufficiently rigid or to implement the methods to do so, Roebling was the first to understand the principles behind the methods and combine them in the building of a suspension bridge.[56] Roebling proved that despite popular opinion, properly built suspension bridges can safely support the passage of heavy railway traffic. The engineer's combination of stiffening methods created the first modern suspension bridge.[68] Such was the rigidity of the Suspension Bridge that it withstood the shockwave caused by the nearby fall of a 5,000-short-ton (4,500?t) mass of rock in 1863; the force of the impact manifested itself as a wave, rippling through the decks of the bridge from the American side to the Canadian side and back.[69]\\r\\nFrom the United States, the New York and Erie Rail Road's Canandaigua and Niagara Falls Railroad and New York Central Railroad's Buffalo and Niagara Falls Railroad crossed over the bridge and reached into Ontario. Similarly, the Great Western Railway in Canada extended its network from Canada into New York. At the time of the bridge's opening, the three railroads were of different gauges: 4?ft?8?1?2?in (1,435?mm) standard gauge on the New York Central, 5?ft?6?in (1,676?mm) on the Great Western, and 6?ft (1,829?mm) on the Erie.[70] Instead of accommodating three railways side-by-side on a single wide deck, the bridge saved space by overlapping the tracks over each other. This method used only four rails; one pair formed the track for one railway, and the other pair formed another. One rail from each pair would then form the final track.[64] In the first year of the bridge's operation, an average of 30 trains trundled across it each day.[71] Five years later, 45 trains passed over the structure daily.[72]\\r\\nRoebling mandated that the trains be limited to a maximum speed of 5 miles per hour (8.0?km/h) to ensure absolute safety. He was confident the bridge could handle faster train traffic, but he preferred a safe operation.[73] In his tests the bridge supported a 326-short-ton (296?t) train, bending 10.5 inches (27?cm) under the weight.[74] This was within the maximum load of 450 short tons (410?t) specified in the design of the bridge.[nb 14] The figure was a conservative estimate.[62] The cables and guy-wires could support 7,300 short tons (6,600?t),[64] and travel journalist Alfred J. Pairpoint commented that it was normal to see 1,200-short-ton (1,100?t) trains pass over the bridge without danger.[75] The bridge shook whenever a train trundled over it, although this had no effect on its integrity. When the frequency of passing trains was high, the trembling was noticeable to travelers on the lower deck and proved uncomfortable to some; writer Mark Twain noted, \\"You drive over to Suspension Bridge and divide your misery between the chances of smashing down two hundred feet into the river below, and the chances of having a railway-train overhead smashing down onto you. Either possibility is discomforting taken by itself, but, mixed together, they amount in the aggregate to positive unhappiness.\\"[38] Despite such commentaries, thousands of people crossed over the bridge safely every day.[64]\\r\\nAmerican engineers regard the Suspension Bridge as a major achievement of efficiency. In a fledgling country where resourcesmaterial and financialwere limited, they had to make do with whatever was available. This goal was espoused by the American Society of Civil Engineers, which opined, \\"That is the best engineering, not which makes the most splendid, or even the most perfect work, but that which makes a work that answers the purpose well, at the least cost.\\" Roebling had built a bridge that rivaled grander bridges of leading European nations at a much lower cost.[76] His Suspension Bridge used only one-sixth the material of Stephenson's Brittania Bridge, but was twice as long and had a capacity that exceeded the tubular bridge.[77] Moreover, the expenditure on Roebling's Suspension Bridge was $400,000, whereas a tubular bridge of equivalent length and load-bearing capability would have cost $4?million.[76] Roebling's success established him as the master of suspension bridges. The inclined guy-wires that stretched from the top of towers to the roadway of the Suspension Bridge became the signature of his future works.[78]\\r\\nAlthough the Suspension Bridge proved that the suspension system could be safely used to carry railroads, no more suspension railway bridges were built. The outbreak of the American Civil War diverted attention from such civil engineering ventures,[79] and by the time attention was paid to building bridges again, cantilever bridges were in vogue for railway bridges.[80] Regardless, the Suspension Bridge's success made it a model for suspension railway bridges. When the city of Quebec called for a structure to span the St. Lawrence River in 1850, it looked to the Suspension Bridge for inspiration.[81] Seventeen years later, the British journal Engineering called for a suspension railway to bridge the Straits of Messina and also referred to Roebling's bridge.[82] Lastly, Stuart opened his 1871 work on the history of American engineering, Lives and Works of Civil and Military Engineering in America, with an illustration of the bridge.[76]\\r\\nAs a border crossing between two large growing countries, the Suspension Bridge had throngs of travelers passing over it. Furthermore, it was the intersection of three major railroads. Coupled with its vicinity to a natural wonder, the Niagara Falls, the bridge brought a lot of railroad traffic into the region once it was opened. The towns at the ends of the bridge benefited greatly from this heavy movement of people and goods. The village of Suspension Bridge, United States, grew quickly within a few years after the opening of the bridge, acquiring shops, factories, and a hotel. Its tourism and commerce soon rivaled the town of Niagara Falls, New York;[83] eventually, the village was merged into the town in 1892. Similarly, Clifton on the Canadian end of the bridge was integrated into the town of Niagara Falls, Ontario.[84] The two Niagara Falls cities boasted commerce that surpassed neighboring settlements. Around the time of its official opening, the bridge was one of the busiest points of trade on the United StatesÿCanada border, carrying $12?million of transitory goods and $2?million of bonded materials into Canada.[64] To handle the large amount of goods exchanged over the border, the Lewiston customs housethe primary customs for the Niagara regionwas relocated to the Niagara Suspension Bridge in 1863.[85][nb 15]\\r\\nThe bridge's depiction as an engineering marvel and beautiful sight lured many visitors to the Falls. Travelers could, while crossing the bridge, enjoy a view of the Falls enhanced by the sensation of standing 250 feet (76?m) in the air. The Falls, however, proved distant and indistinct to some when there was overcast weather. On the whole, the Suspension Bridge was considered as an attraction that must be seen by visitors to Niagara Falls.[88] In paintings and prints of the bridge, the Suspension Bridge became the focus, pushing the Falls into the background. Unlike paintings of the Falls that capture the viewer's eye with their majestic views of the natural wonder, pictures of the bridge impressed viewers with the utilitarian design of the structure.[89] By 1897, the inbound trains to Niagara Falls brought 276,900 visitors during the months of May to August.[90] A streetcar system was established in 1882 to handle the increasing cross-border pedestrian traffic. Initially pulled by horses, the trolleys were converted to run on electricity in 1892.[91] The Suspension Bridge was the pride and symbol of the Great Western Railway,[92] which touted it as the \\"only Route via Niagara Falls & Suspension Bridge\\".[nb 16]\\r\\nTravelers on the Suspension Bridge witnessed several death-defying stunts performed across the Niagara Gorge. On June 30, 1859, they saw Charles Blondin's feat of becoming the first man to cross the chasm on a tightrope.[93] In mid-crossing Blondin sat down on the rope and lowered a line to retrieve a drink from the deck of the Maid of the Mist below.[94] In his later tightrope acts at the same spot, the acrobat would perform a different stunt on each occasion. One time he cooked and ate an omelette in mid-crossing; another time he carried his manager Harry Colcord on his back. While giving Colcord a piggyback ride, Blondin stopped five times on the tightrope to rest and recover his strength; each time Colcord gingerly got off Blondin's back and stood on the tightrope, climbing back on after the acrobat had enough rest.[95] Blondin's success inspired other acrobats, such as William Leonard Hunt (\\"The Great Farini\\"), Samuel Dixon, Clifford Calverly, and Signorina Maria Spelterini, to emulate and try to surpass his acts at the same spot. The Signorina, the only woman to walk across the Niagara on a tightrope, once crossed while blindfolded and another time with her hands and legs in manacles.[96]\\r\\nAnother group of people in America had their own risky crossings over the Niagara Gorge as they fled over the border into Canada. They were enslaved African-Americans who sought freedom by escaping to a country that declared the liberation of any slave who entered it.[97] The bridge was part of the Underground Railroad, a network of routes designed to smuggle slaves in the United States to freedom in Canada. Before the American Civil War, fleeing slaves had only four main routes into Canada, of which one was crossing the Niagara River.[98] Slaves who escaped along the Niagara route had help from several quarters. The state of New York generally favored granting freedom to slaves; this attitude emboldened African-American workers in Niagara, who frequently helped slaves flee to Canada. Before the Suspension Bridge was completed, fugitives either crossed the raging river on a boat or risked their lives by swimming at calmer points of the river. The Suspension Bridge made escape across the river easier and safer, although there was still risk. To avoid getting caught and sent back to their owners, slaves had to sneak across on foot or hide aboard trains and oxcarts.[99] Antislavery activist Harriet Tubman guided fugitives at night and bribed custom officials to turn a blind eye.[100] As a result, many slaves crossed the Suspension Bridge to freedom before the United States was engulfed in civil war.[101]\\r\\nWhen the war ended and the United States turned its focus toward rebuilding, Roebling started building his Brooklyn Bridge. As the monumental task could affect naval navigation, it required state approval, and the government wanted a thorough review of the engineer's credentials; hence, a Bridge Party was organized. Comprising Roebling and his son, as well as their fellow bridge engineers, generals, businessmen, and high society figures, the party toured the country to review four bridges Roebling had built before the civil war.[102] The final item on their itinerary was Roebling's Niagara Suspension Bridge. At the dinner to commemorate the end of the bridge tour, civil war veteran General Henry Warner Slocum gave a toast and called the Suspension Bridge a symbol of inspiration for the United States in its rebuilding efforts. This sentiment was shared by the guests and was expressed at later dinners across the United States.[103] The achievement of building a large suspension bridge over a gorge in the face of overwhelming adversityconstant put-downs by the professional community, American and Europeangave the United States a sense of pride. Nationalism rose as the country lauded the bridge. The completion of the bridge that had been deemed impossible by the Western world gave Americans, who had lesser technical accomplishments than Europe at that time, a trophy that stood above any other.[104] The Suspension Bridge became the American symbol to brave the toughest of challenges and do the impossible, pushing their drive for industrialization even harder. Charles W. Woodman specifically drew attention to the Suspension Bridge in his 1865 address to the United States Senate for approval to build a rail system to transport a ship out of the water and up around the Niagara Falls.[76]\\r\\nBudget concerns forced Roebling to build the Suspension Bridge primarily with wood;[66] the cost of casting the components out of iron and transporting them \\"[way] out West\\" was exorbitant.[34] The organic material decayed and rotted because of the moisture present around Niagara Falls. As the industrialization of the United States moved forward rapidly, the introduction of the Bessemer process greatly lowered the cost of the more durable steel and iron.[105] By 1880, the Suspension Bridge's wooden trusses, beams, and flooring were replaced with steel.[106] The wire cables were not replaced; their cores were still in pristine condition. The outer layer of wires in the cables was, however, lightly corroded and had to be replaced.[107] Due to severe deterioration, the limestone towers were replaced in 1886 with steel framed versions.[26] These renovations increased the bridge's strength and helped it handle heavier loads for a few more years.[44]\\r\\nThe weight of trains in North America had greatly increased by the mid-1890s. Larger and more powerful locomotives were required to pull cars that handled an increasing number of passengers and goods; compared to the 23-short-ton (21?t) locomotives crossing the bridge in the 1850s, 170-short-ton (150?t) locomotives were the common engines 40?years later.[90] The weight of these trains exceeded the specifications of the Suspension Bridge, and the bridge companies took the opportunity to review and request the replacement of the bridge. Civil engineer Leffert L. Buck, who had been hired to maintain the Suspension Bridge, was selected to design the replacement bridge. He settled for a bridge of the arch design. At that time, arch bridges were the new models for railway bridges and were more cost-efficient than suspension bridges. Buck built the new bridge around and below the Suspension Bridge, replacing it a piece at a time. His plan allowed bridge traffictrain and pedestrianto continue without disruption.[80] By August 27, 1897, the last pieces of the Suspension Bridge were dismantled, leaving the Lower Steel Arch Bridgelater renamed the Whirlpool Rapids Bridgein its stead.[34] On inspection, the cores of the cables that formerly held up the Suspension Bridge were found to be as sound as on the day the bridge was built.[56]\\r\\nPrimary sources\\r\\nSecondary sources","input":"What kind of bridge is the niagara falls bridge?"},{"output":"The Battle of Bunker Hill","context":" United Colonies\\r\\n William Prescott\\r\\n Israel Putnam\\r\\n Joseph Warren??\\r\\n William Howe\\r\\n Thomas Gage\\r\\n Sir Robert Pigot\\r\\n James Abercrombie??\\r\\n Henry Clinton\\r\\n Samuel Graves\\r\\nThe Battle of Bunker Hill was fought on June 17, 1775, during the Siege of Boston in the early stages of the American Revolutionary War. The battle is named after Bunker Hill in Charlestown, Massachusetts, which was peripherally involved in the battle. It was the original objective of both the colonial and British troops, though the majority of combat took place on the adjacent hill which later became known as Breed's Hill.[7][8]\\r\\nOn June 13, 1775, the leaders of the colonial forces besieging Boston learned that the British were planning to send troops out from the city to fortify the unoccupied hills surrounding the city, which would give them control of Boston Harbor. In response, 1,200 colonial troops under the command of William Prescott stealthily occupied Bunker Hill and Breed's Hill. During the night, the colonists constructed a strong redoubt on Breed's Hill, as well as smaller fortified lines across the Charlestown Peninsula.[9]\\r\\nBy daybreak of June 17, the British became aware of the presence of colonial forces on the Peninsula and mounted an attack against them that day. Two assaults on the colonial positions were repulsed with significant British casualties; the third and final attack carried the redoubt after the defenders ran out of ammunition. The colonists retreated to Cambridge over Bunker Hill, leaving the British in control of the Peninsula.[10]\\r\\nThe battle was a tactical, though somewhat Pyrrhic victory for the British, as it proved to be a sobering experience for them, involving many more casualties than the Americans had incurred, including a large number of officers. The battle had demonstrated that inexperienced militia were able to stand up to regular army troops in battle. Subsequently, the battle discouraged the British from any further frontal attacks against well defended front lines. American casualties were comparatively much fewer, although their losses included General Joseph Warren and Major Andrew McClary, the final casualty of the battle.[11]\\r\\nThe battle led the British to adopt a more cautious planning and maneuver execution in future engagements, which was evident in the subsequent New York and New Jersey campaign, and arguably helped rather than hindered the American forces. Their new approach to battle was actually giving the Americans greater opportunity to retreat if defeat was imminent. The costly engagement also convinced the British of the need to hire substantial numbers of foreign mercenaries to bolster their strength in the face of the new and formidable Continental Army.\\r\\n\\r\\n\\r\\nBoston, situated on a peninsula,[12] was largely protected from close approach by the expanses of water surrounding it, which were dominated by British warships. In the aftermath of the battles of Lexington and Concord on April 19, 1775, the colonial militia, a force of about 15,000 men[13] had surrounded the town, and effectively besieged it. Under the command of Artemas Ward, they controlled the only land access to Boston itself (the Roxbury Neck), but, lacking a navy, were unable to even contest British domination of the waters of the harbor. The British troops, a force of about 6,000 under the command of General Thomas Gage, occupied the city, and were able to be resupplied and reinforced by sea.[14] In theory, they were thus able to remain in Boston indefinitely.\\r\\nHowever, the land across the water from Boston contained a number of hills, which could be used to advantage.[15] If the militia could obtain enough artillery pieces, these could be placed on the hills and used to bombard the city until the occupying army evacuated it or surrendered. It was with this in mind that the Knox Expedition, led by Henry Knox, later transported cannon from Fort Ticonderoga to the Boston area.[16]\\r\\nThe Charlestown Peninsula, lying to the north of Boston, started from a short, narrow isthmus (known as the Charlestown Neck) at its northwest and extended about 1 mile (1.6?km) southeastward into Boston Harbor. Bunker Hill, with an elevation of 110 feet (34?m), lay at the northern end of the peninsula. Breed's Hill, at a height of 62 feet (19?m), was more southerly and nearer to Boston.[17] The town of Charlestown occupied flats at the southern end of the peninsula. At its closest approach, less than 1,000 feet (305?m) separated the Charlestown Peninsula from the Boston Peninsula, where Copp's Hill was at about the same height as Breed's Hill. While the British retreat from Concord had ended in Charlestown, General Gage, rather than immediately fortifying the hills on the peninsula, had withdrawn those troops to Boston the day after that battle, turning the entire Charlestown Peninsula into a no man's land.[18]\\r\\nThroughout May, in response to orders from Gage requesting support, the British received reinforcements, until they reached a strength of about 6,000 men. On May 25, three generals arrived on HMS?Cerberus: William Howe, John Burgoyne, and Henry Clinton. Gage began planning with them to break out of the city,[19] finalizing a plan on June 12.[20] This plan began with the taking of the Dorchester Neck, fortifying the Dorchester Heights, and then marching on the colonial forces stationed in Roxbury. Once the southern flank had been secured, the Charlestown heights would be taken, and the forces in Cambridge driven away. The attack was set for June 18.[21]\\r\\nOn June 13, the Massachusetts Provincial Congress was notified, by express messenger from the Committee of Safety in Exeter, New Hampshire, that a New Hampshire gentleman \\"of undoubted veracity\\" had, while visiting Boston, overheard the British commanders making plans to capture Dorchester and Charlestown.[22] On June 15, the Massachusetts Committee of Safety decided that additional defenses needed to be erected.[23] General Ward directed General Israel Putnam to set up defenses on the Charlestown Peninsula, specifically on Bunker Hill.[24][25]\\r\\nOn the night of June 16, colonial Colonel William Prescott led about 1,200 men onto the peninsula in order to set up positions from which artillery fire could be directed into Boston.[26] This force was made up of men from the regiments of Prescott, Putnam (the unit was commanded by Thomas Knowlton), James Frye, and Ebenezer Bridge.[27] At first, Putnam, Prescott, and their engineer, Captain Richard Gridley, disagreed as to where they should locate their defense. Some work was performed on Bunker Hill, but Breed's Hill was closer to Boston and viewed as being more defensible. Arguably against orders, they decided to build their primary redoubt there.[28] Prescott and his men, using Gridley's outline, began digging a square fortification about 130 feet (40?m) on a side with ditches and earthen walls. The walls of the redoubt were about 6 feet (1.8?m) high, with a wooden platform inside on which men could stand and fire over the walls.[29][30]\\r\\nThe works on Breed's Hill did not go unnoticed by the British. General Clinton, out on reconnaissance that night, was aware of them, and tried to convince Gage and Howe that they needed to prepare to attack the position at daylight. British sentries were also aware of the activity, but most apparently did not think it cause for alarm.[31] Then, in the early predawn, around 4?a.m., a sentry on board HMS?Lively spotted the new fortification, and notified her captain. Lively opened fire, temporarily halting the colonists' work. Aboard his flagship HMS?Somerset, Admiral Samuel Graves awoke, irritated by the gunfire that he had not ordered.[32] He stopped it, only to have General Gage countermand his decision when he became fully aware of the situation in the morning. He ordered all 128 guns in the harbor, as well as batteries atop Copp's Hill in Boston, to fire on the colonial position, which had relatively little effect.[33] The rising sun also alerted Prescott to a significant problem with the location of the redoubt ÿ it could easily be flanked on either side.[31] He promptly ordered his men to begin constructing a breastwork running down the hill to the east, deciding he did not have the manpower to also build additional defenses to the west of the redoubt.[34]\\r\\nWhen the British generals met to discuss their options, General Clinton, who had urged an attack as early as possible, preferred an attack beginning from the Charlestown Neck that would cut off the colonists' retreat, reducing the process of capturing the new redoubt to one of starving out its occupants. However, he was outvoted by the other three generals. Howe, who was the senior officer present and would lead the assault, was of the opinion that the hill was \\"open and easy of ascent and in short would be easily carried.\\"[35] General Burgoyne concurred, arguing that the \\"untrained rabble\\" would be no match for their \\"trained troops\\".[36] Orders were then issued to prepare the expedition.[37]\\r\\nWhen General Gage surveyed the works from Boston with his staff, Loyalist Abijah Willard recognized his brother-in-law Colonel Prescott. \\"Will he fight?\\" asked Gage. \\"[A]s to his men, I cannot answer for them;\\" replied Willard, \\"but Colonel Prescott will fight you to the gates of hell.\\"[38] Prescott lived up to Willard's word, but his men were not so resolute. When the colonists suffered their first casualty, Asa Pollard of Billerica,[39] a young private killed by cannon fire, Prescott gave orders to bury the man quickly and quietly, but a large group of men gave him a solemn funeral instead, with several deserting shortly thereafter.[38]\\r\\nIt took six hours for the British to organize an infantry force and to gather up and inspect the men on parade. General Howe was to lead the major assault, drive around the colonial left flank, and take them from the rear. Brigadier General Robert Pigot on the British left flank would lead the direct assault on the redoubt, and Major John Pitcairn led the flank or reserve force. It took several trips in longboats to transport Howe's initial forces (consisting of about 1,500 men) to the eastern corner of the peninsula, known as Moulton's Point.[40][41] By 2?p.m., Howe's chosen force had landed.[40] However, while crossing the river, Howe noted the large number of colonial troops on top of Bunker Hill. Believing these to be reinforcements, he immediately sent a message to Gage, requesting additional troops. He then ordered some of the light infantry to take a forward position along the eastern side of the peninsula, alerting the colonists to his intended course of action. The troops then sat down to eat while they waited for the reinforcements.[41]\\r\\nPrescott, seeing the British preparations, called for reinforcements. Among the reinforcements were Joseph Warren, the popular young leader of the Massachusetts Committee of Safety, and Seth Pomeroy, an aging Massachusetts militia leader. Both of these men held commissions of rank, but chose to serve as infantry.[40] Prescott ordered the Connecticut men under Captain Knowlton to defend the left flank, where they used a crude dirt wall as a breastwork, and topped it with fence rails and hay. They also constructed three small v-shaped trenches between this dirt wall and Prescott's breastwork. Troops that arrived to reinforce this flank position included about 200 men from the 1st and 3rd New Hampshire regiments, under Colonels John Stark and James Reed. Stark's men, who did not arrive until after Howe landed his forces (and thus filled a gap in the defense that Howe could have taken advantage of, had he pressed his attack sooner),[42] took positions along the breastwork on the northern end of the colonial position. When low tide opened a gap along the Mystic River to the north, they quickly extended the fence with a short stone wall to the water's edge.[42][43] Colonel Stark placed a stake about 100 feet (30?m) in front of the fence and ordered that no one fire until the regulars passed it.[44] Just prior to the action, further reinforcements arrived, including portions of Massachusetts regiments of Colonels Brewer, Nixon, Woodbridge, Little, and Major Moore, as well as Callender's company of artillery.[45]\\r\\nBehind the colonial lines, confusion reigned. Many units sent toward the action stopped before crossing the Charlestown Neck from Cambridge, which was under constant fire from gun batteries to the south. Others reached Bunker Hill, but then, uncertain about where to go from there, milled around. One commentator wrote of the scene that \\"it appears to me there never was more confusion and less command.\\"[46] While General Putnam was on the scene attempting to direct affairs, unit commanders often misunderstood or disobeyed orders.[46][47]\\r\\nBy 3?p.m., the British reinforcements, which included the 47th Foot and the 1st Marines, had arrived, and the British were ready to march.[48] Brigadier General Pigot's force, gathering just south of Charlestown village, were taking casualties from sniper fire, and Howe asked Admiral Graves for assistance in clearing out the snipers. Graves, who had planned for such a possibility, ordered incendiary shot fired into the village, and then sent a landing party to set fire to the town.[49] The smoke billowing from Charlestown lent an almost surreal backdrop to the fighting, as the winds were such that the smoke was kept from the field of battle.[50]\\r\\nPigot, commanding the 5th, 38th, 43rd, 47th, and 52nd regiments, as well as Major Pitcairn's Marines, were to feint an assault on the redoubt. However, they continued to be harried by snipers in Charlestown, and Pigot, when he saw what happened to Howe's advance, ordered a retreat.[51]\\r\\nGeneral Howe led the light infantry companies and grenadiers in the assault on the American left flank, expecting an easy effort against Stark's recently arrived troops.[52] His light infantry were set along the narrow beach, in column, in order to turn the far left flank of the colonial position.[53] The grenadiers were deployed in the middle. They lined up four deep and several hundred across. As the regulars closed, John Simpson, a New Hampshire man, prematurely fired, drawing an ineffective volley of return fire from the regulars.[citation needed] When the regulars finally closed within range, both sides opened fire. The colonists inflicted heavy casualties on the regulars, using the fence to steady and aim their muskets, and benefit from a modicum of cover. With this devastating barrage of musket fire, the regulars retreated in disarray, and the militia held their ground.[54]\\r\\nThe regulars reformed on the field and marched out again. This time, Pigot was not to feint; he was to assault the redoubt, possibly without the assistance of Howe's force. Howe, instead of marching against Stark's position along the beach, marched instead against Knowlton's position along the rail fence. The outcome of the second attack was much the same as the first. One British observer wrote, \\"Most of our Grenadiers and Light-infantry, the moment of presenting themselves lost three-fourths, and many nine-tenths, of their men. Some had only eight or nine men a company left ...\\"[55] Pigot did not fare any better in his attack on the redoubt, and again ordered a retreat.[56] Meanwhile, in the rear of the colonial forces, confusion continued to reign. General Putnam tried, with only limited success, to send additional troops from Bunker Hill to Breed's Hill to support the men in the redoubt and along the defensive lines.[57][58]\\r\\nThe British rear was also in some disarray. Wounded soldiers that were mobile had made their way to the landing areas, and were being ferried back to Boston, and the wounded lying on the field of battle were the source of moans and cries of pain.[59] General Howe, deciding that he would try again, sent word to General Clinton in Boston for additional troops. Clinton, who had watched the first two attacks, sent about 400 men from the 2nd Marines and the 63rd Foot, and then followed himself to help rally the troops. In addition to the new reserves, he also convinced about 200 of the wounded to form up for the third attack.[60] During the interval between the second and third assaults, General Putnam continued trying to direct troops toward the action. Some companies, and leaderless groups of men, moved toward the action; others retreated.[61] John Chester, a Connecticut captain, seeing an entire company in retreat, ordered his company to aim muskets at that company to halt its retreat; they turned about and headed back to the battlefield.[62]\\r\\nThe third assault, concentrated on the redoubt (with only a feint on the colonists' flank), was successful, although the colonists again poured musket fire into the British ranks, and it cost the life of Major Pitcairn.[63] The defenders had run out of ammunition, reducing the battle to close combat. The British had the advantage once they entered the redoubt, as their troops were equipped with bayonets on their muskets while most of the colonists were not. Colonel Prescott, one of the last colonists to leave the redoubt, parried bayonet thrusts with his normally ceremonial sabre.[64] It is during the retreat from the redoubt that Joseph Warren was killed.[65]\\r\\nThe retreat of much of the colonial forces from the peninsula was made possible in part by the controlled retreat of the forces along the rail fence, led by John Stark and Thomas Knowlton, which prevented the encirclement of the hill. Their disciplined retreat, described by Burgoyne as \\"no flight; it was even covered with bravery and military skill\\", was so effective that most of the wounded were saved;[66] most of the prisoners taken by the British were mortally wounded.[66] General Putnam attempted to reform the troops on Bunker Hill; however the flight of the colonial forces was so rapid that artillery pieces and entrenching tools had to be abandoned. The colonists suffered most of their casualties during the retreat on Bunker Hill. By 5?p.m., the colonists had retreated over the Charlestown Neck to fortified positions in Cambridge, and the British were in control of the peninsula.[67]\\r\\nThe British had taken the ground but at a great loss; they had suffered 1,054 casualties (226 dead and 828 wounded), with a disproportionate number of these officers. The casualty count was the highest suffered by the British in any single encounter during the entire war.[68] General Clinton, echoing Pyrrhus of Epirus, remarked in his diary that \\"A few more such victories would have shortly put an end to British dominion in America.\\"[1] British dead and wounded included 100 commissioned officers, a significant portion of the British officer corps in North America.[69] Much of General Howe's field staff was among the casualties.[70] Major Pitcairn had been killed, and Lieutenant Colonel James Abercrombie fatally wounded. General Gage, in his report after the battle, reported the following officer casualties (listing lieutenants and above by name):[71]\\r\\nThe colonial losses were about 450, of whom 140 were killed. Most of the colonial losses came during the withdrawal. Major Andrew McClary was technically the highest ranking colonial officer to die in the battle; he was hit by cannon fire on Charlestown Neck, the last person to be killed in the battle. He was later commemorated by the dedication of Fort McClary in Kittery, Maine.[72] A serious loss to the Patriot cause, however, was the death of Dr. Joseph Warren. He was the President of Massachusetts' Provincial Congress, and he had been appointed a Major General on June 14. His commission had not yet taken effect when he served as a volunteer private three days later at Bunker Hill.[73] Only thirty men were captured by the British, most of them with grievous wounds; twenty died while held prisoner. The colonials also lost numerous shovels and other entrenching tools, as well as five out of the six cannon they had brought to the peninsula.[74][75]\\r\\nWhen news of the battle spread through the colonies, it was reported as a colonial loss, as the ground had been taken by the enemy, and significant casualties were incurred. George Washington, who was on his way to Boston as the new commander of the Continental Army, received news of the battle while in New York City. The report, which included casualty figures that were somewhat inaccurate, gave Washington hope that his army might prevail in the conflict.[76]\\r\\nThe Massachusetts Committee of Safety, seeking to repeat the sort of propaganda victory it won following the battles at Lexington and Concord, commissioned a report of the battle to send to England. Their report, however, did not reach England before Gage's official account arrived on July 20. His report unsurprisingly caused friction and argument between the Tories and the Whigs, but the casualty counts alarmed the military establishment, and forced many to rethink their views of colonial military capability.[78] King George's attitude toward the colonies hardened, and the news may have contributed to his rejection of the Continental Congress' Olive Branch Petition, the last substantive political attempt at reconciliation. Sir James Adolphus Oughton, part of the Tory majority, wrote to Lord Dartmouth of the colonies, \\"the sooner they are made to Taste Distress the sooner will [Crown control over them] be produced, and the Effusion of Blood be put a stop to.\\"[79] About a month after receiving Gage's report the Proclamation of Rebellion would be issued in response; this hardening of the British position would also lead to a hardening of previously weak support for the rebellion, especially in the southern colonies, in favor of independence.[79]\\r\\nGage's report had a more direct effect on his own career. His dismissal from office was decided just three days after his report was received, although General Howe did not replace him until October 1775.[80] Gage wrote another report to the British Cabinet, in which he repeated earlier warnings that \\"a large army must at length be employed to reduce these people\\", that would require \\"the hiring of foreign troops\\".[81]\\r\\nMuch has been written in the wake of this battle over how it was conducted. Both sides made strategic and tactical missteps which could have altered the outcome of the battle. While hindsight often gives a biased view, some things seem to be apparent after the battle that might reasonably have been within the reach of the command of the day.\\r\\nYears after the battle, and after Israel Putnam was dead, General Dearborn published an account of the battle in Port Folio magazine, accusing General Putnam of inaction, cowardly leadership and failing to supply reinforcements during the battle, which subsequently sparked a long lasting and major controversy among veterans of the war, various friends, family members and historians.[82][a] People were shocked by the rancor of the attack, and this prompted a forceful response from defenders of Putnam, including such notables as John and Abigail Adams. Historian Harold Murdock wrote that Dearborn's account \\"abounds in absurd misstatements and amazing flights of imagination.\\" The Dearborn attack received considerable attention because at the time he was in the middle of considerable controversy himself. He had been relieved of one of the top commands in the War of 1812 due to his mistakes. He had also been nominated to serve as Secretary of War by President Monroe, but was rejected by the United States Senate (which was the first time that the Senate had voted against confirming a presidential cabinet choice).[83][84][85][86]\\r\\nThe colonial forces, while nominally under the overall command of General Ward, with General Putnam and Colonel Prescott leading in the field, often acted quite independently.[87] This was evident in the opening stages of the battle, when a tactical decision was made that had strategic implications. After deliberating with General Putnam and Colonel Gridley, Colonel Prescott and his staff, apparently in contravention of orders, decided to fortify Breed's Hill rather than Bunker Hill.[88] The fortification of Breed's Hill was more provocative; it would have put offensive artillery closer to Boston.[89] It also exposed the forces there to the possibility of being trapped, as they probably could not properly defend against attempts by the British to land troops and take control of Charlestown Neck. If the British had taken that step, they might have had a victory with many fewer casualties.[90]\\r\\nWhile the front lines of the colonial forces were generally well managed, the scene behind them, especially once the action began, was significantly disorganized, due at least in part to a poor chain of command. Only some of the militias operated directly under Ward's and Putnam's authority,[91] and some commanders also disobeyed orders, staying at Bunker Hill rather than joining in the defense on the third British assault. Several officers were subjected to court martial and cashiered.[92] Colonel Prescott was of the opinion that the third assault would have been repulsed, had his forces in the redoubt been reinforced with either more men, or more supplies of ammunition and powder.[93]\\r\\nThe British leadership, for its part, acted slowly once the works on Breed's Hill were spotted. It was 2?p.m. when the troops were ready for the assault, roughly ten hours after the Lively first opened fire. This leisurely pace gave the colonial forces time to reinforce the flanking positions that had been poorly defended.[94] Gage and Howe decided that a frontal assault on the works would be a simple matter, when an encircling move (gaining control of Charlestown Neck), would have given them a more resounding victory.[90] (This move would not have been without risks of its own, as the colonists could have made holding the Neck expensive with fire from the high ground in Cambridge.) But the British leadership was excessively optimistic, believing that \\"two regiments were sufficient to beat the strength of the province\\".[95]\\r\\nOnce in the field, Howe, rather than focusing on the redoubt, opted (twice) to dilute the force attacking the redoubt with a flanking maneuver against the colonial left. It was only with the third attack, when the flank attack was merely a feint,[96] and the main force (now also reinforced with additional reserves) squarely targeted the redoubt, that the attack succeeded.[97]\\r\\nFollowing the taking of the peninsula, the British arguably had a tactical advantage that they could have used to press into Cambridge. General Clinton proposed this to Howe; having just led three assaults with grievous casualties, he declined the idea.[98] The colonial military leaders eventually recognized Howe as a tentative decision-maker, to his detriment; in the aftermath of the Battle of Long Island (1776), he again had tactical advantages that might have delivered Washington's army into his hands, but again refused to act.[99]\\r\\nHistorian John Ferling maintains that had General Gage used the Royal Navy to secure the narrow neck to the Charleston peninsula, cutting the Americans off from the mainland, he could have achieved a far less costly victory, but he was motivated by revenge over patriot resistance at the Battles of Lexington and Concord and relatively heavy British losses, and also felt that the colonial militia were completely untrained and could be overtaken with little effort, opting for a frontal assault.[100]\\r\\nThe famous order \\"Don't fire until you see the whites of their eyes\\" was popularized in stories about the battle of Bunker Hill. It is uncertain as to who said it there, since various histories, including eyewitness accounts,[101] attribute it to Putnam, Stark, Prescott, or Gridley, and it may have been said first by one, and repeated by the others.[102] It was also not an original statement. The idea dates originally to the general-king Gustavus Adolphus (1594ÿ1632) who gave standing orders to his musketeers: \\"never to give fire, till they could see their own image in the pupil of their enemy's eye\\".[103] Gustavus Adolphus's military teachings were widely admired and imitated and caused this saying to be often repeated. It was used by General James Wolfe on the Plains of Abraham, when his troops defeated Montcalm's army on September 13, 1759.[104] The earliest similar quote came from the Battle of Dettingen on June 27, 1743, where Lieutenant-Colonel Sir Andrew Agnew of Lochnaw warned his Regiment, the Royal Scots Fusiliers, not to fire until they could \\"see the white of their e'en.\\"[105] The phrase was also used by Prince Charles of Prussia in 1745, and repeated in 1755 by Frederick the Great, and may have been mentioned in histories the colonial military leaders were familiar with.[106] Whether or not it was actually said in this battle, it was clear that the colonial military leadership were regularly reminding their troops to hold their fire until the moment when it would have the greatest effect, especially in situations where their ammunition would be limited.[107]\\r\\nA significant number of notable people fought in this battle. Henry Dearborn and William Eustis, for example, went on to distinguished military and political careers; both served in Congress, the Cabinet, and in diplomatic posts. Others, like John Brooks, Henry Burbeck, Christian Febiger, Thomas Knowlton, and John Stark, became well known for later actions in the war.[108][109] Stark became known as the \\"Hero of Bennington\\" for his role in the 1777 Battle of Bennington. Free African-Americans also fought in the battle; notable examples include Barzillai Lew, Salem Poor, and Peter Salem.[110][111] Another notable participant was Daniel Shays, who later became famous for his army of protest in Shays' Rebellion.[112] Israel Potter was immortalized in Israel Potter: His Fifty Years of Exile, a novel by Herman Melville.[113][114] Colonel John Paterson commanded the Massachusetts First Militia, served in Shays' Rebellion, and became a congressman from New York.[115] Lt. Col. Seth Read, who served under John Paterson at Bunker Hill, went on to settle Geneva, New York and Erie, Pennsylvania, and was said to have been instrumental in the phrase E pluribus unum being added to U.S. coins.[116][117][118][119] George Claghorn of the Massachusetts militia was shot in the knee at Bunker Hill and went on after the war to become the master builder of the USS Constitution, a.k.a. \\"Old Ironsides\\", which is the oldest naval vessel in the world that is still commissioned and afloat.[120][121]\\r\\nJohn Trumbull's painting, The Death of General Warren at the Battle of Bunker Hill (displayed in lede), was created as an allegorical depiction of the battle and Warren's death, not as an actual pictorial recording of the event. The painting shows a number of participants in the battle including a British officer, John Small, among those who stormed the redoubt, yet came to be the one holding the mortally wounded Warren and preventing a fellow redcoat from bayoneting him. He was friends of Putnam and Trumbull. Other central figures include Andrew McClary who was the last man to fall in the battle.[122]\\r\\nThe Bunker Hill Monument is an obelisk that stands 221 feet (67?m) high on Breed's Hill. On June 17, 1825, the fiftieth anniversary of the battle, the cornerstone of the monument was laid by the Marquis de Lafayette and an address delivered by Daniel Webster.[123] (When Lafayette died, he was buried next to his wife at the Cimetire de Picpus under soil from Bunker Hill, which his son Georges sprinkled over him.)[124] The Leonard P. Zakim Bunker Hill Memorial Bridge was specifically designed to evoke this monument.[125] There is also a statue of William Prescott showing him calming his men down.\\r\\nThe National Park Service operates a museum dedicated to the battle near the monument, which is part of the Boston National Historical Park.[126] A cyclorama of the battle was added in 2007 when the museum was renovated.[127]\\r\\nIn nearby Cambridge, a small granite monument just north of Harvard Yard bears this inscription: \\"Here assembled on the night of June 16, 1775, 1200 Continental troops under command of Colonel Prescott. After prayer by President Langdon, they marched to Bunker Hill.\\" See footnote for picture.[128] (Samuel Langdon, a Congregational minister, was Harvard's 11th president.)[129] Another small monument nearby marks the location of the Committee of Safety, which had become the Patriots' provisional government as Tories left Cambridge.[130] These monuments are on the lawn to the west of Harvard's Littaeur Center, which is itself the west of Harvard's huge Science Center. See footnote for map.[131]\\r\\nBunker Hill Day, observed every June 17, is a legal holiday in Suffolk County, Massachusetts (which includes the city of Boston), as well as Somerville in Middlesex County. Prospect Hill, site of colonial fortifications overlooking the Charlestown Neck, is now located in Somerville, which was previously part of Charlestown.[132][133] State institutions in Massachusetts (such as public institutions of higher education) located in Boston also celebrate the holiday.[134][135] However, the state's FY2011 budget requires that all state and municipal offices in Suffolk County be open on Bunker Hill Day and Evacuation Day.[136]\\r\\nOn June 16 and 17, 1875, the centennial of the battle was celebrated with a military parade and a reception featuring notable speakers, among them General William Tecumseh Sherman and Vice President Henry Wilson. It was attended by dignitaries from across the country.[137] Celebratory events also marked the sesquicentennial (150th anniversary) in 1925 and the bicentennial in 1975.[138][139]\\r\\nOver the years the Battle of Bunker Hill has been commemorated on four U.S. Postage stamps.[140]\\r\\nMajor sources Most of the information about the battle itself in this article comes from the following sources.\\r\\nMinor sources Specific facts not necessarily covered by the major sources come from the following sources.\\r\\nCommemorations Various commemorations of the battle are described in the following sources.\\r\\nAbout the battle\\r\\nAbout people in the battle","input":"What battle took place at breeds hill near boston?"},{"output":"The Comet","context":"The Mercury Comet is an automobile that was produced by Mercury from 1962ÿ1969 and 1971-1977  variously as either a compact or an intermediate car.\\r\\nThe Comet was initially based on the compact Edsel Ford Falcon, then on the intermediate Ford Fairlane and finally on the compact Ford Maverick. As a Mercury, early Comets received better grade interior trim than concurrent Falcons, and a slightly longer wheelbase.\\r\\nThe Comet was originally planned as an Edsel model. It was reassigned to Mercury dealerships, where it was marketed as a standalone product for 1960 and 1961 as the Comet. There was a 1960 Edsel, the final model year for Edsel, but there was no Edsel Comet, only the Comet sold at Mercury-Comet dealers starting in 1960.\\r\\nDeveloped concurrently with the Ford Falcon, early pre-production photographs of the sedan show a car remarkably close to the Comet that emerged, but with a split grille following the pattern established by Edsel models. Early Ford styling mules for the station wagon model carried the Edsel name as well.\\r\\nAt their debut, the split grille was replaced by one more in keeping with Mercury's design themes. However, the canted elliptical taillights, first seen on the Edsel prototype, were used and carried the \\"E\\" (Edsel) part number on them. While the short lived 1960 Edsels used elliptical shaped taillights, the lenses used on both cars differed in length and width. Certain other parts from the 1959 Edsel parts bin, including the parking lights and dashboard knobs, were used on the first-year Comet. Keys for the 1960 and 1961 Comets were shaped like Edsel keys, with the center bar of the \\"E\\" removed to form a \\"C\\".\\r\\nThe \\"comet\\" name was trademarked to Cotner-Bevington as the Comet Coach Company, building ambulance and hearse commercial vehicles. Ford bought the name in 1959.\\r\\nFrom 1960-1965, the Comet was based on the Ford Falcon platform (stretched 5?in (130?mm) for sedans, but not for wagons). The 1960-1963 Comets share a similar basic shape. These are sometimes referred to as the \\"round body\\" Comets. For 1962 and 1963, the Comet shared a considerable number of body and mechanical parts with the short-lived Fairlane-based Mercury Meteor intermediate.\\r\\nThe Comet was initially released without any divisional badging, only \\"Comet\\" badges, similar to Valiant which didn't have Plymouth badging at first. It was sold through Mercury-Comet dealers, but would not be branded as such for two more years. This was similar to Ford's treatment of the Meteor and Fronternac of Canada, sold thru Meteor - Mercury - Fronternac dealers.\\r\\nIntroduced in March 1960, initial body styles were 2-door coupes, 4-door sedans and 2- and 4-door station wagons. Two trim levels were available, standard and \\"Custom\\", with the custom package including badging, additional chrome trim and all-vinyl interiors. In 1960, the only engine available was the 144 cid Thriftpower straight six with a single-barrel Holley carburetor which produced 90?hp (67?kW) at 4200?rpm. (Some sources list it as producing 85?hp (63?kW) at 4200?rpm). Transmission options were a column-shifted 3-speed manual and a 2-speed Merc-O-Matic automatic transmission (unique to the Comet, despite sharing a name with the Merc-O-Matic installed in other Mercurys).\\r\\nFord had purchased the name \\"Comet\\" from Comet Coach Company, a professional car manufacturer in which the term belonged to a line of funeral coaches, mainly Oldsmobiles. The coach company then was renamed Cotner-Bevington.\\r\\nIn Canada, for the 1960 model year, Meteor-Mercury dealers sold a compact car called the \\"Frontenac\\". The Frontenac was considered a model in its own right and was badge-engineered version of the Ford Falcon with only minor trim differences to distinguish it from the Falcon. The Frontenac was produced for only one year. The Comet was introduced to the Canadian market for the 1961 model year and replaced the Frontenac as the compact offering by Meteor-Mercury dealers.\\r\\nIn response to complaints about the low performance of the 144 cid engine, a 170 cid straight-6 with a single-barrel Holley carburetor producing 101?hp (75?kW) at 4400?rpm was released for the 1961 model year. A new 4-speed manual transmission was also an option (a Dagenham without 1st gear synchromesh). The changes to the 1961 Comet were minimal such as moving the Comet Script from the front fender to the rear quarter as well as a new grille design.\\r\\nThe optional S-22 package was released. Available only on the 2-door sedan, it was billed as a \\"sport\\" package, although it shared the same mechanicals as regular Comets, with the only changes being S-22 badging, bucket seats and a center console.\\r\\nComet was officially made a Mercury model for the 1962 model year, and it received some minor restyling, mainly a redesign of the trunk and taillight area to bring the car more in line with the Mercury look. This is the first year the car carried Mercury badging. The S-22 had six bullet shaped tail lights, while regular Comets had four oval with 2 optional flat reverse lights. A Comet Villager station wagon, basically a Comet Custom 4-door station wagon with simulated woodgrain side panels, was added to the lineup. (The Villager name had previously been used to denote the 4-door steel-sided station wagon in the Edsel Ranger series.)\\r\\nWhile the 1963 model looked almost identical to the earlier models, the chassis and suspension were redesigned to accommodate an optional 260 cid V8 engine using a 2-barrel carburetor and producing 164?hp (122?kW). Convertible and hardtop (pillar-less) coupe models were added to the Comet Custom and Comet S-22 lines this year.\\r\\nThe front ends of these Comets differed from their Falcon counterparts in that they had four headlights instead of two; similar situations would resurface in the late 1970s, with the Thunderbird/Cougar and the Fairmont/Zephyr.\\r\\nThe 1964 Comet was redesigned with a much more square shape, though it was still built on the same unibody as the 1963 model. Its basic lines were shared with the new Falcon, but the front grille used styling similar to that of the Lincoln Continental. Along with the redesign, the model designations were changed. The performance version was known as the Cyclone, replacing the previous S-22. Then in descending order of trim levels were the Caliente, 404 and 202, replacing the previous Custom and base models. The 2-door station wagon bodystyle was discontinued. The top-of-the-line station wagon continued to be known as the Villager. The base 144 cid six engine was dropped and the 170 cid six became the new base engine. The 260 V8 was available at the beginning of the production run, with the new 289 being available mid-year. Due to the success of the full size Ford and Mercury \\"fastback\\" roofline introduced in mid-1963, the Falcon and Comet 2-door hardtops got a similar roofline with sharper corners.\\r\\nFor 1964, Ford produced about 50 ultra-high performance lightweight Comet Cyclones, equipped with their racing two-carburetor 427 engine, similar to their cousin, the Ford Thunderbolt. To avoid competing with each other, the Thunderbolts ran in super stock on 7-inch (180?mm) tires, but the Cyclones were modified to run in A/FX on 10-inch (250?mm) tires, where they were as dominant as the Thunderbolts were in super stock. Drivers included Ronnie Sox, Don Nicholson and Wild Bill Shrewsberry in conjunction with Jack Chrisman.[6] Shrewsberry still owns his original 427 Comet in Caliente trim.\\r\\nFor 1965, the Comet received updated styling front and rear (including stacked headlights, similar to what Pontiacs and Cadillacs would use at the same time). The base 6-cylinder engine was increased from 170 cid to 200 cid. Still using a single-barrel carburetor, it produced 120?hp (89?kW) at 4400?rpm. The base 8-cylinder engine was increased from 260 to 289 cid and, using a 2-barrel carburetor, it produced 200?hp (150?kW) at 4400?rpm. The standard transmission continued as a column-shifted 3-speed manual transmission. The optional automatic was changed to a \\"Merc-O-Matic\\" 3-speed automatic transmission (essentially a Ford C4 transmission). The 289 V8 was available in three horsepower ratings, base 2-barrel 200?hp, 4-barrel 225?hp (168?kW) and the premier driveline option was the 289 cubic inch, 271?hp (202?kW) high-performance engine and four-speed manual transmission found on the Ford Mustang.\\r\\nBeginning in 1966, the Comet grew from a compact to become a mid-sized car. It was now based on the same chassis as the Ford Fairlane intermediate (and the previous Mercury Meteor intermediate which was only offered in 1962-1963). These intermediate-sized cars used the same basic chassis as the original Ford Falcon and Mercury Comet compacts, but were stretched with longer wheelbases. The previous generation Comet shared its platform with the all-new Ford Mustang in 1964, and when the Comet graduated to the intermediate platform, the Mercury Cougar became the platform shared with the Mustang.\\r\\nThe Comet wagon would introduce a Dual-Action tailgate, able to both fold down or swing aside, an idea soon copied by all the major U.S. manufacturers.[8]\\r\\nThe 1966 Comet received distinct outer body panels. The Comet Capri would replace the previous Comet 404 and the Comet Voyager 4-door station wagon would replace the previous Comet 404 station wagon. (The Voyager name had previously been used to designate a full-sized Mercury station wagon that was positioned between the base Commuter and the top-of-the-line Colony Park station wagon models.) The Comet 202 4-door station wagon would be discontinued. The new top-of-the-line series was the Comet Cyclone GT.\\r\\nNew engines available in the Comet for 1966 included a 390 cid V8 engine with a 2-barrel carburetor producing 265?hp (198?kW) at 4400?rpm, a 390 cid V8 engine with a 4-barrel carburetor producing 275?hp (205?kW), and 390 cid V8 engine that produced 335?hp (250?kW). The 335?hp 390 cid V8 engine was standard on the Cyclone GT and optional on other models. The Cyclone GT when equipped with an automatic transmission was referred to as the Cyclone GTA.\\r\\nA Cyclone GT convertible was the pace car for the 1966 Indianapolis 500.\\r\\nBeginning with the 1967 model year, the Comet name was used only on the base Comet 202 model, available only in 2 or 4-door sedan body styles. Other models were now referred to by what had previously been their subseries names. Mercury's mid-size line-up ranged from the basic Comet 202, through the Capri, Caliente, Cyclone, and Cyclone GT models, as well as steel-sided Voyager and simulated wood paneled Villager station wagon models, which were comparable to the Capri.\\r\\nIn 1968, Mercury's mid-sized models again received new sheet metal and styling that resembled the full-sized Mercury models and shared their chassis and many parts with Ford's mid-sized Fairlane and Torino models. The mid-sized base model was the Comet (Mercury dropped the 202 suffix) available only as a 2-door coupe. The Capri was replaced by the Montego, and the Caliente by the Montego MX. There was also a more luxurious Montego MX Brougham, basically an option package for the Montego MX. Top-of-the-line mid-sized models continued to use the Cyclone and Cyclone GT names.\\r\\nA 302 cid V8 engine using a 2-barrel carburetor and generating 210?hp (160?kW) at 4600?rpm would replace the previous 289 cid V8 midway in the 1968 model year. For the 1969 model year, the grille was modified and the headlight surrounds were removed. The taillights were also slightly re-styled. There would be few changes to Mercury's mid-sized lineup for the 1969 model year, the last year that the Comet name would grace a mid-sized model. A Comet 4-door sedan for 1969 was supposedly planned, but never offered. New top-of-the-line Cyclone Spoiler and Cyclone CJ models would join the lineup.\\r\\nA 250 cid inline-6 using a single-barrel carburetor and generating 155?hp (116?kW) at 4000?rpm would replace the previous 200 cid 6 as standard. New engine options included a 302 cid V-8 engine using a 4-barrel carburetor and generating 220?hp (160?kW) at 4400?rpm (standard on the Cyclone), a 351 cid V-8 using a 4-barrel carburetor generating 290?hp (220?kW) at 5200?rpm (standard on the Cyclone Spoiler), and a 428 cid V-8 using a 4-barrel carburetor generating 335?hp (250?kW) at 5200?rpm (standard on the Cyclone CJ[10]). These new V-8s replaced the previous 390 cid V-8s.\\r\\nStill using the same basic chassis, 1970 models would receive dramatic new styling, but the base model would now be the Montego. Comet was no longer the base level intermediate. The Cyclone name would continue to be used through the 1971 model year.\\r\\nFor 1971, the Comet name was revived on Mercury's version of the Ford Maverick compact. Sharing most of its sheet-metal with the Maverick, it used a different grille, taillights, and hood, as well as different badging. The taillight pods were shared with the 1970 and 1971 Montego and Cyclone models. Underneath it all was the same basic chassis that had originally been used for the Ford Falcon, the original Comet, and for the mid-sized Ford Fairlane, Mercury Meteor, and later Mercury Comets.\\r\\nThe base engine was the 170 cid inline-6 with a single-barrel carburetor producing 100?hp (75?kW) at 4200?rpm. Optional engines were the 200 cid inline-6 with a single-barrel carburetor producing 115?hp (86?kW) and a 302 cid V8 with a 2-barrel carburetor producing 210?hp (160?kW). Transmissions were either a 3-speed manual or 3-speed automatic with either column or floor-mounted shifters.\\r\\nThe Comet was available as 2- and 4-door sedans and in base (1971ÿ1977), and \\"muscle car\\" Comet GT series (2-door sedan-only 1971-1975). The GT featured a blacked-out grille, dual body-side tape stripes, high-back bucket seats, wheel trim rings, dual racing mirrors, bright window frames, black instrument panel, deluxe door trim panels, and a simulated hood scoop.\\r\\nIn 1972 models, the base 170 cid six was rated at 82?hp (61?kW) at 4400 rpm, the 200 cid six at 91?hp (68?kW), and the 302 cid V8 at 138?hp (103?kW). A new engine option for 1972 was the 250 cid six with a single-barrel carburetor rated at 98?hp (73?kW).\\r\\nFor 1973 models, the base 170 cid six was dropped and the 200 cid six became the base engine. Horsepower ratings would fluctuate slightly up or down through the years the Comet would remain in production, but not by very much. A new, larger front bumper to meet federal standards was added to all models in 1973. A new Custom decor package featuring vinyl roof, body-colored wheel covers, wide vinyl-insert body-side moldings, vinyl bucket seats, luxury carpeting, and extra sound insulation was a popular option.\\r\\nChanges for 1974 included even larger front bumpers and new larger rear bumpers to match. They added 2.5?in (64?mm) to the length of the 2-door model and 4?in (100?mm) to the length of the 4-door model.\\r\\nFord had originally planned to the replace the Comet and its Ford Maverick counterpart for the 1975 model year with updated and extensively redesigned models that would continue to use the Comet and Maverick names. Fairly late, though, they decided that the updated versions would be built alongside the original Maverick and the Comet that had originally been introduced for 1971. These would-be replacements, also using the same basic chassis as the Comet and Maverick, became the Mercury Monarch and the American Ford Granada, came with more standard and optional equipment than the Comet and Maverick, and were considered to be \\"luxury compacts,\\" a step up from the Comet and Maverick.\\r\\nAlthough 1975 was the last year for the Mercury Comet GT, the GT features remained available in 1976 and 1977 with the \\"Sports Accent\\" option group.\\r\\nThe model was offered with comparatively few changes through the 1977 model year, and was then discontinued to make room for the new Mercury Zephyr for the 1978 model year.\\r\\nIn July 2010, USA Today reported on a 91-year-old Florida woman, Rachel Veitch, who was still driving her 1964 Comet Caliente daily. The car was purchased new, and Veitch had recently set a record by accumulating over 562,000 documented miles. The car was retired in 2012 after accumulating 576,000 miles, as Veitch had decided to stop driving due to her eyesight becoming too weak.[12]\\r\\nThe Cyclone was a performance model of the Comet. It was built from 1964-1971.[13]\\r\\nThe Cyclone received Mercurys biggest facelift in 1968, switching from 1967s boxy, Fairlane-derived coupe body to the super-streamlined Torino-based fastback. Unfortunately, the Cyclone GT lost the 335-hp, 390-cid V-8 as its standard engine, instead replaced by the 210-hp, 302-cid V-8. No matter, though, as the fastback was handsome and could be equipped with a 230-hp 302, 265- or 325-hp 390-cid V-8s, (briefly) a 390-hp version of the 427-cid V-8, or a 335-hp, 428-cid V-8.\\r\\nBy 1969, the Mercury Cyclone formal hardtop had been canceled and the GT fastback was also available as a CJ model. That came with the 335-hp, 428-cid V-8 standard, a four-speed transmission, and a plain bench seat interior. At $3,207, the CJ was aimed at the Plymouth Road Runner, and a 435-hp version could run 0-60 in 6.1 seconds with a quarter-mile time of 13.9 seconds.The Mercury Cyclone Spoiler and the Ford Torino Talladega launched the NASCAR streamliner battle when Cale Yarborough won the Daytona 500 in 1968 in a Woods Brothers Cyclone. Dodge produced the Daytona 500 and Ford retaliated with the Torino Talladega and Mercury Spoiler. Both were to have streamlined noses, but the Mercury launch was delayed until the mid-year Cyclone Spoiler II. Only 519 were sold, all with 351-cid V-8s instead of the bigger 428. A Dan Gurney special edition had a dark blue roof, striping, and a signature decal on the white lowers, while the Cale Yarborough edition was red and white like his Woods Brothers car, with a signature.\\r\\nThree Cyclone models were produced for 1970, all of which shared the Torinos semi-fastback body, and all of which carried a four-part nose. The base car had a 360-hp, 429-cid V-8 and a four-speed transmission. Options included a 370-hp, 429-cid V-8 engine and a 375-hp, Super CJ 429-cid engine. There were also a few Boss 429s installed, though those cars are quite rare today. Meanwhile, the Cyclone GT was detuned to a 250-hp, 351-cid V-8 and the Spoiler packed a Ram-Air 370-hp, 429.\\r\\nThe 1971 model year was the Cyclones last, as the muscle car wars wound down. With few changes from 1970, the Cyclone was absorbed into the Mercury Montego line, and only 444 Montego Cyclones were sold, along with 2,287 Cyclone GTs and 353 Cyclone Spoilers. Engine options ranged from the 210-hp, 302-cid V-8, all the way to the fire-breathing 370-hp, 429-cid Cobra-Jet V-8, to which a Ram-Air package could be added.\\r\\nMercury Cyclones occupy a niche in the muscle car world, along with Oldsmobile W-30s and Buick GSX Stage Is. The car is a fantastic expression of American muscle, albeit one from a mid-level, luxury-oriented nameplate. As a result, the Cyclone is mostly overshadowed by the Ford Mustang and Torino. The Cyclones sleeper status makes it a great value, and most cars remain within reach of any buyer. As with any muscle car of the era, the importance of documentation in terms of market price rises exponentially as the cars horsepower ratings climb.","input":"What was the mercury version of the ford maverick?"},{"output":"22 June 1940","context":"Coordinates: 492538N 25423E? / ?49.42736111N 2.90641944E? / 49.42736111; 2.90641944\\r\\n\\r\\nThe Armistice of 22 June 1940 was signed at 18:36[1] near Compigne, France, by officials of Nazi Germany and the French Third Republic. It did not come into effect until after midnight on 25 June.\\r\\n\\r\\nSignatories for Germany included senior military officers like Wilhelm Keitel,[1] the commander-in-chief of the Wehrmacht (the German armed forces), while those on the French side were more junior, such as General Charles Huntziger. Following the decisive German victory in the Battle of France (10 Mayÿ21 June 1940), this armistice established a German occupation zone in Northern and Western France that encompassed all English Channel and Atlantic Ocean ports and left the remainder \\"free\\" to be governed by the French.  Adolf Hitler deliberately chose Compigne Forest as the site to sign the armistice due to its symbolic role as the site of the 1918 Armistice with Germany that signaled the end of World War I with Germany's surrender.\\r\\n\\r\\nThe best, most modernised French armies had been sent north and lost in the resulting encirclement; the French had lost their best heavy weaponry and their best armored formations. Between May and June, French forces were in general retreat and Germany threatened to occupy Paris.  The French government was forced to relocate to Bordeaux on 10 June to avoid capture and declared Paris to be an open city the same day.\\r\\n\\r\\nBy 22 June, the German Armed Forces (Wehrmacht) had losses of 27,000 dead, more than 111,000 wounded and 18,000 missing.\\r\\n\\r\\nFrench losses were 92,000 dead and more than 200,000 wounded.\\r\\n\\r\\nThe British Expeditionary Force suffered 68,000 casualties, with around 10,000 killed.\\r\\n\\r\\nWhen Adolf Hitler received word from the French government that they wished to negotiate an armistice, Hitler selected Compigne Forest as the site for the negotiations. As Compigne was the site of the 1918 Armistice ending the Great War with Germany's conflict cessation, Hitler saw the use of this location as a supreme moment of revenge for Germany over France. Hitler decided that the signing should take place in the same rail carriage, the Compigne Wagon, where the Germans had signed the 1918 armistice. However, in the last sentence of the preamble, the drafters inserted \\"However, Germany does not have the intention to use the armistice conditions and armistice negotiations as a form of humiliation against such a valiant opponent\\", referring to the French forces. Furthermore, in Article 3, Clause 2, the drafters stated that their intention was not to heavily occupy North-West France after the cessation of hostilities with Britain.\\r\\n\\r\\nWilliam Shirer, who was present on that day, reports, \\"I am but fifty yards from him. [] I have seen that face many times at the great moments of his life. But today! It is afire with scorn, anger, hate, revenge, triumph.\\"[2] Then, in the very same railway carriage in which the 1918 Armistice had been signed (removed from a museum building and placed on the precise spot where it was located in 1918), on 21 June 1940, Hitler sat in the same chair in which Marshal Ferdinand Foch had sat when he faced the representatives of the defeated German Empire. After listening to the reading of the preamble, Hitler ÿ in a calculated gesture of disdain for the French delegates ÿ left the carriage, as Foch had done in 1918, leaving the negotiations to his Oberkommando der Wehrmacht (High Command of the Armed Forces) Chief, General Wilhelm Keitel. Then negotiations lasted one day, until the evening of 22 June 1940: General Huntzinger had to discuss the terms by phone with the French government representatives who had fled to Bordeaux, mainly with the newly nominated defence minister, General Maxime Weygand.\\r\\n\\r\\nAdolf Hitler had a number of reasons for agreeing to an armistice. He wanted to ensure that France did not continue to fight from North Africa, and he wanted to ensure that the French Navy was taken out of the war. In addition, leaving a French government in place would relieve Germany of the considerable burden of administering French territory, particularly as he turned his attentions towards Britain. Finally, as Germany lacked a navy sufficient to occupy France's overseas territories, Hitler's only practical recourse to deny the British use of them was to maintain a formally independent and neutral French rump state.\\r\\n\\r\\nAccording to William Shirer's book Rise and Fall of the Third Reich, French General Charles Huntziger complained that the armistice terms imposed on France were harsher than those imposed on Germany in 1918. They provided for German occupation of three-fifths of France north and west of a line through Geneva and Tours and extending to the Spanish border, so as to give Nazi Germany's Kriegsmarine access to all French Channel and Atlantic ports. All persons who had been granted political asylum had to be surrendered and all occupation costs had to be borne by France, to the tune of 400 million French francs a day. A minimal French Army would be permitted. As one of Hitler's few concessions, the French Navy was to be disarmed but not surrendered, for Hitler realized that pushing France too far could result in France fighting on from the French colonial empire. An unoccupied region in the south, the Zone libre, was left relatively free to be governed by a rump French administration based in Vichy, which also administered the occupied zones, albeit under severe restrictions.\\r\\n\\r\\nThis was envisaged to last until a final peace treaty was negotiated. At the time, both French and Germans thought the occupation would be a provisional state of affairs and last only until Britain came to terms, which was believed to be imminent.[citation needed] For instance, none of the French delegation objected to the stipulation that French soldiers would remain prisoners of war until the cessation of all hostilities. Nearly one million Frenchmen were thus forced to spend the next five years in prisoner of war camps (about a third of the initial 1.5 million prisoners taken were released or exchanged as part of the Service du Travail Obligatoire forced labour programme by the Germans, before the war ended).[3]\\r\\n\\r\\nHowever, a final peace treaty was never negotiated, and the unoccupied zone was occupied by Germany and its Italian ally in Operation Anton following the invasion of French North Africa by the Allies in November 1942.\\r\\n\\r\\nArticle 19 of the Franco-German armistice required the French state to turn over to German authorities any German national on French territory, who would then frequently face deportation to a concentration camp (the \\"Surrender on Demand\\" clause).[4] Keitel gave verbal assurances that this would apply mainly to those refugees who had \\"fermented the war\\", a euphemism for Jews, and especially German Jews who until then had enjoyed asylum in France. Keitel also made one other concession, that French aircraft need not be handed over to the Germans.[5]\\r\\n\\r\\nThe French delegation ÿ led by General Charles Huntziger ÿ tried to soften the harsher terms of the armistice, but Keitel replied that they would have to accept or reject the armistice as it was. Given the military situation that France was in, Huntziger had \\"no choice\\" but to accede to the armistice terms. The cease-fire went into effect at 00:35 on 25 June 1940, more than two days later, only after another armistice was signed between France and Italy, the main German ally in Europe.\\r\\n\\r\\nThe armistice did have some relative advantages for the French, compared to worse possible outcomes, such as keeping the colonial empire and the fleet, and, by avoiding full occupation and disarmament, the remaining French rump state in the unoccupied zone could enforce a certain de facto independence and neutrality vis--vis the Axis.\\r\\n\\r\\nThe Armistice site was demolished by the Germans on Hitler's orders three days later.[6] The carriage itself was taken to Berlin as a trophy of war, along with pieces of a large stone tablet which bore the inscription (in French):\\r\\n\\r\\nThe Alsace-Lorraine Monument (depicting a German Eagle impaled by a sword) was also destroyed and all evidence of the site was obliterated, with the notable exception of the statue of Marshal Foch: Hitler intentionally ordered it to be left intact, so that it would be honoring only a wasteland. The railway carriage itself was later exhibited in Berlin, and then taken to Crawinkel in Thuringia in 1945, where it was destroyed by SS troops and the remains buried. The site and memorials were restored by German POW labour, after the war.","input":"When did france sign an armistice with germany?"},{"output":"Rector Timothy Cutler","context":"66000776\\r\\nOld North Church (officially, Christ Church in the City of Boston), at 193 Salem Street, in the North End, Boston, is the location from which the famous \\"One if by land, two if by sea\\" signal is said to have been sent. This phrase is related to Paul Revere's midnight ride, of April 18, 1775, which preceded the Battles of Lexington and Concord during the American Revolution.\\r\\nThe church is a mission of the Episcopal Diocese of Massachusetts. It is the oldest standing church building in Boston and is a National Historic Landmark. Inside the church is a bust of George Washington, which Gilbert du Motier, Marquis de Lafayette, reportedly remarked was the best likeness of the first president he had ever seen.\\r\\n\\r\\n\\r\\nThe Old North Church was built in December, 1723, and was inspired by the works of Christopher Wren, the British architect who was responsible for rebuilding London after the Great Fire. Timothy Cutler was the founding rector after serving as third rector of Yale College from 1719 to 1722.\\r\\nIn April 1775, Paul Revere told three Boston patriots to hang two lanterns in the steeple. These men were the church sexton Robert Newman and Captain John Pullingthe two of whom historian David Hackett Fischer suggests each carried one lantern up to the steepleas well as Thomas Bernard, who stood watch for British troops outside the church. The lanterns were displayed to send a warning to Charlestown patriots across the Charles River about the movements of the British Army. Revere and William Dawes would later deliver the same message to Lexington themselves, but this lantern method was a fast way to inform the back-up riders in Charlestown about the movements of the British; these back-up riders planned to deliver the warning message to Lexington and Concord in case Revere and Dawes were arrested on the way.\\r\\nThe lanterns were hung for just under a minute to avoid catching the eyes of the British troops occupying Boston, but this was long enough for the message to be received in Charlestown. The militia waiting across the river had been told to look for the signal lanterns, and were prepared to act as soon as they saw them.\\r\\nThe meaning of two lanterns has been memorized by countless American schoolchildren. \\"One if by land, and two if by sea\\" is from Henry Wadsworth Longfellow's poem \\"Paul Revere's Ride\\". One lantern was to notify Charlestown that the British Army would march over Boston Neck and the Great Bridge, and two were to notify them that the troops were taking boats across the Charles River to land near Phips farm (the British Army would take the \\"sea\\" route; thus, two lanterns were hung). After receiving the signal, the Charlestown Patriots sent out a rider to Lexington, but this rider did not reach his destination and his identity has disappeared from history. He was the one who might have been captured by a British patrol.\\r\\nBut the warning was delivered miles away to dozens of towns, first by Revere and Dawes on horses, and then by other men on horses and men who rang church bells and town bells, beat drums, and shot off warning guns. (The current status of the lanterns is not entirely clear; one is said to be in the hands of a private collector, another broken during a tour, and yet another is on display at the Concord Museum.)\\r\\nPresident Gerald Ford visited Old North Church on April 18, 1975. In his nationally televised speech, the President said, in part:\\r\\nLet us pray here in the Old North Church tonight that those who follow 100 years or 200 years from now may look back at us and say: We were a society which combined reason with liberty and hope with freedom. May it be said above all: We kept the faith, freedom flourished, liberty lived. These are the abiding principles of our past and the greatest promise of our future.\\r\\nFollowing President Ford's remarks, two lanterns were lit by Robert Newman Ruggles and Robert Newman Sheet, descendants of Robert Newman, who, as sexton of the Old North Church in 1775, lit the two lanterns which signaled the movement of British troops. The President then lit a third lantern, which hangs in a window of the church today.\\r\\nOn July 11, 1976, Queen Elizabeth II visited Boston as part of celebrations honoring the United States Bicentennial, and made reference to the aforementioned celebration events in April 1975 that followed President Ford's speech. She said: \\"At the Old North Church last year, your President lit a third lantern dedicated to America's third century of freedom and to renewed faith in the American ideals. May its light never be dimmed.\\"\\r\\nThe Queen and Prince Philip attended a Sunday morning service at the Old North Church, sitting in a pew at the right front. The Rev. Robert W. Golledge led the service and later presented the Queen with a replica of a silver chalice made by Paul Revere. The Queen was shown the iconic statue of Paul Revere by Cyrus E. Dallin near the church before departing in a motorcade to attend a function at the Old State House.\\r\\nEight change ringing bells (tenor: 13?long?cwt?3?qr?5?lb (1,545?lb or 701?kg) in F) at Old North Church were cast by Abel Rudhall (Rudhall of Gloucester) in Gloucester, England in 1744 and hung in 1745.[2] One bell has the inscription: \\"We are the first ring of bells cast for the British Empire in North America, A.R. 1744.\\" The bells were restored in 1894 and in 1975. They are maintained and rung regularly by the Massachusetts Institute of Technology Guild of Bellringers.\\r\\nThe original steeple of the Old North Church was destroyed by the 1804 Snow hurricane. A replacement steeple, designed by Charles Bulfinch, was toppled by Hurricane Carol on August 25, 1954. The current steeple uses design elements from the original and the Bulfinch version. The church is now 174 feet (53?m) tall.[3] At its tip is the original weather vane.\\r\\nBefore the construction of the \\"Old North Church\\" (Christ Church, Boston), there was another church in Boston called the \\"Old North\\" (Meetinghouse). This Congregationalist meeting house was founded in North Square, across the street from what is now called \\"Paul Revere's house\\". This church was once pastored by Cotton Mather, the minister now known largely for his involvement in the Salem witch trials.\\r\\nIn 2009, an archeologist began examining the estimated 1,100 bodies buried in 37 tombs in the basement.[4] The crypt was in use between 1732 and 1860, and each tomb is sealed with a wooden or slate door, with many doors covered over by plaster as ordered by the city of Boston in the 1850s.\\r\\nFounding Rector Timothy Cutler and his wife were buried under the altar together. Other notable figures buried under the church include British Marine Major John Pitcairn, who died at the Battle of Bunker Hill and was entombed along with many other soldiers killed in this battle. So is Captain Samuel Nicholson of the USS Constitution. A behind the scenes tour run by the church takes tourists down into the crypt, as well as up to the bell-ringing chamber.\\r\\nOld North Church is today one of four church sites among the 16 stops on the Freedom Trail.","input":"Who is buried in the old north church?"},{"output":"Viceroy of New Spain, an appointed minister of the King of Spain","context":"","input":"What was the highest ranking official in new spain called?"},{"output":"Joe Woods","context":"Joe Woods (born June 25, 1970) is an American football coach who currently serves as the defensive coordinator of the Denver Broncos of the National Football League (NFL). A coaching veteran of 26 years, Woods has 14 years of NFL experience with Denver (2015-17), Oakland (2014), Minnesota (2006-13) and Tampa Bay (2004-05). During his NFL coaching career, Woods has coached seven players to 13 total Pro Bowl selections.\\r\\n\\r\\nWoods lettered four times as a cornerback and safety during his collegiate career at Illinois State University, graduating from the school in 1992 with a degree in criminal justice. He was team captain as a senior in 1991 and went on to earn first-team All-Gateway Conference honors following his final season.[1]\\r\\n\\r\\nWoods began his coaching career as a defensive backs coach at Muskingum College in 1992 and moved on to become a graduate assistant coach at Eastern Michigan University in 1993. Woods also served as defensive backs coach at Kent State University (1997) and Grand Valley State University (1994-96) following a stint coaching linebackers during the spring of 1994 at Northwestern State University.[2] He coached the same position with Hofstra University from 1998-2000, helping the school make consecutive trips to the 1-AA playoff quarterfinals. Woods then became the defensive backs coach for three seasons (2001-03) at Western Michigan University.[3]\\r\\n\\r\\nIn 2004, Woods was hired by the Tampa Bay Buccaneers as the defensive backs coach. During his first two seasons with Tampa Bay, Woods coached a talented secondary led by cornerbacks Ronde Barber and Brian Kelly. Barber, an NFL 2000s All-Decade performer, earned first-team All-Pro recognition from the Associated Press following each of his two seasons playing for Woods.[4]\\r\\n\\r\\nWoods was brought to Minnesota in 2006 along with Defensive Coordinator Mike Tomlin, who worked with him as a secondary coach in Tampa Bay. Woods spent eight seasons coaching defensive backs in Minnesota. The Vikings finished among the NFLs top 10 defenses in four of his first five years with the team, capturing back-to-back NFC North Division titles from 2008-09 and making an NFC Championship Game appearance following the 2009 season.[5]\\r\\n\\r\\nWoods coached the Raiders defensive backs in 2014, working with veteran safety Charles Woodson, who led the team with 160 tackles (105 solo) and four interceptions in his 17th NFL season.[6]\\r\\n\\r\\nIn Woods first season coaching the Broncos secondary in 2015, Denver finished first in the NFL against the pass (199.6 ypg) while the defensive backfield accounted for 11 interceptions, 56 passes defensed, nine forced fumbles and four touchdowns.[7] The Broncos posted three interceptions against just one passing touchdown allowed during Denvers postseason run that ended with a victory in Super Bowl 50. In 2016, the Broncos secondary held opponents to the fewest yards per game (185.8), yards per attempt (5.8) and passing touchdowns (13) in the NFL.\\r\\n\\r\\nAfter the departure of defensive coordinator Wade Phillips, Woods was chosen to be promoted to defensive coordinator for the 2017 season.[8] Denver finished first in the NFL in pass defense in both 2015 (199.6 ypg) and 2016 (185.8) with Woods coaching the teams defensive backs.[9] All four of Denvers starting defensive backs made at least one Pro Bowl playing for Woods from 2015-16, including cornerbacks Chris Harris Jr. (2015-16) and Aqib Talib (2015-16), who were also named first-team All-Pro selections by the Associated Press in 2016. Safeties T.J. Ward (2015) and Darian Stewart (2016) also earned Pro Bowl recognitions while playing for Woods. \\r\\n\\r\\nIn Woods first season as defensive coordinator in 2017, the Broncos finished third in the NFL in total defense, giving up just 290.0 yards per game. The Broncos fifth-ranked run defense in 2017 was particularly impressive as it improved by more than 40 yards per game after finishing 28th in the NFL in 2016.[10]","input":"Who is the defensive coordinator for the denver broncos?"},{"output":"October 2003","context":"Andrei Kivilev (20 September 1973 ÿ 12 March 2003) was a professional road bicycle racer from Taldykorgan, Kazakhstan. In March 2003, he crashed during the ParisÿNice race and subsequently died of his injuries. His death was the trigger for the UCI to implement the compulsory wearing of helmets in all endorsed races.\\r\\n\\r\\n\\r\\nBorn in Taldykorgan, Almaty Province, Kivilev began his amateur racing career in Spain, before moving to France, where he wore the EC Saint-Etienne jersey.[1] In 1993, he had a successful Regio-Tour as part of a successful tour for the Kazakh team: Kivilev won the points competition; team mate Alexander Vinokourov won the combined competition; and the team won the team competition.[2] He secured a professional contract with Festina in 1998 and rode with them until the end of 1999. Kivilev had a modest time at Festina, where his best results were fifth at the Championship of Zurich[3] and seventh at the Critrium International.[4] Despite his lack of professional victories, Kivilev attracted admirers for his riding style, and despite interest from US Postal Service,[5] signed with Ag2r Prvoyance in 2000, before moving to Cofidis in 2001. It was at Cofidis that his career started to take off: in his first season, not only did he win the Route du Sud and stage five of the Dauphin Libr race, between Romans-sur-Isre and Grenoble,[6] but also had a sensational performance in the Tour de France. Having lost over eighteen minutes on a windswept and attritional stage 4 between Huy and Verdun,[7] Kivilev was allowed to form part of a fourteen-man breakaway on stage 8 between Colmar and Pontarlier and gained 33 minutes on the race favourites.[8] Kivilev was an able climber, and limited his losses on the big hills. His time trialling let him down when he lost a podium place to Joseba Beloki on the final time trial. Nevertheless, Kivilev finished the tour in 4th position.[9] In fact, with later doping scandals eliminating those ahead of him on the podium, the French newspaper Le Monde retroactively (and unofficially) named Kivilev winner of the 2001 Tour de France.[10]\\r\\nOn 11 March 2003 Kivilev was racing in the second stage of ParisÿNice, between La Clayette and Saint-tienne. Approximately forty kilometres from the stage finish, as the peloton passed through Saint-Chamond, Kivilev collided with Polish teammate Marek Rutkiewicz and German Volker Ordowski of Team Gerolsteiner. Rutkiewicz and Ordowski were not seriously hurt and finished the stage, but the helmetless Kivilev hit the ground and did not rise. Kivilev immediately fell into a coma, initially being taken to the Saint-Chamond hospital before being transferred via air to the intensive care unit at Saint-tienne hospital, where he was diagnosed with a serious skull fracture and two broken ribs. His condition worsened overnight, and Kivilev died of his injuries at 10 a.m. on 12 March 2003. He was survived by his wife Natalia and six-month-old son Leonardo. A few days later, his friend Alexander Vinokourov won the race.\\r\\nAfter Kivilev's death, the UCI made the wearing of helmets compulsory.[11] They had previously tried to introduce this requirement in 1991, but some riders protested this at the ParisÿNice race, so the rule was not introduced. The nature of Kivilev's death, in that he was a lead rider, in one of the top French cycling teams, racing in a top stage race, coupled with advances in helmet technology, brought the debate back to the fore and conclusively so for the UCI. Whilst many riders were initially still against compulsory helmet use, the UCI ensured the rules requiring helmets to be worn at all times would be in place for the 2003 Giro d'Italia, which started just eight weeks after Kivilev's death. Dissension to the rule was initially high, but the new rules were affirmed in October 2003. Whilst at first the rule was loose and not tightly enforced, especially on mountain-top finishes, it has since been enforced more strictly and helmet-wearing is now ubiquitous in the peloton.","input":"When did tour de france riders start wearing helmets?"},{"output":"in Mexico at Parque Los Berros in Xalapa, Veracruz","context":"","input":"Where was the first baseball game ever played?"},{"output":"Harris County","context":"The Harris County Toll Road Authority (HCTRA, pronounced \\"Hectra\\") maintains and operates a 103-mile (165.8?km) toll road system in the Houston/Harris County area. Its headquarters are in Houston.[1]\\r\\n\\r\\n\\r\\nHCTRA came into existence in September 1983 when Harris County voters approved a referendum by a 7-3 margin to release up to $900 million in bonds to create two toll roads - the Hardy Toll Road and the Sam Houston Tollway, to improve the regional mobility and reduce traffic congestion in the Greater Houston area, an area known for rapid population growth.\\r\\nThe need for a county-run toll road system came from TxDOT's budget shortfall and its inability to authorize funding to upgrade the second loop around the city, Beltway 8, which had been on planning maps since the 1950s. The Texas Turnpike Authority turned down the opportunity to improve the road as well, leaving the county to upgrade the road to freeway standards. However, Harris County could not afford to build and maintain a freeway from its general fund.\\r\\nShortly after the referendum, the Commissioners Court created the Toll Road Authority to administer the construction and operation of the new road system. Then-County Judge Jon Lindsay is generally credited with shepherding the referendum from its infancy to its passage, along with the implementation of the plan for the roadway. HCTRA is a part of Harris County's Public Infrastructure Department and is subdivided into a Services and an Operations Division.\\r\\nWhile for many years, the Hardy Toll Road never had the traffic that the HCTRA envisioned it would need to turn a profit, the Sam Houston Tollway has more than made up for the lost revenue. The high profit margins on the Sam Houston Tollway allowed the authority to construct its third and fourth toll roads, the Westpark Tollway and Fort Bend Toll Road, both of which opened in 2004. Both of these toll roads have termini in Fort Bend County and are run in conjunction with the Fort Bend County Toll Road Authority. The most recent project of HCTRA is the construction of managed lanes that run along the median of I-10/Katy Freeway between SH 6 and I-610 that opened in April 2009.[2]\\r\\nThe HCTRA uses their own toll tag called the EZ TAG. The system has been interoperable with the Texas Department of Transportation's TxTag and the North Texas Tollway Authority's TollTag since 2003. Around the 3rd quarter of 2017, the system will be interoperable with the Kansas Turnpike Authority's K-Tag[3] and the Oklahoma Turnpike Authority's PikePass.[3]\\r\\nThe following toll roads (in order of first segment completion) form the current HCTRA system:\\r\\nThe Sam Houston Tollway is the name given to the tolled sections of Beltway 8, the second highway loop around Houston. The first opened section was the Sam Houston Ship Channel Bridge in the east quadrant of the road system. From 1982 to 1994, the bridge, which was originally named in honor of local politician and entrepreneur Jesse H. Jones, was maintained by the Texas Turnpike Authority (now North Texas Tollway Authority). As of February 26, 2011, the Sam Houston Tollway is a complete tolled beltway loop around Houston (minus a few minor sections that are freeways managed by TXDOT).\\r\\nThe Hardy Toll Road was constructed to help alleviate traffic off of I-45 North. The route begins at I-610 North between I-45 North and I-69/US 59 North and travels northward parallel to I-45 for 21.6 miles (34.8?km) after which it merges onto I-45. The toll road also features a 4-mile (6.4?km) spur to George Bush Intercontinental Airport.\\r\\nThe Westpark Tollway is a 20-mile (32.2?km) toll road starting in Uptown Houston and travelling westward parallel to sections of Westpark Drive and FM 1093 and terminating just past the Grand Parkway (SH 99). It is the first all-electronic toll road in the United States. The Fort Bend County Toll Road Authority (FBCTRA) operates the western-most 6 miles (9.7?km) of the tollway.\\r\\nThe Fort Bend Toll Road is a 7.5-mile (12.1?km) tollway that follows the route of the formerly-cancelled State Highway 122. The toll road currently begins with direct connectors at US 90A, just north of the Sam Houston Tollway, and travels southward to its terminus at SH 6. As with the Westpark Tollway, the Fort Bend Toll Road is jointly operated with the FBCTRA.\\r\\nIn 2002, HCTRA entered into an agreement with TxDOT and Harris County for the reconstruction of I-10/Katy Freeway. The toll road authority's portion of the project is a 12-mile (19.3?km) managed lane facility in the center of the reconstructed freeway that is used by METRO and HOV vehicles at no charge and single passenger vehicles for a toll. The four lane roadway, running between I-610/West Loop and SH 6, has been completed. The lanes opened during the second quarter of 2009.\\r\\nThe Tomball Tollway consists of a 6.0-mile (9.7?km) segment of three toll lanes in each direction from Spring Cypress Road up to the northern end of the Tomball Bypass. Texas State Highway 249 serves as toll-free frontage roads for the Tomball Tollway. Tolling on the Tomball Tollway is all-electronic; an EZ TAG, TollTag or TxTag are required for passage. No cash or pay-by-mail option is available for the Tomball Tollway. Construction of Phase I began in Fall 2013 and was finished on April 12, 2015.\\r\\nThough in Montgomery County and owned by Montgomery County Toll Road Authority (MCTRA), HCTRA collects tolls for two ramps: one from northbound I-45 to SH 242 westbound and the other from westbound SH 242 to I-45 southbound near the Woodlands. The two ramps were completed on May 11, 2015 and were free until July 6 when HCTRA began to collect tolls for MCTRA. Both toll ramps are all-electronic and require an EZ TAG, TollTag or TxTag; no pay-by-mail or cash option is available.\\r\\nThis 4-mile (6.4?km) long project will provide a connection between Downtown Houston and the current terminus of the Hardy Toll Road at I-610. Planning for the Hardy Toll Road connection into Downtown Houston was announced in 2000. The project will be completed in two phases. Phase I consists of moving a railroad line, right of way acquisition, and the construction of two overpasses. Phase II will be the construction of 4 toll lanes. Relocation of the rail line is expected to begin Fall of 2012.\\r\\nTo relieve congestion on surface streets, direct connectors between Hardy Toll Road and Beltway 8 will be constructed. Currently there is only one direct connector ramp from Beltway 8 East to Hardy Toll Road North. Expected construction start date is unknown.\\r\\nThis project will add a direct connector to feed traffic travelling south on SH 249 onto the westbound Sam Houston Tollway. This will be the second tolled direct connector at that intersection. Construction began in 2014.\\r\\nPhase II of the SH 249 (Tomball Tollway) project, in partnership with Montgomery County Toll Road Authority, will provide three toll lanes in each direction to the existing SH 249 corridor. The plan for Phase II will extend the toll lanes north of the Tomball Bypass to the Harris County line at Spring Creek and points beyond in Montgomery County. Schematic designs have been completed for the portion that lies within Harris County. Construction of Phase II is projected to begin in 2016.\\r\\nTo help alleviate congestion on SH 288, HCTRA or TxDOT plan to construct toll lanes in the median of the existing freeway. The route would begin at I-69/US 59 just south of Midtown and terminate at the intersection of the proposed Grand Parkway (SH 99) for a total length of 26 miles (41.8?km). It is unknown when construction will begin; or which agency will oversee construction, currently it is TxDOT.\\r\\nThe planned project will add four tolled lanes along the Hempstead Highway corridor between I-610 and the future Grand Parkway (SH 99) northwest segment. The project is one component of the complete US 290 corridor upgrade by TxDOT, which also includes added capacity to US 290, a new HOV system parallel to the Hempstead Highway, and a possible commuter rail line in conjunction with METRO. Construction began in 2013 on US 290, with TxDOT overseeing construction.\\r\\nAdded capacity is planned for the following existing tollway segments:\\r\\nThe project will connect I-610 via the South Post Oak exit (which terminates south of West Bellfort) to the northern terminus of the Fort Bend Parkway with just over 3 miles (4.8?km) of tolled lanes. However, this project is not in planning or design. As of 2016 traffic exiting the Fort Bend Parkway goes directly to US90-A/South Main.\\r\\nProject is no longer being built. As of 03/30/10[7]\\r\\n Houston portal  U.S. Roads portal\\r\\nTexas State Highway 99","input":"Who owns the harris county toll road authority?"},{"output":"George Harvey Strait","context":"George Harvey Strait (born May 18, 1952) is an American country music singer, songwriter, actor, and music producer. He is known as the \\"King of Country\\"[1] and is considered one of the most influential and popular recording artists of all time.[2] He is known for his neotraditionalist country style, cowboy look, and being one of the first and main country artists to bring country music back to its roots and away from the pop country era in the 1980s.\\r\\nStrait's success began when his first single \\"Unwound\\" was a hit in 1981. During the 1980s, seven of his albums reached number one on the country charts. In the 2000s, Strait was named Artist of the Decade by the Academy of Country Music, was elected into the Country Music Hall of Fame, and won his first Grammy award for the album Troubadour. Strait was named CMA Entertainer of the Year in 1989, 1990 and 2013, and ACM Entertainer of the Year in 1990 and 2014. He has been nominated for more CMA and ACM awards and has more wins in both categories than any other artist.\\r\\nBy 2009, he broke Conway Twitty's previous record for the most number-one hits on Billboard's Hot Country Songs chart when his 44 number one singles surpassed Twitty's 40.[3] Counting all music charts, Strait has amassed a total of 60 number-one hits, breaking a record also previously set by Twitty, and giving him more number one songs than any other artist in any genre of music.[4]\\r\\nStrait is also known for his touring career when he designed a 360- degree configuration and introduced festival style tours. For example, the Strait Tours earned $99 million in three years.[5] His concert at AT&T Stadium in Arlington, TX in June 2014 drew 104,793 people, marking a new record for largest indoor concert in North America.[6] Strait was successful innovating country music and in numerous aspects of being a part of popular music.\\r\\nStrait has sold more than 100 million records worldwide,[7] making him one of the best-selling music artists of all time. His certifications from the RIAA include 13 multi-platinum, 33 platinum, and 38 gold albums. His best-selling album is Pure Country (1992), which sold 6 million (6G platinum). His highest certified album is Strait Out of the Box (1995), which sold 2 million copies (8G Platinum due to being a box set with four CDs). According to the RIAA, Strait is the 12th best-selling album recording artist in the United States overall.\\r\\n\\r\\n\\r\\nGeorge Harvey Strait was born on May 18, 1952, in Poteet, Texas,[8] to John Byron Strait, Sr. (January 11, 1922 ÿ June 4, 2013),[9] and Doris Jean Couser (June 26, 1930 ÿ January 30, 2010). He grew up in nearby Pearsall, in Frio County,[8] where his father was a junior high school mathematics teacher and the owner of a 2,000-acre (810?ha) cattle ranch outside of Big Wells, Texas.[8] The family worked at the ranch on the weekends and in the summers.[8] When George was in the fourth grade, his father and mother were divorced, and his mother moved away with his sister, Pency. George and his brother John, Jr., or \\"Buddy\\" (1950ÿ2009), were raised by their father.[10]\\r\\nStrait began his musical interest while attending Pearsall High School, where he played in a rock and roll garage band. The Beatles were popular when Strait was in high school. \\"The Beatles were big\\", Strait confirmed. \\"I listened to them a lot and that whole bunch of groups that were popular then\\". His musical preference soon turned to country with singers Hank Thompson, Lefty Frizzell, Merle Haggard, George Jones, Bob Wills, Hank Williams, and Frank Sinatra influencing his style. Strait did not tune to the country music radio often as a youth, usually listening to the news and the farmer's report. His introduction to country music came mostly by way of live performances, which, according to Strait, could be heard in every town in Texas.[11] He eloped with his high school sweetheart, Norma. The couple initially married in Mexico on December 4, 1971. That same year, he enlisted in the United States Army. While stationed at Schofield Barracks in Hawaii as a part of the 25th Infantry Division, Strait began performing with a U.S. Army-sponsored band, \\"Rambling Country\\", which played off-base under the name \\"Santee\\".[10] On October 6, 1972, while still in Hawaii, George and Norma had their first child, Jennifer.\\r\\nAfter Strait was honorably discharged from the Army in 1975, he enrolled at Southwest Texas State University in San Marcos and graduated with a degree in agriculture.\\r\\nDuring his college years, Strait joined the country band Stoney Ridge, answering a flyer the band posted around campus looking for a new vocalist. Strait renamed the group the Ace in the Hole Band and quickly became the lead; they began to perform at different honky-tonks and bars around south and central Texas, traveling as far east as Huntsville and Houston.[12] They gained a regional following and opened for national acts such as The Texas Playboys. Soon, his band was given the opportunity to record several Strait-penned singles including \\"That Don't Change The Way I Feel About You,\\" and \\"I Can't Go On Dying Like This\\" for the Houston-based D label. However, the songs never achieved wide recognition, and Strait continued to manage his family cattle ranch during the day in order to make some extra cash.[12][13]\\r\\nWhile he continued to play with his band, without any real connections to the recording industry, Strait became friends with Erv Woolsey, who operated one of the bars in which the Ace in the Hole band played, and who had previously worked for the major label MCA Records. Woolsey convinced some of his Music Row (Nashville, TN) connections to come to Texas and to listen to Strait and his band play. Impressed with the performance, but concerned that they couldn't market the Western Swing sound that the band featured, they left without a deal. After several unsuccessful trips to Nashville in search of a record deal in which Strait was turned down by every label in town, he considered giving up music altogether. He was offered a job designing cattle pens and decided to take it. He gave the band notice that he was leaving, but after a discussion with his wife, she convinced him to give music one more year. Not long afterward, MCA signed Strait to a recording contract in February 1981. The initial deal was for one song. If the single did well, the label would then consider doing an album.[14] The Ace in the Hole band remained with Strait, performing as the backup and touring band for the now solo act.[13]\\r\\nIn the spring of 1981, Strait released his first single for MCA Records, entitled \\"Unwound\\", which climbed to #6 on the Billboard Hot Country Songs chart that year, and was included on his debut album Strait Country. The record featured two more singles including \\"Down and Out\\", a No.?16 hit for Strait, and \\"If You're Thinking You Want a Stranger (There's One Coming Home)\\", which reached number three early in 1982, sparking a string of Top Ten hits that ran well into the 1990s.[15] Strait Country was hailed by critics as a traditionalist breakthrough that broke the trend of pop-influenced country prevalent at the time.[15] The year 1982 also saw the release of Strait's second album, the critically acclaimed Strait from the Heart, which featured the first number one single of his career, \\"Fool Hearted Memory\\", and the top five \\"Amarillo by Morning\\", regarded by many as one of the greatest country songs of all-time.[citation needed] In 1983, Strait made his first appearance at the Houston Livestock Show and Rodeo when the headlining star, Eddie Rabbitt, came down sick with the flu. Performing at that rodeo has since become a mainstay throughout his career, making more than twenty appearances at the Rodeo, and playing to a total of more than one million fans.\\r\\nStrait recorded 17 subsequent No.?1's in the decade, including a string of five that lasted from 1983ÿ84[16] from his next two albums Right or Wrong, his first number one album and the CMA award-winning Does Fort Worth Ever Cross Your Mind. The next year, he won the CMA award for top male vocalist, and released his first Greatest hits compilation, which featured songs from his first three albums. Also in 1985, Strait released Something Special, the third straight number-one album of his career, featuring the number-one single \\"The Chair\\".[15] In 1986, Strait repeated as the CMA vocalist of the year and released his fourth No.?1 album #7.\\r\\nStrait and his family were struck with tragedy when his 13-year-old daughter, Jenifer, was killed in a one-car non-alcohol-related accident. She was riding in a Ford Mustang driven by Gregory Wilson Allen, 18, of Staples, Texas. He was subsequently charged with a Class A misdemeanor for vehicular homicide. Mike Cox, spokesman for the Texas Department of Public Safety in Austin, said \\"The responding trooper determined the cause of accident to be excessive speed and that the car did not negotiate the turn properly. Jenifer was riding in the front passengers seat and none of the four occupants were wearing seat belts at the time.[17] When the vehicle flipped over onto its passenger's side, Jenifer was partially ejected, causing her to be dead upon impact.[17][18] The incident caused Strait to greatly limit his contact with the media. He stopped doing interviews for many years after the accident as he and his family did not wish to discuss Jenifer's death.\\r\\nHis grief did not hinder his performance, however, or his output, as he went on to release 11 straight No.?1 hits, starting with \\"Nobody in His Right Mind Would've Left Her\\" in 1986 and ending with \\"Ace in the Hole\\" in 1989.[16] The singles spanned four albums, including #7, Ocean Front Property in 1987, If You Ain't Lovin' You Ain't Livin' in 1988 and 1989's Beyond the Blue Neon, all of which reached the number one spot on country album charts. Ocean Front Property was the first country album to ever debut at No.?1 on the charts by any artist. The streak included such songs as \\"Ocean Front Property\\", \\"All My Ex's Live in Texas\\", \\"Famous Last Words of a Fool\\" and \\"Baby Blue\\". Strait finished the decade by winning the CMA Entertainer of the Year award in 1989. A year later, he won the award again.[15]\\r\\nStrait began the decade with the release of his tenth studio album, Livin' It Up, which featured two No.?1 hits including \\"Love Without End, Amen\\", his first multi-week hit, and \\"I've Come to Expect It From You\\". Both songs remained No.?1 for five weeks in 1990. Chill of an Early Fall shortly followed in 1991, and received positive reviews. Entertainment Weekly noted that the album marked a shift for Strait from \\"repeating himself\\" in his previous works to producing different material.[19] It produced the No.?1's \\"If I Know Me\\" and \\"You Know Me Better Than That\\", but ended his streak of 31 straight top ten hits with the cover of \\"Lovesick Blues\\", which peaked at No.?24. The record blocked his run of eight top charting albums with its peak of No.?4. In the spring of 1992, Holding My Own was released. It did not produce any No.?1s but did include two top five songs including \\"So Much Like My Dad\\".\\r\\nLater in 1992, Strait played the main character in the movie Pure Country, and released the film's soundtrack. It was his most successful studio album, producing such hits as \\"Heartland\\", \\"I Cross My Heart\\", and \\"When Did You Stop Loving Me\\", and peaked at No.?1 and No.?6 respectively on the Country and Billboard 200 album charts. The success continued with his next album, Easy Come, Easy Go in 1993, which reached the top five on the Billboard 200 and featured the hits \\"I'd Like to Have That One Back\\", \\"The Man in Love with You\\", and the No.?1 title track. His next four albums, including Lead On in 1994, Blue Clear Sky in 1996, Carrying Your Love with Me in 1997, and 1998's One Step at a Time, all charted at No.?1, with Blue Clear Sky claiming the spot on its debut week, and Carrying Your Love with Me peaking at No.?1 on the Billboard 200 for the first time in Strait's career. This series of albums produced eight number one singles for Strait, including \\"You Can't Make a Heart Love Somebody\\", \\"Carried Away\\", \\"One Night at a Time\\", and \\"I Just Want to Dance with You\\".[15]\\r\\nDuring this period, Strait also released a four-disc box set career retrospective, Strait Out of the Box, in 1995, which became the second-best-selling box set ever with shipments of 8 million in the United States. He also was named as the CMA's Top Male Vocalist in 1997 and 1998.[15] Starting in '97, and continuing until the first year of the 21st century, Strait headlined the George Strait Country Music Festival, which included artists such as Tim McGraw, Faith Hill, Kenny Chesney, Alan Jackson, and others. In an effort to introduce these acts to as many fans as possible, the festival promised not to visit any market more than twice. It played only a small number of dates, usually no more than twenty a year, but still managed to be the ninth-biggest-grossing tour of 1998. In 2009, the George Strait Country Music Festival was voted the most important tour in the history of country music and the best selling country music tour in the 90s.\\r\\nStrait completed the decade with the album Always Never the Same in 1999, which peaked at No.?2 on country charts and matched the cross-over success of Pure Country by reaching No.?6 on the Billboard 200. The record produced the hits \\"What Do You Say to That\\", \\"Meanwhile\\", and the No.?1 \\"Write This Down\\". Reviews of the album's material were generally moderate, but Entertainment Weekly observed that at this point in his career, Strait could record the \\"most lightweight\\" material and \\"make it soar\\" on the radio with his \\"grace\\".[19] All in all, Strait scored 17 No. 1 hits on the Billboard country airplay charts in the decade, and carried his successes into the next century.[10]\\r\\nStrait released a self-named album in 2000, which despite a No.?1 and No.?7 showing on the country and Billboard 200 album charts, produced no No.?1 singles, and was the first studio album of his career to not be certified platinum. The singles \\"Go On\\" and \\"If You Can Do Anything Else\\" were released from the record, with both peaking in the top five. In May 2001, The Road Less Traveled was released. Reviews for the album were mostly positive, Rolling Stone described it as sticking to the formula \\"but adds a few twists that make it superior to his last few releases.\\"[20] It featured \\"vocal processing\\", and was considered by some critics as an experimental album.[13]\\r\\nThree singles were released from it, two of which reached No.?1, including \\"She'll Leave You with a Smile\\", his 50th on combined charts and \\"Living and Living Well\\", both of which reached the top 30 of Billboard Hot 100, with the former peaking at No.?23, Strait's highest rank on the chart. The single \\"Run\\" peaked at No.?2 and reached No.?34 on the Billboard 100. Strait released two records in 2003. For the Last Time: Live from the Astrodome was a recording of the last Houston Livestock Show and Rodeo to take place in the Astrodome. The performance itself, set the record for paid attendance at the venue, with 68,266 people, breaking Latin superstar Selena's previous record of approximately 67,000 in 1995.\\r\\nHis next album, Honkytonkville was described as \\"a fiery set of hard country\\", and was praised \\"for its mixture of the old Strait with his modern, superstar self.\\"[13] It didn't produce any No.?1's for Strait but included the hits \\"Cowboys Like Us\\" and a cover of Bruce Robison's \\"Desperately\\". His 2004 performance at Reliant Stadium set a new Rodeo attendance record, with 68,679 spectators. That year he issued a Greatest Hits package billed as 50 Number Ones, chronicling the No.?1 hits of his career from all charts, starting with \\"Fool Hearted Memory\\" and ending with \\"She'll Leave You With a Smile.\\" A new track, \\"I Hate Everything\\", was also included, and became his 51st overall Number One in 2004. The next year, Somewhere Down in Texas arrived, which produced the hit \\"You'll Be There,\\" marking Strait's first appearance on the Adult Contemporary chart. The next year, he embarked on a tour that included only 18 performances but grossed over $15 million. He attributed this success to the fact that he and his band are \\"musically very tight,\\" have a large pool of songs to draw from, and perform those songs very similarly to how they sound on their albums.[21]\\r\\nOn October 3, 2006, Strait marked his 30th year in the music industry with the release of a new album titled It Just Comes Natural. The album was recorded in Key West, Fla. in Jimmy Buffett's Shrimp Boat Sound Studio (said to be a better recording location due to lack of allergy flare ups during recording process), which was also the recording location of \\"Troubadour\\". It featured fifteen new songs. Strait's long-time friend and songwriter, Dean Dillon co-wrote two of the songs on the album. It received generally positive reviews from critics. People, in their four-star review, remarked that \\"If ever there was a natural in country music, it's Strait,\\" while USA Today raved that \\"he continues to make such consistent quality look easy\\". The first single from the album, \\"Give It Away\\" reached No.?1, making one of its co-writers, country legend \\"Whispering Bill\\" Anderson, the first songwriter to have a #1 hit in five different decades. The title track, \\"It Just Comes Natural\\" became his 42nd Billboard No.?1.\\r\\nIn 2007, \\"Wrapped\\" reached No. 1 on the Mediabase 24/7 country music charts, giving Strait his 55th overall number-one single. From January through April of that year, Strait headlined a 23-date arena tour with country music legend Ronnie Milsap and then newcomer Taylor Swift. He released a new album titled Troubadour on April 1, 2008. The CD contained 12 tracks, including a duet with Patty Loveless and another with long-time songwriter Dean Dillon. The lead single from the album, \\"I Saw God Today\\", debuted at No.?19 on the Radio and Records and Billboard charts. It is the highest debut ever for a single from Strait and the fourth highest debut for a song in country music history. Troubadour debuted at No.?1 on the Billboard Top 200 album charts, selling over 160,000 copies in its first week of release. \\"River of Love\\" the 3rd single from the album became his 57th number-one song in 2009.[22]\\r\\nIn April 2009, Strait was honored by the Academy of Country Music with the Artist of the Decade Award, which was presented to Strait by the previous ACM Artist of the Decade, Garth Brooks. In June of that year he headlined the first event at the new Dallas Cowboys Stadium in Arlington, Texas. Strait's single \\"Living for the Night\\" was released on May 28, 2009, and was written by Strait, his son Bubba, and Dean Dillon. The song was the lead single from his album Twang, released on August 11, 2009. Twang was certified gold for selling over 500,000 copies. In 2010, Billboard ranked Strait No.?1 in the top 25 country artists of the past 25 years.[23]\\r\\nOn September 6, 2011, Strait released the album, Here for a Good Time, which yielded two No.?1 singles\\"Here for a Good Time\\" and \\"Love's Gonna Make It Alright\\"bringing Strait's No.?1 singles total to 59. The album's third single, \\"Drinkin' Man\\", was less successful, peaking at No.?37.\\r\\nIn October 2012, Strait released the single \\"Give It All We Got Tonight\\",[24] which was included on his album Love Is Everything, released on May 14, 2013. The song initiated a \\"60 for 60\\" movement by Strait's label, to make the song his sixtieth number-one single on all country charts while he was still 60 years old.[25] The song reached the top of the Mediabase charts in May 2013. The album's next single \\"I Believe\\" reached No.?50 on The U.S. Country Airplay chart, making it Strait's first single to miss the Top 40. Strait won the 2013 CMA Entertainer of the Year award.\\r\\nIn November 2013, Billboard presented Strait with its Legend of Live honor during the 10th annual Billboard Touring Awards ceremony.[26] The award honors the concert industry's top artist based on Billboard's Boxscore chart and box office performance.[27] Strait is the first country artist to receive Billboard's highest touring accolade.[28] On April 19, 2015, Strait made a guest appearance at the 2015 ACM Awards, he performed \\"All My Ex's Lives In Texas\\" and his new single \\"Let it Go\\".[29]\\r\\nIn 2016, Strait was selected as one of 30 artists to perform on \\"Forever Country\\", a mash-up track of Take Me Home, Country Roads, On the Road Again and I Will Always Love You which celebrates 50 years of the CMA Awards.[30]\\r\\nOn September 26, 2012, Strait announced that he was retiring from touring, and that his Cowboy Rides Away Tour would be his last.[31][32][33] Tickets for both arenas and stadiums on the Cowboy Rides Away Tour sold out in a matter of hours. The tour started on January 18, 2013 in Lubbock, Texas and was divided into two legs: 21 concerts in 2013 and 26 concerts in 2014, for a total of 47 concerts. The tour ended in Arlington, Texas on June 7, 2014. Strait was supported on the tour by his longtime eleven-member touring group, the Ace in the Hole Band. For the 2013 leg, Martina McBride was the opening performer.[31]\\r\\nOn January 9, 2014, Strait initiated the second leg of the tour, which featured the opening performers Jason Aldean, Eric Church, Martina McBride, Miranda Lambert, Little Big Town, Vince Gill, Sheryl Crow, Lee Ann Womack, Merle Haggard, Chris Young, Ronnie Dunn, Luke Bryan, Tim McGraw, Faith Hill, Kenny Chesney, Alan Jackson, and Asleep at the Wheel.[34] Many of these performers gathered together for the tour's final concert in Arlington, Texas, before 104,793 fansthe largest ticketed attendance at a single-show concert in the United States.[35] The concert also set a record for the largest gross at a single-show country concert, $18,194,374.[35]\\r\\nA live album recorded from the final concert in Arlington titled The Cowboy Rides Away: Live from AT&T Stadium was released on September 16, 2014, with a DVD/CDs of the concert being released on November 10, 2014, with Wal-mart exclusively releasing a Deluxe edition including 2?cd's as well. This Deluxe DVD is the entire 3+ hour concert and the accompanying 2?cd's have 28 of the 40 songs sung that night.[36] On August 29, 2014, the Country Music Television channel broadcast a two-hour concert special of the event titled George Strait: The Cowboy Rides Away.[36] This CMT concert special had 1-1/4 hours of music from the 3+ hour concert, and interviews.\\r\\nStrait eloped to Mexico with his high school sweetheart Norma in December 1971. Their first child, Jenifer, was born on October 6, 1972. Their son, George Strait Jr., known as \\"Bubba\\", was born in 1981.[37] Jenifer was killed in an automobile accident in San Marcos on June 25, 1986, at age 13. The family set up the Jenifer Lynn Strait Foundation, which donates money to children's charities in the San Antonio area.[38] Bubba, who is a graduate of Texas A&M in College Station, used to compete as a Professional Rodeo Cowboys Association (PRCA) team roping competitor.[39] Strait was able to watch his son compete at the Houston Livestock Show and Rodeo in 2006 shortly before taking the stage for his own performance.\\r\\nStrait enjoys fishing, skiing, and playing golf. Along with his son, he is a member of the PRCA and partners in team roping competitions. George and his elder brother John Jr., known as Buddy, hosted the annual George Strait Team Roping Classic, in which they competed against some of the best team ropers in the world. Strait has also said that he very seldom picks up a guitar when not in the studio or touring. He and his wife live in northwest San Antonio in a master-planned community known as The Dominion. He also owns a ranch near Cotulla in La Salle County between San Antonio and Laredo. Strait is a fan of the NBA's San Antonio Spurs and can be seen court-side at many of the Spurs' home basketball games.\\r\\nSince 2010, Strait has served as spokesman for the Wrangler National Patriot program, a campaign designed to raise awareness and funds for America's wounded and fallen military veterans and their families.[40] Strait says, \\"I've been a part of the Wrangler family for a long time... when they came to me with the idea for supporting fallen and wounded American veterans and their families, I knew I wanted to get involved.\\"[40] In February 2012, Strait became a grandfather when George Strait, Jr. and his wife Tamara had their first child, a son. According to reports, he was named George H. Strait, III as a tribute to his famous grandfather.[41] The grandson is known as Harvey, from the middle name he shares with father and grandfather, but is also called \\"Bubba\\".\\r\\nStrait owns a Bombardier Challenger 300 business jet and carries a personal registration N518GS.[42] His personal aircraft is housed at the Landmark Aviation facility in San Antonio.[citation needed] Strait was raised in the Baptist Church. He is believed to be a Republican but does not discuss political issues in public.[43]\\r\\nIn more than 30 years of recording, all of which have been spent with MCA Records, George Strait has garnered 61 No. 1 songs on all country charts (including Mediabase 24/7, the former Radio & Records chart, and the now-defunct Gavin Report chart), and has more No.?1 hits than any other artist in any genre. His 45 Billboard country number 1 hits are a record, four more than Conway Twitty's total that includes several duets with Loretta Lynn.[44] Additionally, Strait is also the first artist in the history of Billboard to have at least one single enter the Top 10 of a Billboard chart for 30 consecutive years, starting in 1981 when his debut single \\"Unwound\\" peaked at No.?6 on the Hot Country Singles chart. All of his Top 10 singles have been on that chart.[45] Strait has sold more than 68 million records in the United States alone[46] and his certifications from the RIAA include 13 multi-platinum, 33 platinum, and 38 gold albums.[47]\\r\\nStrait has acted in several films. He had a bit part in The Soldier (1982) and starred in Pure Country (1992). He also appeared as himself in Grand Champion (2002).\\r\\nThe film Pure Country featured George Strait in the lead role as Dusty Chandler, a famous country singer who strays too far from his country roots and traditional sound. It provided the opportunity for Strait to branch out from his own traditional country sound for a more rock-and-roll approach. The film saw little success at the box office, taking in only $15 million, but the soundtrack, also called Pure Country, produced several hit singles for Strait, and has become his best-selling album to date. Strait had a limited role in the sequel to Pure Country, Pure Country 2: The Gift.[48]\\r\\nStrait holds the record for most number one albums and singles, gold albums, platinum albums, and multi-platinum in the history of country music, and is eleventh in the most number one albums in all other genres. Strait is third only to Elvis Presley and The Beatles with the most gold and platinum albums in the history of music.[49] Strait has been certified as the twelfth best selling artist in American history, with career record sales of 70 million.[50]\\r\\nStrait has recorded the most number one songs and top five songs in the history of music of any kind, and is the only artist in the history of music of any kind to have a top ten hit every year for 30 years. He is also second all-time in top ten hits in the history of music, currently 5 away from breaking the all-time record held by Eddy Arnold who had 92 in his historic career. Strait has also won 22 CMA Awards, including consecutive Entertainer of the Year honors in 1989 and 1990, and also just recently won that same honor in 2013 (and is the only artist to win the top honor in three different decades) and holds the career record for CMA nominations (as a whole) and the most consecutively of all time.\\r\\nAs of 2009 he holds the record for the most CMA awards. Strait also holds those same records for wins and nominations for the ACM Awards. Strait was elected into the Country Music Hall of Fame in 2006, performing his then-latest No. 1 hit \\"Give it Away\\" right before accepting his replica Hall of Fame plaque at the 40th CMA Awards. He was only the second artist (after Eddy Arnold in 1966) to be inducted into the Hall of Fame while still actively recording and producing chart-topping hits and albums.\\r\\nAs of June 8, 2010, Strait was named the top country music artist of the past 25 years according to Billboard. In October 2008, the Academy of Country Music Awards named Strait their Artist of the Decade for the 2000s. He was presented the award by the previous winner Garth Brooks. Past winners of the award are Marty Robbins (1960s), Loretta Lynn (1970s), Alabama (1980s) and Garth Brooks (1990s).[51] And with the win of the entertainer of the year award in 2013 he is the only artist to ever win the entertainer of the year in three different decades and also was the oldest winner. The win is currently the longest span between wins for that award as well. Strait is also tied with Merle Haggard for the most male vocalist of the year awards.\\r\\nOn June 1, 2013, Strait appeared in The Alamodome, in San Antonio, Texas, before seventy thousand fans in the last concert of the first half of his two-year farewell tour. Governor Rick Perry, who was in attendance with First Lady Anita Thigpen Perry, announced that henceforth May 18, Strait's birthday, would be \\"George Strait Day\\" in Texas.[52]","input":"Who is the current king of country music?"},{"output":"Nat Hickey","context":"This is a list of oldest and youngest National Basketball Association players. The National Basketball Association (NBA) is a men's professional basketball league in North America. The NBA was founded in 1946 as the Basketball Association of America (BAA).[1] The league adopted its current name at the start of the 1949ÿ50?season when it merged with the National Basketball League (NBL).[2]\\r\\nThe oldest person ever to play in the NBA was Nat Hickey, a coach who activated himself as a player for a game two days before his 46th birthday. The youngest player ever to play in the NBA was Andrew Bynum, who played his first game six days after his 18th birthday. The oldest active player is Sacramento Kings guard/forward Vince Carter, who is currently 40 years old. The youngest active player in the NBA is Indiana Pacers forward/center Ike Anigbogu, the 47th pick in the 2017 NBA draft, who is currently 19 years old and became the second college player to go from one year of college to the NBA while still playing at 18 years old.\\r\\n\\r\\n\\r\\nThe oldest player ever to play in the NBA was Nat Hickey who played one game in the 1947ÿ48 season when he was 45 years and 363 days old.[3] Hickey, who was coaching the Providence Steamrollers at the time, decided to activate himself and played in a game for the Steamrollers. In his first and only game as a player for the Steamrollers, he missed all six of his shot attempts and only scored two points from three free throw attempts.[4] The second oldest player is Kevin Willis. Willis, who had played 20 seasons (excluding the 1988ÿ89 season he missed due to injury) in the league before he sat out the 2005ÿ06 season and earned a contract with the Dallas Mavericks on April 2, 2007.[5] He then played 5 games for the Mavericks at the age of 44.[4] The third oldest player is Hall of Famer Robert Parish. Parish, who starred with the Boston Celtics in the 1980s, played his last season with the Chicago Bulls at the age of 43.[6] He played in 1,611 regular season games during his 21-year career, more than any other player in NBA history.[4] When the Bulls won the 1997 Finals, Parish became the oldest player ever to win the NBA championship. There are currently 27 players who played in the NBA after they turned 40.\\r\\nThe oldest active player is Vince Carter, who is now 40 years old. Carter played his first game in 1999 and is playing his 20th season. Carter along with Manu Gin܇bili, Jason Terry, and Dirk Nowitzki are the only players who were born in 1979 or earlier and are still active and under contract with an NBA team. Eleven players total, however, are born in 1980 or earlier and still play in the NBA.\\r\\nNBA players usually come from U.S. college basketball. In the past, a college player had to complete his four-year college eligibility before he could enter the league through the NBA Draft or as a free agent. In the 1970s, the league began to allow college underclassmen and high school players to enter the league. However, the trend of drafting high school players only began in the mid 1990s. This has led to more younger players entering the league directly after high school graduation. In 2005, the league and the players' union agreed on a new collective bargaining agreement that includes a minimum age limit which requires that players who wish to enter the league must be at least 19 years old on December 31 of the year of the draft, and at least one year removed from high school. International players who did not play college basketball also have to be at least 19 years old on the same date to be able to play in the NBA.[44] Despite a trend toward drafting younger players, the NBA has a higher average age than it had in the 1980s.[45] However, since the NBA introduced the minimum age limit in 2005, the league's average age has decreased in the past few seasons.[46]\\r\\nThe youngest player to ever play in the NBA was Andrew Bynum who played his first game at the age of 18 years and 6 days old.[47] Bynum, who was also the youngest player ever selected in the NBA Draft, went into the NBA straight out of high school.[48] Jermaine O'Neal and Kobe Bryant, both drafted in 1996, were the second and third youngest players. Serbian Darko Mili?i? was the youngest player ever to play in an NBA Finals game.[49] He played for the Detroit Pistons in Game 3 of the 2004 Finals at the age of 18 years and 356 days old. The Pistons won the 2004 Finals and Mili?i? became the youngest player ever to win the NBA championship, being only five days away from his 19th birthday at the time. There are currently 27 players who played in the NBA before they turned 19. 19 of them came to the league straight out of high school, while 6 of them are international players who never played basketball in the U.S. high schools or colleges before they entered the NBA, and two more players ended up playing only a year of college before entering the NBA.\\r\\nThe youngest active player in the NBA is Ike Anigbogu. As a result of the NBA's latest updates on their scheduling policy, he became the second college player to play in the NBA at 18 years old on October 20 against the Portland Trail Blazers. He now joins Devin Booker as the only other player to go from a year of college to the NBA while remaining 18 years old throughout the process. Coincidentally, both of them played their first NBA games at the exact same age of 18 years, 363 days old in order to start their official NBA careers as players of the league, and their first games played would be the only time they'd play in the NBA as 18 year olds.","input":"Who is the oldest nba player in history?"},{"output":"heronry","context":"The great blue heron (Ardea herodias) is a large wading bird in the heron family Ardeidae, common near the shores of open water and in wetlands over most of North America and Central America, as well as the Caribbean and the Galpagos Islands. It is a rare vagrant to coastal Spain, the Azores, and areas of far southern Europe. An all-white population found only in the Caribbean and Florida was once treated as a separate species and known as the great white heron.\\r\\n\\r\\n\\r\\nThe great blue heron was one of the many species originally described by Carl Linnaeus in his 18th-century work, Systema Naturae.[2] The scientific name comes from Latin ardea, and Ancient Greek erodios, both meaning \\"heron\\".[3]\\r\\nThe great blue heron is replaced in the Old World by the very similar grey heron (Ardea cinerea), which differs in being somewhat smaller (90ÿ98?cm (35ÿ39?in)), with a pale gray neck and legs, lacking the browner colors that great blue heron has there. It forms a superspecies with this and also with the cocoi heron from South America, which differs in having more extensive black on the head, and a white breast and neck.\\r\\nThe five subspecies are:[4]\\r\\nIt is the largest North American heron and, among all extant herons, it is surpassed only by the goliath heron (Ardea goliath) and the white-bellied heron (Ardea insignis). It has head-to-tail length of 91ÿ137?cm (36ÿ54?in), a wingspan of 167ÿ201?cm (66ÿ79?in), a height of 115ÿ138?cm (45ÿ54?in), and a weight of 1.82ÿ3.6?kg (4.0ÿ7.9?lb).[5][6][7][8] In British Columbia, adult males averaged 2.48?kg (5.5?lb) and adult females 2.11?kg (4.7?lb).[9] In Nova Scotia and New England, adult herons of both sexes averaged 2.23?kg (4.9?lb),[10] while in Oregon, both sexes averaged 2.09?kg (4.6?lb)[11] Thus, great blue herons are roughly twice as heavy as great egrets (Ardea alba), although only slightly taller than them, but they can weigh about half as much as a large goliath heron.[12]\\r\\nNotable features of great blue herons include slaty (gray with a slight azure blue) flight feathers, red-brown thighs, and a paired red-brown and black stripe up the flanks; the neck is rusty-gray, with black and white streaking down the front; the head is paler, with a nearly white face, and a pair of black or slate plumes runs from just above the eye to the back of the head. The feathers on the lower neck are long and plume-like; it also has plumes on the lower back at the start of the breeding season. The bill is dull yellowish, becoming orange briefly at the start of the breeding season, and the lower legs are gray, also becoming orangey at the start of the breeding season. Immature birds are duller in color, with a dull blackish-gray crown, and the flank pattern is only weakly defined; they have no plumes, and the bill is dull gray-yellow.[4][13][14] Among standard measurements, the wing chord is 43ÿ49.2?cm (16.9ÿ19.4?in), the tail is 15.2ÿ19.5?cm (6.0ÿ7.7?in), the culmen is 12.3ÿ15.2?cm (4.8ÿ6.0?in), and the tarsus is 15.7ÿ21?cm (6.2ÿ8.3?in).[15][16] The heron's stride is around 22?cm (8.7?in), almost in a straight line. Two of the three front toes are generally closer together. In a track, the front toes, as well as the back, often show the small talons.[17]\\r\\nThe subspecies differ only slightly in size and plumage tone, with the exception of subspecies A. h. occidentalis, which also has a distinct white morph, known as the great white heron (not to be confused with the great egret, for which \\"great white heron\\" was once a common name). It is found only in south Florida and some parts of the Caribbean. The great white heron differs from other great blues in bill morphology, head plume length, and in having a total lack of pigment in its plumage. It averages somewhat larger than the sympatric race A. h. wardi and may be the largest race in the species. In a survey of A. h. occidentalis in Florida, males were found to average 3.02?kg (6.7?lb) and females average 2.57?kg (5.7?lb), with a range for both sexes of 2 to 3.39?kg (4.4 to 7.5?lb).[5] This is mainly found near salt water, and was long thought to be a separate species. Birds intermediate between the normal morph and the white morph are known as Wrdemann's heron; these birds resemble a \\"normal\\" great blue with a white head.\\r\\nThe theory that great white herons may be a separate species (A. occidentalis) from the great blue heron has again been given some support by David Sibley.[18]\\r\\nWith nesting material in Illinois\\r\\nThe \\"great white heron\\" could be confused with great egret, but is larger, with yellow legs as opposed to the great egret's black legs. The reddish egret (Egretta rufescens) and little blue heron (Egretta caerulea) could be mistaken for the great blue heron, but are much smaller, and lack white on the head and yellow in the bill. In the southern reaches of its range, the great blue sometimes overlaps in range with the closely related and similarly sized cocoi heron (A. cocoi). The cocoi is distinguished by a striking white neck and solid black crown, but the duller juveniles are more easily confused. More superficially similar is the slightly smaller grey heron, which may sometimes vagrate to the northern coasts of North America. The grey heron (which occupies the same ecological niche in Eurasia as the great blue heron) has very similar plumage, but has a solidly soft-gray neck. Erroneously, the great blue heron is sometimes referred to as a \\"crane\\".\\r\\nThe great blue heron is found throughout most of North America, as far north as Alaska and the southern Canadian provinces in the summer months. In winter, the range extends south through Florida, Mexico, and the Caribbean to South America. Birds east of the Rocky Mountains in the northern part of their range are migratory and winter in the coastal areas of the southern United States, Central America or northern South America. From the southern United States southwards, and on the lower Pacific coast, they are year-round residents.[4] However, their hardiness is such that individuals often remain through cold northern winters, as well, so long as fish-bearing waters remain unfrozen (which may be the case only in flowing water such as streams, creeks, and rivers).\\r\\nThe great blue heron can adapt to almost any wetland habitat in its range. It may be found in numbers in fresh and saltwater marshes, mangrove swamps, flooded meadows, lake edges, or shorelines. It is quite adaptable and may be seen in heavily developed areas as long as they hold bodies of fish-bearing water.\\r\\nGreat blue herons rarely venture far from bodies of water, but are occasionally seen flying over upland areas. They usually nest in trees or bushes near water's edge, often on islands (which minimizes the potential for predation) or partially isolated spots.[19]\\r\\nIt has been recorded as a vagrant in England,[20] Greenland, Hawaii, and the Azores.[4]\\r\\nThe primary food for great blue heron is small fish, though it is also known to opportunistically feed on a wide range of shrimp, crabs, aquatic insects, rodents, and other small mammals, amphibians, reptiles, and birds. Primary prey is variable based on availability and abundance. In Nova Scotia, 98% of the diet was flounders.[10] In British Columbia, the primary prey species are sticklebacks, gunnels, sculpins, and perch.[21] California herons were found to live mostly on sculpin, bass, perch, flounder, and top smelt.[22] Nonpiscine prey is rarely quantitatively important, though one study in Idaho showed that from 24 to 40% of the diet was made up of voles.[23]\\r\\nHerons locate their food by sight and usually swallow it whole. They have been known to choke on prey that is too large.[24][25] It is generally a solitary feeder. Individuals usually forage while standing in water, but also feed in fields or drop from the air, or a perch, into water. Mice are occasionally preyed on in upland areas far from the species' typical aquatic environment.[19] Occasionally, loose feeding flocks form and may be beneficial since they are able to locate schools of fish more easily.[19]\\r\\nAs large wading birds, great blue herons are capable of feeding in deeper waters, thus are able to harvest from niche areas not open to most other heron species. Typically, the great blue heron feeds in shallow waters, usually less than 50?cm (20?in) deep,[19] or at the water's edge during both the night and the day, but especially around dawn and dusk. The most commonly employed hunting technique of the species is wading slowly with its long legs through shallow water and quickly spearing fish or frogs with its long, sharp bill. Although usually ponderous in movements, the great blue heron is adaptable in its fishing methods. Feeding behaviors variably have consisted of standing in one place, probing, pecking, walking at slow speeds, moving quickly, flying short distances and alighting, hovering over water and picking up prey, diving headfirst into the water, alighting on water feet-first, jumping from perches feet-first, and swimming or floating on the surface of the water.[19]\\r\\nFlying heron\\r\\nThis species usually breeds in colonies, in trees close to lakes or other wetlands. Adults generally return to the colony site after winter from December (in warmer climes such as California and Florida) to March (in cooler areas such as Canada). Usually, colonies include only great blue herons, though sometimes they nest alongside other species of herons. These groups are called a heronry (a more specific term than \\"rookery\\"). The size of these colonies may be large, ranging between five and 500 nests per colony, with an average around 160 nests per colony. A heronry is usually relatively close, usually within 4 to 5?km (2.5 to 3.1?mi), to ideal feeding spots.[19] Heronry sites are usually difficult to reach on foot (e.g., islands, trees in swamps, high branches, etc.) to protect from potential mammalian predators. Trees of any type are used when available. When not, herons may nest on the ground, sagebrush, cacti, channel markers, artificial platforms, beaver mounds, and duck blinds. Other waterbirds (especially smaller herons) and, occasionally, even fish and mammal-eating raptors may nest amongst colonies.[26][27]\\r\\nAlthough nests are often reused for many years and herons are socially monogamous within a single breeding season, individuals usually choose new mates each year.[28] Males arrive at colonies first and settle on nests, where they court females; most males choose a different nest each year.[28] Great blue herons build a bulky stick nest. Nests are usually around 50?cm (20?in) across when first constructed, but can grow to more than 120?cm (47?in) in width and 90?cm (35?in) deep with repeated use and additional construction.[29] If the nest is abandoned or destroyed, the female may lay a replacement clutch. Reproduction is negatively affected by human disturbance, particularly during the beginning of nesting. Repeated human intrusion into nesting areas often results in nest failure, with abandonment of eggs or chicks. However, Vancouver B.C. Canada's Stanley Park has had a healthy colony for some years right near its main entrance and tennis courts adjacent to English Bay and not far from Lost Lagoon.[30] The park's colony has had as many as 183 nests.[31]\\r\\nThe female lays three to six pale blue eggs. Eggs can measure from 50.7 to 76.5?mm (2.00 to 3.01?in) in length and 29 to 50.5?mm (1.14 to 1.99?in) in width, though the smallest eggs in the above sample may have been consider \\"runt eggs\\" too small to produce viable young. Egg weight ranges from 61 to 80?g (2.2 to 2.8?oz).[32] One brood is raised each year. First broods are laid generally from March to April.[33][34] Eggs are usually laid at two-day intervals, incubated around 27 days, and hatch asynchronously over a period of several days.[28] Males incubate for about 10.5 hours of each day, while females usually incubate for the remainder of each day and the night, with eggs left without incubation for about 6 minutes of each hour.[28]\\r\\nThe first chick to hatch usually becomes more experienced in food handling and aggressive interactions with siblings, so often grows more quickly than the other chicks.[35] Both parents feed the young at the nest by regurgitating food. Parent birds have been shown to consume up to four times as much food when they are feeding young chicks (about 4300 kJ/day) than when laying or incubating eggs (about 1200 kJ/day).[28] By the time they are 45 days old, the young weigh 86% of the adult's mass.[36] After about 55 days at the northern edge of the range (Alberta) and 80 days at the southern edge of the range (California), young herons take their first flight.[28] They return to the nest to be fed for about another 3 weeks, following adults back from foraging grounds, and are likely to gradually disperse away from their original nest over the course of the ensuing winter.[28] Young herons are not as successful at fish capture as adults, as strike rates are similar, but capture rates are about half that of adults during the first 2 months after fledging.[28]\\r\\nPredators of eggs and nestlings include turkey vultures (Cathartes aura), common ravens (Corvus corax), and American crows (Corvus brachyrhynchos). Red-tailed hawks (Buteo jamaicensis), American black bears (Ursus americanus), and raccoons (Procyon lotor) are known to take larger nestlings or fledglings and, in the latter predator, many eggs.[9][37][38][39] Adult herons, due to their size, have few natural predators, but a few of the larger avian predators have been known to kill both young and adults, including bald eagles (Haliaeetus leucocephalus) (the only predator known to attack great blue herons at every stage of their lifecycle from in the egg to adulthood), golden eagles (Aquila chrysaetos) and, less frequently, great horned owls (Bubo virginianus) and Harris's hawks (Parabuteo unicinctus).[40][41][42][43][44]\\r\\nAn occasional adult heron or, more likely, an unsteady fledgling may be snatched by an American alligator (Alligator mississippiensis) or an American crocodile (Crocodylus acutus). Using its considerable size and dagger-like bill, a full-grown heron can be a formidable foe to a predator. In one instance, during an act of attempted predation by a golden eagle, a heron was able to mortally wound the eagle although it succumbed to injures sustained in the fight.[45] When predation on an adult or chick occurs at a breeding colony, the colony can sometimes be abandoned by the other birds. The primary source of disturbance and breeding failures at heronries is human activities, mostly through human recreation or habitat destruction, as well as by egg-collectors and hunters.[21][46]\\r\\nJohn James Audubon illustrates the great blue heron in Birds of America, Second Edition (published, London 1827ÿ38) as Plate 161. The image was engraved and colored by Robert Havell's, London workshops. The original watercolor by Audubon was purchased by the New-York Historical Society.[citation needed]\\r\\n\\r\\nFlying heron\\r\\nGreat Blue Heron, Saguenay-Lac-Saint-Jean, Quebec, Canada\\r\\nWading at Grande Lakes Audubon Cooperative Wildlife Sanctuary, Orlando, FL\\r\\nEating a common snapping turtle (Chelydra serpentina) hatchling\\r\\nProfile of the head of a great blue heron: The sharp bill is useful for spearing fish and frogs.\\r\\nTwo great blue herons in synchronous flight\\r\\nGreat Blue Heron landing the Bombay Hook National Wildlife Refuge in Delaware","input":"What is a group of blue herons called?"},{"output":"Trivia","context":"Hecate or Hekate (/?h?k?ti?/; Greek ?? Hekt) is a goddess in Ancient Greek religion and mythology, most often shown holding a pair of torches or a key[1] and in later periods depicted in triple form. She was variously associated with crossroads, entrance-ways, light, magic, witchcraft, knowledge of herbs and poisonous plants, ghosts, necromancy, and sorcery.[2][3] She appears in the Homeric Hymn to Demeter and in Hesiod's Theogony, where she is promoted strongly as a great goddess. The place of origin of her following is uncertain, but it is thought that she had popular followings in Thrace.[4] She was one of the main deities worshiped in Athenian households as a protective goddess and one who bestowed prosperity and daily blessings on the family.[5] In the post-Christian writings of the Chaldean Oracles (2ndÿ3rd century CE) she was regarded with (some) rulership over earth, sea, and sky, as well as a more universal role as Saviour (Soteira), Mother of Angels and the Cosmic World Soul.[6][7] Regarding the nature of her cult, it has been remarked, \\"she is more at home on the fringes than in the center of Greek polytheism. Intrinsically ambivalent and polymorphous, she straddles conventional boundaries and eludes definition.\\"[8]\\r\\n\\r\\n\\r\\nThe etymology of the name Hecate (??, Hekt) is not known. Suggested derivations include:\\r\\nIn Early Modern English, the name was also pronounced disyllabically (as /?h?k?t/) and sometimes spelled Hecat. It remained common practice in English to pronounce her name in two syllables, even when spelled with final e, well into the 19th century.[citation needed]\\r\\nThe spelling Hecat is due to Arthur Golding's 1567 translation of Ovid's Metamorphoses,[14] and this spelling without the final E later appears in plays of the Elizabethan-Jacobean period.[15] Webster's Dictionary of 1866 particularly credits the influence of Shakespeare for the then-predominant disyllabic pronunciation of the name.[16]\\r\\nHecate may have originated among the Carians of Anatolia, where variants of her name are found as names given to children. Hecate was also worshipped in the ancient city of Colchis. William Berg observes, \\"Since children are not called after spooks, it is safe to assume that Carian theophoric names involving hekat- refer to a major deity free from the dark and unsavoury ties to the underworld and to witchcraft associated with the Hecate of classical Athens.\\"[17] In particular, there is some evidence that she might be derived from the local sun goddesses (see also Arinna), based on similar attributes.[18] She also closely parallels the Roman goddess Trivia, with whom she was identified in Rome.\\r\\nHer most important sanctuary was Lagina, a theocratic city-state in which the goddess was served by eunuchs.[4] Lagina, where the famous temple of Hecate drew great festal assemblies every year, lay close to the originally Macedonian colony of Stratonikeia, where she was the city's patroness.[19] In Thrace she played a role similar to that of lesser-Hermes, namely a governess of liminal regions (particularly gates) and the wilderness.\\r\\nAs Hecate Phosphorus (Venus) she is said to have lit the sky during the Siege of Philip II in 340, revealing the attack to its inhabitants. The Byzantines dedicated a statue to her as the \\"lamp carrier.\\"[27]\\r\\nThe earliest Greek depictions of Hecate were not three-formed. Farnell states: \\"The evidence of the monuments as to the character and significance of Hecate is almost as full as that of to express her manifold and mystic nature.\\"[28]\\r\\nThe earliest known monument is a small terracotta found in Athens, with a dedication to Hecate, in writing of the style of the 6th century. The goddess is seated on a throne with a chaplet bound round her head; she is altogether without attributes and character, and the main historical value of this work, which is evidently of quite a general type and gets a special reference and name merely from the inscription, is that it proves the single shape to be her earlier form, and her recognition at Athens to be earlier than the Persian invasion.[28]\\r\\nThe 2nd-century travel writer Pausanias stated that Hecate was first depicted in triplicate by the sculptor Alkamenes in the Greek Classical period of the late 5th century BCE[3] which was placed before the temple of the Wingless Nike in Athens. Greek anthropomorphic conventions of art resisted representing her with three faces: a votive sculpture from Attica of the 3rd century BCE (illustration, left), shows three single images against a column; round the column of Hecate dance the Charites. Some classical portrayals show her as a triplicate goddess holding a torch, a key, serpents, daggers and numerous other items.[29] Depictions of both a single form Hekate and triple formed, as well as occasional four headed descriptions continued throughout her history.\\r\\nIn Egyptian-inspired Greek esoteric writings connected with Hermes Trismegistus, and in magical papyri of Late Antiquity she is described as having three heads: one dog, one serpent, and one horse. In other representations her animal heads include those of a cow and a boar.[30] Hecate's triplicity is elsewhere expressed in a more Hellenic fashion in the vast frieze of the great Pergamon Altar, now in Berlin, wherein she is shown with three bodies, taking part in the battle with the Titans. In the Argolid, near the shrine of the Dioscuri, Pausanias saw the temple of Hecate opposite the sanctuary of Eileithyia; He reported the image to be the work of Scopas, stating further, \\"This one is of stone, while the bronze images opposite, also of Hecate, were made respectively by Polycleitus and his brother Naucydes, son of Mothon.\\" (Description of Greece 2.22.7)\\r\\nIn the Argonautica, a 3rd-century BCE Alexandrian epic based on early material,[31] Jason placates Hecate in a ritual prescribed by Medea, her priestess: bathed at midnight in a stream of flowing water, and dressed in dark robes, Jason is to dig a round pit and over it cut the throat of an ewe, sacrificing it and then burning it whole on a pyre next to the pit as a holocaust. He is told to sweeten the offering with a libation of honey, then to retreat from the site without looking back, even if he hears the sound of footsteps or barking dogs.[32] All these elements betoken the rites owed to a chthonic deity.\\r\\nA 4th-century BCE marble relief from Crannon in Thessaly was dedicated by a race-horse owner.[33] It shows Hecate, with a hound beside her, placing a wreath on the head of a mare. She is commonly attended by a dog or dogs, and the most common form of offering was to leave meat at a crossroads. Images of her attended by a dog[34] are also found at times when she is shown as in her role as mother goddess with child, and when she is depicted alongside the god Hermes and the goddess Kybele in reliefs.[35]\\r\\nHecate has been characterized as a pre-Olympian chthonic goddess.\\r\\nThe first literature mentioning Hecate is the Theogony by Hesiod:\\r\\nAnd she conceived and bore Hecate whom Zeus the son of Cronos honored above all. He gave her splendid gifts, to have a share of the earth and the unfruitful sea. She received honor also in starry heaven, and is honored exceedingly by the deathless gods. For to this day, whenever any one of men on earth offers rich sacrifices and prays for favor according to custom, he calls upon Hecate. Great honor comes full easily to him whose prayers the goddess receives favorably, and she bestows wealth upon him; for the power surely is with her. For as many as were born of Earth and Ocean amongst all these she has her due portion. The son of Cronos did her no wrong nor took anything away of all that was her portion among the former Titan gods: but she holds, as the division was at the first from the beginning, privilege both in earth, and in heaven, and in sea.[36]\\r\\nAccording to Hesiod, she held sway over many things:\\r\\nWhom she will she greatly aids and advances: she sits by worshipful kings in judgement, and in the assembly whom she will is distinguished among the people. And when men arm themselves for the battle that destroys men, then the goddess is at hand to give victory and grant glory readily to whom she will. Good is she also when men contend at the games, for there too the goddess is with them and profits them: and he who by might and strength gets the victory wins the rich prize easily with joy, and brings glory to his parents. And she is good to stand by horsemen, whom she will: and to those whose business is in the grey discomfortable sea, and who pray to Hecate and the loud-crashing Earth-Shaker, easily the glorious goddess gives great catch, and easily she takes it away as soon as seen, if so she will. She is good in the byre with Hermes to increase the stock. The droves of kine and wide herds of goats and flocks of fleecy sheep, if she will, she increases from a few, or makes many to be less. So, then, albeit her mother's only child, she is honored amongst all the deathless gods. And the son of Cronos made her a nurse of the young who after that day saw with their eyes the light of all-seeing Dawn. So from the beginning she is a nurse of the young, and these are her honours.[37]\\r\\nHesiod emphasizes that Hecate was an only child, the daughter of Perses and Asteria, a star-goddess who was the sister of Leto (the mother of Artemis and Apollo). Grandmother of the three cousins was Phoebe the ancient Titaness who personified the moon.\\r\\nHesiod's inclusion and praise of Hecate in the Theogony has been troublesome for scholars, in that he seems to hold her in high regard, while the testimony of other writers, and surviving evidence, suggests that this may have been the exception. One theory is that Hesiod's original village had a substantial Hecate following and that his inclusion of her in the Theogony was a way of adding to her prestige by spreading word of her among his readers.[38] Another theory is that Hekate was mainly a household god and humble household worship could have been more pervasive and yet not mentioned as much as temple worship.[39] In Athens Hecate, along with Zeus, Hermes, Hestia, and Apollo, were very important in daily life as they were the main gods of the household.[5][40] However, it is clear that the special position given to Hecate by Zeus is upheld throughout her history by depictions found on coins depicting Hecate on the hand of Zeus[41] as highlighted in more recent research presented by d'Este and Rankine.[42]\\r\\nHecate possibly originated among the Carians of Anatolia,[4] the region where most theophoric names invoking Hecate, such as Hecataeus or Hecatomnus, the father of Mausolus, are attested,[43] and where Hecate remained a Great Goddess into historical times, at her unrivalled[44] cult site in Lagina. While many researchers favor the idea that she has Anatolian origins, it has been argued that \\"Hecate must have been a Greek goddess.\\"[45] The monuments to Hecate in Phrygia and Caria are numerous but of late date.[46]\\r\\nIf Hecate's cult spread from Anatolia into Greece, it is possible it presented a conflict, as her role was already filled by other more prominent deities in the Greek pantheon, above all by Artemis and Selene. This line of reasoning lies behind the widely accepted hypothesis that she was a foreign deity who was incorporated into the Greek pantheon. Other than in the Theogony, the Greek sources do not offer a consistent story of her parentage, or of her relations in the Greek pantheon: sometimes Hecate is related as a Titaness, and a mighty helper and protector of humans. Her continued presence was explained by asserting that, because she was the only Titan who aided Zeus in the battle of gods and Titans, she was not banished into the underworld realms after their defeat by the Olympians.[citation needed]\\r\\nOne surviving group of stories suggests how Hecate might have come to be incorporated into the Greek pantheon without affecting the privileged position of Artemis.[38] Here, Hecate is a mortal priestess often associated with Iphigeneia. She scorns and insults Artemis, who in retribution eventually brings about the mortal's suicide. There was an area sacred to Hecate in the precincts of the Temple of Artemis at Ephesus, where the priests, megabyzi, officiated.[47]\\r\\nHecate also came to be associated with ghosts, infernal spirits, the dead and sorcery. Shrines to Hecate were placed at doorways to both homes and cities with the belief that it would protect from restless dead and other spirits. Likewise, shrines to Hecate at three way crossroads were created where food offerings were left at the new moon to protect those who did so from spirits and other evils.[48]\\r\\nA medieval commentator has suggested a link connecting the word \\"jinx\\" with Hecate: \\"The Byzantine polymath Michael Psellus [...] speaks of a bullroarer, consisting of a golden sphere, decorated throughout with symbols and whirled on an oxhide thong. He adds that such an instrument is called a iunx (hence \\"jinx\\"), but as for the significance says only that it is ineffable and that the ritual is sacred to Hecate.\\"[49]\\r\\nHecate is the primary feminine figure in the Chaldean Oracles (2nd-3rd century CE),[50] where she is associated in fragment 194 with a strophalos (usually translated as a spinning top, or wheel, used in magic) \\"Labour thou around the Strophalos of Hecate.\\"[51] This appears to refer to a variant of the device mentioned by Psellus.[52]\\r\\nVariations in interpretations of Hecate's role or roles can be traced in 5th-century Athens. In two fragments of Aeschylus she appears as a great goddess. In Sophocles and Euripides she is characterized as the mistress of witchcraft and the Keres.\\r\\nIn the Homeric Hymn to Demeter, Hecate is called the \\"tender-hearted\\", a euphemism perhaps intended to emphasize her concern with the disappearance of Persephone, when she assisted Demeter with her search for Persephone following her abduction by Hades, suggesting that Demeter should speak to the god of the sun, Helios. Subsequently she became Persephone's companion on her yearly journey to and from the realms of Hades; serving as a psychopomp. Because of this association, Hecate was one of the chief goddesses of the Eleusinian Mysteries, alongside Demeter and Persephone.[1]\\r\\nThe modern understanding of Hecate has been strongly influenced by syncretic Hellenistic interpretations. Many of the attributes she was assigned in this period appear to have an older basis. For example, in the magical papyri of Ptolemaic Egypt, she is called the 'she-dog' or 'bitch', and her presence is signified by the barking of dogs. In late imagery she also has two ghostly dogs as servants by her side. However, her association with dogs predates the conquests of Alexander the Great and the emergence of the Hellenistic world. When Philip II laid siege to Byzantium she had already been associated with dogs for some time; the light in the sky and the barking of dogs that warned the citizens of a night time attack, saving the city, were attributed to Hecate Lampadephoros (the tale is preserved in the Suda). In gratitude the Byzantines erected a statue in her honor.[53]\\r\\nAs a virgin goddess, she remained unmarried and had no regular consort, though some traditions named her as the mother of Scylla.[54]\\r\\nHecate was generally represented as three-formed, which probably has some connection with the appearance of the full moon, half moon, and new moon.[55] Triple Hecate was the goddess of the moon with three forms: Selene the Moon in heaven, Artemis the Huntress on earth, and Persephone the Destroyer in the underworld.[56][57][58] Although associated with other moon goddesses such as Selene, she ruled over three kingdoms: the earth, the sea, and the sky. She had the power to create or hold back storms, which influenced her patronage of shepherds and sailors.[59]\\r\\nDogs were closely associated with Hecate in the Classical world. \\"In art and in literature Hecate is constantly represented as dog-shaped or as accompanied by a dog. Her approach was heralded by the howling of a dog. The dog was Hecate's regular sacrificial animal, and was often eaten in solemn sacrament.\\"[60] The sacrifice of dogs to Hecate is attested for Thrace, Samothrace, Colophon, and Athens.[8]\\r\\nIt has been claimed that her association with dogs is \\"suggestive of her connection with birth, for the dog was sacred to Eileithyia, Genetyllis, and other birth goddesses. Although in later times Hecate's dog came to be thought of as a manifestation of restless souls or demons who accompanied her, its docile appearance and its accompaniment of a Hecate who looks completely friendly in many pieces of ancient art suggests that its original signification was positive and thus likelier to have arisen from the dog's connection with birth than the dog's underworld associations.\\"[61] The association with dogs, particularly female dogs, could be explained by a metamorphosis myth. The friendly looking female dog accompanying Hecate was originally the Trojan Queen Hekabe, who leapt into the sea after the fall of Troy and was transformed by Hecate into her familiar.[62]\\r\\nAnother metamorphosis myth explains why the polecat is also associated with Hecate. From Antoninus Liberalis: \\"At Thebes Proitos had a daughter Galinthias. This maiden was playmate and companion of Alkmene, daughter of Elektryon. As the birth throes for Herakles were pressing on Alkmene, the Moirai (Fates) and Eileithyia (Birth-Goddess), as a favour to Hera, kept Alkmene in continuous birth pangs. They remained seated, each keeping their arms crossed. Galinthias, fearing that the pains of her labour would drive Alkmene mad, ran to the Moirai and Eleithyia and announced that by desire of Zeus a boy had been born to Alkmene and that their prerogatives had been abolished.\\r\\nAt all this, consternation of course overcame the Moirai and they immediately let go their arms. Alkmenes pangs ceased at once and Herakles was born. The Moirai were aggrieved at this and took away the womanly parts of Galinthias since, being but a mortal, she had deceived the gods. They turned her into a deceitful weasel (or polecat), making her live in crannies and gave her a grotesque way of mating. She is mounted through the ears and gives birth by bringing forth her young through the throat. Hekate felt sorry for this transformation of her appearance and appointed her a sacred servant of herself.\\"[63]\\r\\nAelian told a different story of a woman transformed into a polecat: \\"\\"I have heard that the polecat was once a human being. It has also reached my hearing that Gale was her name then; that she was a dealer in spells and a sorceress (Pharmakis); that she was extremely incontinent, and that she was afflicted with abnormal sexual desires. Nor has it escaped my notice that the anger of the goddess Hekate transformed it into this evil creature. May the goddess be gracious to me?: fables and their telling I leave to others.\\"[64]\\r\\nAthenaeus (writing in the 1st or 2nd century BCE, and drawing on the etymological speculation of Apollodorus of Athens) notes that the red mullet is sacred to Hecate, \\"on account of the resemblance of their names; for that the goddess is trimorphos, of a triple form\\". The Greek word for mullet was trigle and later trigla. He goes on to quote a fragment of verse \\"O mistress Hecate, Trioditis / With three forms and three faces / Propitiated with mullets\\".[65] In relation to Greek concepts of pollution, Parker observes, \\"The fish that was most commonly banned was the red mullet (trigle), which fits neatly into the pattern. It 'delighted in polluted things,' and 'would eat the corpse of a fish or a man'. Blood-coloured itself, it was sacred to the blood-eating goddess Hecate. It seems a symbolic summation of all the negative characteristics of the creatures of the deep.\\"[66] At Athens, it is said there stood a statue of Hecate Triglathena, to whom the red mullet was offered in sacrifice.[67] After mentioning that this fish was sacred to Hecate, Alan Davidson writes, \\"Cicero, Horace, Juvenal, Martial, Pliny, Seneca and Suetonius have left abundant and interesting testimony to the red mullet fever which began to affect wealthy Romans during the last years of the Republic and really gripped them in the early Empire. The main symptoms were a preoccupation with size, the consequent rise to absurd heights of the prices of large specimens, a habit of keeping red mullet in captivity, and the enjoyment of the highly specialized aesthetic experience induced by watching the color of the dying fish change.\\"[68]\\r\\nThe frog, which was also the symbol of the similarly-named Egyptian goddess Heqet,[69] has also become sacred to Hecate in modern Pagan literature, possibly due in part to its ability to cross between two elements.[70]\\r\\nIn her three-headed representations, discussed above, Hecate often has one or more animal heads, including cow, dog, boar, serpent and horse.[71]\\r\\nHecate was closely associated with plant lore and the concoction of medicines and poisons. In particular she was thought to give instruction in these closely related arts. Apollonius of Rhodes, in the Argonautica mentions that Medea was taught by Hecate, \\"I have mentioned to you before a certain young girl whom Hecate, daughter of Perses, has taught to work in drugs.\\"[72]\\r\\nThe goddess is described as wearing oak in fragments of Sophocles' lost play The Root Diggers (or The Root Cutters), and an ancient commentary on Apollonius of Rhodes' Argonautica (3.1214) describes her as having a head surrounded by serpents, twining through branches of oak.[73]\\r\\nThe yew in particular was sacred to Hecate.\\r\\n\\"Greeks held the yew to be sacred to Hecate... Her attendants draped wreathes of yew around the necks of black bulls which they slaughtered in her honor and yew boughs were burned on funeral pyres. The yew was associated with the alphabet and the scientific name for yew today, taxus, was probably derived from the Greek word for yew, toxos, which is hauntingly similar to toxon, their word for bow and toxicon, their word for poison. It is presumed that the latter were named after the tree because of its superiority for both bows and poison.\\"[74]\\r\\nHecate was said to favor offerings of garlic, which was closely associated with her cult.[75] She is also sometimes associated with cypress, a tree symbolic of death and the underworld, and hence sacred to a number of chthonic deities.[76]\\r\\nA number of other plants (often poisonous, medicinal and/or psychoactive) are associated with Hecate.[77] These include aconite (also called hecateis),[78] belladonna, dittany, and mandrake. It has been suggested that the use of dogs for digging up mandrake is further corroboration of the association of this plant with Hecate; indeed, since at least as early as the 1st century CE, there are a number of attestations to the apparently widespread practice of using dogs to dig up plants associated with magic.[79]\\r\\nHecate was associated with borders, city walls, doorways, crossroads and, by extension, with realms outside or beyond the world of the living. She appears to have been particularly associated with being 'between' and hence is frequently characterized as a \\"liminal\\" goddess. \\"Hecate mediated between regimesOlympian and Titanbut also between mortal and divine spheres.\\"[81] This liminal role is reflected in a number of her cult titles: Apotropaia (that turns away/protects); Enodia (on the way); Propulaia/Propylaia (before the gate); Triodia/Trioditis (who frequents crossroads); Klidouchos (holding the keys), etc.\\r\\nAs a goddess expected to avert harmful or destructive spirits from the house or city over which she stood guard and to protect the individual as she or he passed through dangerous liminal places, Hecate would naturally become known as a goddess who could also refuse to avert the demons, or even drive them on against unfortunate individuals.[82]\\r\\nIt was probably her role as guardian of entrances that led to Hecate's identification by the mid fifth century with Enodia, a Thessalian goddess. Enodia's very name (\\"In-the-Road\\") suggests that she watched over entrances, for it expresses both the possibility that she stood on the main road into a city, keeping an eye on all who entered, and in the road in front of private houses, protecting their inhabitants.[83]\\r\\nThis function would appear to have some relationship with the iconographic association of Hecate with keys, and might also relate to her appearance with two torches, which when positioned on either side of a gate or door illuminated the immediate area and allowed visitors to be identified. \\"In Byzantium small temples in her honor were placed close to the gates of the city. Hecate's importance to Byzantium was above all as a deity of protection. When Philip of Macedon was about to attack the city, according to the legend she alerted the townspeople with her ever present torches, and with her pack of dogs, which served as her constant companions.\\"[84] This suggests that Hecate's close association with dogs derived in part from the use of watchdogs, who, particularly at night, raised an alarm when intruders approached. Watchdogs were used extensively by Greeks and Romans.[85]\\r\\nCult images and altars of Hecate in her triplicate or trimorphic form were placed at three-way crossroads (though they also appeared before private homes and in front of city gates).[8] In this form she came to be known as the goddess Trivia (\\"the three ways\\") in Roman mythology. In what appears to be a 7th-century indication of the survival of cult practices of this general sort, Saint Eligius, in his Sermo warns the sick among his recently converted flock in Flanders against putting \\"devilish charms at springs or trees or crossroads\\",[86] and, according to Saint Ouen would urge them \\"No Christian should make or render any devotion to the deities of the trivium, where three roads meet...\\".[87]\\r\\nLike Hecate, \\"[t]he dog is a creature of the threshold, the guardian of doors and portals, and so it is appropriately associated with the frontier between life and death, and with demons and ghosts which move across the frontier. The yawning gates of Hades were guarded by the monstrous watchdog Cerberus, whose function was to prevent the living from entering the underworld, and the dead from leaving it.\\"[88]\\r\\nHecate was worshipped by both the Greeks and the Romans who had their own festivals dedicated to her.\\r\\nThe Athenian Greeks honored Hekate during the Deipnon. In Greek, deipnon means the evening meal, usually the largest meal of the day. Hekate's Deipnon is, at its most basic, a meal served to Hekate and the restless dead once a lunar month[89] during the new moon. The Deipnon is always followed the next day by the Noumenia,[90] when the first sliver of moon is visible, and then the Agathos Daimon the day after that.\\r\\nThe main purpose of the Deipnon was to honor Hekate and to placate the souls in her wake who longed for vengeance.[91] A secondary purpose was to purify the household and to atone for bad deeds a household member may have committed that offended Hekate, causing her to withhold her favor from them. The Deipnon consists of three main parts: 1) the meal that was set out at a crossroads, usually in a shrine outside the entryway to the home[92] 2) an expiation sacrifice,[93] and 3) purification of the household.[94]\\r\\nThe figure of Hecate can often be associated with the figure of Isis in Egyptian myth. Lucius Apuleius (c. 123170 CE) in his work The Golden Ass associates Hecate with Isis:\\r\\nI am she that is the natural mother of all things, mistress and governess of all the elements, the initial progeny of worlds, chief of powers divine, Queen of heaven, the principal of the Gods celestial, the light of the goddesses: at my will the planets of the air, the wholesome winds of the Seas, and the silences of hell be disposed; my name, my divinity is adored throughout all the world in divers manners, in variable customs and in many names, [...] Some call me Juno, others Bellona of the Battles, and still others Hecate. Principally the Ethiopians which dwell in the Orient, and the Egyptians which are excellent in all kind of ancient doctrine, and by their proper ceremonies accustomed to worship me, do call me Queen Isis. [...][95]\\r\\nIn the syncretism during Late Antiquity of Hellenistic and late Babylonian (\\"Chaldean\\") elements, Hecate was identified with Ereshkigal, the underworld counterpart of Inanna in the Babylonian cosmography. In the Michigan magical papyrus (inv. 7), dated to the late 3rd or early 4th century CE, Hecate Ereschigal is invoked against fear of punishment in the afterlife.[96]\\r\\nBefore she became associated with Greek mythology, she had many similarities with Artemis (wilderness, and watching over wedding ceremonies)[97]\\r\\nDogs were sacred to Hecate and associated with roads, domestic spaces, purification, and spirits of the dead. They played a similar symbolic role in ancient China, where dogs were conceived as representative of the household sphere, and as protective spirits appropriate when transcending geographic and spatial boundaries. Dogs were also sacrificed to the road. As Roel Sterckx observes, \\"The use of dog sacrifices at the gates and doors of the living and the dead as well as its use in travel sacrifices suggest that dogs were perceived as daemonic animals operating in the liminal or transitory realm between the domestic and the unknown, danger-stricken outside world\\".[98]\\r\\nThis can be compared to Pausanias' report that in the Ionian city of Colophon in Asia Minor a sacrifice of a black female puppy was made to Hecate as \\"the wayside goddess\\", and Plutarch's observation that in Boeotia dogs were killed in purificatory rites. Dogs, with puppies often mentioned, were offered to Hecate at crossroads, which were sacred to the goddess.[99]\\r\\nStrmiska notes that Hecate, conflated with the figure of Diana, appears in late antiquity and in the early medieval period as part of an \\"emerging legend complex\\" associated with gatherings of women, the moon, and witchcraft that eventually became established \\"in the area of Northern Italy, southern Germany, and the western Balkans.\\"[100] This theory of the Roman origins of many European folk traditions related to Diana or Hecate was explicitly advanced at least as early as 1807[101] and is reflected in numerous etymological claims by lexicographers from the 17th to the 19th century, deriving \\"hag\\" and/or \\"hex\\" from Hecate by way of haegtesse (Anglo-Saxon) and hagazussa (Old High German).[102] Such derivations are today proposed only by a minority[103] since being refuted by Grimm, who was skeptical of theories proposing non-Germanic origins for German folklore traditions.[104]\\r\\nModern etymology reconstructs Proto-Germanic *hagatusjon- from haegtesse and hagazussa;[105] the first element is probably cognate with hedge, which derives from PIE *kagh- \\"hedge, enclosure\\",[106] and the second perhaps from *dhewes- \\"fly about, be smoke, vanish.\\"[105]\\r\\nHecate is now firmly established as a figure in Neopaganism,[107] which draws heavily on folkloric traditions[108] associating Hecate with 'The Wild Hunt',[109] witches, hedges and 'hedge-riding',[110] and other themes that parallel, but are not explicitly attested in, Classical sources.\\r\\nHecate is worshiped by people who have reconstructed and revived the indigenous polytheist religion of Greece, Hellenismos, such as groups like Hellenion (Hellenion is a 501c3 religious organization based in the USA dedicated to reviving the religions indigenous to Greece)[111] and YSEE. The Supreme Council of Ethnikoi Hellenes is an umbrella group based in Greece that is a legally recognized Non Profit Organization (NPO) and was \\"founded in June of 1997 aiming to the morale and physical protection and restoration of the Polytheistic, Ethnic Hellenic religion, tradition and way of life in the \\"modern\\" Greek Society from which is oppressed due to its institutional intolerance and theocracy\\".[citation needed]\\r\\nShakespeare mentions Hecate both before the turn of the 16th century (A Midsummer Night's Dream, 1594-96), and just after, in Macbeth (1605): specifically, in the title character's \\"dagger\\" soliloquy: \\"Witchcraft celebrates pale Hecate's offerings...\\"[112] Hecate also appears as a main character in the British theater company Punchdrunk's New York-based site-specific theatre work, Sleep No More, an adaptation of Macbeth. The character functions as a villain of the work, silently conducting the three witches who prophesy Macbeth's rise to power, and leading certain audience members into private interactions and stories in her small grotto. Many of Hecate's dominions are represented in various ways throughout the show, such as one of her familiars behaving in a dog-like manner around her; her grotto being connected to an herb-filled apothecary space; and watching from the shadows as the witches give their prophecies to Macbeth.\\r\\nCatweazle often calls upon Hecate in the British television series of the same name.\\r\\nHecate is also one of the \\"patron\\" goddesses of many Wiccans, who in some traditions identify her with the Triple Goddess' aspect of the \\"Crone\\". In other circles Wiccan witches associate her with the \\"Maiden\\", or the \\"Mother\\" aspects as well, for Hecate has three faces, or phases. Her role as a tripartite goddess, which many modern-day Wiccans associate with the concept of \\"the Maiden, the Mother and the Crone\\",[113] was made popular in modern times by writers such as Robert Graves in The White Goddess, and many others, such as the 20th century occultist and author, Aleister Crowley. Historical depictions and descriptions show her facing in three different directions, a clear and precise reference to the tripartite nature of this ancient Goddess; the later Greek Magical Papyri sometimes refer to her as also having the heads of animals, and this can be seen as a reference to her aspect of Motherhood; in this portrayal she is known as \\"Mistress of Animals\\". Modern Hellenic polytheists honor Hecate during the Deipnon.[114]\\r\\nIn 1929, Dr. Lewis Brown, an expert on religious cults, connected the 1920s Blackburn Cult (also known as, \\"The Cult of the Great Eleven,\\") with Hecate worship rituals. He noted that the cult regularly practiced dog sacrifice and had secretly buried the body of one of its \\"queens\\" with seven dogs.[115] Researcher Samuel Fort noted additional parallels, to include the cults focus on mystic and typically nocturnal rites, its female dominated membership, the sacrifice of other animals (to include horses and mules), a focus on the mystical properties of roads and portals, and an emphasis on death, healing, and resurrection.[116]\\r\\nHecate is also the namesake of the hundredth numbered asteroid, which was discovered by American astronomer James Craig Watson on July 11, 1868. Its adopted name commemorates it as the hundredth asteroid, especially as 'hekaton' is Greek for 'hundred.' The name may also be explained as the derivation of the prefix hecto- commonly used in the metric system, or within the decimal system as three digits (e.g. as 100) therefore reflecting her later mythological trinary form.","input":"What was the roman name for the goddess hecate?"},{"output":".500 (50%) or above","context":"Field goal percentage in basketball is the ratio of field goals made to field goals attempted. Its abbreviation is FG%. Although three-point field goal percentage is often calculated separately, three-point field goals are included in the general field goal percentage. Instead of using scales of 0 to 100%, the scale .000 to 1.000 is commonly used. A higher field goal percentage denotes higher efficiency. In basketball, a FG% of .500 (50%) or above is considered a good percentage, although this criterion does not apply equally to all positions. Guards usually have lower FG% than forwards and centers. Field goal percentage does not completely tell the skill of a player, but a low field goal percentage can indicate a poor offensive player or a player who takes many difficult shots. In the NBA, Center Shaquille O'Neal has a high career FG% (around .580) because he plays near the basket making many high percentage layups and slam dunks. Guard Allen Iverson often had a low FG% (around .420) because he took the bulk of his team's shot attempts, even with high difficulty shots.\\r\\nThe NBA career record for field goal percentage is held by DeAndre Jordan at 0.677. The highest field goal percentage for a single season was set by Wilt Chamberlain with 0.727 in the 1972ÿ73 season.\\r\\nField goal percentages were substantially lower in the NBA until the mid-to-late 1960s.[1] For this reason, many early NBA stars have low field goal percentages, such as Bob Cousy at .375, and George Mikan, Bob Pettit, and Bill Russell, whose career field goal percentages of .404, .436, and .440, respectively, are much lower than later post players.[2]\\r\\nThree-point field goal percentage is usually kept as additional statistics. Its abbreviation is 3FG%. A 3FG% of .400 and above is a very good percentage.","input":"What is a good basketball field goal percentage?"},{"output":"fresh water","context":"A lake is an area filled with water, localized in a basin, that is surrounded by land, apart from any river or other outlet that serves to feed or drain the lake.[1] Lakes lie on land and are not part of the ocean, and therefore are distinct from lagoons, and are also larger and deeper than ponds, though there are no official or scientific definitions.[2] Lakes can be contrasted with rivers or streams, which are usually flowing. Most lakes are fed and drained by rivers and streams.\\r\\nNatural lakes are generally found in mountainous areas, rift zones, and areas with ongoing glaciation. Other lakes are found in endorheic basins or along the courses of mature rivers. In some parts of the world there are many lakes because of chaotic drainage patterns left over from the last Ice Age. All lakes are temporary over geologic time scales, as they will slowly fill in with sediments or spill out of the basin containing them.\\r\\nMany lakes are artificial and are constructed for industrial or agricultural use, for hydro-electric power generation or domestic water supply, or for aesthetic or recreational purposes or even for other activities.\\r\\n\\r\\n\\r\\nThe word lake comes from Middle English lake (\\"lake, pond, waterway\\"), from Old English lacu (\\"pond, pool, stream\\"), from Proto-Germanic *lak (\\"pond, ditch, slow moving stream\\"), from the Proto-Indo-European root *le?- (\\"to leak, drain\\"). Cognates include Dutch laak (\\"lake, pond, ditch\\"), Middle Low German lke (\\"water pooled in a riverbed, puddle\\") as in: de:Moorlake, de:Wolfslake, de:Butterlake, German Lache (\\"pool, puddle\\"), and Icelandic l?kur (\\"slow flowing stream\\"). Also related are the English words leak and leach.\\r\\nThere is considerable uncertainty about defining the difference between lakes and ponds, and no current internationally accepted definition of either term across scientific disciplines or political boundaries exists.[4] For example, limnologists have defined lakes as water bodies which are simply a larger version of a pond, which can have wave action on the shoreline or where wind-induced turbulence plays a major role in mixing the water column. None of these definitions completely excludes ponds and all are difficult to measure. For this reason, simple size-based definitions are increasingly used to separate ponds and lakes. One definition of lake is a body of water of 2 hectares (5 acres) or more in area;[5]:331[6] however, others[who?] have defined lakes as waterbodies of 5 hectares (12 acres) and above,[citation needed] or 8 hectares (20 acres) and above [7] (see also the definition of \\"pond\\"). Charles Elton, one of the founders of ecology, regarded lakes as waterbodies of 40 hectares (99 acres) or more.[8] The term lake is also used to describe a feature such as Lake Eyre, which is a dry basin most of the time but may become filled under seasonal conditions of heavy rainfall. In common usage, many lakes bear names ending with the word pond, and a lesser number of names ending with lake are in quasi-technical fact, ponds. One textbook illustrates this point with the following: \\"In Newfoundland, for example, almost every lake is called a pond, whereas in Wisconsin, almost every pond is called a lake.\\"[9]\\r\\nOne hydrology book proposes to define the term \\"lake\\" as a body of water with the following five characteristics:[4]\\r\\nWith the exception of the seawater intrusion criterion, the others have been accepted or elaborated upon by other hydrology publications.[10][11]\\r\\nThe majority of lakes on Earth are fresh water, and most lie in the Northern Hemisphere at higher latitudes. Canada, with a deranged drainage system has an estimated 31,752 lakes larger than 3 square kilometres (1.2?sq?mi)[12] and an unknown total number of lakes, but is estimated to be at least 2 million.[13] Finland has 187,888 lakes 500 square metres (5,400?sq?ft) or larger, of which 56,000 are large (10,000 square metres (110,000?sq?ft) or larger).[14]\\r\\nMost lakes have at least one natural outflow in the form of a river or stream, which maintain a lake's average level by allowing the drainage of excess water.[15] Some lakes do not have a natural outflow and lose water solely by evaporation or underground seepage or both. They are termed endorheic lakes.\\r\\nMany lakes are artificial and are constructed for hydro-electric power generation, aesthetic purposes, recreational purposes, industrial use, agricultural use or domestic water supply.\\r\\nEvidence of extraterrestrial lakes exists; \\"definitive evidence of lakes filled with methane\\" was announced by NASA[citation needed] as returned by the Cassini Probe observing the moon Titan, which orbits the planet Saturn.\\r\\nGlobally, lakes are greatly outnumbered by ponds: of an estimated 304 million standing water bodies worldwide, 91% are 1 hectare (2.5 acres) or less in area (see definition of ponds).[16] Small lakes are also much more numerous than large lakes: in terms of area, one-third of the world's standing water is represented by lakes and ponds of 10 hectares (25 acres) or less.[citation needed] However, large lakes account for much of the area of standing water with 122 large lakes of 1,000 square kilometres (390 sq mi, 100,000 ha, 247,000 acres) or more representing about 29% of the total global area of standing inland water.[citation needed]\\r\\nHutchinson[17] in 1957 published a monograph that is regarded as a landmark discussion and classification of all major lake types, their origin, morphometric characteristics, and distribution.[18][19][20] As summarized and discussed by these researchers, Hutchinson presented in it a comprehensive analysis of the origin of lakes and proposed what is a widely accepted classification of lakes according to their origin. This classification recognizes 11 major lake types that are divided into 76 subtypes. The 11 major lake types are tectonic lakes, volcanic lakes, landslide lakes, glacial lakes, solution lakes, fluvial lakes, aeolian lakes, shoreline lakes, organic lakes, anthropomorphic lakes, and meteorite (extraterrestrial impact) lakes.[19][18][20]\\r\\nTectonic lakes are lakes formed by the deformation and resulting lateral and vertical movements of the Earths crust. These movements include faulting, tilting, folding, and warping. Some of the well-known and largest lakes on Earth are rift lakes occupying rift valleys, e.g. Central African Rift lakes and Lake Baikal. Other well-known tectonic lakes, Caspian Sea, the Sea of Aral, and other lakes from the Pontocaspian occupy basins that have been separated from the sea by the tectonic uplift of the sea floor above sea level.[17][19][18][20]\\r\\nOften, the tectonic action of crustal extension has created an alternating series of parallel grabens and horsts that form elongate basins alternating with mountain ranges. Not only does this promote the creation of lakes by the disruption of preexisting drainage networks, it also creates within arid regions endorheic basins that containing salt lakes (also called saline lakes). They form where there is no natural outlet, a high evaporation rate and the drainage surface of the water table has a higher-than-normal salt content. Examples of these salt lakes include Great Salt Lake and the Dead Sea. another type of tectonic lake caused by faulting is sag ponds.[17][19][18][20]\\r\\nVolcanic lakes are lakes that occupy either local depressions, e.g. craters and maars or larger basins, e.g. calderas, created by volcanism. Crater lakes are formed in volcanic craters and calderas, which fill up with precipitation more rapidly than they empty via either evaporation, groundwater discharge, or combination of both. Sometimes the latter are called caldera lakes, although often no distinction is made. An example is Crater Lake in Oregon, in the caldera of Mount Mazama. The caldera was created in a massive volcanic eruption that led to the subsidence of Mount Mazama around 4860 BC. Other volcanic lakes are created when either rivers or streams are dammed by lava flows or volcanic lahars.[17][19][18][20] The basin within which Malheur Lake, Oregon was created when a lava flow dammed the Malheur River.[21]\\r\\nGlacial lakes are lakes created by the direct action of glaciers and continental ice sheets. A wide variety of glacial processes create enclosed basins. As a result, there are a wide variety of different types of glacial lakes and it is often difficult to define clear-cut distinctions between different types of glacial lakes and lakes influenced by other activities. The general types of glacial lakes that have recognized are lakes in direct contact with ice; glacially carved rock basins and depressions; morainic and outwash lakes; and glacial drift basins. Glacial lakes are the numerous lakes in the world. Most the lakes in northern Europe and North America have been either influenced or created by the latest, but not last, glaciation, to have covered the region.[17][19][18][20] Glacial lakes include proglacial lakes, subglacial lakes, finger lakes, and epishelf lakes. Epishelf lakes are highly stratified lakes in which a layer of freshwater, derived from ice and snow melt, is dammed behind an ice shelf that is attached to the coastline. They are mostly found in Antarctica.[22]\\r\\nFluvial (or riverine)[23] lakes are lakes produced by running water. These lakes include plunge pool lakes, fluviatile dams and meander lakes.\\r\\nThe most common type of fluvial lake is a crescent-shaped lake called an oxbow lake due to the distinctive curved shape. They can form in river valleys as a result of meandering. The slow-moving river forms a sinuous shape as the outer side of bends are eroded away more rapidly than the inner side. Eventually a horseshoe bend is formed and the river cuts through the narrow neck. This new passage then forms the main passage for the river and the ends of the bend become silted up, thus forming a bow-shaped lake.[17][18][19][20]\\r\\nThese form where sediment from a tributary blocks the main river.[24]\\r\\nThese form where sediment from the main river blocks a tributary, usually in the form of a levee.[23]\\r\\nA solution lake is a lake occupying a basin formed by surface dissolution of bedrock. In areas underlain by soluble bedrock, its solution by precipitation and percolating water commonly produce cavities. These cavities frequently collapse to form sinkholes that form part of the local karst topography. Where groundwater lies near the grounds surface, a sinkhole will be filled water as a solution lake.[17][19] If such a lake consists of a large area of standing water that occupies an extensive closed depression in limestone, it is also called a karst lake. Smaller solution lakes that consist of a body of standing water in a closed depression within a karst region are known as karst ponds.[25] Limestone caves often contain pools of standing water, which are known as underground lakes. Classic examples of solution lakes are abundant in the karst regions at the Dalmatian coast of Croatia and within large parts of Florida.[17]\\r\\nLandslide lakes are lakes created by the blockage of a valley by either mudflows, rockslides, or screes. Such lakes are common in mountainous regions. Although landslide lakes may be large and quite deep, they are typically short-lived.[17][19][18][20] An example of a landslide lake is Quake Lake, which formed as a result of the 1959 Hebgen Lake earthquake.[26]\\r\\nAeolian lakes are lakes produced by wind action. They are found mainly in arid environments although some aeolian lakes are relict landforms indicative of arid paleoclimates. Aeolian lakes consist of lake basins dammed by wind-blown sand; interdunal lakes that lies between well-oriented sand dunes; and deflation basins formed by wind action under previously arid paleoenvironments. Moses Lake, Washington, is an example of a lake basins dammed by wind-blown sand.[17][19][18][20]\\r\\nShoreline lakes are generally lakes created by blockage of estuaries or by the uneven accretion of beach ridges by longshore and other currents. They include maritime coastal lakes, ordinarily in drowned estuaries; lakes enclosed by two tombolos or spits connecting an island to the mainland; lakes cut off from larger lakes by a bar; or lakes divided by the meeting of two spits.[17][19][18][20]\\r\\nOrganic lakes are lakes created by the actions of plants and animals. On the whole they are relatively rare in occurrence and quite small in size. In addition, they typically ephemeral features relative to the other types of lakes. The basins in which organic lakes occur are associated with beaver dams, coral lakes, or dams formed by vegetation.[19][20]\\r\\nPeat lakes are a form of organic lake. They form where a buildup of partly decomposed plant material in a wet environment leaves the vegetated surface below the water table for a sustained period of time. They are often low in nutrients and mildly acidic, with bottom waters low in dissolved oxygen.[27]\\r\\nAnthropogenic lakes are artificially created lakes formed by human activity. They can be the result of intentional damming of rivers and streams or subsequent filling of abandon excavations by either ground water, precipitation, or a combination of both.[19][20]\\r\\nMeteorite lakes, which are also known as crater lakes, are lakes created by catastrophic extraterrestrial impacts by either meteorites or asteroids.[17][19][20] Examples of meteorite lakes are Lonar crater lake, India,[28] Lake Elgygytgyn,[29] and Pingualuit crater lake, Quebec, Canada,[30] As in case of Lake El'gygytgyn and Pingualuit crater lake, meteorite (extraterrestrial impact/ crater) lakes can contain unique and scientifically valuable sedimentary deposits associated with long records of paleoclimatic changes.[29][30]\\r\\nIn addition to mode of origin, lakes have been named and classified in various other ways according to their thermal stratification, salinity, relative seasonal permanence, degree of outflow, and other factors. Also, different cultures and regional of the world have their popular nomenclature\\r\\nIn addition to their origin, there are various other ways of either naming or defining types of lakes. One major way of classification lakes in on the basis of thermal stratification because it is a major control on animal and plant life inhabiting a lake and the fate and distribution of dissolved and suspended material in a lake. For example, the thermal stratification and the degree and frequency of mixing exerts a strong control on the distribution of oxygen within it. In addition, lake can be classified according important factors such as seasonal variations in lake volume and level, oxygen saturation, and salinity of its water mass. Finally, the names of types of lakes that are used by the lay public and in the scientific for different types of lakes are often informally derived from either from their morphology of other aspects or their physical characteristics.\\r\\nF.A. Forel,[31] who is also referred to as the father of limnology, was the first scientist to classify lakes according to their thermal stratification.[32] His system of classification was later modified and improved upon by Hutchinson and Laffler.[33] Because the density of water varies with temperature, with a maximum at +4 DC, thermal stratification is an important physical characteristic of lakes that controls the fauna and flora, sedimentation, chemistry, and other aspects of individual lakes. First, the colder, heavier water typically forms a layer near the bottom, which called the hypolimnion. Second, normally overlying it is a transition zone known as the metalimnion. Finally, overlying the metalimnion is a surface layer of a warmer, lighter water is called the epilimnion. However, this typical stratification sequence can vary widely depending either on the specific lake, the time of season, or combination of both.[19][32][33]\\r\\nBased upon thermal stratification, lakes are classified as either holomictic lakes or meromictic lakes. A meromictic lake is a lake which has layers of water which do not intermix. The deepest layer of water in such a lake does not contain any dissolved oxygen. In addition, the layers of sediment at the bottom of a meromictic lake remain relatively undisturbed because there are no living aerobic organisms. The lack of disturbance allows for the development of lacustrine varves. A Holomictic lake is a lake that has a uniform temperature and density from top to bottom at a specific time during the year. This uniformity temperature and density in allows the lake waters to completely mix. Holomictic lakes are non-meromictic lakes. Based upon thermal stratification and frequency of turnover, holomictic lakes are divided into amictic lakes, cold monomictic lakes, dimictic lakes, warm monomictic lakes, polymictic lakes, and oligomictic lakes. The classification of lakes by thermal stratification presupposes lakes with sufficient depth to form a hypolimnion. As a results, very shallow lakes are excluded this classification system.[19][33]\\r\\nThe stratification in a lake is not always the result of variation to density because of thermal gradients. Stratification within a lake can also be the result of differences in density resulting from gradients in salinity. In case of a difference in salinity, the hypolimnion and epilimnion are separated not by a thermocline but by a halocline, which is sometimes referred to as a chemocline.[19][33]\\r\\nLakes are informally classified and named according to the seasonal variation in their lake level and volume. Some of the names include:\\r\\nLakes are also informally classified and named according to the general chemistry of their water mass. Some of the types of lakes include:\\r\\nA paleolake, also spelt palaeolake, is a lake that existed in the past when hydrological conditions were different.[44] Quaternary paleolakes can often be identified on the basis of relict lacustrine landforms such as relict lake plains and coastal landforms that form recognizable relict shorelines, which are called paleoshorelines. Paleolakes can also be recognized by characteristic sedimentary deposits that accumulated in them and any fossils that these sediments might contain. The paleoshorelines and sedimentary deposits of paleolakes provide evidence for prehistoric hydrological changes during the times that they existed.[44][45]\\r\\nTypes of paleolakes include:\\r\\nPaleolakes are of scientific and economic importance. For example, Quaternary paleolakes in semidesert basins are important for two reasons. First, they played an extremely significant, if transient, role in shaping the floors and piedmonts of many basins. Finally, their sediments contain enormous quantities of geologic and paleontologic information concerning past environments.[47] In addition, the organic-rich deposits of pre-Quaternary paleolakes are important either for the thick deposits of oil shale and shale gas that they contain or as source rocks of petroleum and natural gas. Although of significantly less economic importance, strata deposited along the shore of paleolakes sometimes contain coal seams.[48][49]\\r\\nLakes have numerous features in addition to lake type, such as drainage basin (also known as catchment area), inflow and outflow, nutrient content, dissolved oxygen, pollutants, pH, and sedimentation.\\r\\nChanges in the level of a lake are controlled by the difference between the input and output compared to the total volume of the lake. Significant input sources are precipitation onto the lake, runoff carried by streams and channels from the lake's catchment area, groundwater channels and aquifers, and artificial sources from outside the catchment area. Output sources are evaporation from the lake, surface and groundwater flows, and any extraction of lake water by humans. As climate conditions and human water requirements vary, these will create fluctuations in the lake level.\\r\\nLakes can be also categorized on the basis of their richness in nutrients, which typically affect plant growth. Nutrient-poor lakes are said to be oligotrophic and are generally clear, having a low concentration of plant life. Mesotrophic lakes have good clarity and an average level of nutrients. Eutrophic lakes are enriched with nutrients, resulting in good plant growth and possible algal blooms. Hypertrophic lakes are bodies of water that have been excessively enriched with nutrients. These lakes typically have poor clarity and are subject to devastating algal blooms. Lakes typically reach this condition due to human activities, such as heavy use of fertilizers in the lake catchment area. Such lakes are of little use to humans and have a poor ecosystem due to decreased dissolved oxygen.\\r\\nDue to the unusual relationship between water's temperature and its density, lakes form layers called thermoclines, layers of drastically varying temperature relative to depth. Fresh water is most dense at about 4 degrees Celsius (39.2?F) at sea level. When the temperature of the water at the surface of a lake reaches the same temperature as deeper water, as it does during the cooler months in temperate climates, the water in the lake can mix, bringing oxygen-starved water up from the depths and bringing oxygen down to decomposing sediments. Deep temperate lakes can maintain a reservoir of cold water year-round, which allows some cities to tap that reservoir for deep lake water cooling.\\r\\nSince the surface water of deep tropical lakes never reaches the temperature of maximum density, there is no process that makes the water mix. The deeper layer becomes oxygen starved and can become saturated with carbon dioxide, or other gases such as sulfur dioxide if there is even a trace of volcanic activity. Exceptional events, such as earthquakes or landslides, can cause mixing which rapidly brings the deep layers up to the surface and release a vast cloud of gas which lay trapped in solution in the colder water at the bottom of the lake. This is called a limnic eruption. An example is the disaster at Lake Nyos in Cameroon. The amount of gas that can be dissolved in water is directly related to pressure. As deep water surfaces, the pressure drops and a vast amount of gas comes out of solution. Under these circumstances carbon dioxide is hazardous because it is heavier than air and displaces it, so it may flow down a river valley to human settlements and cause mass asphyxiation.\\r\\nThe material at the bottom of a lake, or lake bed, may be composed of a wide variety of inorganics, such as silt or sand, and organic material, such as decaying plant or animal matter. The composition of the lake bed has a significant impact on the flora and fauna found within the lake's environs by contributing to the amounts and the types of nutrients available.\\r\\nA paired (black and white) layer of the varved lake sediments correspond to a year. During winter, when organisms die, carbon is deposited down, resulting to a black layer. At the same year, during summer, only few organic materials are deposited, resulting to a white layer at the lake bed. These are commonly used to track past paleontological events.\\r\\nNatural lakes provide a microcosm of living and nonliving elements that are relatively independent of their surrounding environments. Therefore, lake organisms can often be studied in isolation from the lakes surroundings.[51]\\r\\nLimnology is the study of inland bodies of water and related ecosystems. Limnology divides lakes into three zones: the littoral zone, a sloped area close to land; the photic or open-water zone, where sunlight is abundant; and the deep-water profundal or benthic zone, where little sunlight can reach. The depth to which light can reach in lakes depends on turbidity, determined by the density and size of suspended particles. A particle is in suspension if its weight is less than the random turbidity forces acting upon it. These particles can be sedimentary or biological in origin and are responsible for the color of the water. Decaying plant matter, for instance, may be responsible for a yellow or brown color, while algae may cause greenish water. In very shallow water bodies, iron oxides make water reddish brown. Biological particles include algae and detritus. Bottom-dwelling detritivorous fish can be responsible for turbid waters, because they stir the mud in search of food. Piscivorous fish contribute to turbidity by eating plant-eating (planktonivorous) fish, thus increasing the amount of algae (see aquatic trophic cascade). The light depth or transparency is measured by using a Secchi disk, a 20-cm (8?in) disk with alternating white and black quadrants. The depth at which the disk is no longer visible is the Secchi depth, a measure of transparency. The Secchi disk is commonly used to test for eutrophication. For a detailed look at these processes, see lentic ecosystems.\\r\\nA lake moderates the surrounding region's temperature and climate because water has a very high specific heat capacity (4,186 J{kg?1{K?1). In the daytime a lake can cool the land beside it with local winds, resulting in a sea breeze; in the night it can warm it with a land breeze.\\r\\nThe lake may be infilled with deposited sediment and gradually become a wetland such as a swamp or marsh. Large water plants, typically reeds, accelerate this closing process significantly because they partially decompose to form peat soils that fill the shallows. Conversely, peat soils in a marsh can naturally burn and reverse this process to recreate a shallow lake resulting in a dynamic equilibrium between marsh and lake.[52] This is significant since wildfire has been largely suppressed in the developed world over the past century. This has artificially converted many shallow lakes into emergent marshes. Turbid lakes and lakes with many plant-eating fish tend to disappear more slowly. A \\"disappearing\\" lake (barely noticeable on a human timescale) typically has extensive plant mats at the water's edge. These become a new habitat for other plants, like peat moss when conditions are right, and animals, many of which are very rare. Gradually the lake closes and young peat may form, forming a fen. In lowland river valleys where a river can meander, the presence of peat is explained by the infilling of historical oxbow lakes. In the very last stages of succession, trees can grow in, eventually turning the wetland into a forest.\\r\\nSome lakes can disappear seasonally. These are called intermittent lakes, ephemeral lakes, or seasonal lakes and can be found in karstic terrain. A prime example of an intermittent lake is Lake Cerknica in Slovenia or Lag Prau Pulte in Graubnden. Other intermittent lakes are only the result of above-average precipitation in a closed, or endorheic basin, usually filling dry lake beds. This can occur in some of the driest places on earth, like Death Valley. This occurred in the spring of 2005, after unusually heavy rains.[53] The lake did not last into the summer, and was quickly evaporated (see photos to right). A more commonly filled lake of this type is Sevier Lake of west-central Utah.\\r\\nSometimes a lake will disappear quickly. On 3 June 2005, in Nizhny Novgorod Oblast, Russia, a lake called Lake Beloye vanished in a matter of minutes. News sources reported that government officials theorized that this strange phenomenon may have been caused by a shift in the soil underneath the lake that allowed its water to drain through channels leading to the Oka River.[54]\\r\\nThe presence of ground permafrost is important to the persistence of some lakes. According to research published in the journal Science (\\"Disappearing Arctic Lakes\\", June 2005), thawing permafrost may explain the shrinking or disappearance of hundreds of large Arctic lakes across western Siberia. The idea here is that rising air and soil temperatures thaw permafrost, allowing the lakes to drain away into the ground.\\r\\nSome lakes disappear because of human development factors. The shrinking Aral Sea is described as being \\"murdered\\" by the diversion for irrigation of the rivers feeding it.\\r\\nOnly one world other than Earth is known to harbor large lakes, Saturn's largest moon, Titan. Photographs and spectroscopic analysis by the CassiniÿHuygens spacecraft show liquid ethane on the surface, which is thought to be mixed with liquid methane. The largest Titanean lake, Kraken Mare at 400,000?km2, is three-times[citation needed] the size of any lake on Earth, and even the second, Ligeia Mare, is estimated to be slightly larger than Earth's Lake MichiganÿHuron.\\r\\nJupiter's large moon Io is volcanically active, and as a result sulfur deposits have accumulated on the surface. Some photographs taken during the Galileo mission appear to show lakes of liquid sulfur in volcanic caldera, though these are more analogous to lake of lava than of water on Earth.[55]\\r\\nThe planet Mars is too cold and has too little atmospheric pressure to permit the pooling of liquid water. Geologic evidence appears to confirm, however, that ancient lakes once formed on the surface. It is also possible that volcanic activity on Mars will occasionally melt subsurface ice, creating large temporary lakes.[citation needed] This water would quickly freeze and then sublimate, unless insulated in some manner, such as by a coating of volcanic ash.\\r\\nThere are dark basaltic plains on the Moon, similar to lunar maria but smaller, that are called lacus (singular lacus, Latin for \\"lake\\") because they were thought by early astronomers to be lakes of water.\\r\\nThe largest lakes (surface area) by continent are:","input":"What kind of water is found in most lakes?"},{"output":"began on August 11, 2014","context":"The seventh and final season of Parks and Recreation aired in the United States on the NBC television network from January 13, 2015 until February 24, 2015.[1] The season consisted of 13 episodes.[2]\\r\\n\\r\\nThis season differed from any other season of Parks and Recreation, in that it detailed a much larger story arc for the characters, showcasing their growth over the course of the show. Set in 2017, following Season 6, the season included Leslie Knope (Amy Poehler)'s new career as Regional Director of National Park Service, in addition to her two-year long fallout with former boss Ron Swanson (Nick Offerman). Also included was the rise of fictional tech company Gryzzl taking over Pawnee, Leslie's plea to Sweetums for a Pawnee National Park, and the eventual career departures of the gang from the Parks department.\\r\\n\\r\\n? denotes an extended episode.\\r\\n? denotes an hour-long episode.\\r\\n\\r\\nThe first 12 episodes were aired within six weeks by airing two each week, back-to-back.[1] Production began on August 11, 2014,[26][27] and ended on December 12, 2014.[28] Although the program initially premiered in NBC's Must See TV Thursday night block, the final episodes were moved to Tuesdays, possibly in an attempt to compete with ABC's dramas.[29]\\r\\n\\r\\nThe seventh season of Parks and Recreation overall, as well as the series finale, received universal praise from critics. Rotten Tomatoes gave the season a 100% rating based on 13 reviews.[30] IGN reviewer Matt Fowler gave the series finale a perfect 10 out of 10 score, saying \\"Doing what the show does best, Parks knocked it clear out of the park with \\"One Last Ride.\\" A remarkably irresistible swirl of love and satire. The writers knew it wasn't enough to just send everyone off into the future. They knew we needed to see that future. Not just for peace of mind, but because we've all become so lovingly invested in the characters. This final season proved to us that we could withstand a time jump and still remain attached to everyone. And this finale used that to hop through the Pawnee gang's futures, creating an exciting, heartwarming journey.\\"[31]","input":"When was parks and rec season 7 filmed?"},{"output":"December 20, 1860","context":"In the context of the United States, secession primarily refers to the withdrawal of one or more States from the Union that constitutes the United States; but may loosely refer to leaving a State or territory to form a separate territory or new State, or to the severing of an area from a city or county within a State.\\r\\nThreats and aspirations to secede from the United States, or arguments justifying secession, have been a feature of the country's politics almost since its birth. Some have argued for secession as a constitutional right and others as from a natural right of revolution. In Texas v. White, the United States Supreme Court ruled unilateral secession unconstitutional, while commenting that revolution or consent of the States could lead to a successful secession.\\r\\nThe most serious attempt at secession was advanced in the years 1860 and 1861 as eleven southern States each declared secession from the United States, and joined together to form the Confederate States of America. This movement collapsed in 1865 with the defeat of Confederate forces by Union armies in the American Civil War.[1]\\r\\n\\r\\n\\r\\nThe Declaration of Independence states:\\r\\nWe hold these truths to be self-evident, that all men are created equal, that they are endowed by their Creator with certain unalienable Rights, that among these are Life, Liberty and the pursuit of Happiness.That to secure these rights, Governments are instituted among Men, deriving their just powers from the consent of the governed,That whenever any Form of Government becomes destructive of these ends, it is the Right of the People to alter or to abolish it, and to institute new Government, laying its foundation on such principles and organizing its powers in such form, as to them shall seem most likely to effect their Safety and Happiness.[2]\\r\\nHistorian Pauline Maier argues that this narrative asserted \\"... the right of revolution, which was, after all, the right Americans were exercising in 1776\\"; and notes that Thomas Jefferson's language incorporated ideas explained at length by a long list of seventeenth-century writers including John Milton, Algernon Sidney, and John Locke and other English and Scottish commentators, all of whom had contributed to the development of the Whig tradition in eighteenth-century Britain.[2]\\r\\nThe right of revolution expressed in the Declaration was immediately followed with the observation that long-practised injustice is tolerated until sustained assaults on the rights of the entire people have accumulated enough force to oppress them;[3] then they may defend themselves.[4][5] This reasoning was not original to the Declaration, but can be found in many prior political writings: Locke's Two Treatises of Government (1690); the Fairfax Resolves of 1774; Jefferson's own Summary View of the Rights of British America; the first Constitution of Virginia, which was enacted five days prior to the Declaration.[6] and Thomas Paine's Common Sense (1776):\\r\\nPrudence, indeed, will dictate that Governments long established should not be changed for light and transient causes; ... mankind are more disposed to suffer, while Evils are sufferable, than to right themselves by abolishing the Forms (\\"of Government\\", editor's addition) to which they are accustomed. But when a long train of abuses and usurpations, pursuing ... a design to reduce them under absolute Despotism, it is their right, it is their duty, to throw off such Government, and to provide new Guards for their future security.[7]\\r\\nGordon S. Wood quotes John Adams: \\"Only repeated, multiplied oppressions placing it beyond all doubt that their rulers had formed settled plans to deprive them of their liberties, could warrant the concerted resistance of the people against their government\\".[8]\\r\\nWith origins in the question of states' rights the issue of secession was argued in many forums and advocated from time to time in both the North and South in the decades after adopting the Constitution and before the American Civil War. Historian Maury Klein described the contemporary debate: \\"Was the Republic a unified nation in which the individual states had merged their sovereign rights and identities forever, or was it a federation of sovereign states joined together for specific purposes from which they could withdraw at any time?\\"[9] He observed that \\"the case can be made that no result of the [American Civil] war was more important than the destruction, once and for all .?.?.?of the idea of secession\\".[10]\\r\\nHistorian Forrest McDonald argued that after adopting the Constitution \\"there were no guidelines, either in theory or in history, as to whether the compact could be dissolved and, if so, on what conditions\\". However, during \\"the founding era, many a public figure .?.?.?declared that the states could interpose their powers between their citizens and the power of the federal government, and talk of secession was not unknown\\". But according to McDonald, to avoid resorting to the violence that had accompanied the Revolution, the Constitution established \\"legitimate means for constitutional change in the future\\". In effect, the Constitution \\"completed and perfected the Revolution\\".[11]\\r\\nWhatever the intentions of the Founders, threats of secession and disunion were a constant in the political discourse of Americans preceding the Civil War. Historian Elizabeth R. Varon wrote:\\r\\n... one word [disunion] contained, and stimulated, their [Americans] fears of extreme political factionalism, tyranny, regionalism, economic decline, foreign intervention, class conflict, gender disorder, racial strife, widespread violence and anarchy, and civil war, all of which could be interpreted as God's retribution for America's moral failings. Disunion connoted the dissolution of the republicthe failure of the Founders' efforts to establish a stable and lasting representative government. For many Americans in the North and the South, disunion was a nightmare, a tragic cataclysm that would reduce them to the kind of fear and misery that seemed to pervade the rest of the world. And yet, for many other Americans, disunion served as the main instrument by which they could achieve their political goals.[12]\\r\\nIn late 1777 the Second Continental Congress approved the Articles of Confederation for ratification by the individual states. The confederation government was administered de facto by the Congress under the provisions of the approved (final) draft of the Articles until they achieved ratificationand de jure statusin early 1781. In 1786 delegates of five states (the Annapolis Convention) called for a convention of delegates in Philadelphia to amend the Articleswhich would require unanimous consent of the thirteen states.\\r\\nThe delegates to the Philadelphia Convention convened and deliberated from May to September 1787. Instead of pursuing their official charge they returned a draft (new) Constitution, proposed for constructing and administering a new federallater also known as \\"national\\"government. They further proposed that the draft Constitution not be submitted to the Congress (where it would require unanimous approval of the states); instead that it be presented directly to the states for ratification in special ratification conventions, and that approval by a minimum of nine state conventions would suffice to adopt the new Constitution and initiate the new federal government; and that only those states ratifying the Constitution would be included in the new government. (For a time, eleven of the original states operated under the Constitution without two non-ratifying states, Rhode Island and North Carolina.) In effect, the delegates proposed to abandon and replace the Articles of Confederation rather than amend them.[a]\\r\\nBecause the Articles had specified a \\"perpetual union\\", various arguments have been offered to explain the apparent contradiction (and presumed illegality) of abandoning one form of government and creating another that did not include the members of the original.[b] One explanation was that the Articles of Confederation simply failed to protect the vital interests of the individual states. Necessity then, rather than legality, was the practical factor in abandoning the Articles.[14]\\r\\nAccording to historian John Ferling, by 1786 the Union under the Articles was falling apart. James Madison of Virginia and Alexander Hamilton of New Yorkthey who joined together to vigorously promote a new Constitutionurged that renewed stability of the Union government was critically needed to protect property and commerce. Both founders were strong advocates for a more powerful central government; they published The Federalist Papers to advocate their cause and became known as the federalists. (Because of his powerful advocacy Madison was later accorded the honorific \\"Father of the Constitution\\".)[c] Ferling wrote:\\r\\nRumors of likely secessionist movements were unleashed. There was buzz as well that some states planned to abandon the American Union and form a regional confederacy. America, it was said, would go the way of Europe, and ultimately three or four, or more confederacies would spring up. ... Not only would these confederations be capable of taking steps that were beyond the ability of Congress under the articles, but in private some portrayed such a step in a positive light, in as much as the regional union could adopt constitutions that secured property rights and maintained order.[d]\\r\\nOther arguments that justified abandoning the Articles of Confederation pictured the Articles as an international compact between unconsolidated, sovereign states, any one of which was empowered to renounce the compact at will. (This as opposed to a consolidated union that \\"totally annihilated, without any power of revival\\" the sovereign states.)[17] The Articles required that all states were obliged to comply with all requirements of the agreement; thus, permanence was linked to compliance.\\r\\n'Compliance' was typically perceived as a matter of interpretation by each individual state. Emerich de Vattel, a recognized authority on international law, wrote at the time that \\"Treaties contain promises that are perfect and reciprocal. If one of the allies fails in his engagements, the other may ... disengage himself in his promises, and ... break the treaty.\\"[17] Thus, each state could unilaterally 'secede' from the Articles of Confederation at will; this argument for abandoning the Articlesfor its weakness in the face of secessionwas used by advocates for the new Constitution and was featured by James Madison in Federalist No. 43.[e]\\r\\nSome[who?] argued that abandoning the Articles was the same as seceding from the Articles and thus was legal precedent for future secession(s) from the Constitution. St. George Tucker, a jurist in the early republic era, wrote in 1803:\\r\\nAnd since the seceding states, by establishing a new constitution and form of federal government among themselves, without the consent of the rest, have shown that they consider the right to do so whenever the occasion may, in their opinion require it, we may infer that the right has not been diminished by any new compact which they may since have entered into, since none could be more solemn or explicit than the first, nor more binding upon the contracting partie[s].\\"[18]\\r\\nOthers denied that such a precedent was set; constitutional historian Akhil Reed Amar wrote:\\r\\nThe fact that a new union was lawfully formed in the 1780s by secession from the old confederacy did not mean that a new confederacy could be lawfully formed in the 1860s by secession from the old union. ...\\r\\nWriting in 1824, exactly midway between the fall of the Articles of Confederation and the rise of a second self-described American Confederacy, [Chief Justice John] Marshall summarized the issue nicely: \\"Reference has been made to the political situation of these states, anterior to [the Constitution's] formation. It has been said that they were sovereign, were completely independent, and were connected with each other only by a league. This is true. But, when these allied sovereigns converted their league into a government, when they converted their congress of ambassadors, deputed to deliberate on their common concerns, and to recommend measures of general utility, into a legislature, empowered to enact laws on the most interesting subjects, the whole character in which the states appear underwent a change.\\"[19]\\r\\nOthers[who?] argued the opposite of secession; that indeed the new Constitution inherited perpetuity from the language in the Articles and from other actions done prior to the Constitution. Historian Kenneth Stampp explains their view:\\r\\nLacking an explicit clause in the Constitution with which to establish the Union's perpetuity, the nationalists made their case, first, with a unique interpretation of the history of the country prior to the Philadelphia Convention; second, with inferences drawn from certain passages of the Constitution; and third, with careful selections from the speeches and writings of the Founding Fathers. The historical case begins with the postulate that the Union is older than the states. It quotes the reference in the Declaration of Independence to \\"these united colonies\\", contends that the Second Continental Congress actually called the states into being [i.e., \\"colonies\\" no longer], notes the provision for a perpetual Union in the Articles of Confederation, and ends with the reminder that the preamble to the new Constitution gives as one of its purposes the formation of \\"a more perfect Union\\".[20]\\r\\nConstitutional scholar Akhil Reed Amar argues that the permanence of the Union of the states changed significantly when the U.S. Constitution replaced the Articles of Confederation. This action \\"signaled its decisive break with the Articles' regime of state sovereignty\\".[21] By adopting a constitutionrather than a treaty, or a compact, or an instrument of confederacy, etc.that created a new body of government designed to be senior to the several states, and by approving the particular language and provisions of that new Constitution, the framers and voters made it clear that the fates of the individual states were (severely) changed; and that the new United States was:\\r\\nNot a \\"league\\", however firm; not a \\"confederacy\\" or a \\"confederation\\"; not a compact on among \\"sovereign' states\\"all these high profile and legally freighted words from the Articles were conspicuously absent from the Preamble and every other operative part of the Constitution. The new text proposed a fundamentally different legal framework.[22]\\r\\nPatrick Henry adamantly opposed adopting the Constitution because he interpreted its language to replace the sovereignty of the individual states, including that of his own Virginia. He gave his strong voice to the anti-federalist cause in opposition to the federalists led by Madison and Hamilton. Questioning the nature of the proposed new federal government, Henry asked:\\r\\nThe fate ... of America may depend on this. ... Have they made a proposal of a compact between the states? If they had, this would be a confederation. It is otherwise most clearly a consolidated government. The question turns, sir, on that poor little thingthe expression, We, the people, instead of the states, of America. ...[23]\\r\\nThe federalists acknowledged that national sovereignty would be transferred by the new Constitution to the whole of the American peopleindeed, regard the expression, \\"We the people?...\\". They argued, however, that Henry exaggerated the extent to which a consolidated government was being created and that the states would serve a vital role within the new republic even though their national sovereignty was ending. Tellingly, on the matter of whether states retained a right to unilaterally secede from the United States, the federalists made it clear that no such right would exist under the Constitution.[24]\\r\\nAmar specifically cites the example of New York's ratification as suggestive that the Constitution did not countenance secession. Anti-federalists dominated the Poughkeepsie Convention that would ratify the Constitution. Concerned that the new compact might not sufficiently safeguard states' rights, the anti-federalists sought to insert into the New York ratification message language to the effect that \\"there should be reserved to the state of New York a right to withdraw herself from the union after a certain number of years.\\"[25] The Madison federalists opposed this, with Hamilton, a delegate at the Convention, reading aloud in response a letter from James Madison stating: \\"the Constitution requires an adoption in toto, and for ever\\" [emphasis added]. Hamilton and John Jay then told the Convention that in their view, reserving \\"a right to withdraw [was] inconsistent with the Constitution, and was no ratification\\".[25] The New York convention ultimately ratified the Constitution without including the \\"right to withdraw\\" language proposed by the anti-federalists.\\r\\nAmar explains how the Constitution impacted on state sovereignty:\\r\\nIn dramatic contrast to Article VIIÿwhose unanimity rule that no state can bind another confirms the sovereignty of each state prior to 1787 ÿ Article V does not permit a single state convention to modify the federal Constitution for itself. Moreover, it makes clear that a state may be bound by a federal constitutional amendment even if that state votes against the amendment in a properly convened state convention. And this rule is flatly inconsistent with the idea that states remain sovereign after joining the Constitution, even if they were sovereign before joining it. Thus, ratification of the Constitution itself marked the moment when previously sovereign states gave up their sovereignty and legal independence.[26]\\r\\nDonald Livingston has written that the Founders themselves held that \\"the states were republics, but the central government was not,\\" and as such maintained the right to reclaim their sovereignty from \\"a central government limited to foreign affairs, declaring war, and regulating commerce\\".[27]\\r\\nDebates on the legality of secession often looked back to the example of the American Revolution and the Declaration of Independence. Law professor Daniel Farber defined what he considered the borders of this debate:\\r\\nWhat about the original understanding? The debates contain scattered statements about the permanence or impermanence of the Union. The occasional reference to the impermanency of the Constitution are hard to interpret. They might have referred to a legal right to revoke ratification. But they equally could have referred to an extraconstitutional right of revolution, or to the possibility that a new national convention would rewrite the Constitution, or simply to the factual possibility that the national government might break down. Similarly, references to the permanency of the Union could have referred to the practical unlikelihood of withdrawal rather than any lack of legal power. The public debates seemingly do not speak specifically to whether ratification under Article VII was revocable.[28]\\r\\nIn the public debate over the Nullification Crisis the separate issue of secession was also discussed. James Madison, often referred to as \\"The Father of the Constitution\\", strongly opposed the argument that secession was permitted by the Constitution.[29] In a March 15, 1833, letter to Daniel Webster (congratulating him on a speech opposing nullification), Madison discussed \\"revolution\\" versus \\"secession\\":\\r\\nI return my thanks for the copy of your late very powerful Speech in the Senate of the United S. It crushes \\"nullification\\" and must hasten the abandonment of \\"Secession\\". But this dodges the blow by confounding the claim to secede at will, with the right of seceding from intolerable oppression. The former answers itself, being a violation, without cause, of a faith solemnly pledged. The latter is another name only for revolution, about which there is no theoretic controversy.[30]\\r\\nThus Madison affirms an extraconstitutional right to revolt against conditions of \\"intolerable oppression\\"; but if the case cannot be made (that such conditions exist), then he rejects secessionas a violation of the Constitution.\\r\\nDuring the crisis, President Andrew Jackson, published his Proclamation to the People of South Carolina, which made a case for the perpetuity of the Union; plus, he provided his views re the questions of \\"revolution\\" and \\"secession\\":[31]\\r\\nBut each State having expressly parted with so many powers as to constitute jointly with the other States a single nation, cannot from that period possess any right to secede, because such secession does not break a league, but destroys the unity of a nation, and any injury to that unity is not only a breach which would result from the contravention of a compact, but it is an offense against the whole Union. [emphasis added] To say that any State may at pleasure secede from the Union, is to say that the United States are not a nation because it would be a solecism to contend that any part of a nation might dissolve its connection with the other parts, to their injury or ruin, without committing any offense. Secession, like any other revolutionary act, may be morally justified by the extremity of oppression; but to call it a constitutional right, is confounding the meaning of terms, and can only be done through gross error, or to deceive those who are willing to assert a right, but would pause before they made a revolution, or incur the penalties consequent upon a failure.[32]\\r\\nSome twenty-eight years after Jackson spoke, President James Buchanan gave a different voiceone much more accommodating to the views of the secessionists and the 'slave' statesin the midst of the pre-War secession crisis. In his final State of the Union address to Congress, on December 3, 1860, he acknowledged his view that the South, \\"after having first used all peaceful and constitutional means to obtain redress, would be justified in revolutionary resistance to the Government of the Union\\"; but he also drew his apocalyptic vision of the results to be expected from secession:[33]\\r\\nIn order to justify secession as a constitutional remedy, it must be on the principle that the Federal Government is a mere voluntary association of States, to be dissolved at pleasure by any one of the contracting parties. [emphasis added] If this be so, the Confederacy [here referring to the existing Union] is a rope of sand, to be penetrated and dissolved by the first adverse wave of public opinion in any of the States. In this manner our thirty-three States may resolve themselves into as many petty, jarring, and hostile republics, each one retiring from the Union without responsibility whenever any sudden excitement might impel them to such a course. By this process a Union might be entirely broken into fragments in a few weeks which cost our forefathers many years of toil, privation, and blood to establish.[34]\\r\\nIn response to the 1798 Alien and Sedition Actsadvanced by the Federalist PartyJohn Taylor of the Virginia House of Delegates spoke out, urging Virginia to secede from the United States. He arguedas one of many vociferous responses by the Jeffersonian Republicansthe sense of the Kentucky and Virginia Resolutions, adopted in 1798 and 1799, which reserved to those States the rights of secession and interposition (nullification).[35]\\r\\nThomas Jefferson, while sitting as Vice President of the United States in 1799, wrote to James Madison of his conviction in \\"a reservation of th[ose] rights resulting to us from these palpable violations [the Alien and Sedition Acts]\\" and, if the federal government did not return to\\r\\n\\"the true principles of our federal compact\\", [he was determined to] \\"sever ourselves from that union we so much value, rather than give up the rights of self government which we have reserved, and in which alone we see liberty, safety and happiness.\\"[emphasis added][36]\\r\\nHere Jefferson is arguing in a radical voice (and in a private letter) that he would lead a movement for secession; but it is unclear whether he is arguing for \\"secession at will\\" or for \\"revolution\\" on account of \\"intolerable oppression\\" (see above), or neither. Either way, some historians[who?] conclude that his language and acts were broaching the legal edges of treason. Jefferson secretly wrote (one of) the Kentucky Resolutions, which was doneagainwhile he was holding the office of Vice President. His biographer Dumas Malone argued that, had his actions become known at the time, Jefferson's participation might have gotten him impeached for (charged with) treason.[37] In writing the first Kentucky Resolution, Jefferson warned that, \\"unless arrested at the threshold,\\" the Alien and Sedition Acts would \\"necessarily drive these states into revolution and blood\\". Historian Ron Chernow says of this \\"he wasn't calling for peaceful protests or civil disobedience: he was calling for outright rebellion, if needed, against the federal government of which he was vice president.\\" Jefferson \\"thus set forth a radical doctrine of states' rights that effectively undermined the constitution\\".[38]\\r\\nJeffersonian Republicans were not alone in claiming \\"reserved rights\\" against the federal government. Contributing to the rancorous debates during the War of 1812, Founding Father Gouverneur Morris of Pennsylvania and New Yorka Federalist, a Hamilton ally and a primary author of the Constitution who advanced the concept that Americans were citizens of a single Union of the stateswas persuaded to claim that \\"secession, under certain circumstances, was entirely constitutional.\\"[39]\\r\\nThe election of 1800 showed Jefferson's Democratic-Republican Party on the rise and the Federalists declining. The Federalists felt threatened by initiatives taken by their opponents. They viewed Jefferson's unilateral purchase of the Louisiana territory as violating foundational agreements between the original thirteen statesJefferson transacted the purchase in secret and refused to seek the approval of Congress. The new lands anticipated several future western states that would bethe Federalists supposedpopulated by emigrants from the eastern states who likely would be dominated by the Democratic-Republicans. The impeachment of John Pickering, a Federalist district judge, by the Jeffersonian dominated Congress and similar attacks on Pennsylvania state officials by the Democratic-Republican legislature added to the Federalists' alarm. By 1804, their national leadership was decimated and their viable base was reduced to the states of Massachusetts, Connecticut, and Delaware.[40]\\r\\nTimothy Pickering of Massachusetts and a few Federalists envisioned creating a separate New England confederation, possibly combining with lower Canada to form a new pro-British nation. Historian Richard Buell, Jr., characterizes these separatist musings:\\r\\nMost participants in the explorationsit can hardly be called a plot since it never took concrete formfocused on the domestic obstacles to consummating their fantasy. These included lack of popular support for such a scheme in the region. ... The secessionist movement of 1804 was more of a confession of despair about the future than a realistic proposal for action.[41]\\r\\nThe Embargo Act of 1807 was seen as a threat to the economy of Massachusetts, and, in May 1808, the state legislature debated how the state should respond. These debates generated isolated references to secession, but no definite plot materialized.[42]\\r\\nFederalist party members convened the Hartford Convention on December 15, 1814; they addressed their opposition to the continuing war with England and the domination of the federal government by the 'Virginia dynasty'. Twenty six delegates attendedMassachusetts sent 12, Connecticut seven, and Rhode Island four; New Hampshire and Vermont declined but two counties each from those states sent delegates.[43] Historian Donald R. Hickey noted:\\r\\nDespite pleas in the New England press for secession and a separate peace, most of the delegates taking part in the Hartford Convention were determined to pursue a moderate course. Only Timothy Bigelow of Massachusetts apparently favored extreme measures, and he did not play a major role in the proceedings.[43]\\r\\nThe final report addressed issues related to the war and state defense; and it recommended several amendments to the Constitution dealing with \\"the overrepresentation of white southerners in Congress, the growing power of the West, the trade restrictions and the war, the influence of foreigners (like Albert Gallatin), and the Virginia dynasty's domination of national politics\\".[44][45]\\r\\nMassachusetts and Connecticut endorsed the report, but the war ended as the delegates were returning to Washington, effectively quashing any good impact the report might have had. Generally, the Hartford Convention was a \\"victory for moderation\\", but the timing of events caused the convention to be castigated (by the Jeffersonians) as \\"a synonym for disloyalty and treason\\"; all which became a major factor in the sharp decline of the Federalist Party.[46]\\r\\nBy the late 1830s tensions between north and south, already aggravated over tariff disputes, begin to rise ominously over slavery and related issues. Many northerners, especially New Englanders, saw themselves as political victims of conspiracies between slaveholders and western expansionists. They viewed the movements to annex Texas and to make war on Mexico as fomented by slaveholders bent on dominating western expansionand thereby the national destinywith 'slave' states and a 'slave' national economy.\\r\\nHistorian Joel Sibley wrote of the beliefs held by some leaders in New England:\\r\\nTexas annexation, the abolitionist Benjamin Lundy argued when the issue first arose in 1836, was \\"a long premeditated crusadeset on foot by slaveholders, land speculators, etc., with the view of reestablishing, extending, and perpetuating the system of slavery and the slave trade\\"[.] John Quincy Adams had made a similar argument on the floor of the House of Representatives then. Other expressions of the same themeor accusationhad been heard throughout the decade that followed, whenever Texas was mentioned.[48]\\r\\nVoices demanding separation from the south were beginning (again). In The Liberator of May 1844 with his \\"Address to the Friends of Freedom and Emancipation in the United States,\\" William Lloyd Garrison called for disunion (secession). Garrison wrote: the Constitution was created \\"at the expense of the colored population of the country\\"; southerners were dominating the nationespecially representation in Congressbecause of the Three-Fifths Compromise; now it was time \\"to set the captive free by the potency of truth\\" and to \\"secede from the government\\".[49] Coincidentally, the New England Anti-Slavery Convention endorsed the principles of disunion by a vote of 250ÿ24.[50]\\r\\nFrom 1846, after introduction of the Wilmot Proviso into the public debate, talk in favor of secession shifted to southern voices. Southern leaders' increasing perceptions of helplessness in confronting a powerful political group attacking their interests (and survival) were reminiscent of Federalist alarms at the beginning of the century.\\r\\nDuring the presidential term of Andrew Jackson, South Carolina had its own semi-secession movement due to the 1828 \\"Tariff of Abominations\\" which threatened both South Carolina's economy and the Union. Andrew Jackson also threatened to send federal troops to put down the movement and to hang the leader of the secessionists from the highest tree in South Carolina. Also due to this, Jackson's vice president, John C. Calhoun, who supported the movement and wrote the essay \\"The South Carolina Exposition and Protest\\", became the first US vice-president to resign. On May 1, 1833, Jackson wrote of nullification, \\"the tariff was only a pretext, and disunion and southern confederacy the real object. The next pretext will be the negro, or slavery question.\\"[51] South Carolina also threatened to secede in 1850 over the issue of California's statehood. It became the first state to declare its secession from the Union on December 20, 1860, with the Declaration of the Immediate Causes Which Induce and Justify the Secession of South Carolina from the Federal Union and later joined with the other southern states in the Confederacy.\\r\\nThe most famous secession movement was the case of the Southern states of the United States. Secession from the United States was accepted in eleven states (and failed in two others). The seceding states joined together to form the Confederate States of America (CSA). The eleven states of the CSA, in order of secession, were: South Carolina (seceded December 20, 1860), Mississippi (seceded January 9, 1861), Florida (seceded January 10, 1861), Alabama (seceded January 11, 1861), Georgia (seceded January 19, 1861), Louisiana (seceded January 26, 1861), Texas (seceded February 1, 1861), Virginia (seceded April 17, 1861), Arkansas (seceded May 6, 1861), North Carolina (seceded May 20, 1861), and Tennessee (seceded June 8, 1861). Secession was declared by its supporters in Missouri and Kentucky, but did not become effective as it was opposed by their pro-Union state governments. This secession movement brought about the American Civil War. The position of the Union was that the Confederacy was not a sovereign nationand never had been, but that \\"the Union\\" was always a single nation by intent of the states themselves, from 1776 onwardand thus that a rebellion had been initiated by individuals. Historian Bruce Catton described President Abraham Lincoln's April 15, 1861, proclamation after the attack on Fort Sumter, which defined the Union's position on the hostilities:\\r\\nAfter reciting the obvious fact that \\"combinations too powerful to be suppressed\\" by ordinary law courts and marshalls had taken charge of affairs in the seven secessionist states, it announced that the several states of the Union were called on to contribute 75,000 militia \\"...to suppress said combinations and to cause the laws to be duly executed.\\" ... \\"And I hereby command the persons composing the combinations aforesaid to disperse, and retire peacefully to their respective abodes within twenty days from this date.[52]\\r\\nThe Constitution does not directly mention secession.[53] The legality of secession was hotly debated in the 19th century, with Southerners often claiming and Northerners generally denying that states have a legal right to unilaterally secede.[54] The Supreme Court has consistently interpreted the Constitution to be an \\"indestructible\\" union.[53] There is no legal basis a state can point to for unilaterally seceding.[55] Many scholars hold that the Confederate secession was blatantly illegal. The Articles of Confederation explicitly state the Union is \\"perpetual\\"; the U.S. Constitution declares itself an even \\"more perfect union\\" than the Articles of Confederation.[56] Other scholars, while not necessarily disagreeing that the secession was illegal, point out that sovereignty is often de facto an \\"extralegal\\" question. Had the Confederacy won, any illegality of its actions under U.S. law would have been rendered irrelevant, just as the undisputed illegality of American rebellion under the British law of 1775 was rendered irrelevant. Thus, these scholars argue, the illegality of unilateral secession was not firmly de facto established until the Union won the Civil War; in this view, the legal question was resolved at Appomattox.[54][57]\\r\\nTexas v. White[56] was argued before the United States Supreme Court during the December 1868 term. Chief Justice Salmon P. Chase read the Court's decision, on April 15, 1869.[58] Australian Professors Peter Radan and Aleksandar Pavkovic write:\\r\\nChase, [Chief Justice], ruled in favor of Texas on the ground that the Confederate state government in Texas had no legal existence on the basis that the secession of Texas from the United States was illegal. The critical finding underpinning the ruling that Texas could not secede from the United States was that, following its admission to the United States in 1845, Texas had become part of \\"an indestructible Union, composed of indestructible states\\". In practical terms, this meant that Texas has never seceded from the United States.[59]\\r\\nHowever, the Court's decision recognized some possibility of the divisibility \\"through revolution, or through consent of the States\\".[59][60]\\r\\nIn 1877, the Williams v. Bruffy[61] decision was rendered, pertaining to civil war debts. The Court wrote regarding acts establishing an independent government that \\"The validity of its acts, both against the parent state and the citizens or subjects thereof, depends entirely upon its ultimate success; if it fail to establish itself permanently, all such acts perish with it; if it succeed and become recognized, its acts from the commencement of its existence are upheld as those of an independent nation.\\"[59][62]\\r\\nHistorian Kenneth Stampp notes that a historical case against secession had been made that argued that \\"the Union is older than the states\\" and that \\"the provision for a perpetual Union in the Articles of Confederation\\" was carried over into the Constitution by the \\"reminder that the preamble to the new Constitution gives us one of its purposes the formation of 'a more perfect Union'\\".[20] Concerning the White decision Stampp wrote:\\r\\nIn 1869, when the Supreme Court, in Texas v. White, finally rejected as untenable the case for a constitutional right of secession, it stressed this historical argument. The Union, the Court said, \\"never was a purely artificial and arbitrary relation\\". Rather, \\"It began among the Colonies. ...It was confirmed and strengthened by the necessities of war, and received definite form, and character, and sanction from the Articles of Confederation.\\"[20]\\r\\nThe Republic of Texas successfully seceded from Mexico in 1836 (this, however took the form of outright rebellion against Mexico, and claimed no warrant under the Mexican Constitution to do so). Mexico refused to recognize its revolted province as an independent country, but the major nations of the world did recognize it. In 1845, Congress admitted Texas as a state. The documents governing Texas' accession to the United States of America do not mention any right of secessionalthough they did raise the possibility of dividing Texas into multiple states inside the Union. Mexico warned that annexation meant war and the MexicanÿAmerican War followed in 1846.[63]\\r\\nArticle IV, Section. 3, Clause 1 of the United States Constitutions provides:\\r\\nThe separation referred to is not secession but partition. Some of the movements to partition states have incorrectly identified themselves as \\"secessionist\\" movements.\\r\\nOf the new states admitted to the Union by Congress, three were set off from already existing states,[64] while one was established upon land claimed by an existing state after existing for several years as a de facto independent republic. They are:\\r\\nMany proposals to partition U.S. states have been unsuccessful.\\r\\nThe late 20th and early 21st centuries have seen examples of local and state secession movements. All such movements to create new states have failed. The formation in 1971 of the Libertarian Party and its national platform affirmed the right of states to secede on three vital principles: \\"We shall support recognition of the right to secede. Political units or areas which do secede should be recognized by the United States as independent political entities where: (1) secession is supported by a majority within the political unit, (2) the majority does not attempt suppression of the dissenting minority, and (3) the government of the new entity is at least as compatible with human freedom as that from which it seceded.\\"[72]\\r\\nThere was an attempt by Staten Island to break away from New York City in the late 1980s and early 1990s, leading to a 1993 referendum, in which 65% voted to secede. Implementation was blocked in the State Assembly by assertions that the state's constitution required a \\"home rule message\\" from New York City.[73]\\r\\nThe San Fernando Valley lost a vote to separate from Los Angeles in 2002. Despite the majority (55%) of the valley within the L.A. city limits voting for secession, the city council unanimously voted to block the partition of the valley north of Mulholland Drive.\\r\\nOther attempted city secession drives include Killington, Vermont, which has voted twice (2005 and 2006) to join New Hampshire; the community of Miller Beach, Indiana, originally a separate incorporated community, to split from the city of Gary in 2007 and Northeast Philadelphia to split from the city of Philadelphia in the 1980s.\\r\\nA portion of the town of Calabash, North Carolina voted to secede from the town in 1998 after receiving permission for a referendum on the issue from the state of North Carolina. Following secession, the area incorporated itself as the town of Carolina Shores. Despite the split, the towns continue to share fire and emergency services.[74]\\r\\nSome state movements seek secession from the United States itself and the formation of a nation from one or more states.\\r\\nA September 2017 Zogby International poll found that 68% of Americans were open to states of the USA seceding.[131] A 2014 Reuters/Ipsos poll showed 24% of Americans supported their state seceding from the union if necessary; 53% opposed the idea. Republicans were somewhat more supportive than Democrats. Respondents cited issues like gridlock, governmental overreach, the Affordable Care Act and a loss of faith in the federal government as reasons for secession.[132]","input":"When did the first state secede from the union?"},{"output":"almost 10,000","context":"During the Vietnam War, thousands of U.S. aircraft were lost to antiaircraft artillery (AAA), surface-to-air missiles (SAMs), and fighter interceptors (MiG)s. The great majority of U.S. combat losses in all areas of Southeast Asia were to AAA. The Royal Australian Air Force also flew combat and airlift missions in South Vietnam, as did the Republic of Vietnam. Among fixed-wing aircraft, more F-4 Phantoms were lost than any other type in service with any nation. In total, the United States military lost in Vietnam almost 10,000 aircraft, helicopters and 578 UAVs (554 over Vietnam and 24 over China).[1]\\r\\nSouth Vietnam's army lost 2,500 aircraft and helicopters, excluding number of UAVs (including 1,018 aircraft and helicopters lost from January 1964 to September 1973[2]))\\r\\nNorth Vietnam lost 150 ÿ 200 aircraft and helicopters.\\r\\n\\r\\n\\r\\nAll told, the U.S. Air Force flew 5.25 million sorties over South Vietnam, North Vietnam, northern and southern Laos, and Cambodia, losing 2,251 aircraft: 1,737 to hostile action, and 514 in accidents. 2,197 of the losses were fixed-wing, and the remainder rotary-wing. The USAF sustained approximately 0.4 losses per 1,000 sorties during the conflict, which compared favorably with a 2.0 rate in Korea and a 9.7 figure during World War II.[3][4]:268\\r\\nTwenty-one aircraft carriers conducted 86 war cruises and operated 9,178 total days on the line in the Gulf of Tonkin. 530 aircraft were lost in combat and 329 more to operational causes, resulting in the deaths of 377 naval aviators, with 64 airmen reported missing and 179 taken prisoner of war.\\r\\nU.S. Marine Corps aircraft lost in combat included 193 fixed-wing and 270 rotary-wing aircraft.\\r\\n[citation needed]\\r\\nSource for F-4 losses is Phantom with U.S. Marine Corps (Joe Baugher), others are unsourced\\r\\n5,086 (which include not in addition to the above statistics)[11]\\r\\nVNAF a/c details sourced from \\"Flying Dragon ÿ The Republic of Vietnam Air Force\\" Robert C. Milikesh, Schiffer Military History, 2005\\r\\nNorth Vietnam army captured 877 South Vietnam aircraft at war's end. The total number of downed and captured aircraft is unknown.[12]\\r\\n7 total\\r\\nClaimed by VPAF: 154 MiG aircraft lost through all causes, including 131 in air combat (includes 63 MiG-17s, 8 MiG-19s and 60 MiG-21s)[15][16]\\r\\nSources for USAF figures:\\r\\nSources for USN carrier-based figures:","input":"How many aircraft did the us lost in vietnam?"},{"output":"11 May 2015","context":"\\"Photograph\\" is a song recorded by the English singer-songwriter, Ed Sheeran, for his second studio album, G (2014). Sheeran wrote the song with Snow Patrol member, Johnny McDaid, who had a piano loop from which the composition developed. After recording several versions with other producers, Sheeran eventually solicited help from Jeff Bhasker; the collaboration generated a version that Bhasker further enhanced for months. The ballad derives its music primarily from an acoustic guitar, piano and programmed drums. With visually descriptive lyrics, it discusses a long-distance relationship inspired by Sheeran's own experience of being away from his then-girlfriend while he was on tour.[disambiguation needed]\\r\\nThe song received generally positive commentary from critics, who noted the lyrics and Sheeran's use of imagery. \\"Photograph\\" served as the fifth and final single from the album. It reached the top five on the main singles charts in more than five countries. In the US, where it peaked at No. 10, \\"Photograph\\" became the third single from the album to have reached within the top ten. In the UK, it reached No. 15 and has since been certified platinum for sales of 600,000 units. The single has also been certified double platinum in Australia and Canada, and platinum in New Zealand and Italy.\\r\\nThe single's release on 11 May 2015 followed the premiere of the music video on 9 May 2015. The video is a montage of real home footage of Sheeran's infancy, childhood and adolescence, providing insight on his private early life such as his inclination to playing music instruments and fondness of Lego. The video was nominated for Best Video at the 2016 Brit Awards. Sheeran performed the song on television shows and on his x Tour, which ran from 2014 to 2015.\\r\\nOn 9 June 2016, it was revealed that Sheeran was being sued by songwriters Martin Harrington and Thomas Leonard, writers of Matt Cardle's 2011 single \\"Amazing\\", for $20 million for copyright infringement for note-for-note plagiarism.[2][3] The lawsuit was privately settled in April 2017, with no admission of guilt.[3]\\r\\n\\r\\n\\r\\nEd Sheeran wrote \\"Photograph\\" in May 2012 with Johnny McDaid,[4][5] instrumentalist and background vocalist of the British band Snow Patrol. Sheeran toured with the band, for whom he provided opening performances in select North American dates. McDaid had a three-note[6] piano loop that became the basis of \\"Photograph\\".[7] The song's development began when Sheeran, while in a hotel room in Kansas City, was humming \\"loving can hurt, loving can hurt\\" to the loop that was playing on McDaid's laptop.[5][6][7] Sheeran recalled: \\"I started humming, and then [McDaid] put a beat behind it.\\"[8]\\r\\nThey developed ideas for the song while Sheeran was building a Lego and McDaid was working on his laptop. After four hours, Sheeran picked up a guitar and they began properly structuring the composition.[4] According to Sheeran, they ended up composing the song \\"within about half an hour\\".[8] Both realized what had transpired only after listening back to the song the following day; they then decided on recording it.[8] Sheeran completed writing the song while in Denver, Colorado.[7]\\r\\nSheeran credited \\"Photograph\\" as the first record \\"properly\\" completed for his second studio album.[9] According to him, he had \\"probably\\" recorded 60 to 70 versions of the song; these varied from live to that with piano accompaniment. Aside from the earlier versions he made with McDaid, Sheeran had recordings with songwriter-producer, Jake Gosling, who produced much of Sheeran's debut album, and producer, Rick Rubin, who was involved in other tracks from the follow-up album. However, Sheeran thought these versions \\"never fit\\" and he eventually solicited help from producer, Jeff Bhasker.[9] This particular collaboration generated a version that Bhasker continued to enhance for several months. Emile Haynie was credited on the album's liner notes for his additional production. On 24 January 2015, Sheeran recalled the backstory of \\"Photograph\\" for the VH1 Storytellers.[8]\\r\\nAn acoustic pop[10] ballad, \\"Photograph\\" derives its music from an acoustic guitar, piano, strings, organ, electric and bass guitar, and programmed drums. The melody builds up with the guitar strums and piano keys; the drums, strings, organ etc. then follow.[1] It has a tempo of 108 beats per minute and the originally published key is in E major.[11] \\"Photograph\\" features a chord progression that is common in popular music.[12]\\r\\nThe lyrics to the song chronicle a long-distance relationship.[13] It contains detailed imagery such as the protagonist remembering his girlfriend kissing him \\"under the lamppost, back on 6th street\\",[13][14] and keeping a picture of him \\"in the pocket of [her] ripped jeans\\".[15] These lyrics were inspired by Sheeran's own experience on a long-distance relationship. He dated Nina Nesbitt,[4] a Scottish singer/songwriter, for more than a year. While on this relationship, Sheeran spent five months away from Nesbitt: three months while on a concert tour with Snow Patrol and further two months on his own tour. At his concert in Kansas City on June 29, 2017, Sheeran noted that he wrote the song Photograph at Kansas City's Intercontinental Hotel during a previous tour. [7]\\r\\nIn February 2013, Sheeran played a demo version of \\"Photograph\\" to a German radio station. This performance was not recorded in film or audio, and was the only play Sheeran made prior to the song's release as part of an album. Sheeran favoured the song as one of the best in the album and claimed: \\"I think [\\"Photograph\\"] will be the one that will change my, kind of, career path.\\"[16] He also asserted that \\"Photograph\\" would serve as the \\"collateral\\" song that could \\"sell [the album]\\" even if the rest of the tracks would not prove appealing.[17]\\r\\nThe song was released as an \\"instant grat\\" digital download to the iTunes Store on 20 June 2014;[18] it served as the final of seven promotional singles from his second studio album, G (2014). On 22 April 2015, through his Twitter account, Sheeran announced that \\"Photograph\\" would be the next single off G.[19] It was released on 11 May 2015 to hot adult contemporary format,[20] and the following day to contemporary hit radio in the US.[21] On 12 June 2015, \\"Photograph\\" was released to the German market in CD format with the B-side, \\"I Will Take You Home\\".[22] The latter track was featured in the American television sitcom, Cougar Town.[23]\\r\\n\\"Photograph\\" served as the fifth and last single released from the album.[24] Of the five singles, preceded by two upbeat songs such as the lead single, \\"Sing\\", \\"Photograph\\" was the second mellow track released from G. The first was \\"Thinking Out Loud\\", the third single, which is a blue-eyed soul record produced by Gosling. According to Sheeran, no one from his label wanted \\"Thinking Out Loud\\" as a single release; they favoured \\"Photograph\\" as the \\"big song\\".[25] \\"Photograph\\" was supposed to be the main single, but when \\"Thinking Out Loud\\" spent several weeks within the top 20 on the UK Singles Chart[26] albeit not in radio rotation,[27] the latter song was kept as the third single.\\r\\nUpon the album's release, critical response to \\"Photograph\\" was generally positive. In his track-by-track review of x for Billboard magazine, Jason Lipshutz suggested that the line \\"Loving can hurt sometimes/But it's the only thing that I know\\" in \\"Photograph\\" was the \\"lynchpin line of the whole album\\".[1] Sarah Rodman of The Boston Globe had the same sentiment; she called the song \\"haunting\\" and felt it \\"[crept] up on you with [its] tunefulness\\".[28] Jamieson Cox of Time described Sheeran's use of \\"detail and powerful imagery\\" in the lyrics as \\"smart\\"; Cox opined that it \\"[brought the song] to life\\".[14]\\r\\nNeil McCormick of The Daily Telegraph deemed the track \\"soulful balladry\\" and felt it showcased that Sheeran \\"can slip smoothly through the gears\\" on the album.[29] Lipshutz described his singing as being \\"restrained\\" over \\"hesitant\\" acoustic guitar strum before the \\"arena drums kick in\\".[1] Paul Cantor of Vibe picked \\"Photograph\\" as one of the standouts from the album, and noted that the song's \\"brooding arrangement is an emotional roller coaster\\".[30] Kitty Empire of The Observer called \\"Photograph\\" a \\"swelling ballad\\", and suggested that Sheeran's writing was \\"particularly calculated\\".[15] In his review for MusicOMH, John Murphy also felt that \\"Photograph\\" was \\"calculated and a bit cynical, almost as if it's been written specifically as a soundtrack to a particularly emotional scene in a US television series\\".[31]\\r\\nOn her analysis of the lyrical content of the album, Annie Zaleski of The A.V. Club expressed that Sheeran's \\"self-awareness extends to the rest\\" of the album by tackling homesickness in \\"Photograph\\", for instance.[32] Meanwhile, Carolyn Menyes of the Music Times wrote in her review of the song that \\"in the grander scheme of x, 'Photograph' doesn't quite seem to line up lyrically\\", and noted that most of the album's songs explored \\"the feelings of a lover scorned, cheating exes and a little bit of the excess life\\".[10] She also said: \\"Simply put: 'Photograph' is one of Sheeran's more simplistically beautiful songs.\\"[10]\\r\\nMcDaid's involvement in the song was noted by a few critics. Kevin Harly of The Independent wrote: \\"If you didnt know Snow Patrol's Johnny McDaid produced the ballad 'Photograph', its stolid plod through clichs about how lovin' 'can hurt' and 'heal' should tell you\\".[33] Meanwhile, Dave Hanratty of Drowned in Sound remarked: \\"... the cloying 'Photograph' ... is co-written and produced by a member of Snow Patrol should surprise nobody, given that it follows their heartstring-tugging script so resolutely. At least it moves.\\"[34] The Herald's Alan Morrison felt that \\"Photograph\\" was \\"identikit Snow Patrol\\".[35]\\r\\n\\"Photograph\\" and the rest of the album's tracks entered the UK Singles Chart due to high streaming rates.[36] The single debuted at number 44 on the chart week ending 5 July 2014, ten months prior to the single's release.[18] It peaked at number 15, and has spent 50 weeks on the chart as of the week ending 5 November 2015.[37] On 17 March 2017, the British Phonographic Industry certified the single double platinum for combined sales of 1.2 million units.[38] As of September 2017, the song has accumulated 386,000 copies in actual sales, and with 96 million streams, it has a combined total of 1,347,000 units.[39]\\r\\nIn the US, the single reached number 10 on the Billboard Hot 100 and marked the third top 10 from the album.[40] With \\"Photograph\\", Sheeran also became the ninth male solo artist since 2010 to spawn four top 20 hits from a single album, excluding deluxe editions.[41] In specific formats such as the Mainstream Top 40, the single reached the top 10 on the week ending 29 August 2015;[42] it gave the album four that have achieved the threshold.[43] The single was first certified gold by the Recording Industry Association of America on 21 July 2015, double platinum on February 29, 2016 and triple platinum on August 16, 2017.[44] As of June 2016, the song has sold 1,551,000 copies in the US.[45] Elsewhere, the single reached top five in Austria,[46] Canada,[47] Germany,[48] Ireland,[49] Slovakia,[50] and South Africa.[51]\\r\\nIn April 2015, commercial streaming company Spotify released a report of the most streamed tracks worldwide under the category sleep. \\"Photograph\\" placed at number 18; it joined Sheeran's other six songs ranked in the top 20. Sleep is one of the company's most popular categories that, according to Spotify, \\"people also use for general relaxation and to help themselves unwind\\".[52][53] The Guardian columnist Tim Dowling suggested that the report was an indication of \\"very popular, slightly mellow songs that keep cropping up on sleep playlists\\" but not a list of a \\"carefully curated journey to unconsciousness\\".[54]\\r\\nOn 9 June 2016, it was reported that Sheeran was being sued by songwriters Martin Harrington and Thomas Leonard, writers of Matt Cardle's 2011 single \\"Amazing\\", for $20 million for copyright infringement. The lawsuit says: \\"Given the striking similarity between the chorus of Amazing and Photograph, (the) defendants knew when writing, publishing, recording, releasing, and distributing Photograph that they were infringing on a pre-existing musical composition.\\"[2] The lawsuit was privately settled in April 2017, with no admission of guilt.[3]\\r\\nAn accompanying music video for \\"Photograph\\" was released on 9 May 2015. The video is a montage of real home footage. Sheeran sourced the clips from his father, who was then compiling it into DVDs for their family Christmas present.[55] He initially intended the clips for inclusion in a documentary that was being produced around that time; but looking through the collection, he thought it might work for a music video. Sheeran also admitted he could not attend to an actual video shoot, hence he opted for the montage.[56][57] Emil Nava, who had previously worked with Sheeran on his other promotional music videos, directed \\"Photograph\\".[24] Editor Ellie Johnson worked with Sheeran's father while in central London. According to Johnson, they spent a weekend gathering the clips used in the montage.[58]\\r\\nThe montage chronicles Sheeran's infancy, childhood and adolescence (1990s and 2000s). It features Sheeran playing various music instruments (including piano, cello, bass guitar, acoustic and drums),[24] suggesting that he was musically inclined at a young age.[59] He is also shown displaying his skill in Bodhrn, an Irish frame drum.[60] Other footage depicts a teen Sheeran busking in Galway, Ireland.[61] In another clip before the final, Sheeran is shown performing to a crowd at a festival.[62] Daniel Kreps of Rolling Stone noted that the clips also revealed Sheeran's \\"lifelong obsession with Legos\\",[24] an object the latter referenced on his 2011 single \\"Lego House\\".\\r\\nAccording to Ryan Book of the Music Times, the media form utilized in the montage contradicted the song's title.[18] Kreps stated that the video was reminiscent of Kurt Cobain: Montage of Heck,[24] a documentary film about Nirvana front man and 1990s rock icon Kurt Cobain. According to Kreps, the private life of both artists in their youth were revealed through real home videos.[24]\\r\\n\\"Photograph\\" was performed on television prior to its commercial release. On 13 December 2014, Sheeran appeared on The X Factor UK, where he gave his first televised performance of the song.[63] This performance contributed to the song's first ascent inside the top 40 on the UK Singles Chart.[64] Sheeran also performed the song for various US television shows such as on Good Morning America,[55] The Tonight Show Starring Jimmy Fallon,[65] and Undateable,[66] at Canada's Much Music Video Awards,[67] and at the 2015 Global Citizen Festival.[68] The song was part of the setlist in Sheeran's x Tour;[69] the concert tour ran from 2014 to 2015.\\r\\nIn other usages, English singer Foxes covered the song for the BBC Radio 1 Live Lounge.[70] The song was used, free of charge, in a video campaign that was launched on 2 March 2015. According to Same Dimmer of the Coventry Telegraph, the video \\"[highlighted] the issue of child sexual exploitation\\" in Warwickshire, a non-metropolitan county in England.[71] The song is also used in the trailer and soundtrack for the movie Me Before You.[72] CBS Sports used the song as a backing track for a photo montage of its NFL production crew following its Thanksgiving Day presentation in 2016.\\r\\nThe song was recorded by Jordan Feliz, for his debut studio album, Beloved, released by Centricity Music. A critic says the acoustic rendition shows, \\"his falsetto shining\\",[73] while another writes it is an \\"incredible\\" cover song,[74] on a track meant to convey the temporal nature with which worldly mortal relationships have compared to one with God's son Jesus Christ.[75] Jessica Mauboy covered the song on her 2016 album, The Secret Daughter: Songs from the Original TV Series.\\r\\nCredits adapted from the album liner notes.[77]\\r\\n*sales figures based on certification alone\\r\\n^shipments figures based on certification alone\\r\\nsales+streaming figures based on certification alone","input":"When was ed sheeran's song photograph released?"},{"output":"West African Kaiso","context":"Music television\\r\\nCalypso is a style of Afro-Caribbean music that originated in Trinidad and Tobago during the early to mid-19th century and eventually spread to the rest of Caribbean Antilles and Venezuela by the mid-20th century. Its rhythms can be traced back to West African Kaiso and the arrival of French planters and their slaves from the French Antilles in the 18th century.\\r\\nCalypso drew upon African and French influences, and became the voice of the people[citation needed]. It was characterized by highly rhythmic and harmonic vocals, which was most often sung in a French creole and led by a griot. As calypso developed, the role of the griot became known as a chantuelle and eventually, calypsonian. As English replaced \\"patois\\" (Antillean creole) as the dominant language, calypso migrated into English, and in so doing it attracted more attention from the government. It allowed the masses to challenge the doings of the unelected Governor and Legislative Council, and the elected town councils of Port of Spain and San Fernando. Calypso continued to play an important role in political expression, and also served to document the history of Venezuela and Trinidad and Tobago.\\r\\nCalypso in the Caribbean includes a range of genres, including: the Benna genre of Antiguan and Barbudan music; Mento, a style of Jamaican folk music that greatly influenced ska and reggae; Ska, the precursor to rocksteady and reggae; Spouge, a style of Barbadian popular music; Dominica Cadence-lypso, which mixed calypso with the cadence of Haiti; and soca music, a style of Kaiso/calypso, with influences from cadence-lypso, soul, and funk.\\r\\n\\r\\n\\r\\nIt is thought that the name \\"calypso\\" was originally \\"kaiso\\" which is now believed to come from Efik \\"ka isu\\" (\\"go on!\\") and Ibibio \\"kaa iso\\" (\\"continue, go on\\"), used in urging someone on or in backing a contestant.[2] There is also a Trinidadian term \\"cariso\\" that is used to refer to \\"old-time\\" calypsos.[3] The term \\"calypso\\" is recorded from the 1930s onwards. Alternatively, the insert for The Rough Guide to Calypso and Soca (published by World Music Network) favours John Cowley's arguments in Carnival, Canboulay and Calypso: Traditions in the Making, that the word might be a corruption of the French carrouseaux and through the process of patois and Anglicization became caliso and then finally \\"calypso\\"; however, Cowley also notes that the first mention of the word \\"calypso\\" is given in a description of a dance in 1882 by Abb Masse.[4]\\r\\nCalypso music was developed in Trinidad in the 17th century from the West African Kaiso and canboulay music brought by African slaves imported to that Caribbean island to work on sugar plantations. The slaves, brought to toil on sugar plantations, were stripped of all connections to their homeland and family and not allowed to talk to each other. They used calypso to mock the slave masters and to communicate with each other. Many early calypsos were sung in French Creole by an individual called a griot. As calypso developed, the role of the griot became known as a chantuelle and eventually, calypsonian.\\r\\nModern calypso, however, began in the 19th century, a fusion of disparate elements ranging from the masquerade song lavway, French Creole belair and the calinda stick-fighting chantwell. Calypso's early rise was closely connected with the adoption of Carnival by Trinidadian slaves, including canboulay drumming and the music masquerade processions. The French brought Carnival to Trinidad, and calypso competitions at Carnival grew in popularity, especially after the abolition of slavery in 1834.\\r\\nThe first identifiably calypso genre song was recorded in 1912, by Lovey's String Band while visiting New York City. In 1914, the second calypso song was recorded, this time in Trinidad, by chantwell Julian Whiterose, better known as the Iron Duke and famous calinda stick-fighter. Jules Sims would also record vocal calypsos. The majority of these calypsos of the World War I era were instrumentals by Lovey and Lionel Belasco. Perhaps due to the constraints of the wartime economy, no recordings of note were produced until the late 1920s and early 1930s, when the \\"golden era\\" of calypso would cement the style, form, and phrasing of the music.\\r\\nCalypso evolved into a way of spreading news around Trinidad. Politicians, journalists and public figures often debated the content of each song, and many islanders considered these songs the most reliable news source. Calypsonians pushed the boundaries of free speech as their lyrics spread news of any topic relevant to island life, including speaking out against political corruption. Eventually British rule enforced censorship and police began to scan these songs for damaging content.\\r\\nEven with this censorship, calypsos continued to push boundaries, with a variety of ways to slip songs past the scrutinizing eyes of the editor. Double entendre, or double-speak, was one way, as was the practice of denouncing countries such as Hitler's Germany and its annexation of Poland, while making pointed references toward the UK's policies on Trinidad. Sex, scandal, gossip, innuendo, politics, local news, bravado and insulting other calypsonians were the order of the day in classic calypso, just as it is today with classic hip-hop. And just as the hip-hop of today, the music sparked shock and outrage in the moral sections of society.\\r\\nCountless recordings were dumped at sea in the name of censorship, although in truth, rival US companies did this in the spirit of underhanded competition, claiming that the rivals' material was unfit for US consumption. Decca Records lost untold pressings in this manner, as did its rival, RCA's Bluebird label.\\r\\nAn entrepreneur named Eduardo Sa Gomes played a significant role in spreading calypso in its early days. Sa Gomes, a Portuguese immigrant who owned a local music and phonograph equipment shop in Port of Spain, promoted the genre and gave financial support to the local artists. In March 1934, he sent Roaring Lion and Attila the Hun to New York City to record; they became the first calypsonians to record abroad, bringing the genre out of the West Indies and into pop culture.[5] Lord Invader was quick to follow, and staying in New York City after a protracted legal case involving the theft of his song \\"Rum and Coca-Cola\\", a hit by the Andrews Sisters, made his home there along with Wilmoth Houdini, and became one of the great calypsonians of the USA.\\r\\nEarly forms of calypso were also influenced by jazz such as Sans Humanitae. In this extempo (extemporaneous) melody calypsonians lyricise impromptu, commenting socially or insulting each other, \\"sans humanit\\" or \\"no mercy\\" (which is again a reference to French influence).\\r\\nThe first major stars of calypso started crossing over to new audiences worldwide in the late 1930s. Attila the Hun, Roaring Lion and Lord Invader were first, followed by Lord Kitchener, one of the longest-lasting calypso stars in historyhe continued to release hit records until his death in 2000. 1944's \\"Rum and Coca-Cola\\" by the Andrews Sisters, a cover version of a Lord Invader song, became an American hit despite the song being a very critical commentary on the explosion of prostitution, inflation and other negative influences accompanying the American military bases in Trinidad at the time.[6] Perhaps the most straightforward way to describe the focus of calypso is that it articulated itself as a form of protest against the authoritarian colonial culture which existed at the time.\\r\\nCalypso, especially a toned-down, commercial variant, became a worldwide craze with the release of the \\"Banana Boat Song\\", or \\"Day-O\\", a traditional Jamaican folk song, whose best-known rendition was done by Harry Belafonte on his album Calypso (1956); Calypso was the first full-length record to sell more than a million copies. The success of that album inspired hundreds of \\"Folkies\\", or the American folk music revival to imitate the \\"Belafonte style\\", but with a more folk-oriented flavor. The Kingston Trio would be a good example. 1956 also saw the massive international hit \\"Jean and Dinah\\" by Mighty Sparrow. This song too was a sly commentary as a \\"plan of action\\" for the calypsonian on the widespread prostitution and the prostitutes' desperation after the closing of the U.S. naval base on Trinidad at Chaguaramas.\\r\\nIn the Broadway-theatre musical Jamaica (1957), Harold Arlen and Yip Harburg cleverly parodied \\"commercial\\" Belafonte-style calypso. Several films jumped on the calypso craze in 1957 such as Island in the Sun (20th Century Fox) that featured Belafonte and the low-budget films Calypso Joe (Allied Artists), Calypso Heat Wave (Columbia Pictures), and Bop Girl Goes Calypso (United Artists). Robert Mitchum released an album, Calypso...Is Like So (1957), on Capitol records, capturing the sound, spirit, and subtleties of the genre. Dizzy Gillespie recorded a calypso album Jambo Caribe (1964) with James Moody and Kenny Barron.\\r\\nSoul shouter Gary \\"US\\" Bonds released a calypso album Twist up Calypso (1962) on Legrand records, shortly after returning home from his military post in Port of Spain. Nithi Kanagaratnam from Sri Lanka sang calypso-styled songs in Tamil in 1968, which was a success and earned him the title \\"Father of Tamil Popular Music\\". Since Baila rhythm was popular in Sri Lanka, most of his songs were classified as Tamil Baila.\\r\\nIn the mid-1970s, women entered the calypso men's-oriented arena. [2] Calypso Rose was the first woman to win the Trinidad Road March competition in 1977 with her song \\"Gimme More Tempo\\". The following year with \\"Come Leh We Jam\\", she won the \\"Calypso King \\" competition, the first time a woman had received the award. The competition's title was changed to Calypso Monarch in her honour. The French and pioneer electronic musician Jean Michel Jarre released an album in 1990 called Waiting for Cousteau. The album has four tracks: \\"Calypso\\", \\"Calypso part 2\\", \\"Calypso part 3 Fin de Sicle\\" and \\"Waiting for Cousteau\\". It was dedicated to Jacques-Yves Cousteau in his 80th birthday. This album had a special participation of the Amocco Renegades (a traditional steel-drum band from Trinidad and Tobago). In the first track is possible to notice a strong style influence. Calypso had another short burst of commercial interest when Tim Burton's horror/comedy film Beetlejuice (1988) was released, and used Belafonte's \\"Jump In The Line\\" as the soundtracks headliner and also \\"The Banana Boat Song\\" in the dinner-party scene. Disney's song \\"Under the Sea\\", a calypso theme from The Little Mermaid won an Academy Award for Best Original Song in 1989 as well as the Grammy Award for Best Song Written for Visual Media in 1991.","input":"Who is credited for the creation of calypso?"},{"output":"farmers","context":"","input":"During the colonial era what was the principal occupation in the english colonies?"},{"output":"East Pakistan","context":"","input":"What was the name of bangladesh before independence?"},{"output":"Jawaharlal Nehru","context":"The Prime Minister of India is the chief executive of the Government of India. In India's parliamentary system, the Constitution names the President as head of state de jure, but his or her de facto executive powers are vested in the Prime Minister and his Council of Ministers. Appointed and sworn-in by the President, the Prime Minister is usually the leader of the party or alliance that has a majority in the Lok Sabha, the lower house of India's Parliament.\\r\\nSince 1947, India has had fourteen Prime Ministers, fifteen including Gulzarilal Nanda who twice acted in the role. The first was Jawaharlal Nehru of the Indian National Congress party, who was sworn-in on 15 August 1947, when India gained independence from the British. Serving until his death in May 1964, Nehru remains India's longest-serving prime minister. He was succeeded by fellow Congressman Lal Bahadur Shastri, whose 19-month term also ended in death. Indira Gandhi, Nehru's daughter, succeeded Shastri in 1966 to become the country's first woman premier. Eleven years later, she was voted out of power in favour of the Janata Party, whose leader Morarji Desai became the first non-Congress prime minister. After he resigned in 1979, his former deputy Charan Singh briefly held office until Indira Gandhi was voted back six months later. Indira Gandhi's second stint as Prime Minister ended five years later on the morning of 31 October 1984, when she was gunned down by her own bodyguards. That evening, her son Rajiv Gandhi was sworn-in as India's youngest premier, and the third from his family. Thus far, members of NehruÿGandhi dynasty have been Prime Minister for a total of 37 years and 303 days.[1]\\r\\nRajiv's five-year term ended with his former cabinet colleague, V. P. Singh of the Janata Dal, forming the year-long National Front coalition government in 1989. A six-month interlude under Prime Minister Chandra Shekhar followed, after which the Congress party returned to power, forming the government under P. V. Narasimha Rao in June 1991. Rao's five-year term was succeeded by four short-lived governmentsthe Bharatiya Janata Party's Atal Bihari Vajpayee for 13 days in 1996, a year each under United Front prime ministers H. D. Deve Gowda and I. K. Gujral, and Vajpayee again for 19 months in 1998ÿ99. After Vajpayee was sworn-in for the third time, in 1999, he managed to lead his National Democratic Alliance (NDA) government to a full five-year term, the first non-Congressman to do so. Vajpayee was succeeded by Congressman Manmohan Singh, the first Sikh premier, whose United Progressive Alliance government was in office for 10 years between 2004 and 2014.\\r\\nThe incumbent Prime Minister of India is Narendra Modi who has headed the BJP-led NDA government since 26 May 2014 which is India's first non-Congress single party majority government.[2]\\r\\n\\r\\n\\r\\n(Re-elected)\\r\\n(Re-elected)\\r\\n(acting President)\\r\\n(Re-elected)\\r\\n(Re-elected)\\r\\n(Re-elected)","input":"Who was the first prime minister of indian?"},{"output":"16 September 1941","context":"","input":"When did the shah of iran take power?"},{"output":"February 26, 1929","context":"The establishment of Grand Teton National Park took place over a period spanning more than 50?years. Located in the northwestern region of the U.S. state of Wyoming, Grand Teton National Park is 10 miles (16?km) south of Yellowstone National Park which was established in 1872, when Wyoming, Idaho and Montana were still territories and the region was very sparsely settled.[1] By the late 19th century, conservationists were working to provide further protection to surrounding regions, leading President Grover Cleveland to create the Teton Forest Reserve, which included a portion of northern Jackson Hole.[2] By 1902, the reserve had been combined into the Yellowstone Forest Reserve, then was divided again in 1908 by President Theodore Roosevelt, establishing the Teton National Forest, which protected most of the Teton Range.[3] By 1907, the U.S. Bureau of Reclamation had constructed a temporary dam at the Snake River outlet of Jackson Lake. This dam failed in 1910 and a new concrete Jackson Lake Dam replaced it by 1911. The dam was further enlarged in 1916, raising lake waters 39?ft (12?m) as part of the Minidoka Project, designed to provide irrigation for agriculture in the state of Idaho.[4][5] Though efforts to protect the Teton Range and Jackson Hole as part of an expanded Yellowstone National Park dated back to the late 19th century, proposals to construct more dams on some of the other lakes in Jackson Hole led Yellowstone National Park superintendent Horace Albright to block such efforts. Albright was originally an advocate of the expanded Yellowstone plan which was very unpopular with local residents. By the mid-1920s local sentiment had changed as a result of proposals for a new national park including only the Teton Range and six lakes at the base of the range.[6] With the general agreement of prominent Jackson Hole residents to this plan, President Calvin Coolidge signed the executive order establishing the 96,000-acre (39,000?ha) Grand Teton National Park on February 26, 1929.[7]\\r\\nThe valley of Jackson Hole remained primarily in private ownership when John D. Rockefeller, Jr. and his wife visited the region in the late 1920s.[2] Horace Albright had hoped to protect the valley of Jackson Hole north of the town of Jackson from commercial exploitation. Rockefeller agreed and through a private enterprise known as the Snake River Land Company by 1927 was buying land in Jackson Hole to be later turned over to the National Park Service. In 1930 this plan was revealed to the residents of the region and was met with strong disapproval.[2] By 1942 John D. Rockefeller, Jr. became increasingly impatient that his land holdings in Jackson Hole might never be part of Grand Teton National Park, so he wrote the Secretary of the Interior Harold L. Ickes and informed him that he was considering selling the land to another party.[8] Secretary Ickes recommended to President Franklin Roosevelt that the Antiquities Act (which permitted Presidents to set aside land for protection without the approval of Congress) be used to establish a National Monument in Jackson Hole.\\r\\nFrom property belonging to the Snake River Land Company and adding additional land from Teton National Forest, Roosevelt created the 221,000-acre (89,000?ha) Jackson Hole National Monument in 1943.[9] The monument and park were adjacent to each other and both were administered by the National Park Service, but the monument designation ensured no funding allotment, nor provided a level of resource protection equal to the park. Members of Congress repeatedly attempted to have the new National Monument abolished.[10]\\r\\nAfter the end of World War II public sentiment shifted in favor of adding the monument to the park, and though there was still much local disagreement, the monument and park were combined in 1950.[6] In recognition of John D. Rockefeller, Jr.'s efforts to establish and then expand Grand Teton National Park, a 24,000-acre (9,700?ha) parcel of land between Grand Teton and Yellowstone National Parks was added to the National Park Service in 1972. This land and the road from the southern boundary of Grand Teton National Park to West Thumb in Yellowstone National Park was named the John D. Rockefeller, Jr. Memorial Parkway.[11] In 2001, the Rockefeller family donated the remnants of its JY Ranch for the establishment of the Laurance S. Rockefeller Preserve, dedicated on June 21, 2008.[12]","input":"When did grand teton become a national park?"},{"output":"Bryan","context":"College Station is a city in Brazos County, Texas, situated in East-Central Texas in the heart of the Brazos Valley, in the center of the region known as Texas Triangle. It is 90 miles (140 kilometers) northwest of Houston and 87 miles (140?km) northeast of Austin. As of the 2010 census, College Station had a population of 93,857,[2] which had increased to an estimated population of 117,191 as of September 2017.[3] College Station and Bryan together make up the Bryan-College Station metropolitan area, the 14th-largest metropolitan area in Texas with 255,589 people as of 2015.\\r\\nCollege Station is home to the main campus of Texas A&M University, the flagship institution of the Texas A&M University System. The city owes both its name and existence to the university's location along a railroad. Texas A&M's triple designation as a Land-, Sea-, and Space-Grant institution reflects the broad scope of the research endeavors it brings to the city, with ongoing projects funded by agencies such as NASA, the National Institutes of Health, the National Science Foundation, and the Office of Naval Research.\\r\\nDue largely to the presence of Texas A&M University, College Station was named by Money magazine in 2006 as the most educated city in Texas, and the 11th-most educated city in the United States.[4]\\r\\n\\r\\n\\r\\nThe origins of College Station date from 1860, when the Houston and Texas Central Railway began to build through the region.[5] Eleven years later, the site was chosen as the location for the proposed Agricultural and Mechanical College of Texas, a land-grant school.[5] In 1876, as the nation celebrated its centennial, the school (renamed Texas A&M University in 1963) opened its doors as the first public institution of higher education in the state of Texas.[5]\\r\\nThe population of College Station grew slowly, reaching 350 in 1884 and 391 at the turn of the century.[5] However, during this time, transportation improvements took place in the town. In 1900, the I&GN Railroad was extended to College Station[6] (the line was abandoned by the Missouri Pacific Railroad Company in 1965),[7] and 10 years later, electric interurban service was established between Texas A&M and the neighboring town of Bryan.[5] The interurban was replaced by a city bus system in the 1920s.[5]\\r\\nIn 1930, the community to the north of College Station, known as North Oakwood, was incorporated as part of Bryan.[5] College Station did not incorporate until 1938 with John H. Binney as the first mayor.[5] Within a year, the city established a zoning commission, and by 1940, the population had reached 2,184.[5]\\r\\nThe city grew under the leadership of Ernest Langford, called by some the \\"Father of College Station\\", who began a 26-year stretch as mayor in 1942. Early in his first term, the city adopted a council-manager system of city government.[5]\\r\\nPopulation growth accelerated following World War II as the nonstudent population reached 7,898 in 1950, 11,396 in 1960, 17,676 in 1970, 30,449 in 1980, 52,456 in 1990, and 67,890 in 2000.[5] The population for the Bryan-College Station metropolitan area will range from an estimated 250,846 to 271,773 by 2030.[8]\\r\\nIn the 1990s, College Station and Texas A&M University drew national attention when the George Bush Presidential Library opened in 1997 and, more tragically, when 12 people were killed and 27 injured when the Aggie Bonfire collapsed while being constructed in 1999.\\r\\nCollege Station is located south of the center of Brazos County at 30365N 961852W? / ?30.60139N 96.31444W? / 30.60139; -96.31444 (30.601433, -96.314464).[9] It is bordered by the city of Bryan to the northwest.\\r\\nAccording to the United States Census Bureau, the city has a total area of 49.6?sq?mi (128.5?km2), of which 49.4?sq?mi (128.0?km2) is land and 0.19?sq?mi (0.5?km2), or 0.35%, is covered by water.[2]\\r\\nThe local climate is subtropical and temperate and winters are mild with periods of low temperatures usually lasting less than two months.\\r\\nSnow and ice are rare; most recently, College Station received 5 inches (13?cm) of snowfall on December 7, 2017.[10]\\r\\nSummers are hot and humid with occasional showers being the only real variation in weather. [11]\\r\\nAs of the census of 2000, 67,890 people, 24,691 households, and 10,370 families resided in the city. Of the 24,691 households, 21.0% had children under the age of 18 living with them, 32.2% were married couples living together, 6.8% had a female householder with no husband present, and 58.0% were not families. About 27.1% of all households were made up of individuals, and 2.4% had someone living alone who was 65 years of age or older. The average household size was 2.32 and the average family size was 2.98.\\r\\nIn the city, the population was distributed as 14.4% under the age of 18, 51.2% from 18 to 24, 21.3% from 25 to 44, 9.4% from 45 to 64, and 3.6% who were 65 years of age or older. The median age was 22 years. For every 100 females, there were 104.3 males. For every 100 females age 18 and over, there were 104.0 males.\\r\\nThe median income for a household[clarification needed] in the city was $21,180, and for a family[clarification needed] was $53,147. Males had a median income of $38,216 versus $26,592 for females. The per capita income for the city was $15,170. About 15.4% of families and 37.4% of the population were below the poverty line, including 16.4% of those under age 18 and 7.7% of those age 65 or over.\\r\\nThe city of College Station has a council-manager form of government. Voters elect the members of a city council, who pass laws and make policy. The council hires a professional city manager who is responsible for day-to-day operations of the city and its public services.[18]\\r\\nThe Texas Department of Criminal Justice (TDCJ) operates the Bryan District Parole Office in College Station.[19]\\r\\nThe United States Postal Service operates the College Station and Northgate College Station post offices.[20][21]\\r\\nNorthgate is a mixed-use district north of Texas A&M University that features a combination of businesses, restaurants, apartments, churches, and entertainment. It is a vibrant part of the city known for its eclectic mix of restaurants and bars.[22][23] A large portion of the stores, bars, and restaurants in Northgate are frequented and patronized by Texas A&M students, and the establishments employ A&M students, as well.[23] In total, the district spans about 145 acres (0.59?km2), bounded by Wellborn Road to the west, South College Avenue to the east, the College Station city limits to the north, and University Drive to the south. The district is the home of the Dixie Chicken and of the first Texas location for the regional fast-food chain Freebirds World Burrito.\\r\\nNorthgate's roots started in the 1930s as the city began enjoying rapid population growth from the influx of Texas A&M University students, professors, and their families. Realizing that proximity to the campus would be a boon for revenues, the first business district was established in College Station near the campus, taking its name for the closest on-campus landmark: the north gate. When the city was incorporated in 1938, its first City Hall was opened in the new district. In 1994, restoration efforts began to revitalize the ailing area. A four-day music festival, \\"North By Northgate\\", was introduced in 1998 and has become an annual tradition, renamed the \\"Northgate Music Festival\\" in 2002. In 2006, the city council incorporated Northgate as a special tax zone to finance additional improvements and expansions.[24]\\r\\nLive music is a major draw to the Northgate area, with venues such as Church Street BBQ and Hurricane Harry's consistently providing evening concerts. Many well-known musicians, especially in the Texas country music scene, have gotten their starts playing on the porches and stages found in the Northgate area. Notable names include Robert Earl Keen, Grammy award-winner Lyle Lovett, Dub Miller, and Roger Creager. The district is bisected to the north by Church Street, made famous by the Robert Earl Keen and Lyle Lovett duet \\"The Front Porch Song\\".\\r\\nWolf Pen Creek District is a large commercial development adjacent to Post Oak Mall and between two of the city's main commercial thoroughfares: Earl Rudder Freeway and Texas Avenue. The area consists of a greenway with trails, a $1.5 million amphitheater and entertainment area, a small lake, the Spirit Ice Arena, and is the home of the Arts Council of the Brazos Valley. The amphitheater has hosted a variety of musical events, including the annual Starlight Music Series, a concert series that starts in late spring and runs through late summer. Wolf Pen often has sidewalk for a scenic run that when completed is about 1?mi (2?km).\\r\\nWellborn became a community in 1867 as a construction camp on the Houston and Texas Central Railroad. The town's name has been attributed to a well at the construction camp, a foreman named E.W. Wellborn, or a landowner named W.W. Willburn. Also in 1867, a post office opened in the community under the name Wellborn Station. In 1870, the name was shortened to Wellborn.[25] On April 14, 2011, the City Council of College Station voted 5-2 to annex Wellborn, thus making the community the Wellborn district. Wellborn is often mispronounced as well-born but is pronounced by locals as Well-burn.[26]\\r\\nEasterwood Airport, owned by Texas A&M, is located three miles (5?km) southwest of College Station and has flights to Dallas/Fort Worth International Airport and George Bush Intercontinental Airport in Houston.\\r\\nAs of May 2008, the local unemployment hovered around 3 to 4%, among the lowest in Texas. This rate is largely attributed to the significant role the university plays in the local economy.[27][28] However, underemployment is an ongoing issue.[29]\\r\\nUntil its 2007 acquisition by Tavistock Group, Freebirds World Burrito had its corporate headquarters in College Station.[30][31]\\r\\nPost Oak Mall was the city's first mall and is currently the largest mall in the Brazos Valley. The 82-acre (330,000?m2) mall is home to 125 stores; its opening on February 17, 1982, helped create the impetus for growing economic and commercial developments for College Station.[32] It is currently the largest taxpayer in College Station and the second-largest in the Brazos Valley, though the anchor stores are free-standing units that are privately owned and taxed separate from the mall proper.[33] Over 75% of retail sales in the Brazos Valley come from sales at the mall's stores.[32]\\r\\nLocal channels are NBC affiliate KAGS-LD, CBS affiliate KBTX, ABC affiliate KRHD-CD, Fox affiliate KYLE-TV, and PBS affiliate KAMU, which is owned by Texas A&M University.\\r\\nCollege Station is part of the Bryan-College Station Arbitron market #238.\\r\\n1 = Part 15 station with notability.\\r\\nThe following people have lived or are currently living in College Station:","input":"What cities are close to college station texas?"},{"output":"San Salvador","context":"","input":"What are two major cities in el salvador?"},{"output":"the General Assembly","context":"The United Nations System consists of the United Nations, and the six principal organs of the United Nations: the General Assembly, Security Council, Economic and Social Council (ECOSOC), Trusteeship Council, International Court of Justice (ICJ), and the UN Secretariat,[1] specialized agencies, and affiliated organizations.[2] The executive heads of some of the United Nations System organizations and the World Trade Organization, which is not formally part of the United Nations System,[3][4][5] have seats on the United Nations System Chief Executives' Board for Coordination (CEB).[6] This body, chaired by the Secretary-General of the United Nations, meets twice a year to co-ordinate the work of the organizations of the United Nations System.\\r\\nThe United Nations System includes the United Nations and its subsidiary bodies (such as the separately-administered funds and programmes, research and training institutes, and other subsidiary entities), specialized agencies, and affiliated organizations.[7][8] Some of the organizations of the United Nations System predate the founding of the United Nations in 1945 and were inherited after the dissolution of the League of Nations.\\r\\n\\r\\n\\r\\nThe principal organ of the UN System is the United Nations itself. It consists of the six principal organs established by the Charter of the United Nations:\\r\\nThe United Nations General Assembly (UNGA/GA) is one of the six principal organs of the United Nations and the only one in which all member nations have equal representation. Its powers are to oversee the budget of the United Nations, appoint the non-permanent members to the Security Council, receive reports from other parts of the United Nations and make recommendations in the form of General Assembly Resolutions.[10] It has also established a wide number of subsidiary organs.[11]\\r\\nThe United Nations Security Council (UNSC) is one of the principal organs of the United Nations and is charged with the maintenance of international peace and security. Its powers, outlined in the United Nations Charter, include the establishment of peacekeeping operations, the establishment of international sanctions, and the authorization of military action. Its powers are exercised through United Nations Security Council resolutions.\\r\\nThe Security Council held its first session on 17 January 1946 at Church House, Westminster, London. Since its first meeting, the Council, which exists in continuous session, has travelled widely, holding meetings in many cities, such as Paris and Addis Ababa, as well as at its current permanent home at the United Nations Headquarters in New York City.\\r\\nThere are 15 members of the Security Council, consisting of five veto-wielding permanent members (China, France, Russia, the United Kingdom, and the United States) and 10 elected non-permanent members with two-year terms. This basic structure is set out in Chapter V of the UN Charter. Security Council members must always be present at UN headquarters in New York so that the Security Council can meet at any time.\\r\\nThe United Nations Economic and Social Council (ECOSOC) constitutes one of the six principal organs (one is not active, as of 2011) of the United Nations. It is responsible for co-ordinating the economic, social and related work of 14 UN specialized agencies, their functional commissions and five regional commissions. ECOSOC has 54 members; it holds a four-week session each year in July. Since 1998, it has also held a meeting each April with finance ministers heading key committees of the World Bank and the International Monetary Fund (IMF). The ECOSOC serves as the central forum for discussing international economic and social issues, and for formulating policy recommendations addressed to member states and the United Nations System.[12]\\r\\nThe United Nations Secretariat is headed by the United Nations Secretary-General, assisted by a staff of international civil servants worldwide. It provides studies, information, and facilities needed by United Nations bodies for their meetings. It also carries out tasks as directed by the UN Security Council, the UN General Assembly, the UN Economic and Social Council, and other U.N. bodies. The United Nations Charter provides that the staff to be chosen by application of the \\"highest standards of efficiency, competence, and integrity,\\" with due regard for the importance of recruiting on a wide geographical basis.\\r\\nThe Charter provides that the staff shall not seek or receive instructions from any authority other than the UN. Each UN member country is enjoined to respect the international character of the Secretariat and not seek to influence its staff. The Secretary-General alone is responsible for staff selection.\\r\\nThe International Court of Justice is the primary judicial organ of the United Nations. It is based in the Peace Palace in The Hague, Netherlands. Its main functions are to settle legal disputes submitted to it by states and to provide advisory opinions on legal questions submitted to it by duly authorized international organs, agencies, and the UN General Assembly.\\r\\nThe United Nations Trusteeship Council, one of the principal organs of the United Nations, was established to help ensure that trust territories were administered in the best interests of their inhabitants and of international peace and security. The trust territoriesmost of them are former mandates of the League of Nations or territories taken from nations defeated at the end of World War IIhave all now attained self-government or independence, either as separate nations or by joining neighbouring independent countries. The last was Palau, formerly part of the Trust Territory of the Pacific Islands, which became a member state of the United Nations in December 1994.\\r\\nThe separately-administered funds and programmes, research and training institutes, and other subsidiary bodies are autonomous subsidiary organs of the United Nations.[8]\\r\\nThroughout its history the United Nations General Assembly has established a number of programmes and funds to address particular humanitarian and development concerns. These bodies usually report to the General Assembly through an executive board. Only one UN programme has ever closed in the history of the organization, the United Nations Relief and Rehabilitation Administration (UNRRA), which ceased to exist in 1959 and was subsequently replaced by the UNHCR.\\r\\nEach of the funds and programmes is headed by an Executive Director at the Under-Secretary-General level and is governed by an Executive Board. One former fund, the United Nations Development Fund for Women (UNIFEM), was merged with other elements of the United Nations System into a new organization, UN Women, in January 2011.\\r\\nThe various research and training institutes were established by the General Assembly to perform independent research and training. One former institute, the International Research and Training Institute for the Advancement of Women (INSTRAW), was merged with other elements of the United Nations System into a new organization, UN Women, in January 2011.\\r\\nThe specialized agencies are autonomous organizations working with the United Nations and each other through the co-ordinating machinery of the Economic and Social Council. Each was integrated into the UN System by way of an agreement with the UN under UN Charter article 57.[6]\\r\\nSome organizations have a relationship with the UN defined by an arrangement different from the agreements between the specialized agencies and the UN, which are established under Articles 57 and 63 of the United Nations Charter.[13][14][15][16][17][18]\\r\\nThe IOM, established in 1951, is the leading inter-governmental organization in the field of migration and works closely with governmental, intergovernmental and non-governmental partners. IOM works to help ensure the orderly and humane management of migration, to promote international cooperation on migration issues, to assist in the search for practical solutions to migration problems and to provide humanitarian assistance to migrants in need, including refugees and internally displaced people. In September 2016, IOM joined the United Nations System as a related organization during the United Nations General Assembly high-level summit to address large movements of refugees and migrants.[19]\\r\\nThe CTBTO PrepCom reports directly to the UN General Assembly.[14]\\r\\nThe relationship between the IAEA and the UN was established by a resolution of the UN General Assembly. Unlike the specialized agencies which report to ECOSOC, the IAEA reports directly to the General Assembly as well as the Security Council and ECOSOC.[6] Like the other specialized agency's heads, their executives are part of the United Nations System Chief Executives' Board for Coordination (CEB).[6]\\r\\nThe OPCW is not an agency of the United Nations, but cooperates both on policy and practical issues. On 7 September 2000 the OPCW and the United Nations signed a co-operation agreement outlining how they were to co-ordinate their activities.[20] Under this agreement, the OPCW reports to the UN General Assembly.[14]\\r\\nThe WTO does not have a formal agreement with the UN. Instead, their relationship is governed by exchanges of letters. Unlike the specialized agencies and the IAEA, the WTO has no reporting obligations towards any of the principal organs of the UN, but provides ad-hoc contribution to the work of the General Assembly and ECOSOC.[15] The WTO has a seat on the CEB.[6]\\r\\n\\r\\nThe United Nations Chief Executives' Board for Coordination (CEB) brings together on a regular basis the executive heads of the organizations of the United Nations System, under the chairmanship of the Secretary-General of the UN. The CEB aims to further co-ordination and co-operation on a whole range of substantive and management issues facing UN System organizations. In addition to its regular reviews of contemporary political issues and major concerns facing the UN System, the CEB approves policy statements on behalf of the UN System as a whole. Three committees report to the CEB, namely the High-level Committee on Programme (HCLP), the High-level Committee on Management (HCLM) and the United Nations Development Group (UNDG). Each of those bodies has, in turn, developed a subsidiary machinery of regular and ad hoc bodies on the substantive and managerial aspects of inter-agency co-ordination. The committee structure is supported by a CEB secretariat located in New York and Geneva.[21]\\r\\nThere is also a Senior Management Group, composed of some of the senior officials in the Secretariat and the funds and programmes at the Under-Secretary-General and Assistant Secretary-General rank, which serves as the cabinet of the Secretary-General.[22]\\r\\nThe United Nations, its subsidiary bodies, thirteen of the specialized agencies (ILO, FAO, UNESCO, WHO, ICAO, UPU, ITU, WMO, IMO, WIPO, IFAD, UNDIO, and UNWTO), and one related body (IAEA) are part of the United Nations common system of salaries, allowances, and benefits administered by the International Civil Service Commission. Most, but not all, of the members of the United Nations System are part of the common system; the Bretton Woods institutions (i.e. the World Bank Group and the IMF) are notable exceptions. The WTO utilizes the OECD common system. The UN common system was established to prevent competition amongst organizations of the United Nations System for staff and to facilitate co-operation and exchange between organizations.[23]\\r\\nSome international organizations that are not part of the United Nations System (and therefore not members of the common system) but who voluntarily follow the policies of the common system in whole or in part include:","input":"What are the 5 organs of the un?"},{"output":"20ÿ30%","context":"Flat feet (also called pes planus or fallen arches) is a postural deformity in which the arches of the foot collapse, with the entire sole of the foot coming into complete or near-complete contact with the ground. An estimated 20ÿ30% of the general population have an arch that simply never develops in one or both feet.\\r\\n\\r\\nThere is a functional relationship between the structure of the arch of the foot and the biomechanics of the lower leg. The arch provides an elastic, springy connection between the forefoot and the hind foot. This association safeguards so that a majority of the forces incurred during weight bearing of the foot can be dissipated before the force reaches the long bones of the leg and thigh.[1]\\r\\n\\r\\nIn pes planus, the head of the talus bone is displaced medially and distal from the navicular. As a result, the  Plantar calcaneonavicular ligament (spring ligament) and the tendon of the tibialis posterior muscle are stretched, so much so that the individual with pes planus loses the function of the medial longitudinal arch (MLA). If the MLA is absent or nonfunctional in both the seated and standing positions, the individual has rigid flatfoot. If the MLA is present and functional while the individual is sitting or standing up on their toes, but this arch disappears when assuming a foot-flat stance, the individual has supple flatfoot. This latter condition is often treated with arch supports.[1] However, a recent randomized controlled trial found no evidence for the efficacy of treatment of flat feet in children either from expensive prescribed orthotics i.e (shoe inserts) or less expensive over-the-counter orthotics.[2]\\r\\n\\r\\nThree studies (see citations below in military section) of military recruits have shown no evidence of later increased injury, or foot problems, due to flat feet, in a population of people who reach military service age without prior foot problems. However, these studies cannot be used to judge possible future damage from this condition when diagnosed at younger ages. They also cannot be applied to persons whose flat feet are associated with foot symptoms, or certain symptoms in other parts of the body (such as the leg or back) possibly referable to the foot.\\r\\n\\r\\nStudies have shown children and adolescents with flat feet are a common occurrence. The human arch develops in infancy and early childhood as part of normal muscle, tendon, ligament and bone growth.[3]  Flat arches in children usually become high arches as the child progresses through adolescence and into adulthood. Children with flat feet are at a higher risk of developing knee, hip, and back pain. A recent randomized controlled trial found no evidence for the efficacy of treatment of flat feet in children either from expensive prescribed orthotics i.e (shoe inserts) or less expensive over-the-counter orthotics.[4] As a symptom itself, flat feet usually accompany genetic musculoskeletal conditions such as dyspraxia,[5] ligamentous laxity or hypermobility.\\r\\n\\r\\nSince children are unlikely to suspect or identify flat feet on their own, it is important for adult caregivers to check on this themselves. Besides visual inspection of feet and of the treadwear pattern on shoe soles, caregivers should notice when a child's gait is abnormal or the child seems to be in pain from walking. Children who complain about calf muscle pains, arch pain, or any other pains around the foot area may be developing or have developed flat feet.\\r\\n\\r\\nLateral X-ray of a flat foot with C-sign, which is a bony bridge between the talar dome and sustentaculum tali, in combination with a prominent inferior border of the sustentaculum tali. This represents a talocalcaneal coalition, which is an abnormal connection between the talus and calcaneus, and is thought to cause the flat foot deformity in this case.[6]\\r\\n\\r\\nTraining of the feet, utilizing foot gymnastics and going barefoot on varying terrain, can facilitate the formation of arches during childhood, with a developed arch occurring for most by the age of four to six years. Ligament laxity is also among the factors known to be associated with flat feet. One medical study in India with a large sample size of children who had grown up wearing shoes and others going barefoot found that the longitudinal arches of the bare-footers were generally strongest and highest as a group, and that flat feet were less common in children who had grown up wearing sandals or slippers than among those who had worn closed-toe shoes. Focusing on the influence of footwear on the prevalence of pes planus, the cross-sectional study performed on children noted that wearing shoes throughout early childhood can be detrimental to the development of a normal or a high medial longitudinal arch. The vulnerability for flat foot among shoe-wearing children increases if the child has an associated ligament laxity condition. The results of the study suggest that children be encouraged to play barefooted on various surfaces of terrain and that slippers and sandals are less harmful compared to closed-toe shoes. It appeared that closed-toe shoes greatly inhibited the development of the arch of the foot more so than slippers or sandals. This conclusion may be a result of the notion that intrinsic muscle activity of the arch is required to prevent slippers and sandals from falling off the childs foot.[7] In children with few symptoms orthotics are not recommended.[8]\\r\\n\\r\\n\\r\\nFlat feet can also develop as an adult (\\"adult acquired flatfoot\\") due to injury, illness, unusual or prolonged stress to the foot, faulty biomechanics,[9] or as part of the normal aging process.  This is most common in women over 40 years of age. Known risk factors include obesity, hypertension and diabetes.[10] Flat feet can also occur in pregnant women as a result of temporary changes, due to increased elastin (elasticity) during pregnancy.  However, if developed by adulthood, flat feet generally remain flat permanently.\\r\\nIf a youth or adult appears flatfooted while standing in a full weight bearing position, but an arch appears when the person plantarflexes, or pulls the toes back with the rest of the foot flat on the floor, this condition is called flexible flatfoot.  This is not a true collapsed arch, as the medial longitudinal arch is still present and the windlass mechanism still operates; this presentation is actually due to excessive pronation of the foot (rolling inwards), although the term 'flat foot' is still applicable as it is a somewhat generic term.  Muscular training of the feet is helpful and will often result in increased arch height regardless of age.\\r\\n\\r\\nResearch has shown that tendon specimens from people who suffer from adult acquired flat feet show evidence of increased activity of proteolytic enzymes. These enzymes can break down the constituents of the involved tendons and cause the foot arch to fall. In the future, these enzymes may become targets for new drug therapies.[10]\\r\\n\\r\\nMany medical professionals can diagnose a flat foot by examining the patient standing or just looking at them. On going up onto tip toe the deformity will correct when this is a flexible flat foot in a child with lax joints. Such correction is not seen in adults with a rigid flat foot.\\r\\n\\r\\nAn easy and traditional home diagnosis is the \\"wet footprint\\" test, performed by wetting the feet in water and then standing on a smooth, level surface such as smooth concrete or thin cardboard or heavy paper. Usually, the more the sole of the foot that makes contact (leaves a footprint), the flatter the foot.  In more extreme cases, known as a kinked flatfoot, the entire inner edge of the footprint may actually bulge outward, where in a normal to high arch this part of the sole of the foot does not make contact with the ground at all.\\r\\n\\r\\nOn plain radiography, flat feet can be diagnosed and graded by several measures, the most important in adults being the talonavicular coverage angle, the calcaneal pitch, and the talar-1st metatarsal angle (Meary's angle).[11] The talonavicular coverage angle is abnormally laterally rotated in flat feet.[11] It is normally up to 7 degrees laterally rotated, so a greater rotation indicates flat feet.[11] Radiographies generally need to be taken on weightbearing feet in order to detect misalignment.[12]\\r\\n\\r\\nDorsoplantar projectional radiograph of the foot showing the measurement of the  talonavicular coverage angle.\\r\\n\\r\\nWeight-bearing lateral X-ray showing the measurement of calcaneal pitch, which is an angle of the calcaneus and the inferior aspect of the foot, with different sources giving different reference points.[13] A calcaneal pitch of less than 17 or 18 indicates flat feet.[11]\\r\\n\\r\\nSame lateral X-ray showing the measurement of Meary's angle, which is the angle between the long axis of the talus and first metatarsal bone.[11] An angle greater than 4 convex downward is considered a flat foot, 15 - 30 moderate flat foot, and greater than 30 severe flat foot.[11]\\r\\n\\r\\nMost flexible flat feet are asymptomatic, and do not cause pain. In these cases, there is usually no cause for concern. Flat feet were formerly a physical-health reason for service-rejection in many militaries. However, three military studies on asymptomatic adults (see section below), suggest that persons with asymptomatic flat feet are at least as tolerant of foot stress as the population with various grades of arch. Asymptomatic flat feet are no longer a service disqualification in the U.S. military, but symptomatic flat feet are cause for disqualification during the enlistment process.[citation needed]\\r\\n\\r\\nIn a study performed to analyze the activation of the tibialis posterior muscle in adults with pes planus, it was noted that the tendon of this muscle may be dysfunctional and lead to disabling weightbearing symptoms associated with acquired flat foot deformity. The results of the study indicated that while barefoot, subjects activated additional lower-leg muscles to complete an exercise that resisted foot adduction. However, when the same subjects performed the exercise while wearing arch supporting orthotics and shoes, the tibialis posterior was selectively activated. Such discoveries suggest that the use of shoes with properly fitting, arch-supporting orthics will enhance selective activation of the tibialis posterior muscle thus, acting as an adequate treatment for the undesirable symptoms of pes planus.[14]\\r\\n\\r\\nRigid flatfoot, a condition where the sole of the foot is rigidly flat even when a person is not standing, often indicates a significant problem in the bones of the affected feet, and can cause pain in about a quarter of those affected.[15][16]  Other flatfoot-related conditions, such as various forms of tarsal coalition (two or more bones in the midfoot or hindfoot abnormally joined) or an accessory navicular (extra bone on the inner side of the foot) should be treated promptly, usually by the very early teen years, before a child's bone structure firms up permanently as a young adult.  Both tarsal coalition and an accessory navicular can be confirmed by X-ray.  Rheumatoid arthritis can destroy tendons in the foot (or both feet) which can cause this condition, and untreated can result in deformity and early onset of osteoarthritis of the joint. Such a condition can cause severe pain and considerably reduced ability to walk, even with orthoses.  Ankle fusion is usually recommended.[17]\\r\\n\\r\\nTreatment of flat feet may also be appropriate if there is associated foot or lower leg pain, or if the condition affects the knees or the lower back. Treatment may include foot gymnastics or other exercises as recommended by a podiatrist or physical therapist. In cases of severe flat feet, orthoses should be used through a gradual process to lessen discomfort.  Over several weeks, slightly more material is added to the orthosis to raise the arch.  These small changes allow the foot structure to adjust gradually, as well as giving the patient time to acclimatise to the sensation of wearing orthoses.  In some cases, surgery can provide lasting relief, and even create an arch where none existed before; it should be considered a last resort, as it is usually very time consuming and costly.[18]\\r\\n\\r\\nThroughout history flat feet were seen as a sign of low class and poor health, and high arches were seen as high class and full of vigor. Research has shown that the two distinctions are far from the case. The effects of flat feet fall under two categories, which are asymptomatic and symptomatic. Individuals with rigid flat feet tend to exhibit symptoms such as foot and knee tendinitis, and are recommended to consider surgical options when managing symptoms. Individuals with flexible flat generally exhibit asymptomatic effects in response to their flat feet.[3]\\r\\n\\r\\nAccording to AAP news and journal gateway, being flexibly flat-footed does not impede athletic performance.[19]\\r\\n\\r\\nIt is generally assumed by running professionals (primarily including some physical trainers, podiatrists, and shoe manufacturers) that a person with flat feet tends to overpronate in the running form.[20] However, some also assert that persons with flat feet may have an underpronating if they are not a neutral gait. With standard running shoes, these professionals claim, a person who overpronates in his or her running form may be more susceptible to shin splints, back problems, and tendonitis in the knee.[21][dubious  ÿ discuss] Running in shoes with extra medial support or using special shoe inserts, orthoses, may help correct one's running form by reducing pronation and may reduce risk of injury.[22]\\r\\n\\r\\nStudies analyzing the correlation between flat feet and physical injuries in soldiers have been inconclusive, but none suggests that flat feet are an impediment, at least in soldiers who reached the age of military recruitment without prior foot problems. Instead, in this population, there is a suggestion of more injury in high arched feet.  A 2005 study of Royal Australian Air Force recruits that tracked the recruits over the course of their basic training found that neither flat feet nor high arched feet had any impact on physical functioning, injury rates or foot health. If anything, there was a tendency for those with flat feet to have fewer injuries.[23]  Another study of 295 Israel Defense Forces recruits found that those with high arches suffered almost four times as many stress fractures as those with the lowest arches.[24] A later study of 449 U.S. Navy special warfare trainees found no significant difference in the incidence of stress fractures among sailors and Marines with different arch heights.[25]","input":"What percentage of the population have flat feet?"},{"output":"Thursday, 14 June 2018","context":"\\r\\n\\r\\nThe 2018 FIFA World Cup was the 21st FIFA World Cup, an international football tournament contested by the men's national teams of the member associations of FIFA once every four years. It took place in Russia from 14 June to 15 July 2018.[1] It was the first World Cup to be held in Eastern Europe,[2] and the 11th time that it had been held in Europe. At an estimated cost of over $14.2?billion, it was the most expensive World Cup.[3] It was also the first World Cup to use the video assistant referee (VAR) system.[4][5]\\r\\n\\r\\nThe finals involved 32 teams, of which 31 came through qualifying competitions, while the host nation qualified automatically. Of the 32 teams, 20 had also appeared in the previous tournament in 2014, while both Iceland and Panama made their first appearances at a FIFA World Cup. A total of 64 matches were played in 12 venues across 11 cities.[6]\\r\\n\\r\\nThe final took place on 15 July at the Luzhniki Stadium in Moscow, between France and Croatia. France won the match 4ÿ2 to claim their second World Cup title, marking the fourth consecutive title won by a European team.\\r\\n\\r\\nThe bidding procedure to host the 2018 and 2022 FIFA World Cup tournaments began in January 2009, and national associations had until 2 February 2009 to register their interest.[7] Initially, nine countries placed bids for the 2018 FIFA World Cup, but Mexico later withdrew from proceedings,[8] and Indonesia's bid was rejected by FIFA in February 2010 after the Indonesian government failed to submit a letter to support the bid.[9] During the bidding process, the three remaining non-UEFA nations (Australia, Japan, and the United States) gradually withdrew from the 2018 bids, and the UEFA nations were thus ruled out of the 2022 bid. As such, there were eventually four bids for the 2018 FIFA World Cup, two of which were joint bids: England, Russia, Netherlands/Belgium, and Portugal/Spain.\\r\\n\\r\\nThe 22-member FIFA Executive Committee convened in Zrich on 2 December 2010 to vote to select the hosts of both tournaments.[10] Russia won the right to be the 2018 host in the second round of voting. The Portugal/Spain bid came second, and that from Belgium/Netherlands third. England, which was bidding to host its second tournament, was eliminated in the first round.[11]\\r\\n\\r\\nThe voting results were as follows:[12]\\r\\n\\r\\nThe English Football Association and others raised concerns of bribery on the part of the Russian team and corruption from FIFA members. They claimed that four members of the executive committee had requested bribes to vote for England, and Sepp Blatter had said that it had already been arranged before the vote that Russia would win.[13] The 2014 Garcia Report, an internal investigation led by Michael J. Garcia, was withheld from public release by Hans-Joachim Eckert, FIFA's head of adjudication on ethical matters. Eckert instead released a shorter revised summary, and his (and therefore FIFA's) reluctance to publish the full report caused Garcia to resign in protest.[14] Because of the controversy, the FA refused to accept Eckert's absolving of Russia from blame, with Greg Dyke calling for a re-examination of the affair and David Bernstein calling for a boycott of the World Cup.[15][16]\\r\\n\\r\\nFor the first time in the history of the FIFA World Cup, all eligible nations ÿ the 209 FIFA member associations minus automatically qualified hosts Russia ÿ applied to enter the qualifying process.[17] Zimbabwe and Indonesia were later disqualified before playing their first matches,[18][19] while Gibraltar and Kosovo, who joined FIFA on 13 May 2016 after the qualifying draw but before European qualifying had begun, also entered the competition.[20] Places in the tournament were allocated to continental confederations, with the allocation unchanged from the 2014 World Cup.[21][22] The first qualification game, between Timor-Leste and Mongolia, began in Dili on 12 March 2015 as part of the AFC's qualification,[23] and the main qualifying draw took place at the Konstantinovsky Palace in Strelna, Saint Petersburg, on 25 July 2015.[24][25][26][1]\\r\\n\\r\\nOf the 32 nations qualified to play at the 2018 FIFA World Cup, 20 countries competed at the previous tournament in 2014. Both Iceland and Panama qualified for the first time, with the former becoming the smallest country in terms of population to reach the World Cup.[27] Other teams returning after absences of at least three tournaments include: Egypt, returning to the finals after their last appearance in 1990; Morocco, who last competed in 1998; Peru, returning after 1982; and Senegal, competing for the second time after reaching the quarter-finals in 2002. It is the first time three Nordic countries (Denmark, Iceland and Sweden) and four Arab nations (Egypt, Morocco, Saudi Arabia and Tunisia) have qualified for the World Cup.[28]\\r\\n\\r\\nNotable countries that failed to qualify include four-time champions Italy (for the first time since 1958), three-time runners-up and third placed in 2014 the Netherlands (for the first time since 2002), and four reigning continental champions: 2017 Africa Cup of Nations winners Cameroon, two-time Copa Amrica champions and 2017 Confederations Cup runners-up Chile, 2016 OFC Nations Cup winners New Zealand, and 2017 CONCACAF Gold Cup champions United States (for the first time since 1986). The other notable qualifying streaks broken were for Ghana and Ivory Coast, who had both made the previous three tournaments.[29]\\r\\n\\r\\nNote: Numbers in parentheses indicate positions in the FIFA World Rankings at the time of the tournament.[30]\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nThe draw was held on 1 December 2017 at 18:00 MSK at the State Kremlin Palace in Moscow.[31][32] The 32 teams were drawn into 8 groups of 4, by selecting one team from each of the 4 ranked pots.\\r\\n\\r\\nFor the draw, the teams were allocated to four pots based on the FIFA World Rankings of October 2017. Pot 1 contained the hosts Russia (who were automatically assigned to position A1) and the best seven teams, pot 2 contained the next best eight teams, and so on for pots 3 and 4.[33] This was different from previous draws, when only pot 1 was based on FIFA rankings while the remaining pots were based on geographical considerations. However, teams from the same confederation still were not drawn against each other for the group stage, except that two UEFA teams could be in each group.\\r\\n\\r\\n?Russia (65) (hosts)\\r\\n?Germany (1)\\r\\n?Brazil (2)\\r\\n?Portugal (3)\\r\\n?Argentina (4)\\r\\n?Belgium (5)\\r\\n?Poland (6)\\r\\n?France (7)\\r\\n\\r\\n?Spain (8)\\r\\n?Peru (10)\\r\\n??Switzerland (11)\\r\\n?England (12)\\r\\n?Colombia (13)\\r\\n?Mexico (16)\\r\\n?Uruguay (17)\\r\\n?Croatia (18)\\r\\n\\r\\n?Denmark (19)\\r\\n?Iceland (21)\\r\\n?Costa Rica (22)\\r\\n?Sweden (25)\\r\\n?Tunisia (28)\\r\\n?Egypt (30)\\r\\n?Senegal (32)\\r\\n?Iran (34)\\r\\n\\r\\n?Serbia (38)\\r\\n?Nigeria (41)\\r\\n?Australia (43)\\r\\n?Japan (44)\\r\\n?Morocco (48)\\r\\n?Panama (49)\\r\\n?South Korea (62)\\r\\n?Saudi Arabia (63)\\r\\n\\r\\nInitially, each team had to name a preliminary squad of 30 players but, in February 2018, this was increased to 35.[34] From the preliminary squad, the team had to name a final squad of 23 players (three of whom must be goalkeepers) by 4 June. Players in the final squad may be replaced for serious injury up to 24 hours prior to kickoff of the team's first match and such replacements do not need to have been named in the preliminary squad.[35]\\r\\n\\r\\nFor players named in the 35-player preliminary squad, there was a mandatory rest period between 21 and 27 May 2018, except for those involved in the 2018 UEFA Champions League Final played on 26 May.[36]\\r\\n\\r\\nOn 29 March 2018, FIFA released the list of 36 referees and 63 assistant referees selected to oversee matches.[37] On 30 April 2018, FIFA released the list of 13 video assistant referees, who solely acted in this capacity in the tournament.[38]\\r\\n\\r\\nReferee Fahad Al-Mirdasi of Saudi Arabia was removed in 30 May 2018 over a match-fixing attempt,[39] along with his two assistant referees, compatriots Mohammed Al-Abakry and Abdulah Al-Shalwai. A new referee was not appointed, but two assistant referees, Hasan Al Mahri of the United Arab Emirates and Hiroshi Yamauchi of Japan, were added to the list.[40][41] Assistant referee Marwa Range of Kenya also withdrew after the BBC released an investigation conducted by a Ghanaian journalist which implicated Marwa in a bribery scandal.[42]\\r\\n\\r\\nShortly after the International Football Association Board's decision to incorporate video assistant referees (VARs) into the Laws of the Game, on 16 March 2018, the FIFA Council took the much-anticipated step of approving the use of VAR for the first time in a FIFA World Cup tournament.[43][44]\\r\\n\\r\\nVAR operations for all games are operating from a single headquarters in Moscow, which receives live video of the games and are in radio contact with the on-field referees.[45] Systems are in place for communicating VAR-related information to broadcasters and visuals on stadiums' large screens are used for the fans in attendance.[45]\\r\\n\\r\\nVAR had a significant impact in several games.[46] On 15 June 2018, Diego Costa's goal against Portugal became the first World Cup goal based on a VAR decision;[47] the first penalty as a result of a VAR decision was awarded to France in their match against Australia on 16 June and resulted in a goal by Antoine Griezmann.[48] A record number of penalties were awarded in the tournament, with this phenomenon being partially attributed to VAR.[49] Overall, the new technology has been both praised and criticised by commentators.[50] FIFA declared the implementation of VAR a success after the first week of competition.[51]\\r\\n\\r\\nRussia proposed the following host cities: Kaliningrad, Kazan, Krasnodar, Moscow, Nizhny Novgorod, Rostov-on-Don, Saint Petersburg, Samara, Saransk, Sochi, Volgograd, Yaroslavl, and Yekaterinburg.[52] Most cities are in European Russia, while Sochi[53] and Yekaterinburg[54] are very close to the Europe-Asia border, to reduce travel time for the teams in the huge country. The bid evaluation report stated: \\"The Russian bid proposes 13 host cities and 16 stadiums, thus exceeding FIFA's minimum requirement. Three of the 16 stadiums would be renovated, and 13 would be newly constructed.\\"[55]\\r\\n\\r\\nIn October 2011, Russia decreased the number of stadiums from 16 to 14. Construction of the proposed Podolsk stadium in the Moscow region was cancelled by the regional government, and also in the capital, Otkrytiye Arena was competing with Dynamo Stadium over which would be constructed first.[56]\\r\\n\\r\\nThe final choice of host cities was announced on 29 September 2012. The number of cities was further reduced to 11 and number of stadiums to 12 as Krasnodar and Yaroslavl were dropped from the final list. Of the 12 stadiums used for the tournament, 3 (Luzhniki, Yekaterinburg and Sochi) have been extensively renovated and the other 9 stadiums to be used are brand new; $11.8?billion has been spent on hosting the tournament.[57]\\r\\n\\r\\nSepp Blatter stated in July 2014 that, given the concerns over the completion of venues in Russia, the number of venues for the tournament may be reduced from 12 to 10. He also said, \\"We are not going to be in a situation, as is the case of one, two or even three stadiums in South Africa, where it is a problem of what you do with these stadiums\\".[58]\\r\\n\\r\\nIn October 2014, on their first official visit to Russia, FIFA's inspection committee and its head Chris Unger visited St Petersburg, Sochi, Kazan and both Moscow venues. They were satisfied with the progress.[59]\\r\\n\\r\\nOn 8 October 2015, FIFA and the Local Organising Committee agreed on the official names of the stadiums used during the tournament.[60]\\r\\n\\r\\nOf the twelve venues used, the Luzhniki Stadium in Moscow and the Saint Petersburg Stadium ÿ the two largest stadiums in Russia ÿ were used most, both hosting seven matches. Sochi, Kazan, Nizhny Novgorod and Samara all hosted six matches, including one quarter-final match each, while the Otkrytiye Stadium in Moscow and Rostov-on-Don hosted five matches, including one round-of-16 match each. Volgograd, Kaliningrad, Yekaterinburg and Saransk all hosted four matches, but did not host any knockout stage games.\\r\\n\\r\\nA total of twelve stadiums in eleven Russian cities were built and renovated for the FIFA World Cup.[61]\\r\\n\\r\\nBase camps were used by the 32 national squads to stay and train before and during the World Cup tournament. On 9 February 2018, FIFA announced the base camps for each participating team.[77]\\r\\n\\r\\nAt an estimated cost of over $14.2?billion as of June 2018,[3] it is the most expensive World Cup in history, surpassing the cost of the 2014 FIFA World Cup in Brazil.[81]\\r\\n\\r\\nThe Russian government had originally earmarked a budget of around $20?billion[82] which was later slashed to $10?billion for the preparations of the World Cup, of which half is spent on transport infrastructure.[83] As part of the program for preparation to the 2018 FIFA World Cup, a federal sub-program \\"Construction and Renovation of Transport Infrastructure\\" was implemented with a total budget of 352.5?billion rubles, with 170.3?billion coming from the federal budget, 35.1?billion from regional budgets, and 147.1?billion from investors.[84] The biggest item of federal spending was the aviation infrastructure (117.8?billion rubles).[85] Construction of new hotels was a crucial area of infrastructure development in the World Cup host cities. Costs continued to balloon as preparations were underway.[81]\\r\\n\\r\\nPlatov International Airport in Rostov-on-Don was upgraded with automated air traffic control systems, modern surveillance, navigation, communication, control, and meteorological support systems.[86] Koltsovo Airport in Yekaterinburg was upgraded with radio-engineering tools for flight operation and received its second runway strip. Saransk Airport received a new navigation system; the city also got two new hotels, Mercure Saransk Centre (Accor Hotels) and Four Points by Sheraton Saransk (Starwood Hotels) as well as few other smaller accommodation facilities.[87] In Samara, new tram lines were laid.[88] Khrabrovo Airport in Kaliningrad was upgraded with radio navigation and weather equipment.[89] Renovation and upgrade of radio-engineering tools for flight operation was completed in the airports of Moscow, Saint Petersburg, Volgograd, Samara, Yekaterinburg, Kazan and Sochi.[86] On 27 March, the Ministry of Construction Industry, Housing and Utilities Sector of Russia reported that all communications within its area of responsibility have been commissioned. The last facility commissioned was a waste treatment station in Volgograd. In Yekaterinburg, where four matches are hosted, hosting costs increased to over 7.4?billion rubles, over-running the 5.6?billion rubles originally allocated from the state and regional budget.[90]\\r\\n\\r\\nVolunteer applications to the Russia 2018 Local Organising Committee opened on 1 June 2016. The 2018 FIFA World Cup Russia Volunteer Program received about 177,000 applications,[91] and engaged a total of 35,000 volunteers.[92] They received training at 15 Volunteer Centres of the Local Organising Committee based in 15 universities, and in Volunteer Centres in the host cities. Preference, especially in the key areas, was given to those with knowledge of foreign languages and volunteering experience, but not necessarily to Russian nationals.[93]\\r\\n\\r\\nFree public transport services were offered for ticketholders during the World Cup, including additional trains linking between host cities, as well as services such as bus service within them.[94][95][96]\\r\\n\\r\\nThe full schedule was announced by FIFA on 24 July 2015 (without kick-off times, which were confirmed later).[97][98] On 1 December 2017, following the final draw, six kick-off times were adjusted by FIFA.[99]\\r\\n\\r\\nRussia was placed in position A1 in the group stage and played in the opening match at the Luzhniki Stadium in Moscow on 14 June against Saudi Arabia, the two lowest-ranked teams of the tournament at the time of the final draw.[100] The Luzhniki Stadium also hosted the second semi-final on 11 July and the final on 15 July. The Krestovsky Stadium in Saint Petersburg hosted the first semi-final on 10 July and the third place play-off on 14 July.[101][21]\\r\\n\\r\\nThe opening ceremony took place on Thursday, 14 June 2018, at the Luzhniki Stadium in Moscow, preceding the opening match of the tournament between hosts Russia and Saudi Arabia.[102][103]\\r\\n\\r\\nAt the start of the ceremony, Russian president Vladimir Putin gave a speech, welcoming the countries of the world to Russia and calling football a uniting force.[104] Brazilian World Cup-winning striker Ronaldo entered the stadium with a child in a Russia shirt.[104] Pop singer Robbie Williams then sang two of his songs solo before he and Russian soprano Aida Garifullina performed a duet.[104] Dancers dressed in the flags of the 32 competing teams appeared carrying a sign with the name of each nation.[104] At the end of the ceremony Ronaldo reappeared with the official match ball which had returned from the International Space Station in early June.[104]\\r\\n\\r\\nCompeting countries were divided into eight groups of four teams (groups A to H). Teams in each group played one another in a round-robin basis, with the top two teams of each group advancing to the knockout stage. Ten European teams and four South American teams progressed to the knockout stage, together with Japan and Mexico.\\r\\n\\r\\nFor the first time since 1938, Germany (reigning champions) did not advance past the first round. For the first time since 1982, no African team progressed to the second round. For the first time, the fair play criteria came into use, when Japan qualified over Senegal due to having received fewer yellow cards. Only one match, France v Denmark, was goalless. Until then there were a record 36 straight games in which at least one goal was scored.[105]\\r\\n\\r\\nAll times listed below are local time.[99]\\r\\n\\r\\nThe ranking of teams in the group stage was determined as follows:[35][106]\\r\\n\\r\\nIn the knockout stages, if a match is level at the end of normal playing time, extra time is played (two periods of 15 minutes each) and followed, if necessary, by a penalty shoot-out to determine the winners.[35]\\r\\n\\r\\nIf a match went into extra time, each team was allowed to make a fourth substitution, the first time this had been allowed in a FIFA World Cup tournament.[43]\\r\\n\\r\\nThere were 169 goals scored in 64 matches, for an average of 2.64 goals per match.\\r\\n\\r\\n\\r\\nTwelve own goals were scored during the tournament, doubling the record of six set in 1998.[171]\\r\\n6 goals\\r\\n\\r\\n4 goals\\r\\n\\r\\n3 goals\\r\\n\\r\\n2 goals\\r\\n\\r\\n1 goal\\r\\n\\r\\n1 own goal\\r\\n\\r\\nSource: FIFA[172]\\r\\n\\r\\nIn total, only four players were sent off in the entire tournament, the fewest since 1978.[173] International Football Association Board technical director David Elleray stated a belief that this was due to the introduction of VAR, since players would know that they would not be able to get away with anything under the new system.[174]\\r\\n\\r\\nA player is automatically suspended for the next match for the following offences:[35]\\r\\n\\r\\nThe following suspensions were served during the tournament:\\r\\n\\r\\nThe following awards were given at the conclusion of the tournament. The Golden Boot (top scorer), Golden Ball (best overall player) and Golden Glove (best goalkeeper) awards were all sponsored by Adidas.[175]\\r\\n\\r\\nAdditionally, FIFA.com shortlisted 18 goals for users to vote on as the tournaments' best.[176] The poll closed on 23 July. The award was sponsored by Hyundai.[177]\\r\\n\\r\\nAs was the case during the 2010 and 2014 editions, FIFA did not release an official All-Star Team, but instead invited users of FIFA.com to elect their Fan Dream Team.[178][179]\\r\\n\\r\\nFIFA also published an alternate team of the tournament based on player performances evaluated through statistical data.[180]\\r\\n\\r\\nPrize money amounts were announced in October 2017.[181]\\r\\n\\r\\nThe tournament logo was unveiled on 28 October 2014 by cosmonauts at the International Space Station and then projected onto Moscow's Bolshoi Theatre during an evening television programme. Russian Sports Minister Vitaly Mutko said that the logo was inspired by \\"Russia's rich artistic tradition and its history of bold achievement and innovation\\", and FIFA President Sepp Blatter stated that it reflected the \\"heart and soul\\" of the country.[182] For the branding, Portuguese design agency Brandia Central created materials in 2014, with a typeface called Dusha (from , Russian?for soul) designed by Brandia Central and edited by Adotbelow of DSType Foundry in Portugal.[183]\\r\\n\\r\\nThe official mascot for the tournament was unveiled 21 October 2016, and selected through a design competition among university students. A public vote was used to select from three finalistsa cat, a tiger, and a wolf. The winner, with 53% of approximately 1 million votes, was Zabivakaan anthropomorphic wolf dressed in the colours of the Russian national team. Zabivaka's name is a portmanteau of the Russian words  (\\"hothead\\") and ־Ғ^ (\\"to score\\"), and his official backstory states that he is an aspiring football player who is \\"charming, confident and social\\".[184]\\r\\n\\r\\nThe first phase of ticket sales started on 14 September 2017, 12:00 Moscow Time, and lasted until 12 October 2017.[185]\\r\\n\\r\\nThe general visa policy of Russia did not apply to participants and spectators, who were able to visit Russia without a visa right before and during the competition regardless of their citizenship.[186] Spectators were nonetheless required to register for a \\"Fan-ID\\", a special photo identification pass. A Fan-ID was required to enter the country visa-free, while a ticket, Fan-ID and a valid passport were required to enter stadiums for matches. Fan-IDs also granted World Cup attendees free access to public transport services, including buses, and train service between host cities. Fan-ID was administered by the Ministry of Digital Development, Communications and Mass Media, who could revoke these accreditations at any time to \\"ensure the defence capability or security of the state or public order\\".[94][95][96]\\r\\n\\r\\nThe official match ball of the 2018 World Cup group stage was \\"Telstar 18\\", based on the name and design of the first Adidas World Cup ball from 1970. It was introduced on 9 November 2017.[187]\\r\\n\\r\\nAfter the group stage, \\"Telstar Mechta\\" was used for the knockout stage. The word mechta (Russian: ) means dream or ambition. The difference between Telstar 18 and Mechta is the red details on the design.[188]\\r\\n\\r\\nOn 30 April 2018, EA announced a free expansion for FIFA 18 based on the 2018 FIFA World Cup, featuring all 32 participating teams and all 12 stadiums used at the 2018 World Cup.[189]\\r\\n\\r\\nPanini continued their partnership with FIFA by producing stickers for their World Cup sticker album.[190] Panini also developed an app for the 2018 World Cup where fans could collect and swap virtual stickers, with five million fans gathering digital stickers for the tournament.[191][192]\\r\\n\\r\\nThe official song of the tournament was \\"Live It Up\\", with vocals from Will Smith, Nicky Jam and Era Istrefi, released on 25 May 2018. Its music video was released on 8 June 2018.[193]\\r\\n\\r\\nThirty-three footballers who are alleged to be part of the steroid program are listed in the McLaren Report.[194] On 22 December 2017, it was reported that FIFA fired a doctor who had been investigating doping in Russian football.[195] On 22 May 2018 FIFA confirmed that the investigations concerning all Russian players named for the provisional squad of the FIFA World Cup in Russia had been completed, with the result that insufficient evidence was found to assert an anti-doping rule violation.[196] FIFA's medical committee also decided that Russian personnel would not be involved in performing drug testing procedures at the tournament; the action was taken to reassure teams that the samples would remain untampered.[197]\\r\\n\\r\\nThe choice of Russia as host has been challenged. Controversial issues have included the level of racism in Russian football,[198][199][200] and discrimination against LGBT people in wider Russian society.[201][202] Russia's involvement in the ongoing conflict in Ukraine has also caused calls for the tournament to be moved, particularly following the annexation of Crimea.[203][204] In 2014, FIFA President Sepp Blatter stated that \\"the World Cup has been given and voted to Russia and we are going forward with our work\\".[205]\\r\\n\\r\\nAllegations of corruption in the bidding processes for the 2018 and 2022 World Cups caused threats from England's FA to boycott the tournament.[206] FIFA appointed Michael J. Garcia, a US attorney, to investigate and produce a report on the corruption allegations. Although the report was never published, FIFA released a 42-page summary of its findings as determined by German judge Hans-Joachim Eckert. Eckert's summary cleared Russia and Qatar of any wrongdoing, but was denounced by critics as a whitewash.[207] Garcia criticised the summary as being \\"materially incomplete\\" with \\"erroneous representations of the facts and conclusions\\", and appealed to FIFA's Appeal Committee.[208][209] The committee declined to hear his appeal, so Garcia resigned in protest of FIFA's conduct, citing a \\"lack of leadership\\" and lack of confidence in the independence of Eckert.[210]\\r\\n\\r\\nOn 3 June 2015, the FBI confirmed that the federal authorities were investigating the bidding and awarding processes for the 2018 and 2022 World Cups.[211][212] In an interview published on 7 June 2015, Domenico Scala, the head of FIFA's Audit And Compliance Committee, stated that \\"should there be evidence that the awards to Qatar and Russia came only because of bought votes, then the awards could be cancelled\\".[213][214] Prince William, Duke of Cambridge and former British Prime Minister David Cameron attended a meeting with FIFA vice-president Chung Mong-joon in which a vote-trading deal for the right to host the 2018 World Cup in England was discussed.[215][216]\\r\\n\\r\\nIn response to the March 2018 poisoning of Sergei and Yulia Skripal, British Prime Minister Theresa May announced that no British ministers or members of the royal family would attend the World Cup, and issued a warning to any travelling England fans.[217] Iceland diplomatically boycotted the World Cup.[218] Russia responded to the comments from the UK Parliament claiming that \\"the west are trying to deny Russia the World Cup\\".[219] The Russian Foreign Ministry denounced Boris Johnson's statements that compared the event to the 1936 Olympics held in Nazi Germany as \\"poisoned with venom of hate, unprofessionalism and boorishness\\" and \\"unacceptable and unworthy\\" parallel towards Russia, a \\"nation that lost millions of lives in fighting Nazism\\".[220]\\r\\n\\r\\nThe British Foreign Office and MPs had repeatedly warned English football fans and \\"people of Asian or Afro-Caribbean descent\\" travelling to Russia of \\"racist or homophobic intimidation, hooligan violence and anti-British hostility\\".[221][222] English football fans who have travelled have said they have received a warm welcome from ordinary citizens after arriving in Russia.[223][224]\\r\\n\\r\\nAt the close of the World Cup Russia was widely praised for its success in hosting the tournament, with Steve Rosenberg of the BBC deeming it \\"a resounding public relations success\\" for Putin, adding, \\"The stunning new stadiums, free train travel to venues and the absence of crowd violence has impressed visiting supporters. Russia has come across as friendly and hospitable: a stark contrast with the country's authoritarian image. All the foreign fans I have spoken to are pleasantly surprised.\\"[225]\\r\\n\\r\\nFIFA President Gianni Infantino stated, \\"Everyone discovered a beautiful country, a welcoming country, that is keen to show the world that everything that has been said before might not be true. A lot of preconceived ideas have been changed because people have seen the true nature of Russia.\\"[226] Infantino has proclaimed Russia 2018 to be \\"the best World Cup ever\\", as 98% of the stadiums were sold out, there were three billion viewers on TV all around the world and 7 million fans visited the fan fests.[227]\\r\\n\\r\\nFIFA, through several companies, sold the broadcasting rights for the 2018 FIFA World Cup to various local broadcasters.\\r\\n\\r\\nIn February 2018, Ukrainian rightsholder UA:PBC stated that it would not broadcast the World Cup. This came in the wake of growing boycotts of the tournament among the Football Federation of Ukraine and sports minister Ihor Zhdanov.[228][229] Additionally, the Football Federation of Ukraine refused to accredit journalists for the World Cup and waived their quota of tickets.[230] However, the Ukrainian state TV still broadcast the World Cup, and more than 4 million Ukrainians watched the opening match.[231]\\r\\n\\r\\nBroadcast rights to the tournament in the Middle East were hampered by an ongoing diplomatic crisis in Qatar over alleged support of extremist groups. Qatar is the home country of the region's rightsholder, beIN Sports. Bahrain, Egypt, Saudi Arabia, and the United Arab Emirates cut diplomatic ties with Qatar over the matter. On 2 June 2018, beIN pulled its channels from Du and Etisalat, but with service to the latter restored later that day. Etisalat subsequently announced that it would air the World Cup in the UAE, and continue to offer beIN normally and without interruptions.[232][233][234] In Saudi Arabia, beIN's channels have been widely and illegally repackaged by a broadcaster identifying itself as beoutQ; while FIFA attempted to indirectly negotiate the sale of a package consisting of Saudi matches, as well as the opening and final games, they were unable to do so. On 12 July 2018, FIFA stated that it \\"has engaged counsel to take legal action in Saudi Arabia and is working alongside other sports rights owners that have also been affected to protect its interests.\\"[235][236]\\r\\n\\r\\nIn the United States, the 2018 World Cup was the first men's World Cup whose English rights were held by Fox Sports, and Spanish rights held by Telemundo. The elimination of the United States in qualifying led to concerns that US interest and viewership of this World Cup would be reduced (especially among \\"casual\\" viewers interested in the US team), especially noting how much Fox paid for the rights, and that US games at the 2014 World Cup peaked at 16.5?million viewers. During a launch event prior to the elimination, Fox stated that it had planned to place a secondary focus on the Mexican team in its coverage to take advantage of their popularity among US viewers (factoring Hispanic and Latino Americans). Fox stated that it was still committed to broadcasting a significant amount of coverage for the tournament.[237][238][239] Viewership was down overall over 2014, citing additional factors such as viewer unfamiliarity with the new broadcasters, as well as match scheduling that was not as favourable to viewers in the Americas than 2014 (with many matches airing in the morning hours, although Telemundo's broadcast of the Mexico-Sweden Group F match was announced as being its most-watched weekday daytime program in network history).[240][241]","input":"When did this year's world cup start?"},{"output":"Pennsylvania Liquor Control Board (PLCB)","context":"The Pennsylvania Liquor Control Board (PLCB) is an independent government agency that manages the beverage alcohol industry in Pennsylvania by administering the Pennsylvania Liquor Code. It is responsible for licensing the possession, sale, storage, transportation, importation and manufacture of wine, spirits and malt or brewed beverages in the commonwealth, as well as operating a system of liquor distribution (retailing) and providing education about the harmful effects of underage and dangerous drinking.[1]\\r\\n\\r\\n\\r\\nThe Pennsylvania Liquor Control Board was established in conjunction with the 21st Amendment and the repeal of prohibition. In 1933, just four days before the sale of alcohol became legal in Pennsylvania, the Board was officially organized. Upon its creation, Governor Gifford Pinchot stated that the purpose of the Board was to \\"discourage the purchase of alcoholic beverages by making it as inconvenient and expensive as possible.\\"[2]\\r\\nThe agency has its headquarters in the Northwest Office Building in Harrisburg.[3]\\r\\nOn-premises retail licenses and off-premises wholesale licenses are apportioned through a quota system (see below) established by the Pennsylvania Liquor Code. Under the law, the PLCB may grant one retail license for every 3,000 inhabitants of a county and one wholesale license for every 30,000 inhabitants of a county (with a minimum of five wholesale licenses allowed per county). To prevent a municipality from being inundated by liquor licenses, the Pennsylvania Liquor Code also established a population-based municipal quota that limits the number of retail liquor licenses allowed in a municipality; the issuance or transfer of any additional licenses beyond that quota requires prior municipal approval.\\r\\nAs of November 2016, there were about 20,000 active liquor licenses in Pennsylvania.[4] Restaurants and food operations that are licensed to serve or sell drinks in Pennsylvania must purchase their liquor from the PLCB, which operates more than 600 Fine Wine & Good Spirits stores (originally branded simply as a \\"State Store,\\" then \\"PA Wine & Spirits\\" stores before a rebranding project started in 2010) statewide and an e-commerce site.[5] If a wine or spirit is not on the list of registered brands, then it cannot be bought or sold in Pennsylvania.\\r\\nIn Fiscal Year 2015-16, sales at Fine Wine & Good Spirits stores generated more than $2.43 billion in sales and taxes.[6] Taxes and store profits are returned to Pennsylvanias General Fund; more than $626.3 million was returned to the Pennsylvania Treasury, funded state programs or was returned to local communities in FY2015-16.[7] In the last five fiscal years (FY2011-12 through FY2015-16), the PLCB provided more than $2.66 billion to the Pennsylvania Treasury, $122.5 million to the Pennsylvania State Police, $12.1 million to the Department of Drug and Alcohol Programs, and $22.5 million to local communities.[8] Since its inception, the PLCB has contributed more than $15.1 billion to the Pennsylvania Treasury.[9]\\r\\nThe Board also supervises local option referenda in counties and municipalities that wish to prohibit or permit establishments to sell or serve alcohol. According to Section 472 of the Pennsylvania Liquor Code, a local option referendum to change what alcohol sales a municipality allows or prohibits may be voted on during any election.[10] The issue may not be voted on more than once in four years. A referendum can be broad ÿ for example, allowing all forms of alcohol sales in a municipality ÿ or it can be very narrow, for example, allowing only a specific golf course to sell alcohol. To place a referendum on the ballot requires a petition with a number of signatures equal to at least 25 percent of the highest vote cast for any office in that municipality in the preceding general election. As of August 2017, almost 700 Pennsylvania municipalities are \\"dry\\" or \\"partially dry.\\"[11]\\r\\nUnlike other Pennsylvania administrative agencies, appeals from decisions of the Board are to the local Pennsylvania Court of Common Pleas, rather than directly to the Commonwealth Court of Pennsylvania.\\r\\nAs a result of Act 14 (enacted June 30, 1987), enforcement of the Pennsylvania Liquor Code was transferred from the PLCB to the Pennsylvania State Police Bureau of Liquor Control Enforcement (BLCE). This function is fully funded by the PLCB out of operational revenues.[12]\\r\\nThe Board itself is composed of three members who are appointed by the governor and confirmed by a two-thirds vote of the Pennsylvania State Senate. They are appointed to staggered four-year terms ending the third Tuesday in May, but members may serve up to six months beyond that date. Current Board members are:\\r\\nThe PLCB Bureau of Alcohol Education provides educational material to youth, legal consumers and beverage alcohol servers.[14] This includes RAMP (Responsible Alcohol Management Program), which is directed at establishments selling alcoholic beverages.[15]\\r\\nThe PLCB policy of \\"zero tolerance\\" for sales to minors and intoxicated individuals has resulted in store employees challenging, or \\"carding,\\" those who appear to be underage. Store employees can also require a customer to fill out a form attesting to his/her age before the sale is completed. This policy and effective implementation are considered to be an excellent deterrent to underage drinking in Pennsylvania. According to the PLCB Fiscal Year 2014-15 Annual Report, Fine Wine & Good Spirits store employees conducted more than 1.3 million ID checks during the 2014 calendar year.[16]\\r\\nThe Bureau of Alcohol Education annually awards approximately $1 million in grants to reduce underage and dangerous drinking to colleges and universities, community organizations, law enforcement departments, and high schools.[17] Those same groups send representatives to an annual Alcohol Education conference for prevention professionals in Pennsylvania. Another annual event is the Alcohol Awareness Poster Contest for students in kindergarten through 12th grade.\\r\\nThe quota on retail liquor licenses is set forth in Section 461(a) of the Pennsylvania Liquor Code.[18] While that section lays out exceptions, generally, Restaurant Liquor (R), Eating Place Malt Beverage (E),Club (C) and Catering Club Liquor (CC) licenses are subject to the quota. Quota exceptions include ski resorts and casinos. Hotel (H), Off-Track Wagering Restaurant Liquor (OWR), Airport Restaurant (AR), Golf Course (PGR, PGC, GCC, PGE), Continuing Care Retirement (CRR, CRE), Economic Development (EDR, EDE), Performing Arts (PAF) and Public Venue Restaurant (PV) licenses are not subject to the quota.\\r\\nThe first retail license quota was established by Act 358 of 1939, which set it at 1 license for every 1,000 municipal inhabitants. That was changed to 1 license for every 1,500 inhabitants by Act 702 of 1951; 1 license for every 2,000 inhabitants by Act 108 of 1972; and 1 license for every 3,000 inhabitants by Act 160 of 1990. The quota system was switched to a county-based system by Act 141 of 2000.[19]\\r\\nSection 437(f) of the Pennsylvania Liquor Code establishes quotas for Malt Beverage Distributors (D) and Malt Beverage Importing Distributors (ID).[20] One D or ID license is issued for every 30,000 residents, with a minimum of five available in each county. There are no exceptions. Act 591 of 1952 established the distributor license quota at 1 license for every 10,000 county inhabitants and a minimum of five per county. Act 445 of 1965 changed the quota to 1 license for every 15,000 county inhabitants; Act 160 of 1990 made it 1 license for every 30,000 county inhabitants.[19]\\r\\nFor over forty years, starting with the administration of Governor Milton Shapp, efforts have existed to abolish the Board and privatize liquor sales in Pennsylvania. Critics of the Board argue that the commonwealth would generate significant income by selling state liquor stores to private entities while continuing to reap millions in annual sales taxes from alcohol sales and liquor tax revenues. Further, it has been cited that customers could benefit from lower prices, longer hours and wider selection at privately run liquor stores. In addition, privatizing liquor sales would allow the commonwealth to recoup taxes from sales in neighboring states such as New Jersey, Ohio and Delaware. Despite these arguments, efforts to privatize have largely stalled. According to former governor Dick Thornburgh, \\"the principal roadblock to reform has traditionally been an odd coalition of state store employee unions, fundamentalist anti-alcohol groups and organizations such as Mothers Against Drunk Driving, all of which perceive that they have legitimate interests which are not susceptible to statewide budgetary considerations. It would take some courageous leadership to stare down this combination, something I do not see in the commonwealth today.\\"[21] In September 2014, PA House proposed a bill that would decriminalize purchasing wine and liquor in other states and transporting it to the state.[22]\\r\\nOpponents of privatization argue that keeping the stores public would generate significantly more money over time, as well as keep over 5000 employees from losing their jobs, pensions, and health benefits, many of whom are elderly. Although 45% of the entire LCB workforce is temporary, seasonal or part-time and may not have all the benefits that full time employees have.[16]\\r\\nOn July 2, 2015, Governor Wolf vetoed the first ever privatization bill to reach the governor's desk.[23]","input":"Who is responsible for enforcing the liquor code?"},{"output":"12th century","context":"","input":"When was gunpowder first used as a weapon?"},{"output":"Christian","context":"The Battle of Las Navas de Tolosa, known in Arab history as the Battle of Al-Uqab (????? ??????), took place on 16 July 1212 and was an important turning point in the Reconquista and in the medieval history of Spain.[6] The Christian forces of King Alfonso VIII of Castile were joined by the armies of his rivals, Sancho VII of Navarre, Peter II of Aragon and Afonso II of Portugal, in battle[7] against the Berber Almohad Muslim rulers of the southern half of the Iberian Peninsula. The Caliph al-Nasir (Miramamoln in the Spanish chronicles) led the Almohad army, made up of people from the whole Almohad empire. Most of the men in the Almohad army came from the African side of the empire.\\r\\n\\r\\n\\r\\nIn 1195, Alfonso VIII of Castile was defeated by the Almohads in the so-called Disaster of Alarcos. After this victory the Almohads took several important cities: Trujillo, Plasencia, Talavera, Cuenca, and Ucls. Then, in 1211, Muhammad al-Nasir crossed the Strait of Gibraltar with a powerful army, invaded Christian territory, and captured Salvatierra Castle, the stronghold of the knights of the Order of Calatrava. The threat to the Hispanic Christian kingdoms was so great that Pope Innocent III called European knights to a crusade.\\r\\nThere were some disagreements among the members of the Christian coalition: French and other European knights did not agree with Alfonso's merciful treatment of Jews and Muslims who were previously defeated in the conquest of Malag܇n and Calatrava la Vieja. Previously, they had caused problems in Toledo, (where the different armies of the Crusade gathered), with assaults and murders in the Jewish Quarter.\\r\\nAlfonso crossed the mountain range that defended the Almohad camp, sneaking through the Despe?aperros Pass, being led by Martin Alhaja, a local shepherd who knew the area. The Christian coalition caught the Moorish army at camp by surprise, and Alhaja was granted the hereditary title Cabeza de Vaca for his assistance to Alfonso VIII.\\r\\nAccording to legend, the Caliph had his tent surrounded with a bodyguard of slave-warriors who were chained together as a defense.[citation needed] The Navarrese force led by their king Sancho VII broke through this bodyguard. The Caliph escaped, but the Moors were routed, leaving heavy casualties on the battlefield.[8] The victorious Christians seized several prizes of war: Miramamoln's tent and standard were delivered to Pope Innocent III.[9]\\r\\nChristian losses were far fewer, only about 2,000 men (though not as few as legend had it).[citation needed] The losses were particularly heavy among the Orders. Those killed included Pedro G܇mez de Acevedo (bannerman of the Order of Calatrava), Alvaro Fernndez de Valladares (comendator of the Order of Santiago), Pedro Arias (master of the Order of Santiago, died of wounds on 3 August) and Gomes Ramires (Portuguese master of the Knights Templar and simultaneously master of Leon, Castile and Portugal). Ruy Daz (master of the Order of Calatrava) was so grievously wounded that he had to resign his command.\\r\\nThe Caliph Muhammad al-Nasir himself died in Marrakech shortly after the battle, where he had fled after the defeat.\\r\\nThe crushing defeat of the Almohads significantly hastened their decline both in the Iberian Peninsula and in the Maghreb a decade later. That gave further impulse to the Christian Reconquest and sharply reduced the already declining power of the Moors in Iberia. Shortly after the battle, the Castilians took Baeza and then ~beda, major fortified cities near the battlefield and gateways to invade Andalusia. According to Letter from?Alfonso VIII of Castile to Pope Innocent III, Baeza was evacuated and its people moved to ~beda, here the king laid siege and put to death 60,000 muslims and enslaved many more. According to the latin chronicle of kings of castile the number given is almost 100,000 Saracens, including children and women, were captured[10].\\r\\nThereafter, Alfonso VIII's grandson Ferdinand III of Castile took Cordova in 1236, Jan in 1246, and Seville in 1248; then he took Arcos, Medina-Sidonia, Jerez, and Cadiz. In 1252, Ferdinand was preparing his fleet and army for invasion of the Almohad lands in Africa. But he died in Seville on 30 May 1252, during an outbreak of plague in southern Hispania. Only Ferdinand's death prevented the Castilians from taking the war to the Almohad on the Mediterranean coast, James I of Aragon conquered the Balearic Islands (from 1228 over the following four years) and Valencia (the city capitulated on 28 September 1238).\\r\\nBy 1252 the Almohad empire was almost over, at the mercy of another emerging African power. In 1269 a new association of African tribes, the Marinids, took control of the Maghreb, and most of the former Almohad empire was under their rule. Later, the Marinids tried to recover the former Almohad territories in Iberia, but they were definitively defeated by Alfonso XI of Castile and Afonso IV of Portugal in the Battle of Ro Salado, the last major military encounter between large Christian and Muslim armies in Hispania.\\r\\nIn 1292 Sancho IV took Tarifa (the city resisted a siege in 1294), key to the control of the Strait of Gibraltar. Granada, Almera, and Mlaga were the only major Muslim cities of the time remaining in the Iberian peninsula. These three cities were the core of the Emirate of Granada, ruled by the Nasrid dynasty. Granada was a vassal state of Castile, until finally taken by the Catholic Monarchs in 1492.\\r\\nHarry Harrison's 1972 alternate history/science fiction novel Tunnel Through the Deeps depicts a history where the Moors won at Las Navas de Tolosa and retained part of Spain into the 20th century.","input":"Who won the battle of las navas de tolosa?"},{"output":"a most wanted list maintained by the United States Federal Bureau of Investigation (FBI)","context":"The FBI Ten Most Wanted Fugitives is a most wanted list maintained by the United States Federal Bureau of Investigation (FBI). The list arose from a conversation held in late 1949 between J. Edgar Hoover, Director of the FBI, and William Kinsey Hutchinson,[1] International News Service (the predecessor of the United Press International) editor-in-chief, who were discussing ways to promote capture of the FBI's \\"toughest guys\\". This discussion turned into a published article, which received so much positive publicity that on March 14, 1950, the FBI officially announced the list to increase law enforcement's ability to capture dangerous fugitives.[2]\\r\\nIndividuals are generally only removed from the list if the fugitive is captured, dies, or if the charges against them are dropped; they are then replaced by a new entry selected by the FBI. In nine cases, the FBI removed individuals from the list after deciding that they were no longer a \\"particularly dangerous menace to society\\". Machetero member Vctor Manuel Gerena, added to the list in 1984, was on the list for 32 years, which was longer than anyone else.[1] Billie Austin Bryant spent the shortest amount of time on the list, being listed for two hours in 1969.[3] The oldest person to be added to the list was William Bradford Bishop on April 10, 2014 at 77 years old. On rare occasions, the FBI will add a \\"Number Eleven\\" if that individual is extremely dangerous but the Bureau does not feel any of the current ten should be removed.[4] Despite occasional references in the media, the FBI does not rank their list; no suspect is considered \\"#1 on the FBI's Most Wanted List\\" or \\"The Most Wanted.\\"[1]\\r\\nThe list is commonly posted in public places such as post offices. In many cases, fugitives on the list have turned themselves in on becoming aware of their listing. As of December 4, 2014, 504 fugitives had been listed, eight of them women, and 473 (94%) captured or located, 155 (31%) of them due to public assistance. On May 19, 1996,[5] Leslie Isben Rogge became the first person on the FBI Ten Most Wanted Fugitives list to be apprehended due to the Internet.[6] The FBI maintains other lists of individuals, including the Most Wanted Terrorists,[7] along with crime alerts, missing persons, and other fugitive lists.\\r\\nOn June 17, 2013, the list reached a cumulative total of 500 fugitives having been listed.[8]\\r\\n\\r\\n\\r\\nThe Criminal Investigative Division (CID) at FBI Headquarters calls upon all 56 Field Offices to submit candidates for the FBI's \\"Ten Most Wanted Fugitives\\" list.[9] The nominees received are reviewed by Special Agents in the CID and the Office of Public Affairs.[9] The selection of the \\"proposed\\" candidate(s) is forwarded to the Assistant Director of the CID for his/her approval and then to the FBI's Director for final approval.[9] This process takes some time which is why James Joseph \\"Whitey\\" Bulger, Jr., who was arrested in Santa Monica, California on June 22, 2011,[10] remained on the list until May 9, 2012[11] despite no longer being at large. Osama bin Laden similarly remained on the list for almost a year after his death at the hands of U.S. forces on May 2, 2011.[12]\\r\\nRewards are offered for information leading to capture of fugitives on the list; the reward is $100,000 for all fugitives, with the exception of Jason Derek Brown, which is $200,000.\\r\\nSeven of the ten still at large are believed or known to be living outside the United States.\\r\\n\\r\\n Media related to FBI Ten Most Wanted Fugitives at Wikimedia Commons","input":"What is the fbi's most wanted list?"},{"output":"ancient Egypt","context":"A factory (previously manufactory) or manufacturing plant is an industrial site, usually consisting of buildings and machinery, or more commonly a complex having several buildings, where workers manufacture goods or operate machines processing one product into another.\\r\\nFactories arose with the introduction of machinery during the Industrial Revolution when the capital and space requirements became too great for cottage industryor workshops. Early factories that contained small amounts of machinery, such as one or two spinning mules, and fewer than a dozen workers have been called \\"glorified workshops\\".[1]\\r\\nMost modern factories have large warehouses or warehouse-like facilities that contain heavy equipment used for assembly line production. Large factories tend to be located with access to multiple modes of transportation, with some having rail, highway and water loading and unloading facilities.\\r\\nFactories may either make discrete products or some type of material continuously produced such as chemicals, pulp and paper, or refined oil products. Factories manufacturing chemicals are often called plants and may have most of their equipment ÿ tanks, pressure vessels, chemical reactors, pumps and piping ÿ outdoors and operated from control rooms. Oil refineries have most of their equipment outdoors.\\r\\nDiscrete products may be final consumer goods, or parts and sub-assemblies which are made into final products elsewhere. Factories may be supplied parts from elsewhere or make them from raw materials. Continuous production industries typically use heat or electricity to transform streams of raw materials into finished products.\\r\\nThe term mill originally referred to the milling of grain, which usually used natural resources such as water or wind power until those were displaced by steam power in the 19th century. Because many processes like spinning and weaving, iron rolling, and paper manufacturing were originally powered by water, the term survives as in steel mill, paper mill, etc.\\r\\n\\r\\n\\r\\nMax Weber considered production during ancient times as never warranting classification as factories, with methods of production and the contemporary economic situation incomparable to modern or even pre-modern developments of industry. In ancient times, the earliest production limited to the household, developed into a separate endeavour independent to the place of inhabitation with production at that time only beginning to be characteristic of industry, termed as \\"unfree shop industry\\", a situation caused especially under the reign of the Egyptian pharaoh, with slave employment and no differentiation of skills within the slave group comparable to modern definitions as division of labour.[2][3][4]\\r\\nAccording to translations of Demosthenes and Herodotus, Naucratis was a, or the only, factory in the entirety of ancient Egypt.[5][6][7] A source of 1983 (Hopkins), states the largest factory production in ancient times was of 120 slaves within 4th century BC Athens.[8] An article within the New York Times article dated 13 October 2011 states:\\r\\n\\"In African Cave, Signs of an Ancient Paint Factory\\" ÿ (John Noble Wilford)\\r\\n... discovered at Blombos Cave, a cave on the south coast of South Africa where 100,000-year-old tools and ingredients were found with which early modern humans mixed an ochre-based paint.[9]\\r\\nAlthough The Cambridge Online Dictionary definition of factory states:\\r\\na building or set of buildings where large amounts of goods are made using machines [10]\\r\\nelsewhere:\\r\\n... the utilization of machines presupposes social cooperation and the division of labour\\r\\nThe first machine is stated by one source to have been traps used to assist with the capturing of animals, corresponding to the machine as a mechanism operating independently or with very little force by interaction from a human, with a capacity for use repeatedly with operation exactly the same on every occasion of functioning.[12] The wheel was invented c. 3000 BC, the spoked wheel c. 2000 BC. The Iron Age began approximately 1200ÿ1000 BC.[13][14] However, other sources define machinery as a means of production.[15]\\r\\nArchaeology provides a date for the earliest city as 5000 BC as Tell Brak (Ur et al. 2006), therefore a date for cooperation and factors of demand, by an increased community size and population to make something like factory level production a conceivable necessity.[16][17][18]\\r\\nAccording to one text the water-mill was first made in 555 A.D. by Belisarius,[19] although according to another they were known to Pliny the Elder and Vitruvius in the first century B.C. By the time of the 4th century A.D. mills with a capacity to grind 3 tonnes of cereal an hour, a rate sufficient to meet the needs of 80,000 persons, were in use by the Roman Empire.[20][21][22]\\r\\nThe Venice Arsenal provides one of the first examples of a factory in the modern sense of the word. Founded in 1104 in Venice, Republic of Venice, several hundred years before the Industrial Revolution, it mass-produced ships on assembly lines using manufactured parts. The Venice Arsenal apparently produced nearly one ship every day and, at its height, employed 16,000 people.[verification needed]\\r\\nOne of the earliest factories was John Lombe's water-powered silk mill at Derby, operational by 1721. By 1746, an integrated brass mill was working at Warmley near Bristol. Raw material went in at one end, was smelted into brass and was turned into pans, pins, wire, and other goods. Housing was provided for workers on site. Josiah Wedgwood in Staffordshire and Matthew Boulton at his Soho Manufactory were other prominent early industrialists, who employed the factory system.\\r\\nThe factory system began widespread use somewhat later when cotton spinning was mechanized.\\r\\nRichard Arkwright is the person credited with inventing the prototype of the modern factory. After he patented his water frame in 1769, he established Cromford Mill, in Derbyshire, England, significantly expanding the village of Cromford to accommodate the migrant workers new to the area. The factory system was a new way of organizing labour made necessary by the development of machines which were too large to house in a worker's cottage. Working hours were as long as they had been for the farmer, that is, from dawn to dusk, six days per week. Overall, this practice essentially reduced skilled and unskilled workers to replaceable commodities. Arkwright's factory was the first successful cotton spinning factory in the world; it showed unequivocally the way ahead for industry and was widely copied.\\r\\nBetween 1820 and 1850 mechanized factories supplanted traditional artisan shops as the predominant form of manufacturing institution, because the larger-scale factories enjoyed a significant technological advantage over the small artisan shops. The earliest factories (using the factory system) developed in the cotton and wool textiles industry. Later generations of factories included mechanized shoe production and manufacturing of machinery, including machine tools. Factories that supplied the railroad industry included rolling mills, foundries and locomotive works. Agricultural-equipment factories produced cast-steel plows and reapers. Bicycles were mass-produced beginning in the 1880s.\\r\\nThe Nasmyth, Gaskell and Company's Bridgewater Foundry, which began operation in 1836, was one of the earliest factories to use modern materials handling such as cranes and rail tracks through the buildings for handling heavy items.[23]\\r\\nLarge scale electrification of factories began around 1900 after the development of the AC motor which was able to run at constant speed depending on the number of poles and the current electrical frequency.[24] At first larger motors were added to line shafts, but as soon as small horsepower motors became widely available, factories switched to unit drive. Eliminating line shafts freed factories of layout constraints and allowed factory layout to be more efficient. Electrification enabled sequential automation using relay logic.\\r\\nHenry Ford further revolutionized the factory concept in the early 20th century, with the innovation of the mass production. Highly specialized laborers situated alongside a series of rolling ramps would build up a product such as (in Ford's case) an automobile. This concept dramatically decreased production costs for virtually all manufactured goods and brought about the age of consumerism.[verification needed]\\r\\nIn the mid- to late 20th century, industrialized countries introduced next-generation factories with two improvements:\\r\\nSome speculation[citation needed] as to the future of the factory includes scenarios with rapid prototyping, nanotechnology, and orbital zero-gravity facilities.\\r\\nBefore the advent of mass transportation, factories' needs for ever-greater concentrations of laborers meant that they typically grew up in an urban setting or fostered their own urbanization. Industrial slums developed, and reinforced their own development through the interactions between factories, as when one factory's output or waste-product became the raw materials of another factory (preferably nearby). Canals and railways grew as factories spread, each clustering around sources of cheap energy, available materials and/or mass markets. The exception proved the rule: even greenfield factory sites such as Bournville, founded in a rural setting, developed its own housing and profited from convenient communications systems.[verification needed]\\r\\nRegulation curbed some of the worst excesses of industrialization's factory-based society, a series of Factory Acts leading the way in Britain. Trams, automobiles and town planning encouraged the separate development of industrial suburbs and residential suburbs, with laborers commuting between them.\\r\\nThough factories dominated the Industrial Era, the growth in the service sector eventually began to dethrone them:[verification needed] the focus of labor in general shifted to central-city office towers or to semi-rural campus-style establishments, and many factories stood deserted in local rust belts.\\r\\nThe next blow to the traditional factories came from globalization. Manufacturing processes (or their logical successors, assembly plants) in the late 20th century re-focussed in many instances on Special Economic Zones in developing countries or on maquiladoras just across the national boundaries of industrialized states. Further re-location to the least industrialized nations appears possible as the benefits of out-sourcing and the lessons of flexible location apply in the future.[verification needed]\\r\\nMuch of management theory developed in response to the need to control factory processes.[verification needed] Assumptions on the hierarchies of unskilled, semi-skilled and skilled laborers and their supervisors and managers still linger on; however an example of a more contemporary approach to handle design applicable to manufacturing facilities can be found in Socio-Technical Systems (STS).\\r\\nA shadow factory is a term given to dispersed manufacturing sites in times of war to reduce the risk of disruption due to enemy air-raids and often with the dual purpose of increasing manufacturing capacity. Before World War II Britain had built many shadow factories.\\r\\nProduction of the Supermarine Spitfire at its parent company's base at Woolston, Southampton was vulnerable to enemy attack as a high-profile target and was well within range of Luftwaffe bombers. Indeed, on 26 September 1940 this facility was completely destroyed by an enemy bombing raid. Supermarine had already established a plant at Castle Bromwich; this action prompted them to further disperse Spitfire production around the country with many premises being requisitioned by the British Government.[25]\\r\\nConnected to the Spitfire was production of its equally important Rolls-Royce Merlin engine, Rolls-Royce's main aero engine facility was located at Derby, the need for increased output was met by building new factories in Crewe and Glasgow and using a purpose-built factory of Ford of Britain in Trafford Park Manchester.[26]\\r\\nZeche Ewald in Herten, exterior (2011)\\r\\nZeche Ewald in Herten, interior (2011)\\r\\nColdharbour Mill textile factory, built in 1799.\\r\\nAdolph von Menzel: Moderne Cyklopen\\r\\nNew Lanark mill\\r\\nWorkers in the fuse factory, Woolwich Arsenal late 1800s\\r\\nThe assembly plant of the Bell Aircraft Corporation at Wheatfield, New York, United States, 1944\\r\\nInterior of the Rouge Tool & Die works, 1944\\r\\nHyundai's Assembly line (about 2005)","input":"Where was the first factory built in the world?"},{"output":"17 May 2009","context":"Minecraft is a sandbox video game created and designed by Swedish game designer Markus \\"Notch\\" Persson, and later fully developed and published by Mojang. The creative and building aspects of Minecraft allow players to build with a variety of different cubes in a 3D procedurally generated world. Other activities in the game include exploration, resource gathering, crafting, and combat.\\r\\nMultiple gameplay modes are available, including a survival mode where the player must acquire resources to build the world and maintain health, a creative mode where players have unlimited resources to build with and the ability to fly, an adventure mode where players can play custom maps created by other players, and a spectator mode where players can freely move throughout a world without being affected by gravity or collisions. The PC version of the game is noted for its modding scene, where users create new gameplay mechanics, items, and assets for the game.\\r\\nMinecraft received praise from critics and has won numerous awards and accolades. Social media, parodies, adaptations, merchandise, and the MineCon convention played large roles in popularizing the game. It has also been used in educational environments, especially in the realm of computing systems, as virtual computers and hardware devices have been built in it. By early 2018, over 144 million copies had been sold across all platforms, making it the second best-selling video game of all time. In September 2014, Microsoft announced a deal to buy Mojang and the Minecraft intellectual property for US$2.5 billion, with the acquisition completed two months later. Other games in the franchise have also been released, such as Minecraft: Story Mode.\\r\\n\\r\\n\\r\\nMinecraft is a three-dimensional sandbox game that has no specific goals to accomplish, allowing players a large amount of freedom in choosing how to play the game.[14] However, there is an achievement system.[15] Gameplay is in the first-person perspective by default, but players have the option for third-person perspective.[16] The game world is composed of rough 3D objectsmainly cubes and fluidsrepresenting various materials, such as dirt, stone, ores, tree trunks, water, and lava. The core gameplay revolves around picking up and placing these objects. These blocks are arranged in a 3D grid, while players can move freely around the world. Players can \\"mine\\" blocks and then place them elsewhere, enabling them to build things.[17]\\r\\nThe game world is virtually infinite and procedurally generated as players explore it, using a map seed that is obtained from the system clock at the time of world creation (or manually specified by the player).[18][19][20] There are limits on vertical movement, but Minecraft allows an infinitely large game world to be generated on the horizontal plane, only running into technical problems when extremely distant locations are reached.[nb 1] The game achieves this by splitting the world data into smaller sections called \\"chunks\\" that are only created or loaded when players are nearby.[18] The world is divided into biomes ranging from deserts to jungles to snowfields;[21][22] the terrain includes plains, mountains, forests, caves, and various water bodies.[20] The in-game time system follows a day and night cycle, and one full cycle lasts 20 real-time minutes.\\r\\nPlayers encounter various non-player characters known as mobs, such as animals, villagers, and hostile creatures.[23] Passive mobs can be hunted for food and crafting materials, such as cows, pigs, and chickens. They spawn in the daytime, while hostile mobs spawn during nighttime or in dark places such as cavesincluding large spiders, skeletons, and zombies.[20] Some hostile mobs, such as zombies and skeletons, burn under the sun.[24] Some creatures unique to Minecraft have been noted by reviewers, including the creeper (an exploding creature that sneaks up on the player) and the enderman (a creature with the ability to teleport and pick up blocks).[25]\\r\\nMany commentators have described the game's physics system as unrealistic.[26] Liquids continuously flow for a limited horizontal distance from source blocks, which can be removed by placing a solid block in its place or by scooping it into a bucket. Complex systems can be built using primitive mechanical devices, electrical circuits, and logic gates built with an in-game material known as redstone.[27]\\r\\nMinecraft has two alternate dimensions besides the main world: the Nether and the End.[25] The Nether is a hell-like dimension accessed via player-built portals; it contains many unique resources and can be used to travel great distances in the overworld.[28] The player can build an optional boss mob called the Wither out of materials found in the Nether.[29] The End is a barren land consisting of many islands. A boss dragon called the Ender Dragon dwells on the main island.[30] Killing the dragon cues the game's ending credits, written by Irish novelist Julian Gough.[31] Players are then allowed to teleport back to their original spawn point in the overworld and continue the game indefinitely.[32]\\r\\nThe game consists of five game modes: survival, creative, adventure, hardcore, and spectator. It also has a changeable difficulty system of four levels. For example, the peaceful difficulty prevents hostile creatures from spawning, and when playing on the hard difficulty players can starve to death if their hunger bar is depleted.[33][34]\\r\\nIn survival mode, players have to gather natural resources such as wood and stone found in the environment in order to craft certain blocks and items.[20] Depending on the difficulty, monsters spawn in darker areas outside a certain radius of the character, requiring players to build a shelter at night.[20] The mode also has a health bar which is depleted by attacks from monsters, falls, drowning, falling into lava, suffocation, starvation, and other events. Players also have a hunger bar, which must be periodically refilled by eating food in-game, except in peaceful difficulty. If the hunger bar is depleted, automatic healing will stop and eventually health will deplete.[34] Health replenishes when players have a nearly full hunger bar or continuously on peaceful difficulty.\\r\\nPlayers can craft a wide variety of items in Minecraft.[35] Players can craft armour, which can help mitigate damage from attacks, while weapons such as swords can be crafted to kill enemies and other animals more easily. Players acquire resources to craft tools, such as axes, shovels, or pickaxes, used to chop down trees, dig soil, and mine ores, respectively; e.g. tools made of iron perform their tasks more quickly than tools made of stone or wood and can be used more heavily before they break. Players can construct furnaces which can smelt food, process ores and materials, among others.[36] Players may also trade goods with villager NPCs through a bartering system involving trading emeralds for different goods, and vice versa.[37][23][37]\\r\\nThe game has an inventory system, and players can carry a limited number of items. Upon dying, items in the players' inventories are dropped, and players re-spawn at their spawn point, which is set by default where players begin the game, and can be reset if players sleep in a bed.[38] Dropped items can be recovered if players can reach them before they despawn. Players may acquire experience points by killing mobs and other players, mining, smelting ores, breeding animals, and cooking food. Experience can then be spent on enchanting tools, armour and weapons.[33] Enchanted items are generally more powerful, last longer, or have other special effects.[33]\\r\\nHardcore mode is a survival mode variant that is locked to the hardest setting, and has permanent death, where the world is deleted if the player dies.[39] When a player dies on a server set to hardcore mode, the player is put into spectator mode.[40]\\r\\nIn creative mode, players have access to all resources and items in the game through the inventory menu, and can place or remove them instantly.[41] Players can toggle the ability to fly freely around the game world at will, and their characters do not take any damage and are not affected by hunger.[42][43] The game mode helps players focus on building and creating large projects.[41]\\r\\nAdventure mode was added to Minecraft in version 1.3; it was designed specifically so that players could experience user-crafted custom maps and adventures.[44][45][46] Gameplay is similar to survival mode but introduces various player restrictions, which can be applied to the game world by the creator of the map. This forces players to obtain the required items and experience adventures in the way that the map maker intended.[46] Another addition designed for custom maps is the command block; this block allows map makers to expand interactions with players through scripted server commands.[47]\\r\\nSpectator mode allows players to fly around through blocks and watch gameplay without directly interacting. In this mode, instead of having an inventory, players have the ability to teleport to other players. It is also possible to view from the perspective of another player or creature.[48]\\r\\nMultiplayer in Minecraft is available through direct game-to-game multiplayer, LAN play, local split screen, and servers (player-hosted and business-hosted). It enables multiple players to interact and communicate with each other on a single world.[49] Players can run their own servers, use a hosting provider, or connect directly to another player's game via Xbox Live. Single-player worlds have local area network support, allowing players to join a world on locally interconnected computers without a server setup.[50] Minecraft multiplayer servers are guided by server operators (op for short), who have access to server commands such as setting the time of day and teleporting players. Operators can also set up restrictions concerning which usernames or IP addresses are allowed or disallowed to enter the server.[49] Multiplayer servers have a wide range of activities, with some servers having their own unique rules and customs. Player versus player combat (PvP) can be enabled to allow fighting between players.[51] Many servers have custom plugins that allow actions that are not normally possible. In 2013, Mojang announced Minecraft Realms, a server hosting service intended to enable players to run server multiplayer games easily and safely without having to set up their own.[52] Unlike a standard server, only invited players can join Realms servers, and these servers do not use IP addresses. Minecraft: Java Edition Realms server owners can invite up to twenty people to play on their server, with up to ten players online at a time. Minecraft Realms server owners can invite up to 3000 people to play on their server, with up to ten players online at one time. [53] The Minecraft: Java Edition Realms servers do not support user-made plugins, but players can play custom Minecraft maps.[54] Minecraft Realms servers support user-made add-ons, resource packs, behavior packs, and custom Minecraft maps. [55] At Electronic Entertainment Expo 2016, it was announced that Realms would enable Minecraft to support cross-platform play between Windows 10, iOS, and Android platforms starting in June 2016,[56] with Xbox One and Nintendo Switch support to come later in 2017,[57] and support for virtual reality devices. On 31 July 2017, Mojang released the beta version of the update allowing cross-platform play.[58] Realms also supports the Xbox One, Windows 10, Android, iOS, and Kindle platforms.[59]\\r\\nMarkus \\"Notch\\" Persson began developing the game as a project.[60] He was inspired to create Minecraft by several other games such as Dwarf Fortress, Dungeon Keeper, and later Infiniminer. At the time, he had visualised an isometric 3D building game that would be a cross between his inspirations and had made some early prototypes.[60] Infiniminer heavily influenced the style of gameplay, including the first-person aspect of the game, the \\"blocky\\" visual style and the block-building fundamentals. However, unlike Infiniminer, Persson wanted Minecraft to have RPG elements.[61]\\r\\nMinecraft was first released to the public on 17 May 2009, as a developmental release on TIGSource forums,[62] later becoming known as the Classic version. Further milestones dubbed as Survival Test, Indev and Infdev were released between September 2009 and February 2010, although the game saw updates in-between. The first major update, dubbed alpha version, was released on 28 June 2010. Although Persson maintained a day job with Jalbum.net at first, he later quit in order to work on Minecraft full-time as sales of the alpha version of the game expanded.[63] Persson continued to update the game with releases distributed to users automatically. These updates included new items, new blocks, new mobs, survival mode, and changes to the game's behaviour (e.g. how water flows).[63]\\r\\nTo back the development of Minecraft, Persson set up a video game company, Mojang, with the money earned from the game.[64][65][66] On 11 December 2010, Persson announced that Minecraft was entering its beta testing phase on 20 December 2010. He further stated that bug fixes and all updates leading up to and including the release would still be free.[67] Over the course of the development, Mojang hired several new employees to work on the project.[68]\\r\\nMojang moved the game out of beta and released the full version on 18 November 2011.[69] The game has been continuously updated since the release, with changes ranging from new game content to new server hosts.[70] On 1 December 2011, Jens \\"Jeb\\" Bergensten took full creative control over Minecraft, replacing Persson as lead developer.[71] On 28 February 2012, Mojang announced that they had hired the developers of the popular server platform \\"CraftBukkit\\"[51] to improve Minecraft's support of server modifications.[72] This acquisition also included Mojang apparently taking full ownership of the CraftBukkit modification,[73] although the validity of this claim was questioned due to its status as an open-source project with many contributors, licensed under the GNU General Public License and Lesser General Public License.[74] On 15 September 2014, Microsoft announced a $2.5 billion deal to buy Mojang, along with the ownership of the Minecraft intellectual property. The deal was suggested by Persson when he posted a tweet asking a corporation to buy his share of the game after receiving criticism for \\"trying to do the right thing\\".[75][76] It was completed on 6 November 2014, and led to Persson becoming one of Forbes' \\"World's Billionaires\\".[77][78][79][80]\\r\\nMinecraft's music and sound effects were produced by German musician C418 (Daniel Rosenfeld).[81] The background music in Minecraft is instrumental ambient music. On 4 March 2011, Rosenfeld released a soundtrack, titled Minecraft ÿ Volume Alpha; it includes most of the tracks featured in Minecraft, as well as other music not featured in the game.[82] The video game blog Kotaku chose the music in Minecraft as one of the best video game soundtracks of 2011.[83] On 9 November 2013, Rosenfeld released the second official soundtrack, titled Minecraft?ÿ Volume Beta, which includes the music that was added in later versions of the game.[84][85] A physical release of Volume Alpha, consisting of CDs, black vinyl, and limited-edition transparent green vinyl LPs, was issued by acclaimed indie electronic label Ghostly International on 21 August 2015.[86][87]\\r\\nThe game runs on multiple operating systems, including Microsoft Windows, OS X, and Linux.[49][88] Apart from Minecraft: Java Edition and Minecraft for Windows 10, there are other versions of Minecraft for PC, including Minecraft Classic, Minecraft 4k, and Minecraft: Education Edition.\\r\\nMinecraft Classic is an older version of Minecraft, available online for players. Unlike newer versions of Minecraft, the classic version is free to play, though it is no longer updated. It functions much the same as creative mode, allowing players to build and destroy any and all parts of the world either alone or in a multiplayer server. There are no computer creatures in this mode, and environmental hazards such as lava do not damage players. Some blocks function differently since their behaviour was later changed during development.[89][90][91]\\r\\nMinecraft 4k is a simplified version of Minecraft similar to the classic version that was developed for the Java 4K game programming contest \\"in way less than 4 kilobytes\\".[92] The map itself is finitecomposed of 64G64G64 blocksand the same world is generated every time. Players are restricted to placing or destroying blocks, which consist of grass, dirt, stone, wood, leaves, and brick.[93]\\r\\nMinecraft: Education Edition is a version of Minecraft created specifically for educational institutions and was launched 1 November 2016. [94] It includes a Chemistry Resource Pack [95], free lesson plans on the Minecraft Education website, and two free companion applications: Code Connection and Classroom Mode.[96]\\r\\nMinecraft for Windows 10 is currently exclusive to Microsoft's Windows 10 operating system. The beta for it launched on the Windows Store on 29 July 2015.[97] This version has the ability to play with Xbox Live friends, and to play local multiplayer with owners of Minecraft on mobile platforms. Other features include the ability to use multiple control schemes, such as a gamepad, keyboard, or touchscreen (for Microsoft Surface and other touchscreen-enabled devices), virtual reality support, and to record and take screenshots in-game via the built-in GameDVR.[98]\\r\\nAn Xbox 360 version of the game, developed by 4J Studios, was released on 9 May 2012.[99][100] On 22 March 2012, it was announced that Minecraft would be the flagship game in a new Xbox Live promotion called Arcade NEXT.[100] The game differs from the home computer versions in a number of ways, including a newly designed crafting system, the control interface, in-game tutorials, split-screen multiplayer, and the ability to play with friends via Xbox Live.[101][102] The worlds in the Xbox 360 version are also not \\"infinite\\", and are essentially barricaded by invisible walls.[102] The Xbox 360 version was originally similar in content to older PC versions, but is being gradually updated to bring it closer to the current PC version.[99][103][104] An Xbox One version featuring larger worlds among other enchantments[105] was released on 5 September 2014.[105]\\r\\nVersions of the game for the PlayStation 3 and PlayStation 4 were released on 17 December 2013 and 4 September 2014 respectively.[6] The PlayStation 4 version was announced as a launch title, though it was eventually delayed.[106][107] A version for PS Vita was also released in October 2014.[108] Like the Xbox versions, the PlayStation versions were developed by 4J Studios.[109]\\r\\nOn 17 December 2015, Minecraft: Wii U Edition was released. The Wii U version received a physical release on 17 June 2016 in North America,[110] in Japan on 23 June 2016,[111] and in Europe on 30 June 2016.[112] A Nintendo Switch version of the game was released on the Nintendo eShop on 11 May 2017, along with a physical retail version set for a later date.[113] During a Nintendo Direct presentation on 13 September 2017, Nintendo announced that Minecraft: New Nintendo 3DS Edition would be available for download immediately after the livestream, and a physical copy available on a later date. The game is only compatible with the \\"New\\" versions of the 3DS and 2DS systems, and does not work with the original 3DS, 3DS XL, or 2DS models.[13]\\r\\nOn 16 August 2011, Minecraft: Pocket Edition was released for the Xperia Play on the Android Market as an early alpha version. It was then released for several other compatible devices on 8 October 2011.[114][115] An iOS version of Minecraft was released on 17 November 2011.[116]\\r\\nA port was made available for Windows Phones shortly after Microsoft acquired Mojang.[117] The port concentrates on the creative building and the primitive survival aspect of the game, and does not contain all the features of the PC release. On his Twitter account, Jens Bergensten said that the Pocket Edition of Minecraft is written in C++ and not Java, due to iOS not being able to support Java.[118] Gradual updates are periodically released to bring the port closer to the PC version.[119] On 10 December 2014, in observance of Mojang's acquisition by Microsoft, a port of Pocket Edition was released for Windows Phone 8.1.[120] On 18 January 2017, Microsoft announced that it would no longer maintain the Windows Phone versions of Pocket Edition.[121]\\r\\nOn 2 April 2014, a version of Minecraft based on the Pocket Edition was released for the Amazon Fire.[122] On 29 July 2015, a version of Minecraft based on the Pocket Edition was released for Windows 10.[123] On 19 December 2016, the full version of Minecraft: Pocket Edition was released on iOS, Android, Windows Phone and Windows 10, along with the release of the game based on the Pocket Edition for the Apple TV.[12]\\r\\nOn 31 July 2017, the Pocket Edition portion of the name was dropped and the apps were renamed to Minecraft.[124]\\r\\nA version of Minecraft for the Raspberry Pi was officially revealed at MineCon 2012. Mojang stated that the Pi Edition is similar to the Pocket Edition except that it is downgraded to an older version, and with the added ability of using text commands to edit the game world. Players can open the game code and use programming languages to manipulate things in the game world.[125] The game was leaked on 20 December 2012, but was quickly pulled off.[126] It was officially released on 11 February 2013.[127] It was announced that there would be no further updates for this version in 2016.[128]\\r\\nEarly on, Persson planned to support the Oculus Rift with a port of Minecraft, however after Facebook acquired Oculus in 2013 he abruptly canceled plans noting \\"Facebook creeps me out.\\"[129][130] A community-made modification known as Minecraft VR was developed in 2016 to provide virtual reality support to Minecraft: Java Edition oriented towards Oculus Rift hardware. A fork of the Minecraft VR modification known as Vivecraft ported the mod to OpenVR, and is oriented towards supporting HTC Vive hardware.[131] On 15 August 2016, Microsoft launched official Oculus Rift support for Minecraft on Windows 10.[131] Upon its release, the Minecraft VR mod was discontinued by its developer due to trademark complaints issued by Microsoft, and Vivecraft was endorsed by the community makers of the Minecraft VR modification due to its Rift support and being superior to the original Minecraft VR mod.[131] Also available is a Gear VR version, titled Minecraft: Gear VR Edition.[132] Windows Mixed Reality support was added in 2017. The only officially supported VR versions of Minecraft are Minecraft: Gear VR Edition and Minecraft on Windows 10 for Oculus Rift and Windows Mixed Reality headsets.[133]\\r\\nA wide variety of user-generated downloadable content for Minecraft, such as modifications, texture packs and custom maps, exists and is available on the Internet. Modifications of the Minecraft code, called mods, add a variety of gameplay changes, ranging from new blocks, new items, new mobs to entire arrays of mechanisms to craft.[134][135] The modding community is responsible for a substantial supply of mods from ones that enhance gameplay, such as minimaps, waypoints, and durability counters, to ones that add to the game elements from Pokmon, Portal, and The Hunger Games. To make mods easier to create and install, Mojang announced in November 2012 that it planned to add an official modding application programming interface (API).[51]\\r\\nTexture packs that alter the game's textures and HUD are also available, as created by the community.[136] In July 2013, texture packs were replaced with \\"resource packs\\", which have the same role as texture packs, but allow custom audio as well.[137] Players are also create their own maps, which often contain specific rules, challenges, puzzles and quests, and share them for others to play.[44] In August 2012, Mojang added adventure mode[45] for custom maps and in October 2012, Mojang added command blocks,[47] which were created specially for custom maps. In February 2016, Mojang added 2 new versions (Repeat, and Chain) of the classic command block, which were also created specifically for custom maps.[138][139]\\r\\nThe Xbox 360 Edition supports downloadable content, which is available to purchase via the Xbox Games Store; these content packs usually contain additional character skins.[140] It later received support for texture packs in its twelfth title update while introducing \\"mash-up packs\\", which combines texture packs with skin packs and changes to the game's sounds, music and user interface.[141] The first mash-up pack (and by extension, the first texture pack) for the Xbox 360 Edition was released on 4 September 2013, and was themed after the Mass Effect franchise.[142] Unlike the PC version, however, the Xbox 360 Edition does not support player-made mods or custom maps.[143] A cross-promotional resource pack based on the Super Mario franchise by Nintendo was released for the Wii U Edition worldwide on 17 May 2016.[144] A mash-up pack based on Fallout was announced for release on the Wii U Edition.[145]\\r\\nIn June 2017, Mojang released an update known as the \\"Discovery Update\\".[146] The update includes a new map, a new game mode, the \\"Marketplace\\", a catalogue of user-generated content that gives Minecraft creators \\"another way to make a living from the game\\", and more.[147][148]\\r\\nMinecraft: Story Mode, an episodic spin-off game developed by Telltale Games in collaboration with Mojang, was announced in December 2014. Consisting of five episodes plus three additional downloadable episodes, the standalone game is a narrative and player choice-driven, and it was released on Microsoft Windows, OS X, iOS, PlayStation 3, PlayStation 4, Xbox 360 and Xbox One via download on 13 October 2015.[149][150][151] A physical disc that grants access to all episodes was released for the aforementioned four consoles on 27 October.[151] Wii U [152] and Nintendo Switch version were also later released [153][154] The first trailer for the game was shown at MineCon on 4 July 2015, revealing some of the game's features. In Minecraft: Story Mode, players control Jesse (voiced by Patton Oswalt and Catherine Taber),[151] who sets out on a journey with his or her friends to find The Order of the Stonefour adventurers who slayed an Ender Dragonin order to save their world. Brian Posehn, Ashley Johnson, Scott Porter, Martha Plimpton, Dave Fennoy, Corey Feldman, Billy West and Paul Reubens portray the rest of the cast.[155]\\r\\nIn January 2016, Microsoft announced a new tool for education, called Minecraft: Education Edition or MinecraftEDU, planned to be released in 2016. Minecraft has already been used in classrooms around the world to teach subjects ranging from core STEM topics to arts and poetry. Minecraft: Education Edition will be designed specifically for classroom use. The Education Edition gives teachers the tools they need to use Minecraft on an everyday basis.[156][157]\\r\\nThere are few differences between Minecraft and MinecraftEDU. The main concept is the same, an open sandbox world. The students' characters in MinecraftEDU will be able to retain characteristics. Students will also be able to download the game at home, without having to buy their own version of the game. Finally the last large difference is that students can take in-game photos. These photos will be stored in an online notebook with the students' online notes. These online notebooks will be shareable with other students.[158]\\r\\nMinecraftEDU has brought some partnerships from other traditional publishers to bring educational content within the game. Houghton Mifflin Harcourt developed a full version of The Oregon Trail within MinecraftEDU, keeping the entirety of the original game while adding other educational activities alongside it.[159]\\r\\nMinecraft has been praised for the creative freedom it grants players in-game, as well as the ease of enabling emergent gameplay.[181][182][183] Critics have praised Minecraft's complex crafting system, commenting that it is an important aspect of the game's open-ended gameplay.[173] Most publications were impressed by the game's \\"blocky\\" graphics, with IGN describing them as \\"instantly memorable\\".[14] Reviewers also liked the game's adventure elements, noting that the game creates a good balance between exploring and building.[173] The game's multiplayer feature has been generally received favourably, with IGN commenting that \\"adventuring is always better with friends\\".[14] Jaz McDougall of PC Gamer commended Minecraft, deeming it \\"intuitively interesting and contagiously fun, with an unparalleled scope for creativity and memorable experiences\\".[180] It has been regarded as having introduced millions of children to the digital world, insofar as its basic game mechanics are logically analogous to computer commands. [184]\\r\\nReviewers have said the game's lack of in-game tutorials and instructions make it difficult for new players to learn how to play the game. IGN was disappointed about the troublesome steps needed to set up multiplayer servers, calling it a \\"hassle\\".[14] Critics also said visual glitches that occur periodically.[173] In 2009, GameSpot said the game has an \\"unfinished feel\\", adding that \\"some game elements seem incomplete or thrown together in haste\\".[173]\\r\\nA review of the alpha version, by Scott Munro of the Daily Record, called it \\"already something special\\" and urged readers to buy it.[185] Jim Rossignol of Rock, Paper, Shotgun also recommended the alpha of the game, calling it \\"a kind of generative 8-bit Lego Stalker\\".[186] On 17 September 2010, gaming webcomic Penny Arcade began a series of comics and news posts about the addictiveness of the game.[187]\\r\\nThe Xbox 360 version was generally received positively by critics, but did not receive as much praise as the PC version. Although reviewers were disappointed by the lack of features such as mod support and content from the PC version, they acclaimed the port's addition of a tutorial and in-game tips and crafting recipes, saying that they make the game more user-friendly.[143]\\r\\nMinecraft: Pocket Edition initially received mixed reviews from critics. Although reviewers appreciated the game's intuitive controls, they were disappointed by the lack of content. The inability to collect resources and craft items, as well as the limited types of blocks and lack of hostile mobs, were especially criticised.[175][188][189] After updates adding more content, Pocket Edition started receiving more positive reviews. Reviewers complimented the controls and the graphics, but still noted a lack of content.[175]\\r\\nMinecraft surpassed over a million purchases less than a month after entering its beta phase in early 2011.[190][191] At the same time, the game had no publisher backing and has never been commercially advertised except through word of mouth,[192] and various unpaid references in popular media such as the Penny Arcade webcomic.[193] By April 2011, Persson estimated that Minecraft had made ?23?million (US$33?million) in revenue, with 800,000 sales of the alpha version of the game, and over 1 million sales of the beta version.[194] In November 2011, prior to the game's full release, Minecraft beta surpassed 16 million registered users and 4 million purchases.[195] By March 2012, Minecraft had become the 6th best-selling PC game of all time.[196] As of 10?October?2014[update], the game has sold 17 million copies on PC, becoming the best-selling PC game of all time.[197] As of 10?October?2014[update], the game has sold approximately 60 million copies across all platforms, making it one of the best-selling video games of all time.[197][198] On 25 February 2014, the game reached 100 million registered users.[199] As of January?2018[update], over 144 million copies had been sold across all platforms,[200] making it the second best-selling video game of all time behind Tetris.\\r\\nThe Xbox 360 version of Minecraft became profitable within the first day of the game's release in 2012, when the game broke the Xbox Live sales records with 400,000 players online.[201] Within a week of being on the Xbox Live Marketplace, Minecraft sold upwards of a million copies.[202] GameSpot announced in December 2012 that Minecraft sold over 4.48 million copies since the game debuted on Xbox Live Arcade in May 2012.[203] In 2012, Minecraft was the most purchased title on Xbox Live Arcade; it was also the fourth most played title on Xbox Live based on average unique users per day.[204] As of 4?April?2014[update], the Xbox 360 version has sold 12 million copies.[205] In addition, Minecraft: Pocket Edition has reached a figure of 21 million in sales.[206] The PlayStation 3 version sold one million copies in five weeks.[207] The release of the game's PlayStation Vita version boosted Minecraft sales by 79%, outselling both PS3 and PS4 debut releases and becoming the largest Minecraft launch on a PlayStation console.[208] The PS Vita version sold 100,000 digital copies in Japan within the first two months of release, according to an announcement by SCE Japan Asia.[209] By January 2015, 500,000 digital copies of Minecraft were sold in Japan across all PlayStation platforms, with a surge in primary school children purchasing the PS Vita version.[210] Minecraft helped improve Microsoft's total first-party revenue by $63 million for the 2015 second quarter.[211]\\r\\nIn July 2010, PC Gamer listed Minecraft as the fourth-best game to play at work.[212] In December of that year, Good Game selected Minecraft as their choice for Best Downloadable Game of 2010,[213] Gamasutra named it the eighth best game of the year as well as the eighth best indie game of the year,[214][215] and Rock, Paper, Shotgun named it the \\"game of the year\\".[216] Indie DB awarded the game the 2010 Indie of the Year award as chosen by voters, in addition to two out of five Editor's Choice awards for Most Innovative and Best Singleplayer Indie.[217] It was also awarded Game of the Year by PC Gamer UK.[218] The game was nominated for the Seumas McNally Grand Prize, Technical Excellence, and Excellence in Design awards at the March 2011 Independent Games Festival and won the Grand Prize and the community-voted Audience Award.[219][220] At Game Developers Choice Awards 2011, Minecraft won awards in the categories for Best Debut Game, Best Downloadable Game and Innovation Award, winning every award for which it was nominated.[221][222] It also won GameCity's video game arts award.[223] On 5 May 2011, Minecraft was selected as one of the 80 games that would be displayed at the Smithsonian American Art Museum as part of The Art of Video Games exhibit that opened on 16 March 2012.[224][225] At the 2011 Spike Video Game Awards, Minecraft won the award for Best Independent Game and was nominated in the Best PC Game category.[226][227] In 2012, at the British Academy Video Games Awards, Minecraft was nominated in the GAME Award of 2011 category and Persson received The Special Award.[228] In 2012, Minecraft XBLA was awarded a Golden Joystick Award in the Best Downloadable Game category,[229] and a TIGA Games Industry Award in the Best Arcade Game category.[230] In 2013 it was nominated as the family game of the year at the British Academy Video Games Awards.[231] Minecraft Console Edition won the award for TIGA Game Of The Year in 2014.[232] In 2015, the game placed 6th on USgamer's The 15 Best Games Since 2000 list.[233] In 2016, Minecraft placed 6th on Time's The 50 Best Video Games of All Time list.[234]\\r\\nMinecraft was nominated for the 2013 Kids' Choice Awards for Favorite App, but lost to Temple Run.[235] It was nominated for the 2014 Kids' Choice Awards for Favorite Video Game, but lost to Just Dance 2014.[236] The game later won the award for the Most Addicting Game at the 2015 Kids' Choice Awards.[237] In addition, the Java Edition was nominated for \\"Favorite Video Game\\" at the 2018 Kids' Choice Awards.[238][239]\\r\\n Social media sites such as YouTube, Facebook, and Reddit played a significant role in popularising Minecraft.[240] Research conducted by the University of Pennsylvania's Annenberg School of Communication showed that one-third of Minecraft players learned about the game via Internet videos.[241] In 2010, Minecraft-related videos began to gain influence on YouTube, often made by commentators. The videos usually contain screen-capture footage of the game and voice-overs.[242] Common coverage in the videos includes creations made by players, walkthroughs of various tasks, and parodies of works in popular culture. By May 2012, over 4 million Minecraft-related YouTube videos had been uploaded.[243] Some popular commentators have received employment at Machinima, a gaming video company that owns a highly watched entertainment channel on YouTube.[242] The Yogscast is a British organisation that regularly produces Minecraft videos; their YouTube channel has attained billions of views, and their panel at MineCon 2011 had the highest attendance.[242][244] Other well known YouTube personnel include Jordan Maron, who has created many Minecraft parodies, including \\"Minecraft Style\\", a parody of the internationally successful single \\"Gangnam Style\\" by South Korean rapper PSY.[245] Herobrine is a major community icon of Minecraft, who first appeared as a single image on 4chan's /v/ board. According to rumours, Herobrine appears in players' worlds and builds strange constructions.[246] However, Mojang has confirmed that Herobrine has never existed in Minecraft, and there are no plans to add Herobrine.[247]\\r\\nMinecraft has been referenced by other video games, such as RuneScape,[citation needed] Torchlight II, Borderlands 2, Choplifter HD, Super Meat Boy, The Elder Scrolls V: Skyrim, The Binding of Isaac, The Stanley Parable, and FTL: Faster Than Light.[248][249] It was also referenced by electronic music artist deadmau5 in his performances.[250] A simulation of the game was featured in Lady Gaga's \\"G.U.Y.\\" music video.[251] The game is also referenced heavily in \\"Informative Murder Porn\\", the second episode of the seventeenth season of the animated television series South Park.[252] \\"Luca$\\", the seventeenth episode of the 25th season of the animated sitcom The Simpsons was inspired by Minecraft; Persson responded by tweeting \\"I'm not sure how I feel about it.\\"[253]\\r\\nAfter the release of Minecraft, some video games were released with various similarities with Minecraft, and some were called \\"clones\\" of the game. Examples include Ace of Spades, CastleMiner, CraftWorld, FortressCraft, Terraria, and Total Miner.[254] David Frampton, designer of The Blockheads, reported that one failure of his 2D game was the \\"low resolution pixel art\\" that too closely resembled the art in Minecraft which resulted in \\"some resistance\\" from fans.[255] A homebrew adaptation of the alpha version of Minecraft for the Nintendo DS, titled DScraft, has been released; it has been noted for its similarity to the original game considering the technical limitations of the system.[256]\\r\\nIn response to Microsoft's acquisition of Mojang and their Minecraft IP, various developers announced even further clone titles that were being developed specifically for Nintendo's consoles, as they were the only major platforms to not officially receive Minecraft at the time.[257] These clone titles include UCraft (Nexis Games),[258] Cube Life: Island Survival (Cypronia),[259] Discovery (noowanda),[260] Battleminer (Wobbly Tooth Games),[261] Cube Creator 3D (Big John Games),[262] and Stone Shire (Finger Gun Games).[263] Despite this the fears were unfounded with official Minecraft releases on Nintendo consoles eventually resuming.[264][152][11]\\r\\nIn 2012, Mojang received offers from Hollywood producers who wanted to produce Minecraft-related TV shows; however, Mojang stated that they would only engage in such projects when \\"the right idea comes along\\".[243] By February 2014, Persson revealed that Mojang was in talks with Warner Bros. regarding a Minecraft film.[265][266] and by that October, it was \\"in its early days of development\\".[267][268] The film will be released on 24 May 2019, and is being co-directed by Shawn Levy and Rob McElhenney and written by Jason Fuchs.[269][270][271][272]\\r\\nIn addition, a documentary about the development of Mojang and Minecraft was released in December 2012. Titled Minecraft: The Story of Mojang, the film was produced by 2 Player Productions.[273] In 2014, an attempt to crowdfund a fan film through Kickstarter was shut down after Persson refused to let the filmmakers use the license.[274][275]\\r\\nA Lego set based on Minecraft called Lego Minecraft was released on 6 June 2012.[276] The set, called \\"Micro World\\", centres around the game's default player character and a creeper.[277] Mojang submitted the concept of Minecraft merchandise to Lego in December 2011 for the Lego Cuusoo program, from which it quickly received 10,000 votes by users, prompting Lego to review the concept.[278] Lego Cuusoo approved the concept in January 2012 and began developing sets based on Minecraft.[278] Two more sets based on the Nether and village areas of the game were released on 1 September 2013. A fourth Micro World set, the End, was released in June 2014. Six more sets became available November 2014.[279]\\r\\nMojang collaborates with Jinx, an online game merchandise store, to sell Minecraft merchandise, such as clothing, foam pickaxes, and toys of creatures in the game.[64] By May 2012, over 1 million dollars were made from Minecraft merchandise sales. T-shirts and socks were the most popular products.[243] In March 2013 Mojang signed a deal with the Egmont Group, a children's book publisher, to create Minecraft handbooks, annuals, poster books, and magazines.[280][281][282]\\r\\nMineCon is an official convention dedicated to Minecraft. The first one was held in November 2011 at the Mandalay Bay Hotel and Casino in Las Vegas. All 4,500 tickets for MineCon 2011 were sold out by 31 October.[283] The event included the official launch of Minecraft; keynote speeches, including one by Persson; building and costume contests; Minecraft-themed breakout classes; exhibits by leading gaming and Minecraft-related companies; commemorative merchandise; and autograph and picture times with Mojang employees and well-known contributors from the Minecraft community.[284] After MineCon, there was an Into The Nether after-party with deadmau5.[285] Free codes were given to every attendee of MineCon that unlocked alpha versions of Mojang's Scrolls, as well as an additional non-Mojang game, Cobalt, developed by Oxeye Game Studios.[286] Similar events occurred in MineCon 2012, which took place in Disneyland Paris from in November.[287] The tickets for the 2012 event sold out in less than two hours.[288] MineCon 2013 was held in Orlando in November as well.[289][290] MineCon 2015 was held in London in July.[291] MineCon 2016 was held in Anaheim in September.[292] MineCon 2017 was held as a livestream instead of being held at a show floor. Titled \\"MineCon Earth\\", it was streamed live on November.[nb 2]\\r\\nThe possible applications of Minecraft have been discussed extensively, especially in the fields of computer-aided design and education. In a panel at MineCon 2011, a Swedish developer discussed the possibility of using the game to redesign public buildings and parks, stating that rendering using Minecraft was much more user-friendly for the community, making it easier to envision the functionality of new buildings and parks.[242] In 2012, a member of the Human Dynamics group at the MIT Media Lab, Cody Sumter, said: \\"Notch hasn't just built a game. He's tricked 40 million people into learning to use a CAD program.\\" Various software has been developed to allow virtual designs to be printed using professional 3D printers or personal printers such as MakerBot and RepRap.[295]\\r\\nIn September 2012, Mojang began the Block By Block project in cooperation with UN Habitat to create real-world environments in Minecraft.[296] The project allows young people who live in those environments to participate in designing the changes they would like to see. Using Minecraft, the community has helped reconstruct the areas of concern, and citizens are invited to enter the Minecraft servers and modify their own neighbourhood. Carl Manneh, Mojang's managing director, called the game \\"the perfect tool to facilitate this process\\", adding \\"The three-year partnership will support UN-Habitat's Sustainable Urban Development Network to upgrade 300 public spaces by 2016.\\" Mojang signed Minecraft building community, FyreUK, to help render the environments into Minecraft. The first pilot project began in Kibera, one of Nairobi's informal settlements, and is in the planning phase. The Block By Block project is based on an earlier initiative started in October 2011, Mina Kvarter (My Block), which gave young people in Swedish communities a tool to visualise how they wanted to change their part of town. According to Manneh, the project was a helpful way to visualise urban planning ideas without necessarily having a training in architecture. The ideas presented by the citizens were a template for political decisions.[297]\\r\\nIn April 2014, the Danish Geodata Agency generated all of Denmark in fullscale in Minecraft based on their own geodata.[298] This is possible because Denmark is one of the flattest countries with the highest point at 171 meters (ranking as the country with the 30th smallest elevation span), where the limit in default Minecraft is around 192 meters above in-game sea level.\\r\\nMinecraft has also been used in educational settings.[299] In 2011, an educational organisation named MinecraftEdu was formed with the goal of introducing Minecraft into schools. The group works with Mojang to make the game affordable and accessible to schools. In September 2012, MinecraftEdu said that approximately 250,000 students around the world have access to Minecraft through the company.[300] A wide variety of educational activities involving the game have been developed to teach students various subjects, including history, language arts and science. For an example, one teacher built a world consisting of various historical landmarks for students to learn and explore.[300]\\r\\nWith the introduction of redstone blocks to represent electrical circuits, users have been able to build functional virtual computers within Minecraft.[301] Such virtual creations include a working hard drive,[302] an 8-bit virtual computer,[303] and emulators for the Atari 2600 (by SethBling)[304] and Game Boy Advance.[305] In at least one instance, a mod has been created to use this feature to teach younger players how to program within a language set by the virtual computer within a Minecraft world.[306]\\r\\nMicrosoft and non-profit Code.org had teamed up to offer Minecraft-based games, puzzles, and tutorials aimed to help teach children how to program; by March 2018, Microsoft and Code.org reported that more than 85 million children have used their tutorials.[307]\\r\\nIn September 2014, the British Museum in London announced plans to recreate its building along with all exhibits in Minecraft in conjunction with members of the public.[308]","input":"When was the first version of minecraft made?"},{"output":"May 10, 1775","context":"The Second Continental Congress was a convention of delegates from the Thirteen Colonies that started meeting in the spring of 1775 in Philadelphia, Pennsylvania. It succeeded the First Continental Congress, which met in Philadelphia between September 5, 1774 and October 26, 1774. The Second Congress managed the Colonial war effort and moved incrementally towards independence. It eventually adopted the Lee Resolution which established the new country on July 2, 1776, and it agreed to the United States Declaration of Independence on July 4, 1776. The Congress acted as the de facto national government of the United States by raising armies, directing strategy, appointing diplomats, and making formal treaties such as the Olive Branch Petition.[1]\\r\\nThe Second Continental Congress came together on May 10, 1775, effectively reconvening the First Continental Congress. Many of the 56 delegates who attended the first meeting were in attendance at the second, and the delegates appointed the same president (Peyton Randolph) and secretary (Charles Thomson).[2] Notable new arrivals included Benjamin Franklin of Pennsylvania and John Hancock of Massachusetts. Within two weeks, Randolph was summoned back to Virginia to preside over the House of Burgesses; he was replaced in the Virginia delegation by Thomas Jefferson, who arrived several weeks later. Henry Middleton was elected as president to replace Randolph, but he declined. Hancock was elected president on May 24.[3]\\r\\nDelegates from twelve of the Thirteen Colonies were present when the Second Continental Congress convened. Georgia had not participated in the First Continental Congress and did not initially send delegates to the Second. On May 13, 1775, Lyman Hall was admitted as a delegate from the Parish of St. John's in the Colony of Georgia, not as a delegate from the colony itself.[4] On July 4, 1775, revolutionary Georgians held a Provincial Congress to decide how to respond to the American Revolution, and that congress decided on July 8 to send delegates to the Continental Congress. They arrived on July 20.[5]\\r\\n\\r\\n\\r\\nThe First Continental Congress had sent entreaties to King George III to stop the Coercive Acts; they had also created the Continental Association to establish a coordinated protest of those acts, putting a boycott on British goods. The Second Continental Congress met on May 10, 1775 to plan further responses if the British government had not repealed or modified the acts; however, the American Revolutionary War had already started by that time with the Battles of Lexington and Concord, and the Congress was called upon to take charge of the war effort.\\r\\nFor the first few months of the war, the Patriots carried on their struggle in an ad-hoc and uncoordinated manner. They had seized arsenals, driven out royal officials, and besieged the British army in the city of Boston. On June 14, 1775, the Congress voted to create the Continental Army out of the militia units around Boston and appointed George Washington of Virginia as commanding general.[6] On July 6, 1775, Congress approved a Declaration of Causes outlining the rationale and necessity for taking up arms in the Thirteen Colonies.\\"[7] On July 8, they extended the Olive Branch Petition to the British Crown as a final attempt at reconciliation; however, it was received too late to do any good. Silas Deane was sent to France as a minister (ambassador) of the Congress, and American ports were reopened in defiance of the British Navigation Acts.\\r\\nThe Continental Congress had no explicit legal authority to govern,[8] but it assumed all the functions of a national government, such as appointing ambassadors, signing treaties, raising armies, appointing generals, obtaining loans from Europe, issuing paper money (called \\"Continentals\\"), and disbursing funds. The Congress had no authority to levy taxes and was required to request money, supplies, and troops from the states to support the war effort. Individual states frequently ignored these requests.\\r\\nCongress was moving towards declaring independence from the British Empire in 1776, but many delegates lacked the authority from their home governments to take such a drastic action. Advocates of independence moved to have reluctant colonial governments revise instructions to their delegations, or even replace those governments which would not authorize independence. On May 10, 1776, Congress passed a resolution recommending that any colony with a government that was not inclined toward independence should form one that was. On May 15, they adopted a more radical preamble to this resolution, drafted by John Adams, which advised throwing off oaths of allegiance and suppressing the authority of the Crown in any colonial government that still derived its authority from the Crown. That same day, the Virginia Convention instructed its delegation in Philadelphia to propose a resolution that called for a declaration of independence, the formation of foreign alliances, and a confederation of the states. The resolution of independence was delayed for several weeks, as advocates of independence consolidated support in their home governments.\\r\\nOn June 7, 1776, Richard Henry Lee offered a resolution before the Congress declaring the colonies independent. He also urged Congress to resolve \\"to take the most effectual measures for forming foreign Alliances\\" and to prepare a plan of confederation for the newly independent states.[9] Lee argued that independence was the only way to ensure a foreign alliance, since no European monarchs would deal with America if they remained Britain's colonies. American leaders had rejected the divine right of kings in the New World, but recognized the necessity of proving their credibility in the Old World.[10] Congress formally adopted the resolution of independence, but only after creating three overlapping committees to draft the Declaration, a Model Treaty, and the Articles of Confederation. The Declaration announced the states' entry into the international system; the model treaty was designed to establish amity and commerce with other states; and the Articles of Confederation established \\"a firm league\\" among the thirteen free and independent states. These three things together constituted an international agreement to set up central institutions for conducting vital domestic and foreign affairs.[9]\\r\\nCongress finally approved the resolution of independence on July 2, 1776. They next turned their attention to a formal explanation of this decision, the United States Declaration of Independence which was approved on July 4 and published soon thereafter.\\r\\nThe Congress moved from Philadelphia to Baltimore in the winter of 1776 to avoid capture by British forces who were advancing on Philadelphia. Henry Fite's tavern was the largest building in Baltimore Town at the time and provided a comfortable location of sufficient size for Congress to meet. Its site at the western edge of town was beyond easy reach of the British Royal Navy's ships should they try to sail up the harbor and the Patapsco River to shell the town. Congress was again forced to flee Philadelphia at the end of September 1777, as British troops occupied the city; they moved to York, Pennsylvania and continued their work.\\r\\nCongress passed the Articles of Confederation on November 15, 1777, after more than a year of debate, and sent them to the states for ratification. Jefferson's proposal for a Senate to represent the states and a House to represent the people was rejected, but a similar proposal was adopted later in the United States Constitution. One issue of debate was large states wanting a larger say, nullified by small states who feared tyranny. The small states won and each state had one vote.[13] Congress urged the individual states to pass the Articles as quickly as possible, but it took three and a half years for all the states to ratify them. The State Legislature of Virginia was the first of the Thirteen States to ratify the Articles on December 16, 1777, and the State Legislature of Maryland was the last on February 2, 1781.","input":"When did the second continental congress first meet?"},{"output":"Egyptian language","context":"Coptic or Coptic Egyptian (Bohairic: ????????????? ti.met.rem.?n.khmi and Sahidic: ?????????????? t.m?nt.r?m.?n.kme) is the latest stage of the Egyptian language, a northern Afro-Asiatic language spoken in Egypt until at least the 17th century.[2] Egyptian began to be written in the Coptic alphabet, an adaptation of the Greek alphabet with the addition of six or seven signs from demotic to represent Egyptian sounds the Greek language did not have, in the first century AD.[3]\\r\\nSeveral distinct Coptic dialects are identified, the most prominent of which are Sahidic, originating in parts of Upper Egypt, and Bohairic, originally from the western Nile Delta in Lower Egypt.\\r\\nCoptic and Demotic are grammatically closely related to Late Egyptian, which was written with Egyptian hieroglyphs. Coptic flourished as a literary language from the second to thirteenth centuries, and its Bohairic dialect continues to be the liturgical language of the Coptic Orthodox Church of Alexandria. It was supplanted by Egyptian Arabic as a spoken language toward the early modern period, but language revitalization efforts have been underway since the 19th century.\\r\\n\\r\\n\\r\\nThe native Coptic name for the language is ????????????? /ti-met-rem-en-k?e?-mi/ in the Bohairic (Delta) dialect, ?????????????? /t-ment-rem-en-ki?-me/ in the Sahidic (Valley) dialect. The particle prefix me(n)t- from the verb ???? mouti ('to speak') forms all abstract nouns in Coptic (not only those pertaining to \\"language\\"). The term remenkhmi/remenkme meaning 'Egyptian', literally 'person of Egypt', is a compound of rem-, which is the construct state of the Coptic noun ????/????, 'man, human being', + the genitive preposition (e)n- 'of' + the word for 'Egypt', ????/???? khmi/kme (cf. Kemet). Thus, the whole expression literally means 'language of the people of Egypt', or simply 'Egyptian language'.\\r\\nAnother name by which the language has been called is ????????????? /timentkuptaion/ from the Copto-Greek form ?????????????? /timentaiguption/ ('Egyptian language'). The term logos ?n aiguptios ('Egyptian language') is also attested in Sahidic, but logos and aiguptios are both Greek in origin. In the liturgy of the Coptic Orthodox Church of Alexandria, the name is more officially ????? ??????????? ti aspi ?n rem ?n kmi, 'the Egyptian language', aspi being the Egyptian word for language.\\r\\nCoptic is today spoken liturgically in the Coptic Orthodox and Coptic Catholic Church (along with Modern Standard Arabic). The language is spoken only in Egypt and historically has had little influence outside of the territory, except for monasteries located in Nubia. Coptic's most noticeable linguistic impact has been on the various dialects of Egyptian Arabic, which is characterized by a Coptic substratum in lexical, morphological, syntactical, and phonological features.[citation needed]\\r\\nIn addition to influencing the grammar, vocabulary and syntax of Egyptian Arabic, Coptic has lent to both Arabic and Biblical Hebrew such words as:\\r\\nA few words of Coptic origin are found in the Greek language; some of the words were later lent to various European languages (such as barge, from Coptic ????? bari, \\"small boat\\").\\r\\nHowever, most words of Egyptian origin that entered into Greek and subsequently into other European languages came directly from Ancient Egyptian, often Demotic. An example is the Greek ?ϫ? oasis, which comes directly from Egyptian w?3.t or demotic w??. However, Coptic reborrowed some words of Ancient Egyptian origin into its lexicon, via Greek. For example, both Sahidic and Bohairic use the word ebenos, which was taken directly from Greek ?ǚ? \\"ebony\\", originally from Egyptian hbny.[citation needed]\\r\\nMany major cities' names in modern Egypt are Arabic adaptations of their former Coptic names:\\r\\nThe Coptic name ????????, papnoute (from Egyptian p3y-p3-n?r), means \\"belonging to God\\" or \\"he of God\\"[4][5][6]. It was adapted into Arabic as Babnouda, which remains a common name among Egyptian Copts to this day. It was also borrowed into Greek as the name ϫ?? (Paphnutius). That, in turn, is the source of the Russian name ҳ (Pafnuty), like the mathematician Pafnuty Chebyshev.\\r\\nThe Old Nubian language and the modern Nobiin language borrowed many words of Coptic origin.[citation needed]\\r\\nThe Egyptian language may have the longest documented history of any language, from Old Egyptian that appeared just before 3200 BC[7] to its final phases as Coptic in the Middle Ages. Coptic belongs to the Later Egyptian phase, which started to be written in the New Kingdom of Egypt. Later Egyptian represented colloquial speech of the later periods. It had analytic features like definite and indefinite articles and periphrastic verb conjugation. Coptic, therefore, is a reference to both the most recent stage of Egyptian after Demotic and the new writing system that was adapted from the Greek alphabet.\\r\\nThe earliest attempts to write the Egyptian language using the Greek alphabet are Greek transcriptions of Egyptian proper names, most of which date to the Ptolemaic period. Scholars frequently refer to this phase as pre-Coptic. However, it is clear that by the late pharaonic period, demotic scribes regularly employed a more phonetic orthography, a testament to the increasing cultural contact between Egyptians and Greeks even before Alexander the Great's conquest of Egypt. Coptic itself, or Old Coptic, takes root in the first century. The transition from the older Egyptian scripts to the newly adapted Coptic alphabet was in part due to the decline of the traditional role played by the priestly class of ancient Egyptian religion, who unlike most ordinary Egyptians, were literate in the temple scriptoria. Old Coptic is represented mostly by non-Christian texts such as Egyptian pagan prayers and magical and astrological papyri. Many of them served as glosses to original hieratic and demotic equivalents. The glosses may have been aimed at non-Egyptian speakers.\\r\\nUnder late Roman rule, Diocletian persecuted many Egyptian converts to the new Christian faith, which forced new converts to flee to the Egyptian deserts. In time, the growth of these communities generated the need to write Christian Greek instructions in the Egyptian language. The early Fathers of the Egyptian Church, such as Anthony the Great, Pachomius the Great, Macarius of Egypt and Athanasius of Alexandria, who otherwise usually wrote in Greek, addressed some of their works to the Egyptian monks in Egyptian. The Egyptian language, now written in the Coptic alphabet, flourished in the second and third centuries. However, it was not until Shenouda/Shenoute that Coptic became a fully standardized literary language based on the Sahidic dialect. Shenouda's native Egyptian tongue and knowledge of Greek and rhetoric gave him the necessary tools to elevate Coptic, in content and style, to a literary height nearly equal to the position of the Egyptian language in Ancient Egypt.\\r\\nThe Muslim conquest of Egypt by Arabs came with the spread of Islam in the seventh century. At the turn of the eighth century, Caliph Abd al-Malik ibn Marwan decreed that Arabic replace Koine Greek and Coptic as the sole administrative language. Literary Coptic gradually declined, and within a few hundred years, Egyptian bishop Severus Ibn al-Muqaffa? found it necessary to write his History of the Patriarchs in Arabic. However, the language ecclesiastically retained its important position, and many hagiographic texts were also composed during this period. Until the 10th century, Coptic remained the spoken language of the native population outside the capital.\\r\\nPersecutions under the Mamluk Sultanate (1250ÿ1517) led to the further decline of Coptic[citation needed] until it completely gave way to Egyptian Arabic around the 17th century[citation needed], though it may have survived in isolated pockets for a little longer. In the second half of the 19th century, Pope Cyril IV of Alexandria started a national Church-sponsored movement to revive Coptic. Several works of grammar were published, along with a more comprehensive dictionary than had been previously available. The scholarly findings of the field of Egyptology and the inauguration of the Institute of Coptic Studies further contributed to the renaissance. Efforts at language revitalization continue to be undertaken, both inside and outside the Church, and have attracted the interest of Copts and linguists in and outside of Egypt.\\r\\nCoptic uses a writing system almost wholly derived from the Greek alphabet, with the addition of a number of letters that have their origins in Demotic Egyptian. (That makes it comparable to the Latin-based Icelandic alphabet, which includes the runic letter thorn.)[8] There is some variation in the number and forms of these signs depending on the dialect. Some of the letters in the Coptic alphabet that are of Greek origin were normally reserved for words that are themselves Greek. Old Coptic texts employed several graphemes that were not retained in the literary Coptic orthography of later centuries.\\r\\nIn Sahidic, syllable boundary may have been marked by a supralinear stroke. Such words in the northern dialects have ? ([e] or [?]) in place of the superlinear stroke. Some scribal traditions use a diaeresis over /i/ and /u/ at the beginning of a syllable. Bohairic uses a superposed point or small stroke known as a djinkim. It may be related to the Sahidic supralinear stroke, or it may indicate a glottal stop. Most Coptic texts do not indicate a word division.\\r\\nThe oldest Coptic writings date to the pre-Christian era (Old Coptic), though Coptic literature consists mostly of texts written by prominent saints of the Coptic Church such as Anthony the Great, Pachomius the Great and Shenoute. Shenoute helped fully standardize the Coptic language through his many sermons, treatises and homilies, which formed the basis of early Coptic literature.\\r\\nThe core lexicon of Coptic is Egyptian, most closely related to the preceding Demotic phase of the language. Up to 20% of the vocabulary of literary Coptic is drawn from Greek, but borrowings are not always fully adapted to the Coptic phonological system and may have semantic differences as well. There are instances of Coptic texts having passages that are almost entirely composed from Greek lexical roots. However, that is likely due to the fact that the majority of Coptic religious texts are direct translations of Greek works.\\r\\nWhat invariably attracts the attention of the reader of a Coptic text, especially if it is written in the Sa'idic dialect, is the very liberal use which is made of Greek loan words, of which so few, indeed, are to be found in the Ancient Egyptian language. There Greek loan words occur everywhere in Coptic literature, be it Biblical, liturgical, theological, or non-literary, i.e. legal documents and personal letters. Though nouns and verbs predominate, the Greek loan words may come from any other part of speech except pronouns.[9]\\r\\nWords or concepts for which no adequate Egyptian translation existed were taken directly from Greek to avoid altering the meaning of the religious message. In addition, other Egyptian words that would have adequately translated the Greek equivalents were not employed as they were perceived as having overt pagan associations. Old Coptic texts employ many such words, phrases and epithets; for example, the word ??????? '(Who is) in (His) Mountain', is an epithet of Anubis.[10] There are also traces of some archaic grammatical features, such as residues of the Demotic relative clause, lack of an indefinite article and possessive use of suffixes.\\r\\nThus, the transition from the 'old' traditions to the new Christian religion also contributed to the adoption of Greek words into the Coptic religious lexicon. It is safe to assume that the everyday speech of the native population retained, to a greater extent, its indigenous Egyptian character, which is sometimes reflected in Coptic nonreligious documents such as letters and contracts.\\r\\nCoptic provides the clearest indication of Later Egyptian phonology from its writing system, which fully indicates vowel sounds and occasionally stress pattern. The phonological system of Later Egyptian is also better known than that of the Classical phase of the language because of a greater number of sources indicating Egyptian sounds, including cuneiform letters containing transcriptions of Egyptian words and phrases, and Egyptian renderings of Northwest Semitic names. Coptic sounds, in addition, are known from a variety of Coptic-Arabic papyri in which Arabic letters were used to transcribe Coptic and vice versa. They date to the medieval Islamic period, when Coptic was still spoken.[11]\\r\\nThere are some differences of opinion among Coptic language scholars on the correct phonetic interpretation of the writing system of Coptic. Differences centre on how to interpret the pairs of letters / and /. In Greek spelling, the first member of each pair is a short closed vowel /e, o/, and the second member is a long open vowel /??, ??/. In some interpretations of Coptic phonology,[12] it is assumed that the length difference is primary, with / e/e? and / is o/o?. Other scholars[13][14] argue for a different analysis in which / and / are interpreted as e/? and o/?.\\r\\nThese two charts show the two theories of Coptic vowel phonology:\\r\\nIn the Upper Egyptian dialects, a superlinear stroke is placed over sonorants to mark a reduced /e/. The vowel does not undergo reduction in the northern dialects, where it is indicated by ? in Bohairic and ? or ? in Fayyumic. For example, /?em??/ 'to worship' is Sah/Akh/Lyc ?????, Bohairic ????? and Fayyumic ?????. The vowel quality of /e/ can vary: either [e] or [?] depending on the dialect. In Sahidic and other Upper Egyptian dialects, word-final ? corresponds to word-final ? in the northern dialects.\\r\\nThe vowel // is typically represented by ?, and its presence may be an indicator of emphasis spread in the same syllable. For example, ?? (used in the construction 'man of [trade]') is transcribed ?s?? in medieval Coptic-Arabic papyri. In some phonetic environments, /o/ is a more open [?], and /a/ is a more forward [?]. The vowel /?/ is always unstressed and can be reduced to zero as in earlier Egyptian scripts, which did not indicate unstressed and most stressed vowels.\\r\\nCoptic also has three to four diphthongs (mainly [aj], [?j] and [aw]), but they may be interpreted as series of vowels and glides. In some dialects, they are monophthongized.\\r\\nAs with the vowels, there are differences of opinion over the correct interpretation of the Coptic consonant letters, particular the letters ? and ?. ? is transcribed as ?j? in many older Coptic sources and ? as //[12] or /t?/. Lambdin (1983) notes that the current conventional pronunciations are different from the probable ancient pronunciations: ? was probably pronounced [t?] and ? was probably pronounced [k?]. Reintges (2004, p.?22) suggests that ? was pronounced [t?].\\r\\nThe following chart shows the consonants that are represented in Sahidic Coptic orthography. Consonants that are rare or found primarily in Greek loanwords are shown in parentheses:\\r\\nBohairic Coptic has an additional consonant, /x/, spelled ?. It is possible that in the ancient pronunciation of Coptic that there were additional consonants not spelled in the writing system, such as /?/.\\r\\nEarlier phases of Egyptian may have contrasted voiceless and voiced bilabial plosives, but the distinction seems to have been lost. Late Egyptian, Demotic and Coptic all interchangeably use their respective graphemes to indicate either sound; for example, Coptic for 'iron' appears alternately as ??????, ?????? and ??????. That probably reflects dialect variation. Both letters were interchanged with ? and ? to indicate /f/, and ? was also used in many texts to indicate the bilabial approximant /w/. Coptologists believe that Coptic ? was articulated as a voiced bilabial fricative []. In the present-day Coptic Church services, this letter is realized as /v/, but it is almost certainly a result of the pronunciation reforms instituted in the 19th century.\\r\\nWhereas Old Egyptian contrasts /s/ and /z/, the two sounds appear to be in free variation in Coptic, as they were since the Middle Egyptian period. However, they are contrasted only in Greek loans; for example, native Coptic ?????? (anzؐb?) and ?????? (ansؐb?) 'school' are homophonous. Other consonants that sometimes appear to be either in free variation or to have different distributions across dialects are [t] and [d], [r] and [l] (especially in the Fayyumic dialect, a feature of earlier Egyptian) and [k] and [], with the voiceless stop consonants being more common in Coptic words and the voiced ones in Greek borrowings. Apart from the liquid consonants, this pattern may indicate a sound change in Later Egyptian, leading to a neutralization of voiced alveolar and velar plosives. When the voiced plosives are realized, it is usually the result of consonant voicing in proximity to /n/.\\r\\nOld Coptic texts graphically express the Egyptian pharyngeals in a variety of ways. For example, the Old Coptic grapheme ? was occasionally used to convey a voiceless pharyngeal fricative. In literary Coptic, the two sounds are not indicated by separate letters, suggesting loss of phonemic status. Instead, the adapted demotic grapheme ?, which normally stands for /h/, is used to express either sound. In unstressed initial syllables and stressed final syllables, the voiced pharyngeal fricative is sometimes conveyed by ? as in ???? (??ai) 'to multiply'. Similarly, different methods are employed to graphically express the glottal stop: with ? word-initially, with ? word-finally in monosyllabic words in northern dialects and ? in monosyllabic words in Akhmimic and Assiutic, by reduplication of a vowel's grapheme but mostly as [?].\\r\\nCoptic is agglutinative with subjectÿverbÿobject word order but can be verbÿsubjectÿobject with the correct preposition in front of the subject. Number, gender, tense, and mood are indicated by prefixes that come from Late Egyptian. The earlier phases of Egyptian did this through suffixation. Some vestiges of the suffix inflection survive in Coptic, mainly to indicate inalienable possession and in some verbs. Compare the Middle Egyptian form *satpafa 'he chooses' (written stp.f in hieroglyphs) to Coptic (Sahidic) f.sotp ?????? 'he chooses'.\\r\\nAll Coptic nouns carry grammatical gender, either masculine or feminine, usually marked through a prefixed definite article as in the Romance languages. Masculine nouns are marked with the article /p?, pe?/ and feminine nouns with the article /t?, te?/[15] in the Sahidic dialect and /pi, ?p/ and /ti, ?t/ in the Bohairic dialect.\\r\\nBohairic: ?????? /pi-ro?mi/ - 'the man' / ???? /ti-d?ig/ - 'the hand'\\r\\nSahidic: ?????? /p?-ro?me/ - 'the man' / ????? /t?-ci?/ - 'the hand'\\r\\nThe definite and indefinite articles also indicate number; however, only definite articles mark gender. Coptic has a number of broken plurals, a vestige of Older Egyptian, but in the majority of cases, the article marks number. Generally, nouns inflected for plurality end in /w?/, but there are some irregularities. The dual was another feature of earlier Egyptian that survives in Coptic in only few words, such as ???? (snau) 'two'.\\r\\nWords of Greek origin keep their original grammatical gender, except for neuter nouns, which become masculine in Coptic.\\r\\nCoptic pronouns are of two kinds, dependent and independent. Independent pronouns are used when the pronoun is acting as the subject of a sentence, as the object of a verb, or with a preposition. Dependent pronouns are a series of prefixes and suffixes that can attach to verbs and other nouns. Coptic verbs can therefore be said to inflect for the person, number and gender of the subject and the object: a pronominal prefix marks the subject, and a pronominal suffix marks the object, e.g. \\"I I'have'it the ball.\\" When (as in this case) the subject is a pronoun, it normally isn't also expressed independently, unless for emphasis.\\r\\nAs in other Afroasiatic languages, gender of pronouns differ only in the second and third person singular. The following table shows the pronouns of the Sahidian dialect:\\r\\nMost Coptic adjectives are actually nouns that have the attributive particle n to make them adjectival. In all stages of Egyptian, this morpheme is also used to express the genitive; for example, the Bohairic word for 'Egyptian', ????????? /remenk?e?mi/, is a combination of the nominal prefix rem- (the reduced form of ???? rmi 'man'), followed by the genitive morpheme ?n ('of') and finally the word for Egypt, khmi.\\r\\nCoptic, like Ancient Egyptian and Semitic languages, has root-and-pattern or templatic morphology, and the basic meaning of a verb is contained in a root and various derived forms of root are obtained by varying the vowel pattern. For example, the root for 'build' is kt. It has four derived forms: k?t (the absolute state grade); ket- (the nominal state grade), kot= (the pronominal state grade), and k?t (the stative grade). (The nominal state grade is also called the construct state in some grammars of Coptic.)\\r\\nThe absolute, nominal, and pronominal state grades are used in different syntactic contexts. The absolute state grade of a transitive verb is used before a direct object with the accusative preposition /?n, ?m/, and the nominal state grade is used before a direct object with no case-marking. The pronominal state grade is used before a pronominal direct object enclitic. In addition, many verbs also have a neutral state grade, used to express a state resulting from the action of the verb. Compare the following forms:[16]\\r\\nAbsolute state grade\\r\\n??????\\r\\na-i-d?imi\\r\\nPFV-1SG-find.ABS\\r\\n???????\\r\\n?m-p-a-jo?t\\r\\nPREP-DEF:MASC:SG-1SG-father\\r\\n?????? ???????\\r\\na-i-d?imi ?m-p-a-jo?t\\r\\nPFV-1SG-find.ABS PREP-DEF:MASC:SG-1SG-father\\r\\n'I found my father.'\\r\\nNominal state grade\\r\\n?????\\r\\na-i-d?em\\r\\nPFV-1SG-find.NOM\\r\\n???????\\r\\n?m-p-a-jo?t[dubious ÿ discuss]\\r\\nDEF:MASC:SG-1SG-father\\r\\n????? ???????\\r\\na-i-d?em ?m-p-a-jo?t[dubious ÿ discuss]\\r\\nPFV-1SG-find.NOM DEF:MASC:SG-1SG-father\\r\\n'I found my father.'\\r\\nPronominal state grade\\r\\n???????\\r\\na-i-k??nt=f\\r\\nPFV-1SG-find.PRONOM=3MSG\\r\\n???????\\r\\na-i-k??nt=f\\r\\nPFV-1SG-find.PRONOM=3MSG\\r\\n'I found him.'\\r\\nFor most transitive verbs, both absolute and nominal state grade verbs are available for non-pronominal objects. However, there is one important restriction, known as Jernstedt's rule (or the Stern-Jernstedt rule) (Jernstedt 1927): present-tense sentences cannot be used in the nominal state grade. Thus sentences in the present tense always show a pattern like the first example above (absolute state), never the second pattern (nominal state).\\r\\nIn general, the four grades of Coptic verb are not predictable from the root, and are listed in the lexicon for each verb. The following chart shows some typical patterns of correspondence:\\r\\nIt is hazardous to make firm generalizations about the relationships between these grade forms, but the nominal state is usually shorter than the corresponding absolute and neutral forms. Absolute and neutral state forms are usually bisyllabic or contain a long vowel; the corresponding nominal state forms are monosyllabic or have short vowels.\\r\\nCoptic has a very large number of distinct tense/aspect/mood categories, expressed by particles which are either before the verb or before the subject. The future I /na/ is a preverbal particle and follows the subject:[17]\\r\\n???????\\r\\nP?-t?oeis\\r\\nDEF:MASC:SG-lord\\r\\n???????\\r\\nna-krine\\r\\nFUT-judge\\r\\n????????\\r\\n?n-n?-Laos\\r\\nPREP-DEF:PL-people\\r\\n??????? ??????? ????????\\r\\nP?-t?oeis na-krine ?n-n?-Laos\\r\\nDEF:MASC:SG-lord FUT-judge PREP-DEF:PL-people\\r\\n'The lord will judge the nations.'\\r\\nIn contrast, the perfective /a/ is a pre-subject particle:\\r\\n?\\r\\nA\\r\\nPFV\\r\\n???????\\r\\nte-f-so?ne\\r\\nDEF:F:SG-3MSG-sister\\r\\n??\\r\\nde\\r\\npart\\r\\n??\\r\\nol\\r\\ncarry.ABS\\r\\n????????\\r\\n?n-ne-f-ke?s\\r\\nPREP-DEF:PL-3MSG-bone\\r\\n? ??????? ?? ?? ????????\\r\\nA te-f-so?ne de ol ?n-ne-f-ke?s\\r\\nPFV DEF:F:SG-3MSG-sister part carry.ABS PREP-DEF:PL-3MSG-bone\\r\\n'His sister carried his bones.'\\r\\nThere is some variation in the labels for the tense/aspect/mood categories. The chart below shows the labels from Reintges (2004), Lambdin (1983), Plumley (1948). (Where they agree, only one label is shown.) Each form lists the morphology found with a nonpronominal subject and a third person singular masculine pronominal subject('he'):\\r\\nAn approximate range of use for most of the tense/aspect/mood categories is shown in the following table:\\r\\nAn unusual feature of Coptic is the extensive use of a set of \\"second tenses\\", which are required in certain syntactic contexts. \\"Second tenses\\" are also called \\"relative tenses\\" in some work.[3]\\r\\nCoptic has prepositions, rather than postpositions:\\r\\nhi\\r\\non\\r\\np-t?oi\\r\\nDEF:M:SG-ship\\r\\nhi p-t?oi\\r\\non DEF:M:SG-ship\\r\\n'on the ship'\\r\\nPronominal objects of prepositions are indicated with enclitic pronouns:\\r\\nMany prepositions have different forms before the enclitic pronouns.[18] Compare\\r\\nCoptic typically shows subjectÿverbÿobject (SVO) word order, as in the following examples:[19]\\r\\n?\\r\\nA\\r\\nPFV\\r\\n?????????\\r\\nt?-k?amaule\\r\\nDEF:F:SG-camel\\r\\n????\\r\\nmise\\r\\ndeliver.ABS\\r\\n????????\\r\\n?n-u-?e?re\\r\\nPREP-INDEF:SG-girl\\r\\n??????\\r\\n?n-shime\\r\\nlink-woman\\r\\n? ????????? ???? ???????? ??????\\r\\nA t?-k?amaule mise ?n-u-?e?re ?n-shime\\r\\nPFV DEF:F:SG-camel deliver.ABS PREP-INDEF:SG-girl link-woman\\r\\n'The she-camel delivered a daughter.'\\r\\n???????\\r\\nP?-t?oeis\\r\\nDEF:M:SG-lord\\r\\n???????\\r\\nna-krine\\r\\nFUT-judge\\r\\n????????\\r\\n?n-n?-Laos\\r\\nPREP-DEF:PL-people\\r\\n??????? ??????? ????????\\r\\nP?-t?oeis na-krine ?n-n?-Laos\\r\\nDEF:M:SG-lord FUT-judge PREP-DEF:PL-people\\r\\n'The Lord will judge the people.'\\r\\n??????\\r\\nA-i-k?ine\\r\\nPFV-1sg-find.ABS\\r\\n????????\\r\\n?m-p-a-eio?t\\r\\nPREP-DEF:MASC:SG-1SG-father\\r\\n?????? ????????\\r\\nA-i-k?ine ?m-p-a-eio?t\\r\\nPFV-1sg-find.ABS PREP-DEF:MASC:SG-1SG-father\\r\\n'I found my father.'\\r\\nThe verbs in these sentences are in the absolute state grade,[20] which requires that its direct object be introduced with the preposition /?n, ?m/. This preposition functions like accusative case.\\r\\nThere is also an alternative nominal state grade of the verb in which the direct object of the verb follows with no preposition:\\r\\n??????\\r\\na-i-k??n\\r\\nPFV-1SG-find.NOM\\r\\n??????\\r\\np-a-eio?t\\r\\nDEF:M:SG-1SG-father\\r\\n?????? ??????\\r\\na-i-k??n p-a-eio?t\\r\\nPFV-1SG-find.NOM DEF:M:SG-1SG-father\\r\\n'I found my father.'\\r\\nThere is little written evidence of dialectal differences in the pre-Coptic phases of the Egyptian language due to the centralized nature of the political and cultural institutions of ancient Egyptian society. However, literary Old and Middle (Classical) Egyptian represent the spoken dialect of Lower Egypt around the city of Memphis, the capital of Egypt in the Old Kingdom. Later Egyptian is more representative of the dialects spoken in Upper Egypt, especially around the area of Thebes as it became the cultural and religious center of the New Kingdom.\\r\\nCoptic more obviously displays a number of regional dialects that were in use from the coast of the Mediterranean Sea in northern Egypt, south into Nubia, and in the western oases. However, while many of these dialects reflect actual regional linguistic (namely phonological and some lexical) variation, they mostly reflect localized orthographic traditions with very little grammatical differences.\\r\\nSahidic (also known as Thebaic) is the dialect in which most known Coptic texts are written, and was the leading dialect in the pre-Islamic period. It is thought to have originally been a regional dialect from the area around Hermopolis (Coptic ???????? Shmounein). Around 300 it began to be written in literary form, including translations of major portions of the Bible (see Coptic versions of the Bible). By the 6th century, a standardized spelling had been attained throughout Egypt. Almost all native authors wrote in this dialect of Coptic. Sahidic was, beginning in the 9th century, challenged by Bohairic, but is attested as late as the 14th century.\\r\\nWhile texts in other Coptic dialects are primarily translations of Greek literary and religious texts, Sahidic is the only dialect with a considerable body of original literature and non-literary texts. Because Sahidic shares most of its features with other dialects of Coptic with few peculiarities specific to itself, and has an extensive corpus of known texts, it is generally the dialect studied by learners of Coptic, particularly by scholars outside of the Coptic Church.\\r\\nAkhmimic was the dialect of the area around the town of Akhmim (Greek Panopolis). It flourished during the fourth and fifth centuries, after which no writings are attested. Akhmimic is phonologically the most archaic of the Coptic dialects. One characteristic feature is the retention of the phoneme /x/, which is realized as /?/ in most other dialects. Similarly, it uses an exceptionally conservative writing system strikingly similar to Old Coptic.\\r\\nLycopolitan (also known as Subakhmimic and Assiutic) is a dialect closely related to Akhmimic in terms of when and where it was attested, but manuscripts written in Lycopolitan tend to be from the area of Asyut. The main differences between the two dialects seem to be graphic in nature. The Lycopolitan variety was used extensively for translations of Gnostic and Manichaean works, including the texts of the Nag Hammadi library.\\r\\nThe Bohairic (also known as Memphitic) dialect originated in the western Nile Delta. The earliest Bohairic manuscripts date to the 4th century, but most texts come from the 9th century and later; this may be due to poor preservation conditions for texts in the humid regions of northern Egypt. It shows several conservative features in lexicon and phonology not found in other dialects. Bohairic is the dialect used today as the liturgical language of the Coptic Orthodox Church, replacing Sahidic some time in the eleventh century. In contemporary liturgical use, there are two traditions of pronunciation, arising from successive reforms in the 19th and 20th centuries (see Coptic pronunciation reform). Modern revitalization efforts are based on this dialect.\\r\\nFayyumic (also written as Faiyumic; in older works it is often called Bashmuric) was spoken primarily in the Faiyum west of the Nile Valley. It is attested from the 3rd to the 10th centuries. It is most notable for writing ? (which corresponds to /l/), where other dialects generally use ? /r/ (probably corresponding to a flap [?]). In earlier stages of Egyptian, the liquids were not distinguished in writing until the New Kingdom, when Late Egyptian became the administrative language. Late Egyptian orthography utilized a grapheme that combined the graphemes for /r/ and /n/ in order to express /l/. Demotic for its part indicated /l/ using a diacritic variety of /r/.\\r\\nOxyrhynchite (also known as Mesokemic or [confusingly] Middle Egyptian) is the dialect of Oxyrhynchus and surrounding areas. It shows similarities with Fayyumic and is attested in manuscripts from the fourth and fifth centuries.","input":"What is the origin of the coptic language?"},{"output":"Muhammad of Ghor","context":"\\r\\n\\r\\nThe Delhi Sultanate (Persian:???? ?????, Urdu: ???? ??????) was a Muslim sultanate based mostly in Delhi that stretched over large parts of the Indian subcontinent for 320 years (1206ÿ1526).[5][6] Five dynasties ruled over the Delhi Sultanate sequentially: the Mamluk dynasty (1206ÿ90), the Khalji dynasty (1290ÿ1320), the Tughlaq dynasty (1320ÿ1414),[7] the Sayyid dynasty (1414ÿ51), and the Lodi dynasty (1451ÿ1526). The sultanate is noted for being one of the few states to repel an attack by the Mongol Empire,[8] and enthroned one of the few female rulers in Islamic history, Razia Sultana, who reigned from 1236 to 1240.[9]\\r\\n\\r\\nQutb al-Din Aibak, a former Turkic Mamluk slave of Muhammad Ghori, was the first sultan of Delhi, and his Mamluk dynasty conquered large areas of northern India. Afterwards, the Khalji dynasty was also able to conquer most of central India, but both failed to conquer the whole of the Indian subcontinent. The sultanate reached the peak of its geographical reach during the Tughlaq dynasty, occupying most of the Indian subcontinent.[10] This was followed by decline due to Hindu reconquests, states such as the Vijayanagara Empire asserting independence, and new Muslim sultanates such as the Bengal Sultanate breaking off.[11][12]\\r\\n\\r\\nDuring and in the Delhi Sultanate, there was a synthesis of Indian civilization with that of Islamic civilization, and the further integration of the Indian subcontinent with a growing world system and wider international networks spanning large parts of Afro-Eurasia, which had a significant impact on Indian culture and society, as well as the wider world.[13] The time of their rule included the earliest forms of Indo-Islamic architecture,[14][15] increased growth rates in India's population and economy,[16] and the emergence of the Hindi-Urdu language.[17] The Delhi Sultanate was also responsible for repelling the Mongol Empire's potentially devastating invasions of India in the 13th and 14th centuries.[18] However, the Delhi Sultanate also caused large scale destruction and desecration of temples in the Indian subcontinent.[19] In 1526, the Sultanate was conquered and succeeded by the Mughal Empire.\\r\\n\\r\\nThe context behind the rise of the Delhi Sultanate in India was part of a wider trend affecting much of the Asian continent, including the whole of southern and western Asia: the influx of nomadic Turkic peoples from the Central Asian steppes. This can be traced back to the 9th century, when the Islamic Caliphate began fragmenting in the Middle East, where Muslim rulers in rival states began enslaving non-Muslim nomadic Turks from the Central Asian steppes, and raising many of them to become loyal military slaves called Mamluks. Soon, Turks were migrating to Muslim lands and becoming Islamicized. Many of the Turkic Mamluk slaves eventually rose up to become rulers, and conquered large parts of the Muslim world, establishing Mamluk Sultanates from Egypt to Afghanistan, before turning their attention to the Indian subcontinent.[18]\\r\\n\\r\\nIt is also part of a longer trend predating the spread of Islam. Like other settled, agrarian societies in history, those in the Indian subcontinent have been attacked by nomadic tribes throughout its long history. In evaluating the impact of Islam on the subcontinent, one must note that the northwestern subcontinent was a frequent target of tribes raiding from Central Asia in the pre-Islamic era. In that sense, the Muslim intrusions and later Muslim invasions were not dissimilar to those of the earlier invasions during the 1st millennium.[20]\\r\\n\\r\\nBy 962 AD, Hindu and Buddhist kingdoms in South Asia were under a wave of raids from Muslim armies from Central Asia.[21] Among them was Mahmud of Ghazni, the son of a Turkic Mamluk military slave,[22] who raided and plundered kingdoms in north India from east of the Indus river to west of Yamuna river seventeen times between 997 and 1030.[23] Mahmud of Ghazni raided the treasuries but retracted each time, only extending Islamic rule into western Punjab.[24][25]\\r\\n\\r\\nThe wave of raids on north Indian and western Indian kingdoms by Muslim warlords continued after Mahmud of Ghazni.[26] The raids did not establish or extend permanent boundaries of their Islamic kingdoms. The Ghurid sultan Mu'izz ad-Din Muhammad Ghori, commonly known as Muhammad of Ghor, began a systematic war of expansion into north India in 1173.[27] He sought to carve out a principality for himself by expanding the Islamic world.[23][28] Muhammad of Ghor sought a Sunni Islamic kingdom of his own extending east of the Indus river, and he thus laid the foundation for the Muslim kingdom called the Delhi Sultanate.[23] Some historians chronicle the Delhi Sultanate from 1192 due to the presence and geographical claims of Muhammad Ghori in South Asia by that time.[29]\\r\\n\\r\\nGhori was assassinated in 1206, by Ism?ؐlؐ Shia Muslims in some accounts or by Hindu Khokhars in others.[30] After the assassination, one of Ghori's slaves (or mamluks, Arabic: ?????), the Turkic Qutb al-Din Aibak, assumed power, becoming the first Sultan of Delhi.[23]\\r\\n\\r\\nQutb al-Din Aibak, a former slave of Mu'izz ad-Din Muhammad Ghori (known more commonly as Muhammad of Ghor), was the first ruler of the Delhi Sultanate. Aibak was of Cuman-Kipchak (Turkic) origin, and due to his lineage, his dynasty is known as the Mamluk (Slave) dynasty (not to be confused with the Mamluk dynasty of Iraq or the Mamluk dynasty of Egypt).[31] Aibak reigned as the Sultan of Delhi for four years, from 1206 to 1210.\\r\\n\\r\\nAfter Aibak died, Aram Shah assumed power in 1210, but he was assassinated in 1211 by Shams ud-Din Iltutmish.[32] Iltutmish's power was precarious, and a number of Muslim amirs (nobles) challenged his authority as they had been supporters of Qutb al-Din Aibak. After a series of conquests and brutal executions of opposition, Iltutmish consolidated his power.[33] His rule was challenged a number of times, such as by Qubacha, and this led to a series of wars.[34] Iltumish conquered Multan and Bengal from contesting Muslim rulers, as well as Ranthambore and Siwalik from the Hindu rulers. He also attacked, defeated, and executed Taj al-Din Yildiz, who asserted his rights as heir to Mu'izz ad-Din Muhammad Ghori.[35] Iltutmish's rule lasted till 1236. Following his death, the Delhi Sultanate saw a succession of weak rulers, disputing Muslim nobility, assassinations, and short-lived tenures. Power shifted from Rukn ud-Din Firuz to Razia Sultana and others, until Ghiyas ud-Din Balban came to power and ruled from 1266 to 1287.[34][35] He was succeeded by 17-year-old Muiz ud-Din Qaiqabad, who appointed Jalal ud-Din Firuz Khalji as the commander of the army. Khalji assassinated Qaiqabad and assumed power, thus ending the Mamluk dynasty and starting the Khalji dynasty.\\r\\n\\r\\nQutb al-Din Aibak initiated the construction of the Qutub Minar[36] and the Quwwat-ul-Islam (Might of Islam) Mosque, now a UNESCO world heritage site.[37] It was built from the remains of twenty seven demolished Hindu and Jain temples. The Qutub Minar Complex or Qutb Complex was expanded by Iltutmish, and later by Ala ud-Din Khalji (the second ruler of the Khalji dynasty) in the early 14th century.[37][38] During the Mamluk dynasty, many nobles from Afghanistan and Persia migrated and settled in India, as West Asia came under Mongol siege.[39]\\r\\n\\r\\nThe Khalji dynasty was of Turko-Afghan heritage.[40][41][42][43] They were originally of Turkic origin.[44] They had long been settled in present-day Afghanistan before proceeding to Delhi in India. The name \\"Khalji\\" refers to an Afghan village or town known as Qalat-e Khalji (Fort of Ghilji).[45] Sometimes they were treated by others as ethnic Afghans due to their intermarraiges with local Afghans, adoption of Afghan habits and customs.[46][47] As a result of this, the dynasty is sometimes referred to as Turko-Afghan.[41][42][43] The dynasty later also had Indian ancestry, through Jhatyapali (daughter of Ramachandra of Devagiri), wife of Alauddin Khalji and mother of Shihabuddin Omar.[48]\\r\\n\\r\\nThe first ruler of the Khalji dynasty was Jalal ud-Din Firuz Khalji. Firuz Khalji had already gathered enough support among the Afghans for taking over the crown. [49] He came to power in 1290 after killing the last ruler of the Mamluk dynasty, Muiz ud-Din Qaiqabad, with the support of Afghan and Turkic nobles. He was around 70 years old at the time of his ascension, and was known as a mild-mannered, humble and kind monarch to the general public.[50][51] Jalal ud-Din Firuz was of Turko Afghan origin,[52][53][54] and ruled for 6 years before he was murdered in 1296 by his nephew and son-in-law Juna Muhammad Khalji,[55] who later came to be known as Ala ud-Din Khalji.\\r\\n\\r\\nAla ud-Din began his military career as governor of Kara province, from where he led two raids on Malwa (1292) and Devagiri (1294) for plunder and loot. His military campaigning returned to these lands as well other south Indian kingdoms after he assumed power. He conquered Gujarat, Ranthambore, Chittor, and Malwa.[56] However, these victories were cut short because of Mongol attacks and plunder raids from the northwest. The Mongols withdrew after plundering and stopped raiding northwest parts of the Delhi Sultanate.[57]\\r\\n\\r\\nAfter the Mongols withdrew, Ala ud-Din Khalji continued expanding the Delhi Sultanate into southern India with the help of generals such as Malik Kafur and Khusro Khan. They collected lots of war booty (anwatan) from those they defeated.[58] His commanders collected war spoils and paid ghanima (Arabic: ??????????, a tax on spoils of war), which helped strengthen the Khalji rule. Among the spoils was the Warangal loot that included the famous Koh-i-noor diamond.[59]\\r\\n\\r\\nAla ud-Din Khalji changed tax policies, raising agriculture taxes from 20% to 50% (payable in grain and agricultural produce), eliminating payments and commissions on taxes collected by local chiefs, banned socialization among his officials as well as inter-marriage between noble families to help prevent any opposition forming against him, and he cut salaries of officials, poets, and scholars.[55] These tax policies and spending controls strengthened his treasury to pay the keep of his growing army; he also introduced price controls on all agriculture produce and goods in the kingdom, as well as controls on where, how, and by whom these goods could be sold. Markets called \\"shahana-i-mandi\\" were created.[60] Muslim merchants were granted exclusive permits and monopoly in these \\"mandis\\" to buy and resell at official prices. No one other than these merchants could buy from farmers or sell in cities. Those found violating these \\"mandi\\" rules were severely punished, often by mutilation. Taxes collected in the form of grain were stored in the kingdom's storage. During famines that followed, these granaries ensured sufficient food for the army.[55]\\r\\n\\r\\nHistorians note Ala ud-Din Khalji as being a tyrant. Anyone Ala ud-Din suspected of being a threat to this power was killed along with the women and children of that family. In 1298, between 15,000 and 30,000 people near Delhi, who had recently converted to Islam, were slaughtered in a single day, due to fears of an uprising.[61] He is also known for his cruelty against kingdoms he defeated in battle.\\r\\n\\r\\nAfter Ala ud-Din's death in 1316, his eunuch general Malik Kafur, who was born in a Hindu family in India and had converted to Islam, tried to assume power. He lacked the support of Persian and Turkic nobility and was subsequently killed.[55] The last Khalji ruler was Ala ud-Din Khalji's 18-year-old son Qutb ud-Din Mubarak Shah Khalji, who ruled for four years before he was killed by Khusro Khan, another of Ala ud-Din's generals. Khusro Khan's reign lasted only a few months, when Ghazi Malik, later to be called Ghiyath al-Din Tughlaq, killed him and assumed power in 1320, thus ending the Khalji dynasty and starting the Tughlaq dynasty.[39][61]\\r\\n\\r\\nThe Tughlaq dynasty lasted from 1320 to nearly the end of the 14th century. The first ruler Ghazi Malik rechristened himself as Ghiyath al-Din Tughlaq and is also referred to in scholarly works as Tughlak Shah. He was of Turko-Indian origins; his father was a Turkic slave and his mother was a Hindu.[1] Ghiyath al-Din ruled for five years and built a town near Delhi named Tughlaqabad.[citation needed] According to some historians such as Vincent Smith,[62] he was killed by his son Juna Khan, who then assumed power in 1325. Juna Khan rechristened himself as Muhammad bin Tughlaq and ruled for 26 years.[63] During his rule, Delhi Sultanate reached its peak in terms of geographical reach, covering most of the Indian subcontinent.[10]\\r\\n\\r\\nMuhammad bin Tughlaq was an intellectual, with extensive knowledge of the Quran, Fiqh, poetry and other fields. He was also deeply suspicious of his kinsmen and wazirs (ministers), extremely severe with his opponents, and took decisions that caused economic upheaval. For example, he ordered minting of coins from base metals with face value of silver coins - a decision that failed because ordinary people minted counterfeit coins from base metal they had in their houses and used them to pay taxes and jizya.[10][62]\\r\\n\\r\\nOn another occasion, after becoming upset by some accounts, or to run the Sultanate from the center of India by other accounts, Muhammad bin Tughlaq ordered the transfer of his capital from Delhi to Devagiri in modern-day Maharashtra (renaming it to Daulatabad), by forcing the mass migration of Delhi's population. Those who refused were killed. One blind person who failed to move to Daulatabad was dragged for the entire journey of 40 days - the man died, his body fell apart, and only his tied leg reached Daulatabad.[62] The capital move failed because Daulatabad was arid and did not have enough drinking water to support the new capital. The capital then returned to Delhi. Nevertheless, Muhammad bin Tughlaq's orders affected history as a large number of Delhi Muslims who came to the Deccan area did not return to Delhi to live near Muhammad bin Tughlaq. This influx of the then-Delhi residents into the Deccan region led to a growth of Muslim population in central and southern India.[10] Muhammad bin Tughlaq's adventures in the Deccan region also marked campaigns of destruction and desecration of Hindu and Jain temples, for example the Swayambhu Shiva Temple and the Thousand Pillar Temple.[64]\\r\\n\\r\\nRevolts against Muhammad bin Tughlaq began in 1327, continued over his reign, and over time the geographical reach of the Sultanate shrunk. The Vijayanagara Empire originated in southern India as a direct response to attacks from the Delhi Sultanate.,[65] and liberated south India from the Delhi Sultanate's rule.[66] In 1337, Muhammad bin Tughlaq ordered an attack on China,[citation needed] sending part of his forces over the Himalayas. Few survived the journey, and they were executed upon their return for failing.[62] During his reign, state revenues collapsed from his policies such as the base metal coins from 1329-1332. To cover state expenses, he sharply raised taxes. Those who failed to pay taxes were hunted and executed. Famines, widespread poverty, and rebellion grew across the kingdom. In 1338 his own nephew rebelled in Malwa, whom he attacked, caught, and flayed alive.[citation needed] By 1339, the eastern regions under local Muslim governors and southern parts led by Hindu kings had revolted and declared independence from the Delhi Sultanate. Muhammad bin Tughlaq did not have the resources or support to respond to the shrinking kingdom.[67] The historian Walford chronicled Delhi and most of India faced severe famines during Muhammad bin Tughlaq's rule in the years after the base metal coin experiment.[68][69] By 1347, the Bahmani Sultanate had become an independent and competing Muslim kingdom in Deccan region of South Asia.[21]\\r\\n\\r\\nMuhammad bin Tughlaq died in 1351 while trying to chase and punish people in Gujarat who were rebelling against the Delhi Sultanate.[67] He was succeeded by Firuz Shah Tughlaq (1351ÿ1388), who tried to regain the old kingdom boundary by waging a war with Bengal for 11 months in 1359. However, Bengal did not fall. Firuz Shah ruled for 37 years. His reign attempted to stabilize the food supply and reduce famines by commissioning an irrigation canal from the Yamuna river. An educated sultan, Firuz Shah left a memoir.[73] In it he wrote that he banned the practice of torture, such as amputations, tearing out of eyes, sawing people alive, crushing people's bones as punishment, pouring molten lead into throats, setting people on fire, driving nails into hands and feet, among others.[74] He also wrote that he did not tolerate attempts by Rafawiz Shia Muslim and Mahdi sects from proselytizing people into their faith, nor did he tolerate Hindus who tried to rebuild temples that his armies had destroyed.[75] As punishment for proselytizing, Firuz Shah put many Shias, Mahdi, and Hindus to death (siyasat). Firuz Shah Tughlaq also lists his accomplishments to include converting Hindus to Sunni Islam by announcing an exemption from taxes and jizya for those who convert, and by lavishing new converts with presents and honours. Simultaneously, he raised taxes and jizya, assessing it at three levels, and stopping the practice of his predecessors who had historically exempted all Hindu Brahmins from the jizya.[74][76]  He also vastly expanded the number of slaves in his service and those of Muslim nobles. The reign of Firuz Shah Tughlaq was marked by reduction in extreme forms of torture, eliminating favours to select parts of society, but also increased intolerance and persecution of targeted groups.[74]\\r\\n\\r\\nThe death of Firuz Shah Tughlaq created anarchy and disintegration of the kingdom. The last rulers of this dynasty both called themselves Sultan from 1394 to 1397: Nasir ud-Din Mahmud Shah Tughlaq, the grandson of Firuz Shah Tughlaq who ruled from Delhi, and Nasir ud-Din Nusrat Shah Tughlaq, another relative of Firuz Shah Tughlaq who ruled from Firozabad, which was a few miles from Delhi.[77] The battle between the two relatives continued till Timur's invasion in 1398. Timur, also known as Tamerlane in Western scholarly literature, was the Turkic ruler of the Timurid Empire. He became aware of the weakness and quarreling of the rulers of the Delhi Sultanate, so he marched with his army to Delhi, plundering and killing all the way.[78][79] Estimates for the massacre by Timur in Dehli range from 100,000 to 200,000 people.[80][81] Timur had no intention of staying in or ruling India. He looted the lands he crossed, then plundered and burnt Delhi. Over five days, Timur and his army raged a massacre.[citation needed] Then he collected and carried the wealth, captured women and slaves (particularly skilled artisans), and returned to Samarkand. The people and lands within the Delhi Sultanate were left in a state of anarchy, chaos, and pestilence.[77] Nasir ud-Din Mahmud Shah Tughlaq, who had fled to Gujarat during Timur's invasion, returned and nominally ruled as the last ruler of Tughlaq dynasty, as a puppet of various factions at the court.[82][citation needed]\\r\\n\\r\\nThe Sayyid dynasty was a Turkic dynasty[83] that ruled the Delhi Sultanate from 1415 to 1451.[21] The Timurid invasion and plunder had left the Delhi Sultanate in shambles, and little is known about the rule by the Sayyid dynasty. Annemarie Schimmel notes the first ruler of the dynasty as Khizr Khan, who assumed power by claiming to represent Timur. His authority was questioned even by those near Delhi. His successor was Mubarak Khan, who rechristened himself as Mubarak Shah and tried to regain lost territories in Punjab, unsuccessfully.[82]","input":""}]`),M={name:"App",components:{PoemCard:C},data(){return{visibleCount:20,poemsData:x}},computed:{visiblePoems(){return this.poemsData.slice(0,this.visibleCount)},hasMorePoems(){return this.visibleCount<this.poemsData.length}},methods:{loadMore(){this.visibleCount+=20}}},I={class:"card-container"};function P(h,t,n,c,u,o){const m=p("PoemCard");return a(),i(l,null,[t[1]||(t[1]=e("section",null,[e("div",{class:"top-Banner"},[e("div",{class:"top-Banner-Title"},[e("div",{class:"top-Banner-Title-Text"},"🎉Q&A Life🥳")])])],-1)),e("section",null,[e("div",I,[(a(!0),i(l,null,g(o.visiblePoems,(r,f)=>(a(),y(m,{key:f,poem:r},null,8,["poem"]))),128))]),o.hasMorePoems?(a(),i("button",{key:0,class:"load-more-button",onClick:t[0]||(t[0]=(...r)=>o.loadMore&&o.loadMore(...r))},"See more")):w("",!0)])],64)}const B=d(M,[["render",P]]),G=JSON.parse('{"title":"","description":"","frontmatter":{"page":true},"headers":[],"relativePath":"qapage/33.md","filePath":"qapage/33.md"}'),F={name:"qapage/33.md"},N=Object.assign(F,{setup(h){return(t,n)=>(a(),i("div",null,[b(B)]))}});export{G as __pageData,N as default};
